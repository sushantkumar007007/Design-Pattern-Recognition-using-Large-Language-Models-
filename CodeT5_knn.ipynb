{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c7b1226-a018-46b3-9e63-a5822828a3e0",
      "metadata": {
        "id": "2c7b1226-a018-46b3-9e63-a5822828a3e0",
        "outputId": "795945fd-9e85-4a2c-d395-91cb0b8caf53"
      },
      "outputs": [
        {
          "ename": "UnicodeDecodeError",
          "evalue": "'utf-8' codec can't decode byte 0xf8 in position 2945: invalid start byte",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [2], line 57\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m java_files:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(java_code_dir, file), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 57\u001b[0m         java_code \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;66;03m# Determine if it's a positive class (\"prototype\") or negative class\u001b[39;00m\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingleton\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m file:\n",
            "File \u001b[0;32m/apps/Arch/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/codecs.py:322\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m--> 322\u001b[0m     (result, consumed) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;66;03m# keep undecoded input until the next call\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m=\u001b[39m data[consumed:]\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xf8 in position 2945: invalid start byte"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"singleton\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Determine if it's a positive class (\"prototype\") or negative class\n",
        "        if \"singleton\" in file:\n",
        "            label = 1\n",
        "        else:\n",
        "            label = 0\n",
        "\n",
        "        true_labels.append(label)\n",
        "\n",
        "        # Get mean embedding for each line and store in program_embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for KNN\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(flattened_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 5  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [true_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(true_labels, predicted_labels)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# Print the KNN results and performance metrics\n",
        "print(\"K-Nearest Neighbors (KNN) Classification Results:\")\n",
        "for i, java_file in enumerate(java_files):\n",
        "    print(f\"File: {java_file}, Predicted Label: {predicted_labels[i]}, True Label: {true_labels[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d5739a3-4d05-4d90-9219-46cca05637c0",
      "metadata": {
        "id": "1d5739a3-4d05-4d90-9219-46cca05637c0"
      },
      "outputs": [],
      "source": [
        "Singleton with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f74f897-94f1-4f91-9be7-697048c7896c",
      "metadata": {
        "id": "1f74f897-94f1-4f91-9be7-697048c7896c",
        "outputId": "96dd4b65-bb22-45e4-f293-b0d17068a0c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors (KNN) Classification Results:\n",
            "File: nons (12).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (50).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (54).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (29).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (25).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (18).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (42).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (27).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (19).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (55).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (34).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (49).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (61).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (68).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (4).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (9).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (7).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (44).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (38).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (14).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (59).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (33).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (3).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (41).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (1).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (30).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (22).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (3).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (53).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (23).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (35).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (17).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (43).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (16).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (20).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (2).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (14).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (48).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (16).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (11).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (63).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (26).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (40).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (66).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (8).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (67).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (21).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (31).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (6).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (6).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (37).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (13).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (21).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (22).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (51).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (47).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (10).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (4).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (15).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (60).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (32).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (46).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (23).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (9).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (58).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (39).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (56).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (62).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (24).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (7).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (45).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (64).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (19).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (65).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (5).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (52).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (28).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (36).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (57).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.78, Recall: 0.56, F1 Score: 0.65\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"singleton\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    try:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding file {file}: {e}\")\n",
        "        continue  # Skip to the next file if decoding fails\n",
        "\n",
        "    # Determine if it's a positive class (\"prototype\") or negative class\n",
        "    if \"singleton\" in file:\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    true_labels.append(label)\n",
        "\n",
        "    # Get mean embedding for each line and store in program_embeddings\n",
        "    program_embedding = get_line_embeddings(java_code)\n",
        "    program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for KNN\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(flattened_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 5  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [true_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# Print the KNN results and performance metrics\n",
        "print(\"K-Nearest Neighbors (KNN) Classification Results:\")\n",
        "for i, java_file in enumerate(java_files):\n",
        "    print(f\"File: {java_file}, Predicted Label: {predicted_labels[i]}, True Label: {true_labels[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac41c6ff-c6e3-4f22-be55-da97b7efcbfc",
      "metadata": {
        "id": "ac41c6ff-c6e3-4f22-be55-da97b7efcbfc"
      },
      "outputs": [],
      "source": [
        "Singleton with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c5c1433-7da2-477b-b50d-9b47c175c611",
      "metadata": {
        "id": "5c5c1433-7da2-477b-b50d-9b47c175c611",
        "outputId": "492cea35-7738-4555-f16e-bf158eb043f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors (KNN) Classification Results:\n",
            "File: nons (12).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (50).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (54).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (29).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (25).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (18).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (42).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (27).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (19).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (55).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (34).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (49).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (61).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (68).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (4).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (9).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (7).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (44).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (38).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (14).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (59).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (33).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (3).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (41).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (1).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (30).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (22).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (3).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (53).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (23).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (35).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (17).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (43).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (16).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (20).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (2).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (14).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (48).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (16).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (11).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (63).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (26).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (40).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (66).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (8).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (67).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (21).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (31).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (6).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (6).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (37).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (13).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (22).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (51).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (47).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (10).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (4).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (15).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (60).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (32).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (46).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (23).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (9).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (58).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (17).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (39).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (56).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (62).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (24).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (7).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (45).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (64).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (19).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (65).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (5).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (52).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (28).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (36).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (57).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.81, Recall: 0.52, F1 Score: 0.63\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"singleton\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    try:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding file {file}: {e}\")\n",
        "        continue  # Skip to the next file if decoding fails\n",
        "\n",
        "    # Determine if it's a positive class (\"prototype\") or negative class\n",
        "    if \"singleton\" in file:\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    true_labels.append(label)\n",
        "\n",
        "    # Get mean embedding for each line and store in program_embeddings\n",
        "    program_embedding = get_line_embeddings(java_code)\n",
        "    program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for KNN\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(flattened_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 3  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [true_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# Print the KNN results and performance metrics\n",
        "print(\"K-Nearest Neighbors (KNN) Classification Results:\")\n",
        "for i, java_file in enumerate(java_files):\n",
        "    print(f\"File: {java_file}, Predicted Label: {predicted_labels[i]}, True Label: {true_labels[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed72060e-d670-423d-a3db-6023d200b790",
      "metadata": {
        "id": "ed72060e-d670-423d-a3db-6023d200b790"
      },
      "outputs": [],
      "source": [
        "Singleton with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c5c5102-06c8-4f4e-9853-a8c3df6f357b",
      "metadata": {
        "id": "6c5c5102-06c8-4f4e-9853-a8c3df6f357b",
        "outputId": "48a2b94e-c6d4-426b-e4fb-988c3855e01a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors (KNN) Classification Results:\n",
            "File: nons (12).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (50).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (54).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (29).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (25).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (18).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (42).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (27).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (19).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (55).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (34).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (49).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (61).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (68).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (4).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (9).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (7).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (44).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (38).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (14).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (59).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (33).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (3).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (41).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (1).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (30).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (22).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (3).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (53).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (23).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (35).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (17).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (43).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (16).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (20).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (2).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (14).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (48).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (16).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (11).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (63).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (26).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (40).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (66).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (8).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (67).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (21).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (31).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (6).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (6).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (37).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (13).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (22).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (51).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (47).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (10).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (4).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (15).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (60).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (32).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (46).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (23).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (9).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (58).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (17).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (39).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (56).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (62).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (24).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (7).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (45).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (64).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (19).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (65).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (5).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (52).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (28).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (36).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (57).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.81, Recall: 0.52, F1 Score: 0.63\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"singleton\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    try:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding file {file}: {e}\")\n",
        "        continue  # Skip to the next file if decoding fails\n",
        "\n",
        "    # Determine if it's a positive class (\"prototype\") or negative class\n",
        "    if \"singleton\" in file:\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    true_labels.append(label)\n",
        "\n",
        "    # Get mean embedding for each line and store in program_embeddings\n",
        "    program_embedding = get_line_embeddings(java_code)\n",
        "    program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for KNN\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(flattened_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 3  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [true_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# Print the KNN results and performance metrics\n",
        "print(\"K-Nearest Neighbors (KNN) Classification Results:\")\n",
        "for i, java_file in enumerate(java_files):\n",
        "    print(f\"File: {java_file}, Predicted Label: {predicted_labels[i]}, True Label: {true_labels[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ced6c38-0db1-4f79-b128-775a46e08eae",
      "metadata": {
        "id": "7ced6c38-0db1-4f79-b128-775a46e08eae"
      },
      "outputs": [],
      "source": [
        "Singleton with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "931ceefc-3852-4ab5-bca2-6918e04b6abb",
      "metadata": {
        "id": "931ceefc-3852-4ab5-bca2-6918e04b6abb",
        "outputId": "5cb90fb5-957e-4768-85dd-bb3c0c870ad5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors (KNN) Classification Results:\n",
            "File: nons (54).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (25).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (18).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (27).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (19).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (55).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (34).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (68).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (14).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (33).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (3).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (30).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (3).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (53).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (23).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (35).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (17).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (16).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (20).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (14).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (16).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (8).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (21).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (6).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (6).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (22).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (47).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (4).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (15).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (60).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (46).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (23).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (24).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (7).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (19).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (65).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (5).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (52).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (28).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.89, Recall: 0.68, F1 Score: 0.77\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"singleton\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    try:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding file {file}: {e}\")\n",
        "        continue  # Skip to the next file if decoding fails\n",
        "\n",
        "    # Determine if it's a positive class (\"prototype\") or negative class\n",
        "    if \"singleton\" in file:\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    true_labels.append(label)\n",
        "\n",
        "    # Get mean embedding for each line and store in program_embeddings\n",
        "    program_embedding = get_line_embeddings(java_code)\n",
        "    program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for KNN\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(flattened_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 3  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [true_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# Print the KNN results and performance metrics\n",
        "print(\"K-Nearest Neighbors (KNN) Classification Results:\")\n",
        "for i, java_file in enumerate(java_files):\n",
        "    print(f\"File: {java_file}, Predicted Label: {predicted_labels[i]}, True Label: {true_labels[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aef5eaeb-7bea-4d2a-a0bb-96437d3ab56b",
      "metadata": {
        "id": "aef5eaeb-7bea-4d2a-a0bb-96437d3ab56b"
      },
      "outputs": [],
      "source": [
        "#Singleton with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4bdcdcb-f368-463c-b13d-83fab8d7c9f0",
      "metadata": {
        "id": "a4bdcdcb-f368-463c-b13d-83fab8d7c9f0",
        "outputId": "2a5fa459-b7bb-434f-e544-576dcd54ee70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors (KNN) Classification Results:\n",
            "File: nons (12).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (50).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (27).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (19).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (4).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (44).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (38).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (14).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (33).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (41).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (30).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (22).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (3).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (23).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (16).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (2).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (48).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (63).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (40).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (21).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (6).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (37).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (22).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (51).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (10).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (4).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (15).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (32).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (23).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (9).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (39).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (56).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (62).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (24).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (7).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (64).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (19).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.73, Recall: 0.64, F1 Score: 0.68\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"singleton\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    try:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding file {file}: {e}\")\n",
        "        continue  # Skip to the next file if decoding fails\n",
        "\n",
        "    # Determine if it's a positive class (\"prototype\") or negative class\n",
        "    if \"singleton\" in file:\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    true_labels.append(label)\n",
        "\n",
        "    # Get mean embedding for each line and store in program_embeddings\n",
        "    program_embedding = get_line_embeddings(java_code)\n",
        "    program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for KNN\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(flattened_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 3  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [true_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# Print the KNN results and performance metrics\n",
        "print(\"K-Nearest Neighbors (KNN) Classification Results:\")\n",
        "for i, java_file in enumerate(java_files):\n",
        "    print(f\"File: {java_file}, Predicted Label: {predicted_labels[i]}, True Label: {true_labels[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ba4c83a-7203-4ce1-bcff-979efd8f2b5d",
      "metadata": {
        "id": "3ba4c83a-7203-4ce1-bcff-979efd8f2b5d"
      },
      "outputs": [],
      "source": [
        "#Builder with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7b10292-2601-468e-9c08-a7be73a393ce",
      "metadata": {
        "id": "b7b10292-2601-468e-9c08-a7be73a393ce",
        "outputId": "e72e82fc-daeb-4091-a070-2a444df5803d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors (KNN) Classification Results:\n",
            "File: builder (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nonb (41).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (115).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (49).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (50).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (109).java, Predicted Label: 0, True Label: 0\n",
            "File: builder (5).java, Predicted Label: 1, True Label: 1\n",
            "File: builder (6).java, Predicted Label: 1, True Label: 1\n",
            "File: nonb (61).java, Predicted Label: 0, True Label: 0\n",
            "File: builder (3).java, Predicted Label: 0, True Label: 1\n",
            "File: nonb (53).java, Predicted Label: 1, True Label: 0\n",
            "File: nonb (51).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (46).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (58).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (82).java, Predicted Label: 0, True Label: 0\n",
            "File: builder (7).java, Predicted Label: 1, True Label: 1\n",
            "File: nonb (73).java, Predicted Label: 0, True Label: 0\n",
            "File: builder (9).java, Predicted Label: 0, True Label: 1\n",
            "File: nonb (122).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (116).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (38).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (27).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (72).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (119).java, Predicted Label: 0, True Label: 0\n",
            "File: builder (8).java, Predicted Label: 1, True Label: 1\n",
            "File: nonb (64).java, Predicted Label: 0, True Label: 0\n",
            "File: builder (1).java, Predicted Label: 0, True Label: 1\n",
            "File: builder (4).java, Predicted Label: 0, True Label: 1\n",
            "File: nonb (74).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (108).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (131).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (1).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (62).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (52).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (75).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.83, Recall: 0.56, F1 Score: 0.67\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"builder\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    try:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding file {file}: {e}\")\n",
        "        continue  # Skip to the next file if decoding fails\n",
        "\n",
        "    # Determine if it's a positive class (\"prototype\") or negative class\n",
        "    if \"builder\" in file:\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    true_labels.append(label)\n",
        "\n",
        "    # Get mean embedding for each line and store in program_embeddings\n",
        "    program_embedding = get_line_embeddings(java_code)\n",
        "    program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for KNN\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(flattened_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 3  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [true_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# Print the KNN results and performance metrics\n",
        "print(\"K-Nearest Neighbors (KNN) Classification Results:\")\n",
        "for i, java_file in enumerate(java_files):\n",
        "    print(f\"File: {java_file}, Predicted Label: {predicted_labels[i]}, True Label: {true_labels[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "476fc620-5149-43bf-997f-8f5140b294ae",
      "metadata": {
        "id": "476fc620-5149-43bf-997f-8f5140b294ae"
      },
      "outputs": [],
      "source": [
        "#Builder with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7761a87c-3294-4ecc-9842-68364ad164a0",
      "metadata": {
        "id": "7761a87c-3294-4ecc-9842-68364ad164a0",
        "outputId": "9de28aa0-54fe-4ff6-ede0-873cbf4663e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors (KNN) Classification Results:\n",
            "File: builder (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nonb (115).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (89).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (3).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (49).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (28).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (50).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (103).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (36).java, Predicted Label: 1, True Label: 0\n",
            "File: builder (5).java, Predicted Label: 1, True Label: 1\n",
            "File: nonb (126).java, Predicted Label: 0, True Label: 0\n",
            "File: builder (6).java, Predicted Label: 1, True Label: 1\n",
            "File: nonb (44).java, Predicted Label: 0, True Label: 0\n",
            "File: builder (3).java, Predicted Label: 1, True Label: 1\n",
            "File: nonb (87).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (120).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (69).java, Predicted Label: 0, True Label: 0\n",
            "File: builder (7).java, Predicted Label: 1, True Label: 1\n",
            "File: builder (9).java, Predicted Label: 1, True Label: 1\n",
            "File: nonb (122).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (129).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (42).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (38).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (114).java, Predicted Label: 0, True Label: 0\n",
            "File: builder (8).java, Predicted Label: 1, True Label: 1\n",
            "File: builder (1).java, Predicted Label: 0, True Label: 1\n",
            "File: builder (4).java, Predicted Label: 0, True Label: 1\n",
            "File: nonb (39).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (33).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (62).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.88, Recall: 0.78, F1 Score: 0.82\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"builder\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    try:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding file {file}: {e}\")\n",
        "        continue  # Skip to the next file if decoding fails\n",
        "\n",
        "    # Determine if it's a positive class (\"prototype\") or negative class\n",
        "    if \"builder\" in file:\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    true_labels.append(label)\n",
        "\n",
        "    # Get mean embedding for each line and store in program_embeddings\n",
        "    program_embedding = get_line_embeddings(java_code)\n",
        "    program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for KNN\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(flattened_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 3  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [true_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# Print the KNN results and performance metrics\n",
        "print(\"K-Nearest Neighbors (KNN) Classification Results:\")\n",
        "for i, java_file in enumerate(java_files):\n",
        "    print(f\"File: {java_file}, Predicted Label: {predicted_labels[i]}, True Label: {true_labels[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "882c335d-5f70-4a4b-b494-ce9cb0aca605",
      "metadata": {
        "id": "882c335d-5f70-4a4b-b494-ce9cb0aca605"
      },
      "outputs": [],
      "source": [
        "#Builder with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8448357-73f9-4eeb-962a-436a675f5084",
      "metadata": {
        "id": "e8448357-73f9-4eeb-962a-436a675f5084",
        "outputId": "049c8608-1e66-424e-f635-a7e4c0bf79e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors (KNN) Classification Results:\n",
            "File: nonb (14).java, Predicted Label: 0, True Label: 0\n",
            "File: builder (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nonb (98).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (26).java, Predicted Label: 0, True Label: 0\n",
            "File: builder (5).java, Predicted Label: 1, True Label: 1\n",
            "File: builder (6).java, Predicted Label: 1, True Label: 1\n",
            "File: nonb (18).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (17).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (100).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (128).java, Predicted Label: 0, True Label: 0\n",
            "File: builder (3).java, Predicted Label: 0, True Label: 1\n",
            "File: nonb (19).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (86).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (85).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (81).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (82).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (57).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (66).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (132).java, Predicted Label: 0, True Label: 0\n",
            "File: builder (7).java, Predicted Label: 1, True Label: 1\n",
            "File: nonb (92).java, Predicted Label: 0, True Label: 0\n",
            "File: builder (9).java, Predicted Label: 0, True Label: 1\n",
            "File: nonb (116).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (91).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (16).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (27).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (106).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (13).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (99).java, Predicted Label: 0, True Label: 0\n",
            "File: builder (8).java, Predicted Label: 1, True Label: 1\n",
            "File: nonb (23).java, Predicted Label: 0, True Label: 0\n",
            "File: builder (1).java, Predicted Label: 0, True Label: 1\n",
            "File: builder (4).java, Predicted Label: 0, True Label: 1\n",
            "File: nonb (93).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (45).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (20).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (4).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (112).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (2).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (94).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (24).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (55).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 1.00, Recall: 0.56, F1 Score: 0.71\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"builder\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    try:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding file {file}: {e}\")\n",
        "        continue  # Skip to the next file if decoding fails\n",
        "\n",
        "    # Determine if it's a positive class (\"prototype\") or negative class\n",
        "    if \"builder\" in file:\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    true_labels.append(label)\n",
        "\n",
        "    # Get mean embedding for each line and store in program_embeddings\n",
        "    program_embedding = get_line_embeddings(java_code)\n",
        "    program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for KNN\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(flattened_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 3  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [true_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# Print the KNN results and performance metrics\n",
        "print(\"K-Nearest Neighbors (KNN) Classification Results:\")\n",
        "for i, java_file in enumerate(java_files):\n",
        "    print(f\"File: {java_file}, Predicted Label: {predicted_labels[i]}, True Label: {true_labels[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4746627c-76f5-478c-a3bb-bf6611df03fb",
      "metadata": {
        "id": "4746627c-76f5-478c-a3bb-bf6611df03fb"
      },
      "outputs": [],
      "source": [
        "#Builder with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "127a5b6a-1c0d-40e8-a378-bf7809340961",
      "metadata": {
        "id": "127a5b6a-1c0d-40e8-a378-bf7809340961",
        "outputId": "1ed30b29-3aae-4d3b-d233-09e8e446c2c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors (KNN) Classification Results:\n",
            "File: nonb (14).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (77).java, Predicted Label: 0, True Label: 0\n",
            "File: builder (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nonb (26).java, Predicted Label: 0, True Label: 0\n",
            "File: builder (5).java, Predicted Label: 1, True Label: 1\n",
            "File: builder (6).java, Predicted Label: 1, True Label: 1\n",
            "File: nonb (110).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (18).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (61).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (17).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (128).java, Predicted Label: 1, True Label: 0\n",
            "File: builder (3).java, Predicted Label: 0, True Label: 1\n",
            "File: nonb (53).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (19).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (46).java, Predicted Label: 1, True Label: 0\n",
            "File: builder (7).java, Predicted Label: 1, True Label: 1\n",
            "File: builder (9).java, Predicted Label: 1, True Label: 1\n",
            "File: nonb (91).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (48).java, Predicted Label: 1, True Label: 0\n",
            "File: builder (8).java, Predicted Label: 1, True Label: 1\n",
            "File: builder (1).java, Predicted Label: 0, True Label: 1\n",
            "File: builder (4).java, Predicted Label: 0, True Label: 1\n",
            "File: nonb (93).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (20).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (131).java, Predicted Label: 1, True Label: 0\n",
            "File: nonb (94).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (7).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (24).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (88).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.60, Recall: 0.67, F1 Score: 0.63\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"builder\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    try:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding file {file}: {e}\")\n",
        "        continue  # Skip to the next file if decoding fails\n",
        "\n",
        "    # Determine if it's a positive class (\"prototype\") or negative class\n",
        "    if \"builder\" in file:\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    true_labels.append(label)\n",
        "\n",
        "    # Get mean embedding for each line and store in program_embeddings\n",
        "    program_embedding = get_line_embeddings(java_code)\n",
        "    program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for KNN\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(flattened_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 3  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [true_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# Print the KNN results and performance metrics\n",
        "print(\"K-Nearest Neighbors (KNN) Classification Results:\")\n",
        "for i, java_file in enumerate(java_files):\n",
        "    print(f\"File: {java_file}, Predicted Label: {predicted_labels[i]}, True Label: {true_labels[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dc6fbf3-9d75-4725-b200-dba34e003c75",
      "metadata": {
        "id": "9dc6fbf3-9d75-4725-b200-dba34e003c75"
      },
      "outputs": [],
      "source": [
        "#Builder with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55ac2695-df75-4bd9-8c53-f8852b012f20",
      "metadata": {
        "id": "55ac2695-df75-4bd9-8c53-f8852b012f20",
        "outputId": "72e05fb2-efe3-49bd-e3a5-af801150d8ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors (KNN) Classification Results:\n",
            "File: nonb (14).java, Predicted Label: 0, True Label: 0\n",
            "File: builder (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nonb (41).java, Predicted Label: 1, True Label: 0\n",
            "File: nonb (5).java, Predicted Label: 0, True Label: 0\n",
            "File: builder (5).java, Predicted Label: 1, True Label: 1\n",
            "File: builder (6).java, Predicted Label: 1, True Label: 1\n",
            "File: nonb (110).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (18).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (17).java, Predicted Label: 0, True Label: 0\n",
            "File: builder (3).java, Predicted Label: 1, True Label: 1\n",
            "File: nonb (85).java, Predicted Label: 0, True Label: 0\n",
            "File: builder (7).java, Predicted Label: 1, True Label: 1\n",
            "File: nonb (92).java, Predicted Label: 0, True Label: 0\n",
            "File: builder (9).java, Predicted Label: 1, True Label: 1\n",
            "File: nonb (13).java, Predicted Label: 0, True Label: 0\n",
            "File: builder (8).java, Predicted Label: 1, True Label: 1\n",
            "File: nonb (23).java, Predicted Label: 0, True Label: 0\n",
            "File: builder (1).java, Predicted Label: 0, True Label: 1\n",
            "File: builder (4).java, Predicted Label: 0, True Label: 1\n",
            "File: nonb (93).java, Predicted Label: 1, True Label: 0\n",
            "File: nonb (20).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (108).java, Predicted Label: 1, True Label: 0\n",
            "File: nonb (131).java, Predicted Label: 1, True Label: 0\n",
            "File: nonb (2).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (7).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (24).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.64, Recall: 0.78, F1 Score: 0.70\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"builder\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    try:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding file {file}: {e}\")\n",
        "        continue  # Skip to the next file if decoding fails\n",
        "\n",
        "    # Determine if it's a positive class (\"prototype\") or negative class\n",
        "    if \"builder\" in file:\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    true_labels.append(label)\n",
        "\n",
        "    # Get mean embedding for each line and store in program_embeddings\n",
        "    program_embedding = get_line_embeddings(java_code)\n",
        "    program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for KNN\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(flattened_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 3  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [true_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# Print the KNN results and performance metrics\n",
        "print(\"K-Nearest Neighbors (KNN) Classification Results:\")\n",
        "for i, java_file in enumerate(java_files):\n",
        "    print(f\"File: {java_file}, Predicted Label: {predicted_labels[i]}, True Label: {true_labels[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf3a5f1c-8846-42ec-97cf-9701a999031e",
      "metadata": {
        "id": "bf3a5f1c-8846-42ec-97cf-9701a999031e"
      },
      "outputs": [],
      "source": [
        "#Factory Method with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55b4d0a6-81f2-42a1-a6aa-427fba2410a8",
      "metadata": {
        "id": "55b4d0a6-81f2-42a1-a6aa-427fba2410a8",
        "outputId": "e08f6068-a1de-4a69-932e-2b219c487050"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors (KNN) Classification Results:\n",
            "File: nonfm (52).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (13).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (68).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (37).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (29).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (1).java, Predicted Label: 1, True Label: 1\n",
            "File: factorymethod (9).java, Predicted Label: 0, True Label: 1\n",
            "File: nonfm (4).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (5).java, Predicted Label: 1, True Label: 1\n",
            "File: factorymethod (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (72).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (49).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (8).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (10).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (11).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (7).java, Predicted Label: 1, True Label: 1\n",
            "File: factorymethod (4).java, Predicted Label: 0, True Label: 1\n",
            "File: nonfm (66).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (3).java, Predicted Label: 0, True Label: 1\n",
            "File: nonfm (81).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (34).java, Predicted Label: 1, True Label: 0\n",
            "File: factorymethod (11).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (60).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (8).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (45).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (6).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (16).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (51).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (21).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (10).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (73).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.89, Recall: 0.73, F1 Score: 0.80\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"factorymethod\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    try:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding file {file}: {e}\")\n",
        "        continue  # Skip to the next file if decoding fails\n",
        "\n",
        "    # Determine if it's a positive class (\"prototype\") or negative class\n",
        "    if \"factorymethod\" in file:\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    true_labels.append(label)\n",
        "\n",
        "    # Get mean embedding for each line and store in program_embeddings\n",
        "    program_embedding = get_line_embeddings(java_code)\n",
        "    program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for KNN\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(flattened_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 3  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [true_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# Print the KNN results and performance metrics\n",
        "print(\"K-Nearest Neighbors (KNN) Classification Results:\")\n",
        "for i, java_file in enumerate(java_files):\n",
        "    print(f\"File: {java_file}, Predicted Label: {predicted_labels[i]}, True Label: {true_labels[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5458813-087f-4507-836e-4b772986fd8c",
      "metadata": {
        "id": "b5458813-087f-4507-836e-4b772986fd8c"
      },
      "outputs": [],
      "source": [
        "#Factory Method with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87def82d-145b-4ed6-bb2d-a12a6a77cc51",
      "metadata": {
        "id": "87def82d-145b-4ed6-bb2d-a12a6a77cc51",
        "outputId": "c61ab3f6-f971-4c0a-ebee-788be2256588"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors (KNN) Classification Results:\n",
            "File: nonfm (6).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (5).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (13).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (1).java, Predicted Label: 1, True Label: 1\n",
            "File: factorymethod (9).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (12).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (4).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (5).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (2).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (18).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (1).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (8).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (10).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (11).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (7).java, Predicted Label: 0, True Label: 1\n",
            "File: nonfm (14).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (17).java, Predicted Label: 1, True Label: 0\n",
            "File: factorymethod (4).java, Predicted Label: 1, True Label: 1\n",
            "File: factorymethod (3).java, Predicted Label: 0, True Label: 1\n",
            "File: nonfm (9).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (11).java, Predicted Label: 1, True Label: 1\n",
            "File: factorymethod (8).java, Predicted Label: 1, True Label: 1\n",
            "File: factorymethod (6).java, Predicted Label: 0, True Label: 1\n",
            "File: nonfm (3).java, Predicted Label: 1, True Label: 0\n",
            "File: nonfm (16).java, Predicted Label: 1, True Label: 0\n",
            "File: nonfm (20).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (7).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (19).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (10).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (15).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.73, Recall: 0.73, F1 Score: 0.73\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"factorymethod\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    try:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding file {file}: {e}\")\n",
        "        continue  # Skip to the next file if decoding fails\n",
        "\n",
        "    # Determine if it's a positive class (\"prototype\") or negative class\n",
        "    if \"factorymethod\" in file:\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    true_labels.append(label)\n",
        "\n",
        "    # Get mean embedding for each line and store in program_embeddings\n",
        "    program_embedding = get_line_embeddings(java_code)\n",
        "    program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for KNN\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(flattened_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 3  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [true_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# Print the KNN results and performance metrics\n",
        "print(\"K-Nearest Neighbors (KNN) Classification Results:\")\n",
        "for i, java_file in enumerate(java_files):\n",
        "    print(f\"File: {java_file}, Predicted Label: {predicted_labels[i]}, True Label: {true_labels[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "791e6662-b37e-4bf2-9776-3b8262997a1c",
      "metadata": {
        "id": "791e6662-b37e-4bf2-9776-3b8262997a1c"
      },
      "outputs": [],
      "source": [
        "#Factory method with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fbbafce-1750-4778-884b-bdc87ca58bc6",
      "metadata": {
        "id": "2fbbafce-1750-4778-884b-bdc87ca58bc6",
        "outputId": "e232d2b1-7c4a-4dbb-adab-4a5a461d9d54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors (KNN) Classification Results:\n",
            "File: nonfm (77).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (80).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (1).java, Predicted Label: 0, True Label: 1\n",
            "File: factorymethod (9).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (79).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (5).java, Predicted Label: 1, True Label: 1\n",
            "File: factorymethod (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (75).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (72).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (10).java, Predicted Label: 1, True Label: 1\n",
            "File: factorymethod (7).java, Predicted Label: 0, True Label: 1\n",
            "File: nonfm (78).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (4).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (82).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (74).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (3).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (81).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (11).java, Predicted Label: 1, True Label: 1\n",
            "File: factorymethod (8).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (76).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (6).java, Predicted Label: 0, True Label: 1\n",
            "File: nonfm (71).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (73).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 1.00, Recall: 0.73, F1 Score: 0.84\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"factorymethod\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    try:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding file {file}: {e}\")\n",
        "        continue  # Skip to the next file if decoding fails\n",
        "\n",
        "    # Determine if it's a positive class (\"prototype\") or negative class\n",
        "    if \"factorymethod\" in file:\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    true_labels.append(label)\n",
        "\n",
        "    # Get mean embedding for each line and store in program_embeddings\n",
        "    program_embedding = get_line_embeddings(java_code)\n",
        "    program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for KNN\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(flattened_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 3  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [true_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# Print the KNN results and performance metrics\n",
        "print(\"K-Nearest Neighbors (KNN) Classification Results:\")\n",
        "for i, java_file in enumerate(java_files):\n",
        "    print(f\"File: {java_file}, Predicted Label: {predicted_labels[i]}, True Label: {true_labels[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e66886e3-4774-4ce9-a516-16b6a020e2dc",
      "metadata": {
        "id": "e66886e3-4774-4ce9-a516-16b6a020e2dc"
      },
      "outputs": [],
      "source": [
        "#Factory method with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28f7d86a-b97b-4c88-9628-0fbfe2bc8deb",
      "metadata": {
        "id": "28f7d86a-b97b-4c88-9628-0fbfe2bc8deb",
        "outputId": "e16d4f8d-03ef-4c52-e170-6a820f812d96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors (KNN) Classification Results:\n",
            "File: nonfm (68).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (1).java, Predicted Label: 0, True Label: 1\n",
            "File: factorymethod (9).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (79).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (5).java, Predicted Label: 1, True Label: 1\n",
            "File: factorymethod (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (65).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (63).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (10).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (40).java, Predicted Label: 1, True Label: 0\n",
            "File: nonfm (47).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (7).java, Predicted Label: 0, True Label: 1\n",
            "File: factorymethod (4).java, Predicted Label: 0, True Label: 1\n",
            "File: nonfm (43).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (3).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (53).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (27).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (11).java, Predicted Label: 1, True Label: 1\n",
            "File: factorymethod (8).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (57).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (6).java, Predicted Label: 0, True Label: 1\n",
            "File: nonfm (36).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (16).java, Predicted Label: 1, True Label: 0\n",
            "File: nonfm (21).java, Predicted Label: 1, True Label: 0\n",
            "File: nonfm (73).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.70, Recall: 0.64, F1 Score: 0.67\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"factorymethod\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    try:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding file {file}: {e}\")\n",
        "        continue  # Skip to the next file if decoding fails\n",
        "\n",
        "    # Determine if it's a positive class (\"prototype\") or negative class\n",
        "    if \"factorymethod\" in file:\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    true_labels.append(label)\n",
        "\n",
        "    # Get mean embedding for each line and store in program_embeddings\n",
        "    program_embedding = get_line_embeddings(java_code)\n",
        "    program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for KNN\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(flattened_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 3  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [true_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# Print the KNN results and performance metrics\n",
        "print(\"K-Nearest Neighbors (KNN) Classification Results:\")\n",
        "for i, java_file in enumerate(java_files):\n",
        "    print(f\"File: {java_file}, Predicted Label: {predicted_labels[i]}, True Label: {true_labels[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6f9362f-5bc7-435e-a26f-7d6f5157ef4f",
      "metadata": {
        "id": "c6f9362f-5bc7-435e-a26f-7d6f5157ef4f"
      },
      "outputs": [],
      "source": [
        "#Factory Method with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37aba286-2085-4372-88d6-3bff719b37ea",
      "metadata": {
        "id": "37aba286-2085-4372-88d6-3bff719b37ea",
        "outputId": "390e1089-7a0e-475f-8a28-169cf8927c37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors (KNN) Classification Results:\n",
            "File: nonfm (77).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (80).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (1).java, Predicted Label: 0, True Label: 1\n",
            "File: factorymethod (9).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (79).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (5).java, Predicted Label: 1, True Label: 1\n",
            "File: factorymethod (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (75).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (72).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (10).java, Predicted Label: 1, True Label: 1\n",
            "File: factorymethod (7).java, Predicted Label: 0, True Label: 1\n",
            "File: nonfm (70).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (78).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (4).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (82).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (74).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (3).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (81).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (11).java, Predicted Label: 1, True Label: 1\n",
            "File: factorymethod (8).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (76).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (6).java, Predicted Label: 0, True Label: 1\n",
            "File: nonfm (71).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (73).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 1.00, Recall: 0.73, F1 Score: 0.84\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"factorymethod\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    try:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding file {file}: {e}\")\n",
        "        continue  # Skip to the next file if decoding fails\n",
        "\n",
        "    # Determine if it's a positive class (\"prototype\") or negative class\n",
        "    if \"factorymethod\" in file:\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    true_labels.append(label)\n",
        "\n",
        "    # Get mean embedding for each line and store in program_embeddings\n",
        "    program_embedding = get_line_embeddings(java_code)\n",
        "    program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for KNN\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(flattened_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 3  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [true_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# Print the KNN results and performance metrics\n",
        "print(\"K-Nearest Neighbors (KNN) Classification Results:\")\n",
        "for i, java_file in enumerate(java_files):\n",
        "    print(f\"File: {java_file}, Predicted Label: {predicted_labels[i]}, True Label: {true_labels[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65f972cd-518c-4cac-b122-ebeaeea27f88",
      "metadata": {
        "id": "65f972cd-518c-4cac-b122-ebeaeea27f88"
      },
      "outputs": [],
      "source": [
        "#Abstract Factory with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c66baa0-934c-4962-9ea7-db604fbe4a0c",
      "metadata": {
        "id": "0c66baa0-934c-4962-9ea7-db604fbe4a0c",
        "outputId": "03f5f5d4-dd61-4a93-f07d-06ef7b31aa34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors (KNN) Classification Results:\n",
            "File: nondp (7).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (2).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (18).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nondp (33).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (29).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (31).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (11).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (39).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (45).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (19).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (23).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (38).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (30).java, Predicted Label: 1, True Label: 0\n",
            "File: nondp (26).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (6).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (10).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (9).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (13).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (16).java, Predicted Label: 1, True Label: 1\n",
            "File: nondp (42).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (4).java, Predicted Label: 1, True Label: 1\n",
            "File: nondp (49).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (12).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (40).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (5).java, Predicted Label: 1, True Label: 1\n",
            "File: nondp (32).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (36).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (1).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (12).java, Predicted Label: 1, True Label: 1\n",
            "File: nondp (20).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (14).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (43).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (21).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (25).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (3).java, Predicted Label: 1, True Label: 1\n",
            "File: nondp (13).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (47).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (10).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (44).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (22).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (27).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (15).java, Predicted Label: 1, True Label: 1\n",
            "File: nondp (24).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (1).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (35).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (34).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (11).java, Predicted Label: 1, True Label: 1\n",
            "File: nondp (3).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (48).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (5).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (7).java, Predicted Label: 1, True Label: 1\n",
            "File: nondp (46).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (15).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (4).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (16).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (8).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (14).java, Predicted Label: 1, True Label: 1\n",
            "File: nondp (8).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (28).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (9).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (41).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (37).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (6).java, Predicted Label: 1, True Label: 1\n",
            "File: nondp (17).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (50).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.94, Recall: 1.00, F1 Score: 0.97\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"abstractfactory\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    try:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding file {file}: {e}\")\n",
        "        continue  # Skip to the next file if decoding fails\n",
        "\n",
        "    # Determine if it's a positive class (\"prototype\") or negative class\n",
        "    if \"abstractfactory\" in file:\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    true_labels.append(label)\n",
        "\n",
        "    # Get mean embedding for each line and store in program_embeddings\n",
        "    program_embedding = get_line_embeddings(java_code)\n",
        "    program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for KNN\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(flattened_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 3  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [true_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# Print the KNN results and performance metrics\n",
        "print(\"K-Nearest Neighbors (KNN) Classification Results:\")\n",
        "for i, java_file in enumerate(java_files):\n",
        "    print(f\"File: {java_file}, Predicted Label: {predicted_labels[i]}, True Label: {true_labels[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2636c602-e7db-48e7-923b-65c7adc89d47",
      "metadata": {
        "id": "2636c602-e7db-48e7-923b-65c7adc89d47"
      },
      "outputs": [],
      "source": [
        "#Abstract Factory with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e01e61ee-991c-44b2-9548-b9a1d50ed8c2",
      "metadata": {
        "id": "e01e61ee-991c-44b2-9548-b9a1d50ed8c2",
        "outputId": "0607a115-5f61-4441-df7d-f97606df63a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors (KNN) Classification Results:\n",
            "File: nonfm (31).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (2).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (30).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (10).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (9).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (13).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (16).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (20).java, Predicted Label: 1, True Label: 0\n",
            "File: abstractfactory (4).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (5).java, Predicted Label: 0, True Label: 1\n",
            "File: abstractfactory (1).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (12).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (29).java, Predicted Label: 1, True Label: 0\n",
            "File: abstractfactory (3).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (23).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (15).java, Predicted Label: 0, True Label: 1\n",
            "File: nonfm (21).java, Predicted Label: 1, True Label: 0\n",
            "File: nonfm (26).java, Predicted Label: 1, True Label: 0\n",
            "File: abstractfactory (11).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (7).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (27).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (28).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (24).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (3).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (22).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (8).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (14).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (25).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (6).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.78, Recall: 0.88, F1 Score: 0.82\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"abstractfactory\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    try:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding file {file}: {e}\")\n",
        "        continue  # Skip to the next file if decoding fails\n",
        "\n",
        "    # Determine if it's a positive class (\"prototype\") or negative class\n",
        "    if \"abstractfactory\" in file:\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    true_labels.append(label)\n",
        "\n",
        "    # Get mean embedding for each line and store in program_embeddings\n",
        "    program_embedding = get_line_embeddings(java_code)\n",
        "    program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for KNN\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(flattened_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 3  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [true_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# Print the KNN results and performance metrics\n",
        "print(\"K-Nearest Neighbors (KNN) Classification Results:\")\n",
        "for i, java_file in enumerate(java_files):\n",
        "    print(f\"File: {java_file}, Predicted Label: {predicted_labels[i]}, True Label: {true_labels[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "398cad4b-ffaf-4138-812d-4a2b32421aeb",
      "metadata": {
        "id": "398cad4b-ffaf-4138-812d-4a2b32421aeb"
      },
      "outputs": [],
      "source": [
        "#Abstract Factory with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be4ae779-7ba0-4a50-b390-19064375e1e6",
      "metadata": {
        "id": "be4ae779-7ba0-4a50-b390-19064375e1e6",
        "outputId": "b862d379-5d0e-4707-a0ba-b6dd1b10054d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors (KNN) Classification Results:\n",
            "File: nonab (11).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (48).java, Predicted Label: 1, True Label: 0\n",
            "File: abstractfactory (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (5).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (65).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (7).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (10).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (9).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (13).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (16).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (8).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (4).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (5).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (3).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (1).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (12).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (14).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (3).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (74).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (4).java, Predicted Label: 1, True Label: 0\n",
            "File: nonab (86).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (15).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (40).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (11).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (7).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (8).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (12).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (14).java, Predicted Label: 0, True Label: 1\n",
            "File: nonab (63).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (17).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (18).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (47).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (6).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.88, Recall: 0.88, F1 Score: 0.88\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"abstractfactory\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    try:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding file {file}: {e}\")\n",
        "        continue  # Skip to the next file if decoding fails\n",
        "\n",
        "    # Determine if it's a positive class (\"prototype\") or negative class\n",
        "    if \"abstractfactory\" in file:\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    true_labels.append(label)\n",
        "\n",
        "    # Get mean embedding for each line and store in program_embeddings\n",
        "    program_embedding = get_line_embeddings(java_code)\n",
        "    program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for KNN\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(flattened_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 3  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [true_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# Print the KNN results and performance metrics\n",
        "print(\"K-Nearest Neighbors (KNN) Classification Results:\")\n",
        "for i, java_file in enumerate(java_files):\n",
        "    print(f\"File: {java_file}, Predicted Label: {predicted_labels[i]}, True Label: {true_labels[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d6c7390-37ff-4de0-a02e-619537d01312",
      "metadata": {
        "id": "8d6c7390-37ff-4de0-a02e-619537d01312"
      },
      "outputs": [],
      "source": [
        "#Abstract Factory with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "880918c8-4806-48e6-a83e-cc315a1ac9ab",
      "metadata": {
        "id": "880918c8-4806-48e6-a83e-cc315a1ac9ab",
        "outputId": "3d8c9a2b-faac-40d9-c563-3c06d40ebb87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors (KNN) Classification Results:\n",
            "File: nonab (11).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (48).java, Predicted Label: 1, True Label: 0\n",
            "File: abstractfactory (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (5).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (65).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (7).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (10).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (9).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (13).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (16).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (8).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (4).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (5).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (3).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (1).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (12).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (14).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (3).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (74).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (4).java, Predicted Label: 1, True Label: 0\n",
            "File: nonab (86).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (15).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (40).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (11).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (7).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (54).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (8).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (12).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (14).java, Predicted Label: 0, True Label: 1\n",
            "File: nonab (63).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (17).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (18).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (47).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (6).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.88, Recall: 0.88, F1 Score: 0.88\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"abstractfactory\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    try:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding file {file}: {e}\")\n",
        "        continue  # Skip to the next file if decoding fails\n",
        "\n",
        "    # Determine if it's a positive class (\"prototype\") or negative class\n",
        "    if \"abstractfactory\" in file:\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    true_labels.append(label)\n",
        "\n",
        "    # Get mean embedding for each line and store in program_embeddings\n",
        "    program_embedding = get_line_embeddings(java_code)\n",
        "    program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for KNN\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(flattened_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 3  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [true_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# Print the KNN results and performance metrics\n",
        "print(\"K-Nearest Neighbors (KNN) Classification Results:\")\n",
        "for i, java_file in enumerate(java_files):\n",
        "    print(f\"File: {java_file}, Predicted Label: {predicted_labels[i]}, True Label: {true_labels[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a665a56b-d65f-4746-8a13-bdb7288d6feb",
      "metadata": {
        "id": "a665a56b-d65f-4746-8a13-bdb7288d6feb"
      },
      "outputs": [],
      "source": [
        "#Abstract Factory with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "892d906e-f50d-463e-bef2-754ceee048cb",
      "metadata": {
        "id": "892d906e-f50d-463e-bef2-754ceee048cb",
        "outputId": "ce355fc6-ed08-4120-dbba-9e38d046a400"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors (KNN) Classification Results:\n",
            "File: abstractfactory (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (19).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (5).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (30).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (10).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (9).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (13).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (16).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (4).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (5).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (1).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (12).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (14).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (80).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (3).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (4).java, Predicted Label: 1, True Label: 0\n",
            "File: abstractfactory (15).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (6).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (62).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (11).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (7).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (54).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (85).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (8).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (12).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (39).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (14).java, Predicted Label: 0, True Label: 1\n",
            "File: nonab (49).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (63).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (79).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (20).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (18).java, Predicted Label: 1, True Label: 0\n",
            "File: abstractfactory (6).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (52).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.88, Recall: 0.94, F1 Score: 0.91\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"abstractfactory\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    try:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding file {file}: {e}\")\n",
        "        continue  # Skip to the next file if decoding fails\n",
        "\n",
        "    # Determine if it's a positive class (\"prototype\") or negative class\n",
        "    if \"abstractfactory\" in file:\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    true_labels.append(label)\n",
        "\n",
        "    # Get mean embedding for each line and store in program_embeddings\n",
        "    program_embedding = get_line_embeddings(java_code)\n",
        "    program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for KNN\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(flattened_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 3  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [true_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# Print the KNN results and performance metrics\n",
        "print(\"K-Nearest Neighbors (KNN) Classification Results:\")\n",
        "for i, java_file in enumerate(java_files):\n",
        "    print(f\"File: {java_file}, Predicted Label: {predicted_labels[i]}, True Label: {true_labels[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "749d36e4-3763-4b55-9b44-35b35d58042c",
      "metadata": {
        "id": "749d36e4-3763-4b55-9b44-35b35d58042c"
      },
      "outputs": [],
      "source": [
        "#Abstract Factory with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5c5d268-346e-4ce0-aba8-467ec7f5a015",
      "metadata": {
        "id": "e5c5d268-346e-4ce0-aba8-467ec7f5a015",
        "outputId": "869a7fa2-bb5e-4706-f102-0044363e98db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors (KNN) Classification Results:\n",
            "File: nonab (11).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nondp (33).java, Predicted Label: 1, True Label: 0\n",
            "File: nondp (31).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (39).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (5).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (38).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (30).java, Predicted Label: 1, True Label: 0\n",
            "File: nonab (7).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (10).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (9).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (13).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (16).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (8).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (4).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (5).java, Predicted Label: 1, True Label: 1\n",
            "File: nondp (32).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (3).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (36).java, Predicted Label: 1, True Label: 0\n",
            "File: abstractfactory (1).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (12).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (14).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (3).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (74).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (15).java, Predicted Label: 1, True Label: 1\n",
            "File: nondp (35).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (34).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (11).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (7).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (8).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (14).java, Predicted Label: 0, True Label: 1\n",
            "File: nonab (63).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (17).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (37).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (6).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.82, Recall: 0.88, F1 Score: 0.85\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"abstractfactory\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    try:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding file {file}: {e}\")\n",
        "        continue  # Skip to the next file if decoding fails\n",
        "\n",
        "    # Determine if it's a positive class (\"prototype\") or negative class\n",
        "    if \"abstractfactory\" in file:\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    true_labels.append(label)\n",
        "\n",
        "    # Get mean embedding for each line and store in program_embeddings\n",
        "    program_embedding = get_line_embeddings(java_code)\n",
        "    program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for KNN\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(flattened_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 3  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [true_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# Print the KNN results and performance metrics\n",
        "print(\"K-Nearest Neighbors (KNN) Classification Results:\")\n",
        "for i, java_file in enumerate(java_files):\n",
        "    print(f\"File: {java_file}, Predicted Label: {predicted_labels[i]}, True Label: {true_labels[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e35b95ac-eb24-4676-956b-817d0bdd29be",
      "metadata": {
        "id": "e35b95ac-eb24-4676-956b-817d0bdd29be"
      },
      "outputs": [],
      "source": [
        "#Abstract Factory with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58c0edeb-f2d6-43d7-a59c-40390f38bc01",
      "metadata": {
        "id": "58c0edeb-f2d6-43d7-a59c-40390f38bc01",
        "outputId": "a94109fc-7a51-4f0e-9a61-3b3fe5fc3309"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors (KNN) Classification Results:\n",
            "File: abstractfactory (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (19).java, Predicted Label: 1, True Label: 0\n",
            "File: nonab (5).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (65).java, Predicted Label: 1, True Label: 0\n",
            "File: nonab (56).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (15).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (10).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (9).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (51).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (13).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (2).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (16).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (8).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (4).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (5).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (26).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (1).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (12).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (13).java, Predicted Label: 1, True Label: 0\n",
            "File: nonab (36).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (3).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (4).java, Predicted Label: 1, True Label: 0\n",
            "File: nonab (86).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (15).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (11).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (7).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (55).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (8).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (9).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (14).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (17).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (82).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (47).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (6).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.79, Recall: 0.94, F1 Score: 0.86\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"abstractfactory\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    try:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding file {file}: {e}\")\n",
        "        continue  # Skip to the next file if decoding fails\n",
        "\n",
        "    # Determine if it's a positive class (\"prototype\") or negative class\n",
        "    if \"abstractfactory\" in file:\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    true_labels.append(label)\n",
        "\n",
        "    # Get mean embedding for each line and store in program_embeddings\n",
        "    program_embedding = get_line_embeddings(java_code)\n",
        "    program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for KNN\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(flattened_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 3  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [true_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# Print the KNN results and performance metrics\n",
        "print(\"K-Nearest Neighbors (KNN) Classification Results:\")\n",
        "for i, java_file in enumerate(java_files):\n",
        "    print(f\"File: {java_file}, Predicted Label: {predicted_labels[i]}, True Label: {true_labels[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c77269fb-f518-494d-ae6d-ba29f8a85b7a",
      "metadata": {
        "id": "c77269fb-f518-494d-ae6d-ba29f8a85b7a"
      },
      "outputs": [],
      "source": [
        "#Abstract Factory with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97d4aedc-8418-45fd-a167-1b9e48376ca9",
      "metadata": {
        "id": "97d4aedc-8418-45fd-a167-1b9e48376ca9",
        "outputId": "bbc1363b-15de-447a-ee12-9e4dc69ae383"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors (KNN) Classification Results:\n",
            "File: nonab (72).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (11).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (19).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (5).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (7).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (1).java, Predicted Label: 1, True Label: 0\n",
            "File: abstractfactory (10).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (9).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (13).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (2).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (16).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (8).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (4).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (5).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (1).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (12).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (3).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (83).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (74).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (15).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (11).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (7).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (54).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (85).java, Predicted Label: 1, True Label: 0\n",
            "File: nonab (67).java, Predicted Label: 1, True Label: 0\n",
            "File: abstractfactory (8).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (12).java, Predicted Label: 1, True Label: 0\n",
            "File: nonab (9).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (14).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (49).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (18).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (6).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.79, Recall: 0.94, F1 Score: 0.86\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"abstractfactory\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    try:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding file {file}: {e}\")\n",
        "        continue  # Skip to the next file if decoding fails\n",
        "\n",
        "    # Determine if it's a positive class (\"prototype\") or negative class\n",
        "    if \"abstractfactory\" in file:\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    true_labels.append(label)\n",
        "\n",
        "    # Get mean embedding for each line and store in program_embeddings\n",
        "    program_embedding = get_line_embeddings(java_code)\n",
        "    program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for KNN\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(flattened_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 3  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [true_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# Print the KNN results and performance metrics\n",
        "print(\"K-Nearest Neighbors (KNN) Classification Results:\")\n",
        "for i, java_file in enumerate(java_files):\n",
        "    print(f\"File: {java_file}, Predicted Label: {predicted_labels[i]}, True Label: {true_labels[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d92135e1-b0f0-4602-8c94-df0deb2230e3",
      "metadata": {
        "id": "d92135e1-b0f0-4602-8c94-df0deb2230e3"
      },
      "outputs": [],
      "source": [
        "#Prototype with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "724b2c91-ee39-4613-b6d4-00ac3f693d37",
      "metadata": {
        "id": "724b2c91-ee39-4613-b6d4-00ac3f693d37",
        "outputId": "45b202c8-312d-4c3b-81ae-11c99a1c7eed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors (KNN) Classification Results:\n",
            "File: prototype (27).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (53).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (23).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (43).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (35).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (51).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (59).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (5).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (31).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (13).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (22).java, Predicted Label: 0, True Label: 1\n",
            "File: nonp (7).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (13).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (29).java, Predicted Label: 1, True Label: 0\n",
            "File: prototype (15).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (44).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (8).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (37).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (21).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (36).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (58).java, Predicted Label: 1, True Label: 0\n",
            "File: prototype (14).java, Predicted Label: 0, True Label: 1\n",
            "File: nonp (28).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (16).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (49).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (18).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (22).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (32).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (6).java, Predicted Label: 0, True Label: 1\n",
            "File: prototype (19).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (12).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (39).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (38).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (32).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (26).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (48).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (46).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (42).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (45).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (11).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (25).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (12).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (33).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (4).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (50).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (29).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (2).java, Predicted Label: 0, True Label: 1\n",
            "File: prototype (31).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (6).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (19).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (52).java, Predicted Label: 1, True Label: 0\n",
            "File: nonp (14).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (24).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (10).java, Predicted Label: 0, True Label: 1\n",
            "File: prototype (4).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (21).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (3).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (10).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (17).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (41).java, Predicted Label: 1, True Label: 0\n",
            "File: nonp (2).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (20).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (55).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (3).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (9).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (7).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (8).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (60).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (20).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (56).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (15).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (47).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (30).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (23).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (5).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (1).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (28).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (16).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (30).java, Predicted Label: 0, True Label: 1\n",
            "File: nonp (54).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (24).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (18).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (57).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (34).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (26).java, Predicted Label: 1, True Label: 0\n",
            "File: prototype (1).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (25).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (17).java, Predicted Label: 1, True Label: 0\n",
            "File: nonp (27).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (11).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (9).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (40).java, Predicted Label: 1, True Label: 0\n",
            "File: nonp (61).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.79, Recall: 0.81, F1 Score: 0.80\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"prototype\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    try:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding file {file}: {e}\")\n",
        "        continue  # Skip to the next file if decoding fails\n",
        "\n",
        "    # Determine if it's a positive class (\"prototype\") or negative class\n",
        "    if \"prototype\" in file:\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    true_labels.append(label)\n",
        "\n",
        "    # Get mean embedding for each line and store in program_embeddings\n",
        "    program_embedding = get_line_embeddings(java_code)\n",
        "    program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for KNN\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(flattened_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 3  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [true_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# Print the KNN results and performance metrics\n",
        "print(\"K-Nearest Neighbors (KNN) Classification Results:\")\n",
        "for i, java_file in enumerate(java_files):\n",
        "    print(f\"File: {java_file}, Predicted Label: {predicted_labels[i]}, True Label: {true_labels[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd2bbb23-d14f-42ed-97a6-d237b5ee595a",
      "metadata": {
        "id": "bd2bbb23-d14f-42ed-97a6-d237b5ee595a",
        "outputId": "be8ee453-68a3-4fc0-8add-a1835e5e5a31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors (KNN) Classification Results:\n",
            "File: prototype (27).java, Predicted Label: 1, True Label: 1\n",
            "File: non-DP (44).java, Predicted Label: 0, True Label: 0\n",
            "File: non-DP (34).java, Predicted Label: 0, True Label: 0\n",
            "File: non-DP (29).java, Predicted Label: 0, True Label: 0\n",
            "File: non-DP (35).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (13).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (22).java, Predicted Label: 0, True Label: 1\n",
            "File: non-DP (48).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (15).java, Predicted Label: 1, True Label: 1\n",
            "File: non-DP (25).java, Predicted Label: 0, True Label: 0\n",
            "File: non-DP (45).java, Predicted Label: 0, True Label: 0\n",
            "File: non-DP (39).java, Predicted Label: 0, True Label: 0\n",
            "File: non-DP (2).java, Predicted Label: 0, True Label: 0\n",
            "File: non-DP (33).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (14).java, Predicted Label: 0, True Label: 1\n",
            "File: prototype (16).java, Predicted Label: 1, True Label: 1\n",
            "File: non-DP (50).java, Predicted Label: 0, True Label: 0\n",
            "File: non-DP (38).java, Predicted Label: 1, True Label: 0\n",
            "File: prototype (18).java, Predicted Label: 1, True Label: 1\n",
            "File: non-DP (27).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (32).java, Predicted Label: 1, True Label: 1\n",
            "File: non-DP (42).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (6).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (19).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (12).java, Predicted Label: 1, True Label: 1\n",
            "File: non-DP (23).java, Predicted Label: 0, True Label: 0\n",
            "File: non-DP (1).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (26).java, Predicted Label: 1, True Label: 1\n",
            "File: non-DP (43).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (11).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (25).java, Predicted Label: 1, True Label: 1\n",
            "File: non-DP (26).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (29).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (2).java, Predicted Label: 0, True Label: 1\n",
            "File: non-DP (30).java, Predicted Label: 1, True Label: 0\n",
            "File: prototype (31).java, Predicted Label: 1, True Label: 1\n",
            "File: non-DP (4).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (10).java, Predicted Label: 0, True Label: 1\n",
            "File: prototype (4).java, Predicted Label: 1, True Label: 1\n",
            "File: non-DP (36).java, Predicted Label: 0, True Label: 0\n",
            "File: non-DP (41).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (21).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (3).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (17).java, Predicted Label: 1, True Label: 1\n",
            "File: non-DP (3).java, Predicted Label: 0, True Label: 0\n",
            "File: non-DP (6).java, Predicted Label: 0, True Label: 0\n",
            "File: non-DP (37).java, Predicted Label: 1, True Label: 0\n",
            "File: non-DP (47).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (7).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (8).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (20).java, Predicted Label: 1, True Label: 1\n",
            "File: non-DP (28).java, Predicted Label: 0, True Label: 0\n",
            "File: non-DP (46).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (23).java, Predicted Label: 1, True Label: 1\n",
            "File: non-DP (49).java, Predicted Label: 1, True Label: 0\n",
            "File: prototype (5).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (28).java, Predicted Label: 1, True Label: 1\n",
            "File: non-DP (40).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (30).java, Predicted Label: 1, True Label: 1\n",
            "File: non-DP (5).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (24).java, Predicted Label: 1, True Label: 1\n",
            "File: non-DP (7).java, Predicted Label: 0, True Label: 0\n",
            "File: non-DP (31).java, Predicted Label: 0, True Label: 0\n",
            "File: non-DP (24).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (1).java, Predicted Label: 1, True Label: 1\n",
            "File: non-DP (32).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (9).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.88, Recall: 0.88, F1 Score: 0.88\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"prototype\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    try:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding file {file}: {e}\")\n",
        "        continue  # Skip to the next file if decoding fails\n",
        "\n",
        "    # Determine if it's a positive class (\"prototype\") or negative class\n",
        "    if \"prototype\" in file:\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    true_labels.append(label)\n",
        "\n",
        "    # Get mean embedding for each line and store in program_embeddings\n",
        "    program_embedding = get_line_embeddings(java_code)\n",
        "    program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for KNN\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(flattened_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 3  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [true_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# Print the KNN results and performance metrics\n",
        "print(\"K-Nearest Neighbors (KNN) Classification Results:\")\n",
        "for i, java_file in enumerate(java_files):\n",
        "    print(f\"File: {java_file}, Predicted Label: {predicted_labels[i]}, True Label: {true_labels[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08391b07-175e-4601-b4e0-c76c1fae3fcd",
      "metadata": {
        "id": "08391b07-175e-4601-b4e0-c76c1fae3fcd"
      },
      "outputs": [],
      "source": [
        "#Prototype with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61c67fcf-bb60-41de-8559-bc0ad99a4a0e",
      "metadata": {
        "id": "61c67fcf-bb60-41de-8559-bc0ad99a4a0e",
        "outputId": "d9bcc6bd-1414-45f6-dd3d-7a792d131876"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "K-Nearest Neighbors (KNN) Classification Results:\n",
            "File: prototype (27).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (53).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (23).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (43).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (35).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (51).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (59).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (5).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (31).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (13).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (22).java, Predicted Label: 0, True Label: 1\n",
            "File: nonp (7).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (13).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (29).java, Predicted Label: 1, True Label: 0\n",
            "File: prototype (15).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (44).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (8).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (37).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (21).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (36).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (58).java, Predicted Label: 1, True Label: 0\n",
            "File: prototype (14).java, Predicted Label: 0, True Label: 1\n",
            "File: nonp (28).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (16).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (49).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (18).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (22).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (32).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (6).java, Predicted Label: 0, True Label: 1\n",
            "File: prototype (19).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (12).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (39).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (38).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (32).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (26).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (48).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (46).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (42).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (45).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (11).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (25).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (12).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (33).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (4).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (50).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (29).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (2).java, Predicted Label: 0, True Label: 1\n",
            "File: prototype (31).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (6).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (19).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (52).java, Predicted Label: 1, True Label: 0\n",
            "File: nonp (14).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (24).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (10).java, Predicted Label: 0, True Label: 1\n",
            "File: prototype (4).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (21).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (3).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (10).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (17).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (41).java, Predicted Label: 1, True Label: 0\n",
            "File: nonp (2).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (20).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (55).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (3).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (9).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (7).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (8).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (60).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (20).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (56).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (15).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (47).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (30).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (23).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (5).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (1).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (28).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (16).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (30).java, Predicted Label: 0, True Label: 1\n",
            "File: nonp (54).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (24).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (18).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (57).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (34).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (26).java, Predicted Label: 1, True Label: 0\n",
            "File: prototype (1).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (25).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (17).java, Predicted Label: 1, True Label: 0\n",
            "File: nonp (27).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (11).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (9).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (40).java, Predicted Label: 1, True Label: 0\n",
            "File: nonp (61).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.79, Recall: 0.81, F1 Score: 0.80\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"prototype\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    try:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding file {file}: {e}\")\n",
        "        continue  # Skip to the next file if decoding fails\n",
        "\n",
        "    # Determine if it's a positive class (\"prototype\") or negative class\n",
        "    if \"prototype\" in file:\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    true_labels.append(label)\n",
        "\n",
        "    # Get mean embedding for each line and store in program_embeddings\n",
        "    program_embedding = get_line_embeddings(java_code)\n",
        "    program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for KNN\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(flattened_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 3  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [true_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "# Print the KNN results and performance metrics\n",
        "print(\"K-Nearest Neighbors (KNN) Classification Results:\")\n",
        "for i, java_file in enumerate(java_files):\n",
        "    print(f\"File: {java_file}, Predicted Label: {predicted_labels[i]}, True Label: {true_labels[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdae07f7-bd2a-4ef8-8462-e2c99f774def",
      "metadata": {
        "id": "bdae07f7-bd2a-4ef8-8462-e2c99f774def"
      },
      "outputs": [],
      "source": [
        "#tNSE plot for design patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acc4137b-486b-4108-84ef-2c2447d21d94",
      "metadata": {
        "id": "acc4137b-486b-4108-84ef-2c2447d21d94"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code, model, tokenizer):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Function to perform t-SNE visualization\n",
        "def perform_tsne(embeddings, labels):\n",
        "    tsne = TSNE(n_components=2, random_state=42)\n",
        "    tsne_results = tsne.fit_transform(embeddings)\n",
        "\n",
        "    # Create a scatter plot for t-SNE visualization\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    sns.scatterplot(x=tsne_results[:, 0], y=tsne_results[:, 1], hue=labels, palette=\"dark\", s=50, alpha=0.7)\n",
        "\n",
        "    plt.title('t-SNE Visualization for CodeT5 on Different Classes', fontsize=16)\n",
        "    plt.xlabel('t-SNE Dimension 1', fontsize=14)\n",
        "    plt.ylabel('t-SNE Dimension 2', fontsize=14)\n",
        "    plt.legend(title='Class', loc='upper right', fontsize=12)\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"prototype\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    try:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding file {file}: {e}\")\n",
        "        continue  # Skip to the next file if decoding fails\n",
        "\n",
        "    # Determine if it's a positive class (\"prototype\") or negative class\n",
        "    if \"prototype\" in file:\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    true_labels.append(label)\n",
        "\n",
        "    # Get mean embedding for each line and store in program_embeddings\n",
        "    program_embedding = get_line_embeddings(java_code, model, tokenizer)\n",
        "    program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for t-SNE\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Perform t-SNE visualization\n",
        "perform_tsne(flattened_embeddings, true_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FXmQazanG2__",
      "metadata": {
        "id": "FXmQazanG2__"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c82aa53-a934-411c-b7d6-6763384330d1",
      "metadata": {
        "id": "3c82aa53-a934-411c-b7d6-6763384330d1"
      },
      "outputs": [],
      "source": [
        "#Prototype with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6a31099-3581-428c-bc2f-477b167e8861",
      "metadata": {
        "id": "a6a31099-3581-428c-bc2f-477b167e8861"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code, model, tokenizer):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        # Encode the input using the T5 tokenizer\n",
        "        inputs = tokenizer(\"translate English to Java: \" + line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Add a dummy decoder input\n",
        "        inputs[\"decoder_input_ids\"] = inputs[\"input_ids\"]\n",
        "\n",
        "        # Forward pass through the T5 model\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Function to perform t-SNE visualization\n",
        "def perform_tsne(embeddings, labels):\n",
        "    tsne = TSNE(n_components=2, random_state=42)\n",
        "    tsne_results = tsne.fit_transform(embeddings)\n",
        "\n",
        "    # Create a scatter plot for t-SNE visualization\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    sns.scatterplot(x=tsne_results[:, 0], y=tsne_results[:, 1], hue=labels, palette=\"dark\", s=50, alpha=0.7)\n",
        "\n",
        "    plt.title('t-SNE Visualization for CodeT5 on Different Classes', fontsize=16)\n",
        "    plt.xlabel('t-SNE Dimension 1', fontsize=14)\n",
        "    plt.ylabel('t-SNE Dimension 2', fontsize=14)\n",
        "    plt.legend(title='Class', loc='upper right', fontsize=12)\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"prototype\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "\n",
        "# Define the true labels for each program\n",
        "true_labels = []\n",
        "\n",
        "for file in java_files:\n",
        "    try:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(f\"Error decoding file {file}: {e}\")\n",
        "        continue  # Skip to the next file if decoding fails\n",
        "\n",
        "    # Determine if it's a positive class (\"prototype\") or negative class\n",
        "    if \"prototype\" in file:\n",
        "        label = 1\n",
        "    else:\n",
        "        label = 0\n",
        "\n",
        "    true_labels.append(label)\n",
        "\n",
        "    # Get mean embedding for each line and store in program_embeddings\n",
        "    program_embedding = get_line_embeddings(java_code, model, tokenizer)\n",
        "    program_embeddings.append(program_embedding)\n",
        "\n",
        "# Flatten the embeddings for t-SNE\n",
        "flattened_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Perform t-SNE visualization\n",
        "perform_tsne(flattened_embeddings, true_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc92b5cf-c49e-4a67-986e-cd4b5cdf6ee6",
      "metadata": {
        "id": "dc92b5cf-c49e-4a67-986e-cd4b5cdf6ee6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ANjXAPe-G4xB",
      "metadata": {
        "id": "ANjXAPe-G4xB"
      },
      "source": [
        "**Time calcultation for Singleton**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nyf79N4nG913",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799,
          "referenced_widgets": [
            "9b250a2ef81f4b3cb512415406711303",
            "d12aa0b1124443189a32f27ce26bca58",
            "ef6b38bd39904e66a5aeef095cb96fdd",
            "e4bc6f7da9a44a05b81b5a391e88f77f",
            "696da689d04c43e1972e3bdbfc3c3236",
            "2eb080c4973f4b2499072c3e141e0890",
            "1650169fd8824b7fb9f6e3f4a14ef360",
            "af7a67476dd846eca3add66b1ff7e3df",
            "0dff3af71be645568ea246a538d58f91",
            "94e70d77bf9846479e143df73cd04c49",
            "8f708922453c4152861dca12ee550aba",
            "383766ae43494cf3a8e15835afdea21f",
            "811d4d9dd7df4937b63181262198ac4c",
            "477adaf5bef746deaeea243541796fd3",
            "b4a82c2a81d74f75a0cee586f682f925",
            "2fc5d2b9b0f043e0ab15e52b72e83dee",
            "104a8896a2ce45b89c2fb5176cef9595",
            "9de976e7646d4741a91dc839532f641b",
            "9f5389cdb47a4f4695281651deaa4ff3",
            "da54876bfa4a435cbc1642a365e1767c",
            "17e0acab31274b12a68fd4f7aa1f57f6",
            "7565cec1befe4318bfcb36eba79b6b0e",
            "f2554f50683b4ccaa3f00a6a4fb3588d",
            "9ebac06e0ed94a82ab33bf7b8e0fc924",
            "ef752dad89094c40b34832b4827ee694",
            "24a620a2d0724166b4df02198e06e11b",
            "08cc5634b8a9468db79104753d2381d0",
            "eb549e606d454b93aa5ff2183cdfe19b",
            "f80411c16cc247f2b28c4b4cb0c8a177",
            "ed228e13d733479593f7feb1d04cc38d",
            "d96a885793b141e297a276e1a7ea8201",
            "d85ce552ee6b49e7991b27c834586d29",
            "8b5f3cd8234247508235acc3b1d31633",
            "6e1040d69c8c4f2d9aa571dce192a988",
            "660c68bcd9f24d3c93af469ece5af6b3",
            "d1b7b30e56944ab6a86722a25b346510",
            "56c99ee706124ca18f9619e6520101a5",
            "11b1664cfbf848d192fc09eacc4e9937",
            "572b197c0bd048a9a302a244c9ab6b50",
            "33c6e322a81c42df888cc121e2578481",
            "7d3b1ec9eab648908297dc13154691a3",
            "2c3bb8d49c5a4889827d3477bd30db18",
            "879dd54789d54c63bff62080048bdb7b",
            "de84b765f8bc449e8e9c05ee1995ada7",
            "4afe2b54f702420e9401b9d848f8efc0",
            "db39d052a2794a329f1bcf59c29494fc",
            "496de13ee4854173ab74d361bb0c5073",
            "ead4304dc577443c83101fe73930c3b7",
            "4d54ab3afec64e5ca3e2550aa383a374",
            "7659351a902f4cb9bec834ff6250dc3a",
            "d10270c536c24e6fa6ae2c79417ba9b1",
            "4bbede88a6614d979cdaf20eb1272417",
            "e384ece82520443882bb8d56c7510766",
            "a279306713754e0b8a84e789a38c83f8",
            "8d553621bfce4e66a3e33e84c3d14eee",
            "ee0561c442c0464280d3a5afaf889dc1",
            "b9a3e9a87c474c4d9ceaaba6f000453e",
            "241283bb4fb14349aee1f9609cbf9f8d",
            "f4b780ebac7d42eb9c6dbae53647b274",
            "80629de117f34f7e9450978e03199966",
            "317aba6ea917449cad14cedfa4c9b02b",
            "89eea58eebfc44289fb5a6da4a3a94af",
            "5d0e447decb94da0aff5f95cca837fa3",
            "0a77a4be3dd546e1ac586476e2707759",
            "228de4430715440abe4e6cad5000be07",
            "8b5dd03a9cf8441e8dc2535643d0c895",
            "aa1c39c8da254ffa997893d32f9e3c52",
            "0a6a02404f4b4795889c41dc989ff25a",
            "9247799fdf0f4b65941e8bf4fd4f178c",
            "4c4f9a14b96b4793bdfedc2dc6f46556",
            "8f6b2280927941aab803853f202ae96b",
            "e8d54debf8804744ab600afaa96ac822",
            "f97067a63c2e4cae9f5dc8a638adf9d8",
            "af337f12cca34c1db5aea4664211a34b",
            "74f7f95447b5479bb12777b6b38c4331",
            "2287967c9d8d490eb729d9c07146915f",
            "76427e1858484e4886f98f0e5d604ce8"
          ]
        },
        "id": "nyf79N4nG913",
        "outputId": "875fd0f2-9017-4166-b155-b6190cdc4c32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.57k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b250a2ef81f4b3cb512415406711303"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "383766ae43494cf3a8e15835afdea21f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2554f50683b4ccaa3f00a6a4fb3588d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/703k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e1040d69c8c4f2d9aa571dce192a988"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/294k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4afe2b54f702420e9401b9d848f8efc0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee0561c442c0464280d3a5afaf889dc1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/12.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa1c39c8da254ffa997893d32f9e3c52"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1/10\n",
            "Precision: 0.33, Recall: 0.33, F1 Score: 0.33\n",
            "Run 2/10\n",
            "Precision: 0.55, Recall: 0.60, F1 Score: 0.57\n",
            "Run 3/10\n",
            "Precision: 0.38, Recall: 0.45, F1 Score: 0.42\n",
            "Run 4/10\n",
            "Precision: 0.33, Recall: 0.30, F1 Score: 0.32\n",
            "Run 5/10\n",
            "Precision: 0.47, Recall: 0.80, F1 Score: 0.59\n",
            "Run 6/10\n",
            "Precision: 0.33, Recall: 0.45, F1 Score: 0.38\n",
            "Run 7/10\n",
            "Precision: 0.67, Recall: 0.55, F1 Score: 0.60\n",
            "Run 8/10\n",
            "Precision: 0.33, Recall: 0.29, F1 Score: 0.31\n",
            "Run 9/10\n",
            "Precision: 0.20, Recall: 0.13, F1 Score: 0.16\n",
            "Run 10/10\n",
            "Precision: 0.27, Recall: 0.36, F1 Score: 0.31\n",
            "\n",
            "Mean Training Time: 55256.77 ms\n",
            "Mean Prediction Time: 0.09 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "import random\n",
        "\n",
        "# Check if GPU is available and use it; otherwise, use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/singleton\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)  # Move model to the appropriate device\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":  # Skip empty lines\n",
        "            continue\n",
        "\n",
        "        # Encode the input using the tokenizer\n",
        "        inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to device\n",
        "\n",
        "        # Forward pass through the encoder model\n",
        "        with torch.no_grad():\n",
        "            encoder_outputs = model.encoder(**inputs)  # Use only the encoder part\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = encoder_outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move output to CPU for NumPy conversion\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    if len(line_embeddings) == 0:  # To handle files with no valid lines\n",
        "        return np.zeros((1, model.config.hidden_size))\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Define the number of iterations for the experiment\n",
        "n_runs = 10\n",
        "k = 3  # Number of neighbors to consider\n",
        "training_times = []\n",
        "prediction_times = []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1}/{n_runs}\")\n",
        "\n",
        "    # Separate positive and negative examples\n",
        "    positive_files = [file for file in java_files if \"singleton\" in file]\n",
        "    negative_files = [file for file in java_files if \"singleton\" not in file]\n",
        "\n",
        "    # Select an approximately equal number of positive and negative examples (40%-60% range)\n",
        "    num_positive = len(positive_files)\n",
        "    num_negative = len(negative_files)\n",
        "\n",
        "    lower_bound = int(0.4 * min(num_positive, num_negative))\n",
        "    upper_bound = int(0.6 * min(num_positive, num_negative))\n",
        "\n",
        "    num_samples = random.randint(lower_bound, upper_bound)\n",
        "\n",
        "    positive_sample = random.sample(positive_files, num_samples)\n",
        "    negative_sample = random.sample(negative_files, num_samples)\n",
        "\n",
        "    selected_files = positive_sample + negative_sample\n",
        "    random.shuffle(selected_files)\n",
        "\n",
        "    true_labels = [1] * len(positive_sample) + [0] * len(negative_sample)\n",
        "    program_embeddings = []\n",
        "\n",
        "    # Start training time\n",
        "    start_training_time = time.time()\n",
        "\n",
        "    # Extract embeddings for each file\n",
        "    for file in selected_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "    # Convert to NumPy array\n",
        "    program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "    # Calculate the distance matrix\n",
        "    distance_metric = 'euclidean'  # Can switch between 'cosine' or 'euclidean'\n",
        "    distance_matrix = calculate_distance_matrix(program_embeddings, metric=distance_metric)\n",
        "\n",
        "    # Get k-nearest neighbors indices for each program\n",
        "    knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "    # End training time\n",
        "    end_training_time = time.time()\n",
        "    training_time = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "    training_times.append(training_time)\n",
        "\n",
        "    # Start prediction time\n",
        "    start_prediction_time = time.time()\n",
        "\n",
        "    # Predict labels based on neighbors\n",
        "    predicted_labels = []\n",
        "    for indices in knn_indices:\n",
        "        neighbor_labels = [true_labels[i] for i in indices]\n",
        "        predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "        predicted_labels.append(predicted_label)\n",
        "\n",
        "    # End prediction time\n",
        "    end_prediction_time = time.time()\n",
        "    prediction_time = (end_prediction_time - start_prediction_time) * 1000  # Convert to milliseconds\n",
        "    prediction_times.append(prediction_time)\n",
        "\n",
        "    # Calculate precision, recall, and f1-score\n",
        "    predicted_labels = np.array(predicted_labels)\n",
        "    precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "    recall = recall_score(true_labels, predicted_labels)\n",
        "    f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "    print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Calculate the mean training and prediction times\n",
        "mean_training_time = np.mean(training_times)\n",
        "mean_prediction_time = np.mean(prediction_times)\n",
        "\n",
        "print(f\"\\nMean Training Time: {mean_training_time:.2f} ms\")\n",
        "print(f\"Mean Prediction Time: {mean_prediction_time:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d8jDHWIHb38",
      "metadata": {
        "id": "9d8jDHWIHb38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "664b589d-2d19-4432-9db3-c42e5680722a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1/10\n",
            "Precision: 0.55, Recall: 0.40, F1 Score: 0.46\n",
            "Run 2/10\n",
            "Precision: 0.17, Recall: 0.10, F1 Score: 0.12\n",
            "Run 3/10\n",
            "Precision: 0.60, Recall: 0.60, F1 Score: 0.60\n",
            "Run 4/10\n",
            "Precision: 0.59, Recall: 0.77, F1 Score: 0.67\n",
            "Run 5/10\n",
            "Precision: 0.55, Recall: 0.46, F1 Score: 0.50\n",
            "Run 6/10\n",
            "Precision: 0.50, Recall: 0.60, F1 Score: 0.55\n",
            "Run 7/10\n",
            "Precision: 0.42, Recall: 0.50, F1 Score: 0.45\n",
            "Run 8/10\n",
            "Precision: 0.31, Recall: 0.38, F1 Score: 0.34\n",
            "Run 9/10\n",
            "Precision: 0.64, Recall: 0.50, F1 Score: 0.56\n",
            "Run 10/10\n",
            "Precision: 0.37, Recall: 0.50, F1 Score: 0.42\n",
            "\n",
            "Mean Training Time: 52697.69 ms\n",
            "Mean Prediction Time: 0.10 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "import random\n",
        "\n",
        "# Check if GPU is available and use it; otherwise, use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/singleton\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)  # Move model to the appropriate device\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":  # Skip empty lines\n",
        "            continue\n",
        "\n",
        "        # Encode the input using the tokenizer\n",
        "        inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to device\n",
        "\n",
        "        # Forward pass through the encoder model\n",
        "        with torch.no_grad():\n",
        "            encoder_outputs = model.encoder(**inputs)  # Use only the encoder part\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = encoder_outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move output to CPU for NumPy conversion\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    if len(line_embeddings) == 0:  # To handle files with no valid lines\n",
        "        return np.zeros((1, model.config.hidden_size))\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Define the number of iterations for the experiment\n",
        "n_runs = 10\n",
        "k = 3  # Number of neighbors to consider\n",
        "training_times = []\n",
        "prediction_times = []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1}/{n_runs}\")\n",
        "\n",
        "    # Separate positive and negative examples\n",
        "    positive_files = [file for file in java_files if \"singleton\" in file]\n",
        "    negative_files = [file for file in java_files if \"singleton\" not in file]\n",
        "\n",
        "    # Select an approximately equal number of positive and negative examples (40%-60% range)\n",
        "    num_positive = len(positive_files)\n",
        "    num_negative = len(negative_files)\n",
        "\n",
        "    lower_bound = int(0.4 * min(num_positive, num_negative))\n",
        "    upper_bound = int(0.6 * min(num_positive, num_negative))\n",
        "\n",
        "    num_samples = random.randint(lower_bound, upper_bound)\n",
        "\n",
        "    positive_sample = random.sample(positive_files, num_samples)\n",
        "    negative_sample = random.sample(negative_files, num_samples)\n",
        "\n",
        "    selected_files = positive_sample + negative_sample\n",
        "    random.shuffle(selected_files)\n",
        "\n",
        "    true_labels = [1] * len(positive_sample) + [0] * len(negative_sample)\n",
        "    program_embeddings = []\n",
        "\n",
        "    # Start training time\n",
        "    start_training_time = time.time()\n",
        "\n",
        "    # Extract embeddings for each file\n",
        "    for file in selected_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "    # Convert to NumPy array\n",
        "    program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "    # Calculate the distance matrix\n",
        "    distance_metric = 'euclidean'  # Can switch between 'cosine' or 'euclidean'\n",
        "    distance_matrix = calculate_distance_matrix(program_embeddings, metric=distance_metric)\n",
        "\n",
        "    # Get k-nearest neighbors indices for each program\n",
        "    knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "    # End training time\n",
        "    end_training_time = time.time()\n",
        "    training_time = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "    training_times.append(training_time)\n",
        "\n",
        "    # Start prediction time\n",
        "    start_prediction_time = time.time()\n",
        "\n",
        "    # Predict labels based on neighbors\n",
        "    predicted_labels = []\n",
        "    for indices in knn_indices:\n",
        "        neighbor_labels = [true_labels[i] for i in indices]\n",
        "        predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "        predicted_labels.append(predicted_label)\n",
        "\n",
        "    # End prediction time\n",
        "    end_prediction_time = time.time()\n",
        "    prediction_time = (end_prediction_time - start_prediction_time) * 1000  # Convert to milliseconds\n",
        "    prediction_times.append(prediction_time)\n",
        "\n",
        "    # Calculate precision, recall, and f1-score\n",
        "    predicted_labels = np.array(predicted_labels)\n",
        "    precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "    recall = recall_score(true_labels, predicted_labels)\n",
        "    f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "    print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Calculate the mean training and prediction times\n",
        "mean_training_time = np.mean(training_times)\n",
        "mean_prediction_time = np.mean(prediction_times)\n",
        "\n",
        "print(f\"\\nMean Training Time: {mean_training_time:.2f} ms\")\n",
        "print(f\"Mean Prediction Time: {mean_prediction_time:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "import random\n",
        "\n",
        "# Check if GPU is available and use it; otherwise, use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/singleton\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)  # Move model to the appropriate device\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":  # Skip empty lines\n",
        "            continue\n",
        "\n",
        "        # Encode the input using the tokenizer\n",
        "        inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to device\n",
        "\n",
        "        # Forward pass through the encoder model\n",
        "        with torch.no_grad():\n",
        "            encoder_outputs = model.encoder(**inputs)  # Use only the encoder part\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = encoder_outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move output to CPU for NumPy conversion\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    if len(line_embeddings) == 0:  # To handle files with no valid lines\n",
        "        return np.zeros((1, model.config.hidden_size))\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Define the number of iterations for the experiment\n",
        "n_runs = 10\n",
        "k = 3  # Number of neighbors to consider\n",
        "training_times = []\n",
        "prediction_times = []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1}/{n_runs}\")\n",
        "\n",
        "    # Separate positive and negative examples\n",
        "    positive_files = [file for file in java_files if \"singleton\" in file]\n",
        "    negative_files = [file for file in java_files if \"singleton\" not in file]\n",
        "\n",
        "    # Select an approximately equal number of positive and negative examples (40%-60% range)\n",
        "    num_positive = len(positive_files)\n",
        "    num_negative = len(negative_files)\n",
        "\n",
        "    lower_bound = int(0.4 * min(num_positive, num_negative))\n",
        "    upper_bound = int(0.6 * min(num_positive, num_negative))\n",
        "\n",
        "    num_samples = random.randint(lower_bound, upper_bound)\n",
        "\n",
        "    positive_sample = random.sample(positive_files, num_samples)\n",
        "    negative_sample = random.sample(negative_files, num_samples)\n",
        "\n",
        "    selected_files = positive_sample + negative_sample\n",
        "    random.shuffle(selected_files)\n",
        "\n",
        "    true_labels = [1] * len(positive_sample) + [0] * len(negative_sample)\n",
        "    program_embeddings = []\n",
        "\n",
        "    # Start training time\n",
        "    start_training_time = time.time()\n",
        "\n",
        "    # Extract embeddings for each file\n",
        "    for file in selected_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "    # Convert to NumPy array\n",
        "    program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "    # Calculate the distance matrix\n",
        "    distance_metric = 'euclidean'  # Can switch between 'cosine' or 'euclidean'\n",
        "    distance_matrix = calculate_distance_matrix(program_embeddings, metric=distance_metric)\n",
        "\n",
        "    # Get k-nearest neighbors indices for each program\n",
        "    knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "    # End training time\n",
        "    end_training_time = time.time()\n",
        "    training_time = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "    training_times.append(training_time)\n",
        "\n",
        "    # Start prediction time\n",
        "    start_prediction_time = time.time()\n",
        "\n",
        "    # Predict labels based on neighbors\n",
        "    predicted_labels = []\n",
        "    for indices in knn_indices:\n",
        "        neighbor_labels = [true_labels[i] for i in indices]\n",
        "        predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "        predicted_labels.append(predicted_label)\n",
        "\n",
        "    # End prediction time\n",
        "    end_prediction_time = time.time()\n",
        "    prediction_time = (end_prediction_time - start_prediction_time) * 1000  # Convert to milliseconds\n",
        "    prediction_times.append(prediction_time)\n",
        "\n",
        "    # Calculate precision, recall, and f1-score\n",
        "    predicted_labels = np.array(predicted_labels)\n",
        "    precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "    recall = recall_score(true_labels, predicted_labels)\n",
        "    f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "    print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Calculate the mean training and prediction times\n",
        "mean_training_time = np.mean(training_times)\n",
        "mean_prediction_time = np.mean(prediction_times)\n",
        "\n",
        "print(f\"\\nMean Training Time: {mean_training_time:.2f} ms\")\n",
        "print(f\"Mean Prediction Time: {mean_prediction_time:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfjsPIqAy5aF",
        "outputId": "86ca43f4-b761-4ea4-9d69-fe65976744e9"
      },
      "id": "jfjsPIqAy5aF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1/10\n",
            "Precision: 0.35, Recall: 0.46, F1 Score: 0.40\n",
            "Run 2/10\n",
            "Precision: 0.60, Recall: 0.69, F1 Score: 0.64\n",
            "Run 3/10\n",
            "Precision: 0.53, Recall: 0.67, F1 Score: 0.59\n",
            "Run 4/10\n",
            "Precision: 0.43, Recall: 0.46, F1 Score: 0.44\n",
            "Run 5/10\n",
            "Precision: 0.56, Recall: 0.50, F1 Score: 0.53\n",
            "Run 6/10\n",
            "Precision: 0.37, Recall: 0.47, F1 Score: 0.41\n",
            "Run 7/10\n",
            "Precision: 0.46, Recall: 0.50, F1 Score: 0.48\n",
            "Run 8/10\n",
            "Precision: 0.45, Recall: 0.42, F1 Score: 0.43\n",
            "Run 9/10\n",
            "Precision: 0.27, Recall: 0.25, F1 Score: 0.26\n",
            "Run 10/10\n",
            "Precision: 0.43, Recall: 0.60, F1 Score: 0.50\n",
            "\n",
            "Mean Training Time: 56524.08 ms\n",
            "Mean Prediction Time: 0.11 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculation for prototype**"
      ],
      "metadata": {
        "id": "IA1bIDxt46fT"
      },
      "id": "IA1bIDxt46fT"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "import random\n",
        "\n",
        "# Check if GPU is available and use it; otherwise, use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/singleton\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)  # Move model to the appropriate device\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":  # Skip empty lines\n",
        "            continue\n",
        "\n",
        "        # Encode the input using the tokenizer\n",
        "        inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to device\n",
        "\n",
        "        # Forward pass through the encoder model\n",
        "        with torch.no_grad():\n",
        "            encoder_outputs = model.encoder(**inputs)  # Use only the encoder part\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = encoder_outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move output to CPU for NumPy conversion\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    if len(line_embeddings) == 0:  # To handle files with no valid lines\n",
        "        return np.zeros((1, model.config.hidden_size))\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Define the number of iterations for the experiment\n",
        "n_runs = 10\n",
        "k = 3  # Number of neighbors to consider\n",
        "training_times = []\n",
        "prediction_times = []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1}/{n_runs}\")\n",
        "\n",
        "    # Separate positive and negative examples\n",
        "    positive_files = [file for file in java_files if \"singleton\" in file]\n",
        "    negative_files = [file for file in java_files if \"singleton\" not in file]\n",
        "\n",
        "    # Select an approximately equal number of positive and negative examples (40%-60% range)\n",
        "    num_positive = len(positive_files)\n",
        "    num_negative = len(negative_files)\n",
        "\n",
        "    lower_bound = int(0.4 * min(num_positive, num_negative))\n",
        "    upper_bound = int(0.6 * min(num_positive, num_negative))\n",
        "\n",
        "    num_samples = random.randint(lower_bound, upper_bound)\n",
        "\n",
        "    positive_sample = random.sample(positive_files, num_samples)\n",
        "    negative_sample = random.sample(negative_files, num_samples)\n",
        "\n",
        "    selected_files = positive_sample + negative_sample\n",
        "    random.shuffle(selected_files)\n",
        "\n",
        "    true_labels = [1] * len(positive_sample) + [0] * len(negative_sample)\n",
        "    program_embeddings = []\n",
        "\n",
        "    # Start training time\n",
        "    start_training_time = time.time()\n",
        "\n",
        "    # Extract embeddings for each file\n",
        "    for file in selected_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "    # Convert to NumPy array\n",
        "    program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "    # Calculate the distance matrix\n",
        "    distance_metric = 'euclidean'  # Can switch between 'cosine' or 'euclidean'\n",
        "    distance_matrix = calculate_distance_matrix(program_embeddings, metric=distance_metric)\n",
        "\n",
        "    # Get k-nearest neighbors indices for each program\n",
        "    knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "    # End training time\n",
        "    end_training_time = time.time()\n",
        "    training_time = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "    training_times.append(training_time)\n",
        "\n",
        "    # Start prediction time\n",
        "    start_prediction_time = time.time()\n",
        "\n",
        "    # Predict labels based on neighbors\n",
        "    predicted_labels = []\n",
        "    for indices in knn_indices:\n",
        "        neighbor_labels = [true_labels[i] for i in indices]\n",
        "        predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "        predicted_labels.append(predicted_label)\n",
        "\n",
        "    # End prediction time\n",
        "    end_prediction_time = time.time()\n",
        "    prediction_time = (end_prediction_time - start_prediction_time) * 1000  # Convert to milliseconds\n",
        "    prediction_times.append(prediction_time)\n",
        "\n",
        "    # Calculate precision, recall, and f1-score\n",
        "    predicted_labels = np.array(predicted_labels)\n",
        "    precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "    recall = recall_score(true_labels, predicted_labels)\n",
        "    f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "    print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Calculate the mean training and prediction times\n",
        "mean_training_time = np.mean(training_times)\n",
        "mean_prediction_time = np.mean(prediction_times)\n",
        "\n",
        "print(f\"\\nMean Training Time: {mean_training_time:.2f} ms\")\n",
        "print(f\"Mean Prediction Time: {mean_prediction_time:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVvEsCSE1J4E",
        "outputId": "0344e698-ef38-405c-f0b3-ea12d26dd0a9"
      },
      "id": "bVvEsCSE1J4E",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1/10\n",
            "Precision: 0.70, Recall: 0.47, F1 Score: 0.56\n",
            "Run 2/10\n",
            "Precision: 0.40, Recall: 0.27, F1 Score: 0.32\n",
            "Run 3/10\n",
            "Precision: 1.00, Recall: 0.60, F1 Score: 0.75\n",
            "Run 4/10\n",
            "Precision: 0.53, Recall: 0.67, F1 Score: 0.59\n",
            "Run 5/10\n",
            "Precision: 0.36, Recall: 0.50, F1 Score: 0.42\n",
            "Run 6/10\n",
            "Precision: 0.44, Recall: 0.50, F1 Score: 0.47\n",
            "Run 7/10\n",
            "Precision: 0.60, Recall: 0.60, F1 Score: 0.60\n",
            "Run 8/10\n",
            "Precision: 0.46, Recall: 0.60, F1 Score: 0.52\n",
            "Run 9/10\n",
            "Precision: 0.50, Recall: 0.58, F1 Score: 0.54\n",
            "Run 10/10\n",
            "Precision: 0.67, Recall: 0.67, F1 Score: 0.67\n",
            "\n",
            "Mean Training Time: 62751.02 ms\n",
            "Mean Prediction Time: 0.12 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Builder time calculation**"
      ],
      "metadata": {
        "id": "wTY89_6V7uMg"
      },
      "id": "wTY89_6V7uMg"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "import random\n",
        "\n",
        "# Check if GPU is available and use it; otherwise, use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/builder\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)  # Move model to the appropriate device\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":  # Skip empty lines\n",
        "            continue\n",
        "\n",
        "        # Encode the input using the tokenizer\n",
        "        inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to device\n",
        "\n",
        "        # Forward pass through the encoder model\n",
        "        with torch.no_grad():\n",
        "            encoder_outputs = model.encoder(**inputs)  # Use only the encoder part\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = encoder_outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move output to CPU for NumPy conversion\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    if len(line_embeddings) == 0:  # To handle files with no valid lines\n",
        "        return np.zeros((1, model.config.hidden_size))\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Define the number of iterations for the experiment\n",
        "n_runs = 10\n",
        "k = 3  # Number of neighbors to consider\n",
        "training_times = []\n",
        "prediction_times = []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1}/{n_runs}\")\n",
        "\n",
        "    # Separate positive and negative examples\n",
        "    positive_files = [file for file in java_files if \"builder\" in file]\n",
        "    negative_files = [file for file in java_files if \"builder\" not in file]\n",
        "\n",
        "    # Select an approximately equal number of positive and negative examples (40%-60% range)\n",
        "    num_positive = len(positive_files)\n",
        "    num_negative = len(negative_files)\n",
        "\n",
        "    lower_bound = int(0.4 * min(num_positive, num_negative))\n",
        "    upper_bound = int(0.6 * min(num_positive, num_negative))\n",
        "\n",
        "    num_samples = random.randint(lower_bound, upper_bound)\n",
        "\n",
        "    positive_sample = random.sample(positive_files, num_samples)\n",
        "    negative_sample = random.sample(negative_files, num_samples)\n",
        "\n",
        "    selected_files = positive_sample + negative_sample\n",
        "    random.shuffle(selected_files)\n",
        "\n",
        "    true_labels = [1] * len(positive_sample) + [0] * len(negative_sample)\n",
        "    program_embeddings = []\n",
        "\n",
        "    # Start training time\n",
        "    start_training_time = time.time()\n",
        "\n",
        "    # Extract embeddings for each file\n",
        "    for file in selected_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "    # Convert to NumPy array\n",
        "    program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "    # Calculate the distance matrix\n",
        "    distance_metric = 'euclidean'  # Can switch between 'cosine' or 'euclidean'\n",
        "    distance_matrix = calculate_distance_matrix(program_embeddings, metric=distance_metric)\n",
        "\n",
        "    # Get k-nearest neighbors indices for each program\n",
        "    knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "    # End training time\n",
        "    end_training_time = time.time()\n",
        "    training_time = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "    training_times.append(training_time)\n",
        "\n",
        "    # Start prediction time\n",
        "    start_prediction_time = time.time()\n",
        "\n",
        "    # Predict labels based on neighbors\n",
        "    predicted_labels = []\n",
        "    for indices in knn_indices:\n",
        "        neighbor_labels = [true_labels[i] for i in indices]\n",
        "        predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "        predicted_labels.append(predicted_label)\n",
        "\n",
        "    # End prediction time\n",
        "    end_prediction_time = time.time()\n",
        "    prediction_time = (end_prediction_time - start_prediction_time) * 1000  # Convert to milliseconds\n",
        "    prediction_times.append(prediction_time)\n",
        "\n",
        "    # Calculate precision, recall, and f1-score\n",
        "    predicted_labels = np.array(predicted_labels)\n",
        "    precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "    recall = recall_score(true_labels, predicted_labels)\n",
        "    f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "    print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Calculate the mean training and prediction times\n",
        "mean_training_time = np.mean(training_times)\n",
        "mean_prediction_time = np.mean(prediction_times)\n",
        "\n",
        "print(f\"\\nMean Training Time: {mean_training_time:.2f} ms\")\n",
        "print(f\"Mean Prediction Time: {mean_prediction_time:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTrSy0GX5JiL",
        "outputId": "9bcf90e3-1443-480e-f0d7-7f8d7daa7564"
      },
      "id": "pTrSy0GX5JiL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1/10\n",
            "Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
            "Run 2/10\n",
            "Precision: 0.50, Recall: 0.50, F1 Score: 0.50\n",
            "Run 3/10\n",
            "Precision: 0.20, Recall: 0.25, F1 Score: 0.22\n",
            "Run 4/10\n",
            "Precision: 0.25, Recall: 0.33, F1 Score: 0.29\n",
            "Run 5/10\n",
            "Precision: 0.17, Recall: 0.20, F1 Score: 0.18\n",
            "Run 6/10\n",
            "Precision: 0.20, Recall: 0.25, F1 Score: 0.22\n",
            "Run 7/10\n",
            "Precision: 0.29, Recall: 0.40, F1 Score: 0.33\n",
            "Run 8/10\n",
            "Precision: 0.75, Recall: 1.00, F1 Score: 0.86\n",
            "Run 9/10\n",
            "Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
            "Run 10/10\n",
            "Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
            "\n",
            "Mean Training Time: 27341.18 ms\n",
            "Mean Prediction Time: 0.04 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Specify the directory you want to delete\n",
        "directory_to_delete = '/content/builder'  # Change this to your directory name\n",
        "\n",
        "# Remove the directory\n",
        "shutil.rmtree(directory_to_delete)\n"
      ],
      "metadata": {
        "id": "_LrVOuSi9aLy"
      },
      "id": "_LrVOuSi9aLy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Builder time calculation**"
      ],
      "metadata": {
        "id": "WvKFJYXY9Jhe"
      },
      "id": "WvKFJYXY9Jhe"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "import random\n",
        "\n",
        "# Check if GPU is available and use it; otherwise, use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/builder\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)  # Move model to the appropriate device\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":  # Skip empty lines\n",
        "            continue\n",
        "\n",
        "        # Encode the input using the tokenizer\n",
        "        inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to device\n",
        "\n",
        "        # Forward pass through the encoder model\n",
        "        with torch.no_grad():\n",
        "            encoder_outputs = model.encoder(**inputs)  # Use only the encoder part\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = encoder_outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move output to CPU for NumPy conversion\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    if len(line_embeddings) == 0:  # To handle files with no valid lines\n",
        "        return np.zeros((1, model.config.hidden_size))\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Define the number of iterations for the experiment\n",
        "n_runs = 10\n",
        "k = 3  # Number of neighbors to consider\n",
        "training_times = []\n",
        "prediction_times = []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1}/{n_runs}\")\n",
        "\n",
        "    # Separate positive and negative examples\n",
        "    positive_files = [file for file in java_files if \"builder\" in file]\n",
        "    negative_files = [file for file in java_files if \"builder\" not in file]\n",
        "\n",
        "    # Select an approximately equal number of positive and negative examples (40%-60% range)\n",
        "    num_positive = len(positive_files)\n",
        "    num_negative = len(negative_files)\n",
        "\n",
        "    lower_bound = int(0.4 * min(num_positive, num_negative))\n",
        "    upper_bound = int(0.6 * min(num_positive, num_negative))\n",
        "\n",
        "    num_samples = random.randint(lower_bound, upper_bound)\n",
        "\n",
        "    positive_sample = random.sample(positive_files, num_samples)\n",
        "    negative_sample = random.sample(negative_files, num_samples)\n",
        "\n",
        "    selected_files = positive_sample + negative_sample\n",
        "    random.shuffle(selected_files)\n",
        "\n",
        "    true_labels = [1] * len(positive_sample) + [0] * len(negative_sample)\n",
        "    program_embeddings = []\n",
        "\n",
        "    # Start training time\n",
        "    start_training_time = time.time()\n",
        "\n",
        "    # Extract embeddings for each file\n",
        "    for file in selected_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "    # Convert to NumPy array\n",
        "    program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "    # Calculate the distance matrix\n",
        "    distance_metric = 'euclidean'  # Can switch between 'cosine' or 'euclidean'\n",
        "    distance_matrix = calculate_distance_matrix(program_embeddings, metric=distance_metric)\n",
        "\n",
        "    # Get k-nearest neighbors indices for each program\n",
        "    knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "    # End training time\n",
        "    end_training_time = time.time()\n",
        "    training_time = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "    training_times.append(training_time)\n",
        "\n",
        "    # Start prediction time\n",
        "    start_prediction_time = time.time()\n",
        "\n",
        "    # Predict labels based on neighbors\n",
        "    predicted_labels = []\n",
        "    for indices in knn_indices:\n",
        "        neighbor_labels = [true_labels[i] for i in indices]\n",
        "        predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "        predicted_labels.append(predicted_label)\n",
        "\n",
        "    # End prediction time\n",
        "    end_prediction_time = time.time()\n",
        "    prediction_time = (end_prediction_time - start_prediction_time) * 1000  # Convert to milliseconds\n",
        "    prediction_times.append(prediction_time)\n",
        "\n",
        "    # Calculate precision, recall, and f1-score\n",
        "    predicted_labels = np.array(predicted_labels)\n",
        "    precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "    recall = recall_score(true_labels, predicted_labels)\n",
        "    f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "    print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Calculate the mean training and prediction times\n",
        "mean_training_time = np.mean(training_times)\n",
        "mean_prediction_time = np.mean(prediction_times)\n",
        "\n",
        "print(f\"\\nMean Training Time: {mean_training_time:.2f} ms\")\n",
        "print(f\"Mean Prediction Time: {mean_prediction_time:.2f} ms\")\n"
      ],
      "metadata": {
        "id": "AtU7Pn_G8FJB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eed7495c-83e3-4bdb-afb5-a5ae2ec67210"
      },
      "id": "AtU7Pn_G8FJB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1/10\n",
            "Precision: 0.33, Recall: 0.20, F1 Score: 0.25\n",
            "Run 2/10\n",
            "Precision: 1.00, Recall: 0.67, F1 Score: 0.80\n",
            "Run 3/10\n",
            "Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
            "Run 4/10\n",
            "Precision: 0.33, Recall: 0.25, F1 Score: 0.29\n",
            "Run 5/10\n",
            "Precision: 0.67, Recall: 0.50, F1 Score: 0.57\n",
            "Run 6/10\n",
            "Precision: 0.67, Recall: 0.67, F1 Score: 0.67\n",
            "Run 7/10\n",
            "Precision: 0.50, Recall: 0.20, F1 Score: 0.29\n",
            "Run 8/10\n",
            "Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
            "Run 9/10\n",
            "Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
            "Run 10/10\n",
            "Precision: 0.25, Recall: 0.33, F1 Score: 0.29\n",
            "\n",
            "Mean Training Time: 24367.04 ms\n",
            "Mean Prediction Time: 0.04 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Abstract Factory time calculation**"
      ],
      "metadata": {
        "id": "YbyfWVzr_Ej4"
      },
      "id": "YbyfWVzr_Ej4"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "import random\n",
        "\n",
        "# Check if GPU is available and use it; otherwise, use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/abstractfactory\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)  # Move model to the appropriate device\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":  # Skip empty lines\n",
        "            continue\n",
        "\n",
        "        # Encode the input using the tokenizer\n",
        "        inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to device\n",
        "\n",
        "        # Forward pass through the encoder model\n",
        "        with torch.no_grad():\n",
        "            encoder_outputs = model.encoder(**inputs)  # Use only the encoder part\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = encoder_outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move output to CPU for NumPy conversion\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    if len(line_embeddings) == 0:  # To handle files with no valid lines\n",
        "        return np.zeros((1, model.config.hidden_size))\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Define the number of iterations for the experiment\n",
        "n_runs = 10\n",
        "k = 3  # Number of neighbors to consider\n",
        "training_times = []\n",
        "prediction_times = []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1}/{n_runs}\")\n",
        "\n",
        "    # Separate positive and negative examples\n",
        "    positive_files = [file for file in java_files if \"abstractfactory\" in file]\n",
        "    negative_files = [file for file in java_files if \"abstractfactory\" not in file]\n",
        "\n",
        "    # Select an approximately equal number of positive and negative examples (40%-60% range)\n",
        "    num_positive = len(positive_files)\n",
        "    num_negative = len(negative_files)\n",
        "\n",
        "    lower_bound = int(0.4 * min(num_positive, num_negative))\n",
        "    upper_bound = int(0.6 * min(num_positive, num_negative))\n",
        "\n",
        "    num_samples = random.randint(lower_bound, upper_bound)\n",
        "\n",
        "    positive_sample = random.sample(positive_files, num_samples)\n",
        "    negative_sample = random.sample(negative_files, num_samples)\n",
        "\n",
        "    selected_files = positive_sample + negative_sample\n",
        "    random.shuffle(selected_files)\n",
        "\n",
        "    true_labels = [1] * len(positive_sample) + [0] * len(negative_sample)\n",
        "    program_embeddings = []\n",
        "\n",
        "    # Start training time\n",
        "    start_training_time = time.time()\n",
        "\n",
        "    # Extract embeddings for each file\n",
        "    for file in selected_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "    # Convert to NumPy array\n",
        "    program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "    # Calculate the distance matrix\n",
        "    distance_metric = 'euclidean'  # Can switch between 'cosine' or 'euclidean'\n",
        "    distance_matrix = calculate_distance_matrix(program_embeddings, metric=distance_metric)\n",
        "\n",
        "    # Get k-nearest neighbors indices for each program\n",
        "    knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "    # End training time\n",
        "    end_training_time = time.time()\n",
        "    training_time = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "    training_times.append(training_time)\n",
        "\n",
        "    # Start prediction time\n",
        "    start_prediction_time = time.time()\n",
        "\n",
        "    # Predict labels based on neighbors\n",
        "    predicted_labels = []\n",
        "    for indices in knn_indices:\n",
        "        neighbor_labels = [true_labels[i] for i in indices]\n",
        "        predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "        predicted_labels.append(predicted_label)\n",
        "\n",
        "    # End prediction time\n",
        "    end_prediction_time = time.time()\n",
        "    prediction_time = (end_prediction_time - start_prediction_time) * 1000  # Convert to milliseconds\n",
        "    prediction_times.append(prediction_time)\n",
        "\n",
        "    # Calculate precision, recall, and f1-score\n",
        "    predicted_labels = np.array(predicted_labels)\n",
        "    precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "    recall = recall_score(true_labels, predicted_labels)\n",
        "    f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "    print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Calculate the mean training and prediction times\n",
        "mean_training_time = np.mean(training_times)\n",
        "mean_prediction_time = np.mean(prediction_times)\n",
        "\n",
        "print(f\"\\nMean Training Time: {mean_training_time:.2f} ms\")\n",
        "print(f\"Mean Prediction Time: {mean_prediction_time:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlG64-UE-Fjy",
        "outputId": "b17f975c-5e8c-4e18-92a7-261d6c0dec80"
      },
      "id": "rlG64-UE-Fjy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1/10\n",
            "Precision: 0.50, Recall: 0.50, F1 Score: 0.50\n",
            "Run 2/10\n",
            "Precision: 0.44, Recall: 0.44, F1 Score: 0.44\n",
            "Run 3/10\n",
            "Precision: 0.71, Recall: 0.83, F1 Score: 0.77\n",
            "Run 4/10\n",
            "Precision: 0.67, Recall: 0.86, F1 Score: 0.75\n",
            "Run 5/10\n",
            "Precision: 0.78, Recall: 0.88, F1 Score: 0.82\n",
            "Run 6/10\n",
            "Precision: 0.50, Recall: 0.43, F1 Score: 0.46\n",
            "Run 7/10\n",
            "Precision: 0.60, Recall: 0.50, F1 Score: 0.55\n",
            "Run 8/10\n",
            "Precision: 0.43, Recall: 0.50, F1 Score: 0.46\n",
            "Run 9/10\n",
            "Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
            "Run 10/10\n",
            "Precision: 0.17, Recall: 0.14, F1 Score: 0.15\n",
            "\n",
            "Mean Training Time: 23333.28 ms\n",
            "Mean Prediction Time: 0.06 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Abstract Factory time calculation**"
      ],
      "metadata": {
        "id": "ZDU0UzLvA3go"
      },
      "id": "ZDU0UzLvA3go"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "import random\n",
        "\n",
        "# Check if GPU is available and use it; otherwise, use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/abstractfactory\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)  # Move model to the appropriate device\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":  # Skip empty lines\n",
        "            continue\n",
        "\n",
        "        # Encode the input using the tokenizer\n",
        "        inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to device\n",
        "\n",
        "        # Forward pass through the encoder model\n",
        "        with torch.no_grad():\n",
        "            encoder_outputs = model.encoder(**inputs)  # Use only the encoder part\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = encoder_outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move output to CPU for NumPy conversion\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    if len(line_embeddings) == 0:  # To handle files with no valid lines\n",
        "        return np.zeros((1, model.config.hidden_size))\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Define the number of iterations for the experiment\n",
        "n_runs = 10\n",
        "k = 3  # Number of neighbors to consider\n",
        "training_times = []\n",
        "prediction_times = []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1}/{n_runs}\")\n",
        "\n",
        "    # Separate positive and negative examples\n",
        "    positive_files = [file for file in java_files if \"abstractfactory\" in file]\n",
        "    negative_files = [file for file in java_files if \"abstractfactory\" not in file]\n",
        "\n",
        "    # Select an approximately equal number of positive and negative examples (40%-60% range)\n",
        "    num_positive = len(positive_files)\n",
        "    num_negative = len(negative_files)\n",
        "\n",
        "    lower_bound = int(0.4 * min(num_positive, num_negative))\n",
        "    upper_bound = int(0.6 * min(num_positive, num_negative))\n",
        "\n",
        "    num_samples = random.randint(lower_bound, upper_bound)\n",
        "\n",
        "    positive_sample = random.sample(positive_files, num_samples)\n",
        "    negative_sample = random.sample(negative_files, num_samples)\n",
        "\n",
        "    selected_files = positive_sample + negative_sample\n",
        "    random.shuffle(selected_files)\n",
        "\n",
        "    true_labels = [1] * len(positive_sample) + [0] * len(negative_sample)\n",
        "    program_embeddings = []\n",
        "\n",
        "    # Start training time\n",
        "    start_training_time = time.time()\n",
        "\n",
        "    # Extract embeddings for each file\n",
        "    for file in selected_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "    # Convert to NumPy array\n",
        "    program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "    # Calculate the distance matrix\n",
        "    distance_metric = 'euclidean'  # Can switch between 'cosine' or 'euclidean'\n",
        "    distance_matrix = calculate_distance_matrix(program_embeddings, metric=distance_metric)\n",
        "\n",
        "    # Get k-nearest neighbors indices for each program\n",
        "    knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "    # End training time\n",
        "    end_training_time = time.time()\n",
        "    training_time = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "    training_times.append(training_time)\n",
        "\n",
        "    # Start prediction time\n",
        "    start_prediction_time = time.time()\n",
        "\n",
        "    # Predict labels based on neighbors\n",
        "    predicted_labels = []\n",
        "    for indices in knn_indices:\n",
        "        neighbor_labels = [true_labels[i] for i in indices]\n",
        "        predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "        predicted_labels.append(predicted_label)\n",
        "\n",
        "    # End prediction time\n",
        "    end_prediction_time = time.time()\n",
        "    prediction_time = (end_prediction_time - start_prediction_time) * 1000  # Convert to milliseconds\n",
        "    prediction_times.append(prediction_time)\n",
        "\n",
        "    # Calculate precision, recall, and f1-score\n",
        "    predicted_labels = np.array(predicted_labels)\n",
        "    precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "    recall = recall_score(true_labels, predicted_labels)\n",
        "    f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "    print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Calculate the mean training and prediction times\n",
        "mean_training_time = np.mean(training_times)\n",
        "mean_prediction_time = np.mean(prediction_times)\n",
        "\n",
        "print(f\"\\nMean Training Time: {mean_training_time:.2f} ms\")\n",
        "print(f\"Mean Prediction Time: {mean_prediction_time:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pg2sy2un_dTi",
        "outputId": "6b9a1119-8a7c-493a-ca7b-5b268c321432"
      },
      "id": "Pg2sy2un_dTi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1/10\n",
            "Precision: 1.00, Recall: 0.71, F1 Score: 0.83\n",
            "Run 2/10\n",
            "Precision: 0.50, Recall: 0.57, F1 Score: 0.53\n",
            "Run 3/10\n",
            "Precision: 0.60, Recall: 0.50, F1 Score: 0.55\n",
            "Run 4/10\n",
            "Precision: 0.45, Recall: 0.56, F1 Score: 0.50\n",
            "Run 5/10\n",
            "Precision: 0.71, Recall: 0.62, F1 Score: 0.67\n",
            "Run 6/10\n",
            "Precision: 0.62, Recall: 0.89, F1 Score: 0.73\n",
            "Run 7/10\n",
            "Precision: 0.50, Recall: 0.71, F1 Score: 0.59\n",
            "Run 8/10\n",
            "Precision: 0.67, Recall: 1.00, F1 Score: 0.80\n",
            "Run 9/10\n",
            "Precision: 0.71, Recall: 0.62, F1 Score: 0.67\n",
            "Run 10/10\n",
            "Precision: 0.29, Recall: 0.22, F1 Score: 0.25\n",
            "\n",
            "Mean Training Time: 25789.83 ms\n",
            "Mean Prediction Time: 0.07 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Factory method time calculation**"
      ],
      "metadata": {
        "id": "Wdk9KZlPG-Fs"
      },
      "id": "Wdk9KZlPG-Fs"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "import random\n",
        "\n",
        "# Check if GPU is available and use it; otherwise, use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/factorymethod\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)  # Move model to the appropriate device\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":  # Skip empty lines\n",
        "            continue\n",
        "\n",
        "        # Encode the input using the tokenizer\n",
        "        inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to device\n",
        "\n",
        "        # Forward pass through the encoder model\n",
        "        with torch.no_grad():\n",
        "            encoder_outputs = model.encoder(**inputs)  # Use only the encoder part\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = encoder_outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move output to CPU for NumPy conversion\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    if len(line_embeddings) == 0:  # To handle files with no valid lines\n",
        "        return np.zeros((1, model.config.hidden_size))\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Define the number of iterations for the experiment\n",
        "n_runs = 10\n",
        "k = 3  # Number of neighbors to consider\n",
        "training_times = []\n",
        "prediction_times = []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1}/{n_runs}\")\n",
        "\n",
        "    # Separate positive and negative examples\n",
        "    positive_files = [file for file in java_files if \"factorymethod\" in file]\n",
        "    negative_files = [file for file in java_files if \"factorymethod\" not in file]\n",
        "\n",
        "    # Select an approximately equal number of positive and negative examples (40%-60% range)\n",
        "    num_positive = len(positive_files)\n",
        "    num_negative = len(negative_files)\n",
        "\n",
        "    lower_bound = int(0.4 * min(num_positive, num_negative))\n",
        "    upper_bound = int(0.6 * min(num_positive, num_negative))\n",
        "\n",
        "    num_samples = random.randint(lower_bound, upper_bound)\n",
        "\n",
        "    positive_sample = random.sample(positive_files, num_samples)\n",
        "    negative_sample = random.sample(negative_files, num_samples)\n",
        "\n",
        "    selected_files = positive_sample + negative_sample\n",
        "    random.shuffle(selected_files)\n",
        "\n",
        "    true_labels = [1] * len(positive_sample) + [0] * len(negative_sample)\n",
        "    program_embeddings = []\n",
        "\n",
        "    # Start training time\n",
        "    start_training_time = time.time()\n",
        "\n",
        "    # Extract embeddings for each file\n",
        "    for file in selected_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "    # Convert to NumPy array\n",
        "    program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "    # Calculate the distance matrix\n",
        "    distance_metric = 'euclidean'  # Can switch between 'cosine' or 'euclidean'\n",
        "    distance_matrix = calculate_distance_matrix(program_embeddings, metric=distance_metric)\n",
        "\n",
        "    # Get k-nearest neighbors indices for each program\n",
        "    knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "    # End training time\n",
        "    end_training_time = time.time()\n",
        "    training_time = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "    training_times.append(training_time)\n",
        "\n",
        "    # Start prediction time\n",
        "    start_prediction_time = time.time()\n",
        "\n",
        "    # Predict labels based on neighbors\n",
        "    predicted_labels = []\n",
        "    for indices in knn_indices:\n",
        "        neighbor_labels = [true_labels[i] for i in indices]\n",
        "        predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "        predicted_labels.append(predicted_label)\n",
        "\n",
        "    # End prediction time\n",
        "    end_prediction_time = time.time()\n",
        "    prediction_time = (end_prediction_time - start_prediction_time) * 1000  # Convert to milliseconds\n",
        "    prediction_times.append(prediction_time)\n",
        "\n",
        "    # Calculate precision, recall, and f1-score\n",
        "    predicted_labels = np.array(predicted_labels)\n",
        "    precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "    recall = recall_score(true_labels, predicted_labels)\n",
        "    f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "    print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Calculate the mean training and prediction times\n",
        "mean_training_time = np.mean(training_times)\n",
        "mean_prediction_time = np.mean(prediction_times)\n",
        "\n",
        "print(f\"\\nMean Training Time: {mean_training_time:.2f} ms\")\n",
        "print(f\"Mean Prediction Time: {mean_prediction_time:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRfbcQKKA7sr",
        "outputId": "c61419dd-b2e8-4cb2-eda2-024d439cdd10"
      },
      "id": "IRfbcQKKA7sr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1/10\n",
            "Precision: 0.29, Recall: 0.40, F1 Score: 0.33\n",
            "Run 2/10\n",
            "Precision: 0.20, Recall: 0.20, F1 Score: 0.20\n",
            "Run 3/10\n",
            "Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
            "Run 4/10\n",
            "Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
            "Run 5/10\n",
            "Precision: 1.00, Recall: 0.25, F1 Score: 0.40\n",
            "Run 6/10\n",
            "Precision: 0.50, Recall: 0.25, F1 Score: 0.33\n",
            "Run 7/10\n",
            "Precision: 0.29, Recall: 0.33, F1 Score: 0.31\n",
            "Run 8/10\n",
            "Precision: 0.75, Recall: 0.60, F1 Score: 0.67\n",
            "Run 9/10\n",
            "Precision: 0.33, Recall: 0.20, F1 Score: 0.25\n",
            "Run 10/10\n",
            "Precision: 0.33, Recall: 0.25, F1 Score: 0.29\n",
            "\n",
            "Mean Training Time: 24440.02 ms\n",
            "Mean Prediction Time: 0.05 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Factory method time calculation**"
      ],
      "metadata": {
        "id": "0bCDkFskKBcu"
      },
      "id": "0bCDkFskKBcu"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "import random\n",
        "\n",
        "# Check if GPU is available and use it; otherwise, use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/factorymethod\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)  # Move model to the appropriate device\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":  # Skip empty lines\n",
        "            continue\n",
        "\n",
        "        # Encode the input using the tokenizer\n",
        "        inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to device\n",
        "\n",
        "        # Forward pass through the encoder model\n",
        "        with torch.no_grad():\n",
        "            encoder_outputs = model.encoder(**inputs)  # Use only the encoder part\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = encoder_outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move output to CPU for NumPy conversion\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    if len(line_embeddings) == 0:  # To handle files with no valid lines\n",
        "        return np.zeros((1, model.config.hidden_size))\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Define the number of iterations for the experiment\n",
        "n_runs = 10\n",
        "k = 3  # Number of neighbors to consider\n",
        "training_times = []\n",
        "prediction_times = []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1}/{n_runs}\")\n",
        "\n",
        "    # Separate positive and negative examples\n",
        "    positive_files = [file for file in java_files if \"factorymethod\" in file]\n",
        "    negative_files = [file for file in java_files if \"factorymethod\" not in file]\n",
        "\n",
        "    # Select an approximately equal number of positive and negative examples (40%-60% range)\n",
        "    num_positive = len(positive_files)\n",
        "    num_negative = len(negative_files)\n",
        "\n",
        "    lower_bound = int(0.4 * min(num_positive, num_negative))\n",
        "    upper_bound = int(0.6 * min(num_positive, num_negative))\n",
        "\n",
        "    num_samples = random.randint(lower_bound, upper_bound)\n",
        "\n",
        "    positive_sample = random.sample(positive_files, num_samples)\n",
        "    negative_sample = random.sample(negative_files, num_samples)\n",
        "\n",
        "    selected_files = positive_sample + negative_sample\n",
        "    random.shuffle(selected_files)\n",
        "\n",
        "    true_labels = [1] * len(positive_sample) + [0] * len(negative_sample)\n",
        "    program_embeddings = []\n",
        "\n",
        "    # Start training time\n",
        "    start_training_time = time.time()\n",
        "\n",
        "    # Extract embeddings for each file\n",
        "    for file in selected_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "    # Convert to NumPy array\n",
        "    program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "    # Calculate the distance matrix\n",
        "    distance_metric = 'euclidean'  # Can switch between 'cosine' or 'euclidean'\n",
        "    distance_matrix = calculate_distance_matrix(program_embeddings, metric=distance_metric)\n",
        "\n",
        "    # Get k-nearest neighbors indices for each program\n",
        "    knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "    # End training time\n",
        "    end_training_time = time.time()\n",
        "    training_time = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "    training_times.append(training_time)\n",
        "\n",
        "    # Start prediction time\n",
        "    start_prediction_time = time.time()\n",
        "\n",
        "    # Predict labels based on neighbors\n",
        "    predicted_labels = []\n",
        "    for indices in knn_indices:\n",
        "        neighbor_labels = [true_labels[i] for i in indices]\n",
        "        predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "        predicted_labels.append(predicted_label)\n",
        "\n",
        "    # End prediction time\n",
        "    end_prediction_time = time.time()\n",
        "    prediction_time = (end_prediction_time - start_prediction_time) * 1000  # Convert to milliseconds\n",
        "    prediction_times.append(prediction_time)\n",
        "\n",
        "    # Calculate precision, recall, and f1-score\n",
        "    predicted_labels = np.array(predicted_labels)\n",
        "    precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "    recall = recall_score(true_labels, predicted_labels)\n",
        "    f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "    print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Calculate the mean training and prediction times\n",
        "mean_training_time = np.mean(training_times)\n",
        "mean_prediction_time = np.mean(prediction_times)\n",
        "\n",
        "print(f\"\\nMean Training Time: {mean_training_time:.2f} ms\")\n",
        "print(f\"Mean Prediction Time: {mean_prediction_time:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nS1AE63THtN9",
        "outputId": "423a1031-b011-42cb-eb62-f99bf7faf61b"
      },
      "id": "nS1AE63THtN9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1/10\n",
            "Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
            "Run 2/10\n",
            "Precision: 0.50, Recall: 0.50, F1 Score: 0.50\n",
            "Run 3/10\n",
            "Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
            "Run 4/10\n",
            "Precision: 0.00, Recall: 0.00, F1 Score: 0.00\n",
            "Run 5/10\n",
            "Precision: 0.43, Recall: 0.75, F1 Score: 0.55\n",
            "Run 6/10\n",
            "Precision: 0.40, Recall: 0.40, F1 Score: 0.40\n",
            "Run 7/10\n",
            "Precision: 0.40, Recall: 0.50, F1 Score: 0.44\n",
            "Run 8/10\n",
            "Precision: 0.86, Recall: 1.00, F1 Score: 0.92\n",
            "Run 9/10\n",
            "Precision: 0.25, Recall: 0.25, F1 Score: 0.25\n",
            "Run 10/10\n",
            "Precision: 0.33, Recall: 0.40, F1 Score: 0.36\n",
            "\n",
            "Mean Training Time: 21695.20 ms\n",
            "Mean Prediction Time: 0.05 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Silhouette Score Davies-Bouldin Index calculation**"
      ],
      "metadata": {
        "id": "3FvhdPUqMg2g"
      },
      "id": "3FvhdPUqMg2g"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "import random\n",
        "\n",
        "# Check if GPU is available and use it; otherwise, use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the directory containing Java programs of different design patterns\n",
        "java_code_dir = \"/content/design_patterns\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)  # Move model to the appropriate device\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":  # Skip empty lines\n",
        "            continue\n",
        "\n",
        "        # Encode the input using the tokenizer\n",
        "        inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to device\n",
        "\n",
        "        # Forward pass through the encoder model\n",
        "        with torch.no_grad():\n",
        "            encoder_outputs = model.encoder(**inputs)  # Use only the encoder part\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = encoder_outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move output to CPU for NumPy conversion\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    if len(line_embeddings) == 0:  # To handle files with no valid lines\n",
        "        return np.zeros((1, model.config.hidden_size))\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Function to get design pattern label based on the file name\n",
        "def get_design_pattern_label(file_name):\n",
        "    if file_name.startswith(\"singleton\"):\n",
        "        return 0  # Singleton\n",
        "    elif file_name.startswith(\"builder\"):\n",
        "        return 1  # Builder\n",
        "    elif file_name.startswith(\"abstractfactory\"):\n",
        "        return 2  # Abstract Factory\n",
        "    elif file_name.startswith(\"prototype\"):\n",
        "        return 3  # Prototype\n",
        "    elif file_name.startswith(\"factorymethod\"):\n",
        "        return 4  # Factory Method\n",
        "    else:\n",
        "        return -1  # Unknown, but ideally should not happen\n",
        "\n",
        "# Define the number of iterations for the experiment\n",
        "n_runs = 10\n",
        "training_times = []\n",
        "prediction_times = []\n",
        "silhouette_scores = []\n",
        "db_scores = []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1}/{n_runs}\")\n",
        "\n",
        "    # Select files for each design pattern\n",
        "    singleton_files = [file for file in java_files if file.startswith(\"singleton\")]\n",
        "    builder_files = [file for file in java_files if file.startswith(\"builder\")]\n",
        "    abstractfactory_files = [file for file in java_files if file.startswith(\"abstractfactory\")]\n",
        "    prototype_files = [file for file in java_files if file.startswith(\"prototype\")]\n",
        "    factorymethod_files = [file for file in java_files if file.startswith(\"factorymethod\")]\n",
        "\n",
        "    # Collect all files\n",
        "    selected_files = singleton_files + builder_files + abstractfactory_files + prototype_files + factorymethod_files\n",
        "    random.shuffle(selected_files)\n",
        "\n",
        "    # Get true labels (design pattern labels) for the files\n",
        "    true_labels = [get_design_pattern_label(file) for file in selected_files]\n",
        "    program_embeddings = []\n",
        "\n",
        "    # Start training time\n",
        "    start_training_time = time.time()\n",
        "\n",
        "    # Extract embeddings for each file\n",
        "    for file in selected_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "    # Convert to NumPy array\n",
        "    program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "    # End training time\n",
        "    end_training_time = time.time()\n",
        "    training_time = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "    training_times.append(training_time)\n",
        "\n",
        "    # Calculate clustering metrics: Silhouette Score and Davies-Bouldin Index\n",
        "    distance_metric = 'euclidean'  # Can switch between 'cosine' or 'euclidean'\n",
        "\n",
        "    # Check if all labels are identical, which would make silhouette score invalid\n",
        "    if len(set(true_labels)) > 1:\n",
        "        silhouette = silhouette_score(program_embeddings, true_labels, metric=distance_metric)\n",
        "        db_index = davies_bouldin_score(program_embeddings, true_labels)\n",
        "    else:\n",
        "        silhouette = np.nan  # Not applicable if all labels are the same\n",
        "        db_index = np.nan  # Not applicable if all labels are the same\n",
        "\n",
        "    silhouette_scores.append(silhouette)\n",
        "    db_scores.append(db_index)\n",
        "\n",
        "    print(f\"Silhouette Score: {silhouette:.2f}, Davies-Bouldin Index: {db_index:.2f}\")\n",
        "\n",
        "# Calculate the mean training and prediction times\n",
        "mean_training_time = np.mean(training_times)\n",
        "mean_silhouette_score = np.nanmean(silhouette_scores)  # Handle NaN values\n",
        "mean_db_score = np.nanmean(db_scores)  # Handle NaN values\n",
        "\n",
        "print(f\"\\nMean Training Time: {mean_training_time:.2f} ms\")\n",
        "print(f\"Mean Silhouette Score: {mean_silhouette_score:.2f}\")\n",
        "print(f\"Mean Davies-Bouldin Index: {mean_db_score:.2f}\")\n"
      ],
      "metadata": {
        "id": "5IRBvHkpKGff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816,
          "referenced_widgets": [
            "c30e83596fd7412abb93b7795359c11a",
            "9152216417b049c7811cb7d540deab61",
            "e897b9d06d1e4ae2a5d29086f2e58a42",
            "1f5e550c9b52499f8ab5a171404921a6",
            "f1c4d0fd95ab42feab9567fd35b30369",
            "a607aa03afb44bdebd45f8bdce83c83e",
            "93862745866b4b779e83024368054979",
            "327c1956189a44cc9ab6cae16f8cad24",
            "658ecfb89ffc4c769a56e5203b96b971",
            "0db6c09cad9746819c3289b8a4eb1699",
            "c384f0b4a06948f2af301c09a80a6e61",
            "06a79f69457a41628abd36e3d4a7f7ac",
            "30d944a8b9da4f6c9383f3ad28f609a5",
            "45d45318ec4f4b788ee2adbc00984216",
            "26b737c02b41438395104efab176521c",
            "ba018e548e6945989e0d70fd9b99dce3",
            "588265bf338a4447b5551c85f81b8df9",
            "ce221d5498e14e1a8b2cb1dd04eda902",
            "73ccd90cf2734461ad0054f2edc64b93",
            "229584f190ff4309a5492cccab44bdc3",
            "a03803ce8eed4ff5b522beb152c35ff5",
            "8bf4b8878b3b4634a7c86e73e74f0f84",
            "55ffab93822b45faa023dfd1d680153f",
            "9462a6f702b24a97aea8daf21eeadbe0",
            "c06bd4d45faf4099867d6170f37e8b85",
            "dc4d414e4fb947c98df658cfe277dd05",
            "942a3237ba494e91b121ca44c6735f9a",
            "938ffd053e8f40fb97902a47e44812ef",
            "03037aa9b1a84c798f9756a6be103f61",
            "4cc79f3d3b86475082264de5dcf4a74a",
            "48e50b00e11d47c088b27cb3ead7ef07",
            "0cd9ced173c14542bfa70e80fad83239",
            "d232754bded143aa8f8b5ff4686a5762",
            "548bafff4052489cbdcf6a487efa8680",
            "82ca21b1e9e74024b323344b9f09b03b",
            "c2135a9aacd4414f8777ba2ab3810593",
            "4bc47da38b86429d967d19177e11566d",
            "8b420ef77bf84ca0bbdb4fa8e4349f58",
            "af87ac3084d34171be9e17ea015af189",
            "369f0baca06146c78756f63a30ec6838",
            "88a14864173545899d18c7c1a44ff771",
            "393c77192ff543a9813e97e451e88bb1",
            "ec50a742746c4e01870d79cf2d4ab16c",
            "894c787cbc0149b19396b21ea294f52d",
            "a436c740784046ab8cab0e9e24fc065c",
            "3bb04892e470428cb8c2726ca73cbdb5",
            "48bb24bdff7a4e7a8e235fb41a34014a",
            "e9ad595c766b4609a0077bfe13c5d68a",
            "48ff6a1e30d14a44a7c5c4581d3f0970",
            "a912ed65edec4470b7559bacaa5e8705",
            "232c367cc55a4231a7b387e254e24034",
            "ad478a8cc4994de482dbafefefbf9f2b",
            "667137a8ec884343929ab504fc351a44",
            "ed9d129e090041feae62ac3823849b8c",
            "48c7d4dbea044322b67ce73c5001063c",
            "f444e1f4d18c41f8920d85a0ff00dc0a",
            "6c7f44ade6ac4a5794f23f21708160c6",
            "c39a89944455488e9ef36b91bdf8c2a0",
            "52116dcaa3284154ae10a9260c1047d2",
            "87ad63d983af4382a379b8bcc98b416a",
            "3228bd816090448bbc16a9c066715acb",
            "0746ede38c724de5b6e3d223f71b30a6",
            "eac8f917e36a471cbf3de196aeb40bc8",
            "bb3fe6edf4fa488da58667bca3630372",
            "340a61cfc68d4133ad45404f88653b26",
            "2031be89d5154c8fb551b26e2ba03a32",
            "b9cbe66e4be94e658d0355604428f873",
            "2eaaf1bb50e1486791b406e5f003fd11",
            "0d29f71cdf9b487eae8ea1361bcef7cc",
            "f65fb39b822848d8893a845ab6f378b6",
            "8c6074dcfa2947dfb3da0ef5520cefae",
            "af2d667217e84b248422ae734f5d3e28",
            "a04f55eaedd44d71b407afd7ce7c7ed2",
            "da45073e778f4562ae737842d71e93e5",
            "c4bfa38ea1ca49158c3fbaff87d34cf8",
            "b4f60d9a1cd7414cbcad286e889e64f7",
            "1fadeaa91e73494f9ec81ef931195ac2"
          ]
        },
        "outputId": "4560238c-ccd2-4d4a-822a-9bd040e274f6"
      },
      "id": "5IRBvHkpKGff",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.57k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c30e83596fd7412abb93b7795359c11a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06a79f69457a41628abd36e3d4a7f7ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55ffab93822b45faa023dfd1d680153f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/703k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "548bafff4052489cbdcf6a487efa8680"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/294k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a436c740784046ab8cab0e9e24fc065c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f444e1f4d18c41f8920d85a0ff00dc0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/12.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9cbe66e4be94e658d0355604428f873"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1/10\n",
            "Silhouette Score: 0.05, Davies-Bouldin Index: 2.66\n",
            "Run 2/10\n",
            "Silhouette Score: 0.05, Davies-Bouldin Index: 2.66\n",
            "Run 3/10\n",
            "Silhouette Score: 0.05, Davies-Bouldin Index: 2.66\n",
            "Run 4/10\n",
            "Silhouette Score: 0.05, Davies-Bouldin Index: 2.66\n",
            "Run 5/10\n",
            "Silhouette Score: 0.05, Davies-Bouldin Index: 2.66\n",
            "Run 6/10\n",
            "Silhouette Score: 0.05, Davies-Bouldin Index: 2.66\n",
            "Run 7/10\n",
            "Silhouette Score: 0.05, Davies-Bouldin Index: 2.66\n",
            "Run 8/10\n",
            "Silhouette Score: 0.05, Davies-Bouldin Index: 2.66\n",
            "Run 9/10\n",
            "Silhouette Score: 0.05, Davies-Bouldin Index: 2.66\n",
            "Run 10/10\n",
            "Silhouette Score: 0.05, Davies-Bouldin Index: 2.66\n",
            "\n",
            "Mean Training Time: 208390.44 ms\n",
            "Mean Silhouette Score: 0.05\n",
            "Mean Davies-Bouldin Index: 2.66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "import random\n",
        "\n",
        "# Check if GPU is available and use it; otherwise, use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/abstractfactory\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)  # Move model to the appropriate device\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":  # Skip empty lines\n",
        "            continue\n",
        "\n",
        "        # Encode the input using the tokenizer\n",
        "        inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to device\n",
        "\n",
        "        # Forward pass through the encoder model\n",
        "        with torch.no_grad():\n",
        "            encoder_outputs = model.encoder(**inputs)  # Use only the encoder part\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = encoder_outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move output to CPU for NumPy conversion\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    if len(line_embeddings) == 0:  # To handle files with no valid lines\n",
        "        return None  # Return None if there are no valid embeddings\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Define the number of iterations for the experiment\n",
        "n_runs = 10\n",
        "k = 3  # Number of neighbors to consider\n",
        "training_times = []\n",
        "prediction_times = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1}/{n_runs}\")\n",
        "\n",
        "    # Separate positive and negative examples\n",
        "    positive_files = [file for file in java_files if \"abstractfactory\" in file]\n",
        "    negative_files = [file for file in java_files if \"abstractfactory\" not in file]\n",
        "\n",
        "    # Select an approximately equal number of positive and negative examples (40%-60% range)\n",
        "    num_positive = len(positive_files)\n",
        "    num_negative = len(negative_files)\n",
        "\n",
        "    lower_bound = int(0.4 * min(num_positive, num_negative))\n",
        "    upper_bound = int(0.6 * min(num_positive, num_negative))\n",
        "\n",
        "    num_samples = random.randint(lower_bound, upper_bound)\n",
        "\n",
        "    positive_sample = random.sample(positive_files, num_samples)\n",
        "    negative_sample = random.sample(negative_files, num_samples)\n",
        "\n",
        "    selected_files = positive_sample + negative_sample\n",
        "    random.shuffle(selected_files)\n",
        "\n",
        "    true_labels = [1] * len(positive_sample) + [0] * len(negative_sample)\n",
        "    program_embeddings = []\n",
        "\n",
        "    # Start training time\n",
        "    start_training_time = time.time()\n",
        "\n",
        "    # Extract embeddings for each file\n",
        "    for file in selected_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "\n",
        "        if program_embedding is not None:\n",
        "            program_embeddings.append(program_embedding)\n",
        "\n",
        "    # Check if we have valid embeddings\n",
        "    if len(program_embeddings) == 0:\n",
        "        print(f\"No valid embeddings for run {run + 1}. Skipping this run.\")\n",
        "        continue\n",
        "\n",
        "    # Convert to NumPy array\n",
        "    program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "    # Calculate the distance matrix\n",
        "    distance_metric = 'euclidean'  # Can switch between 'cosine' or 'euclidean'\n",
        "    distance_matrix = calculate_distance_matrix(program_embeddings, metric=distance_metric)\n",
        "\n",
        "    # Get k-nearest neighbors indices for each program\n",
        "    knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "    # End training time\n",
        "    end_training_time = time.time()\n",
        "    training_time = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "    training_times.append(training_time)\n",
        "\n",
        "    # Start prediction time\n",
        "    start_prediction_time = time.time()\n",
        "\n",
        "    # Predict labels based on neighbors\n",
        "    predicted_labels = []\n",
        "    for indices in knn_indices:\n",
        "        neighbor_labels = [true_labels[i] for i in indices]\n",
        "        predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "        predicted_labels.append(predicted_label)\n",
        "\n",
        "    # End prediction time\n",
        "    end_prediction_time = time.time()\n",
        "    prediction_time = (end_prediction_time - start_prediction_time) * 1000  # Convert to milliseconds\n",
        "    prediction_times.append(prediction_time)\n",
        "\n",
        "    # Calculate precision, recall, and f1-score\n",
        "    predicted_labels = np.array(predicted_labels)\n",
        "    precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "    recall = recall_score(true_labels, predicted_labels)\n",
        "    f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Calculate the mean and standard deviation for training and prediction times\n",
        "mean_training_time = np.mean(training_times)\n",
        "std_training_time = np.std(training_times)\n",
        "mean_prediction_time = np.mean(prediction_times)\n",
        "std_prediction_time = np.std(prediction_times)\n",
        "\n",
        "# Calculate the mean and standard deviation for performance metrics\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "\n",
        "print(f\"\\nMean Training Time: {mean_training_time:.2f} ms ( {std_training_time:.2f})\")\n",
        "print(f\"Mean Prediction Time: {mean_prediction_time:.2f} ms ( {std_prediction_time:.2f})\")\n",
        "print(f\"Mean Precision: {mean_precision:.2f} ( {std_precision:.2f})\")\n",
        "print(f\"Mean Recall: {mean_recall:.2f} ( {std_recall:.2f})\")\n",
        "print(f\"Mean F1 Score: {mean_f1:.2f} ( {std_f1:.2f})\")\n"
      ],
      "metadata": {
        "id": "MYLDpN69MnAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d577baaa-65e7-49aa-da17-2bf23e3e0469"
      },
      "id": "MYLDpN69MnAk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1/10\n",
            "Precision: 0.50, Recall: 0.50, F1 Score: 0.50\n",
            "Run 2/10\n",
            "Precision: 0.70, Recall: 0.78, F1 Score: 0.74\n",
            "Run 3/10\n",
            "Precision: 0.62, Recall: 0.89, F1 Score: 0.73\n",
            "Run 4/10\n",
            "Precision: 0.44, Recall: 0.67, F1 Score: 0.53\n",
            "Run 5/10\n",
            "Precision: 0.57, Recall: 0.57, F1 Score: 0.57\n",
            "Run 6/10\n",
            "Precision: 0.50, Recall: 0.56, F1 Score: 0.53\n",
            "Run 7/10\n",
            "Precision: 0.57, Recall: 0.67, F1 Score: 0.62\n",
            "Run 8/10\n",
            "Precision: 0.17, Recall: 0.17, F1 Score: 0.17\n",
            "Run 9/10\n",
            "Precision: 0.50, Recall: 0.56, F1 Score: 0.53\n",
            "Run 10/10\n",
            "Precision: 0.38, Recall: 0.43, F1 Score: 0.40\n",
            "\n",
            "Mean Training Time: 18424.65 ms ( 3127.17)\n",
            "Mean Prediction Time: 0.05 ms ( 0.01)\n",
            "Mean Precision: 0.49 ( 0.14)\n",
            "Mean Recall: 0.58 ( 0.19)\n",
            "Mean F1 Score: 0.53 ( 0.16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Specify the directory path you want to delete\n",
        "dir_path = '/content/abstractfactory'\n",
        "\n",
        "# Remove the directory and its contents\n",
        "shutil.rmtree(dir_path)\n",
        "\n",
        "print(f\"Directory '{dir_path}' has been deleted.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1KMdVs1WR8y",
        "outputId": "da57c28a-b36e-461f-871f-e2833589802b"
      },
      "id": "Q1KMdVs1WR8y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory '/content/abstractfactory' has been deleted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "import random\n",
        "\n",
        "# Check if GPU is available and use it; otherwise, use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/singleton\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)  # Move model to the appropriate device\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":  # Skip empty lines\n",
        "            continue\n",
        "\n",
        "        # Encode the input using the tokenizer\n",
        "        inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to device\n",
        "\n",
        "        # Forward pass through the encoder model\n",
        "        with torch.no_grad():\n",
        "            encoder_outputs = model.encoder(**inputs)  # Use only the encoder part\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = encoder_outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move output to CPU for NumPy conversion\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    if len(line_embeddings) == 0:  # To handle files with no valid lines\n",
        "        return None  # Return None if there are no valid embeddings\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Define the number of iterations for the experiment\n",
        "n_runs = 10\n",
        "k = 3  # Number of neighbors to consider\n",
        "training_times = []\n",
        "prediction_times = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1}/{n_runs}\")\n",
        "\n",
        "    # Separate positive and negative examples\n",
        "    positive_files = [file for file in java_files if \"singleton\" in file]\n",
        "    negative_files = [file for file in java_files if \"singleton\" not in file]\n",
        "\n",
        "    # Select an approximately equal number of positive and negative examples (40%-60% range)\n",
        "    num_positive = len(positive_files)\n",
        "    num_negative = len(negative_files)\n",
        "\n",
        "    lower_bound = int(0.4 * min(num_positive, num_negative))\n",
        "    upper_bound = int(0.6 * min(num_positive, num_negative))\n",
        "\n",
        "    num_samples = random.randint(lower_bound, upper_bound)\n",
        "\n",
        "    positive_sample = random.sample(positive_files, num_samples)\n",
        "    negative_sample = random.sample(negative_files, num_samples)\n",
        "\n",
        "    selected_files = positive_sample + negative_sample\n",
        "    random.shuffle(selected_files)\n",
        "\n",
        "    true_labels = [1] * len(positive_sample) + [0] * len(negative_sample)\n",
        "    program_embeddings = []\n",
        "\n",
        "    # Start training time\n",
        "    start_training_time = time.time()\n",
        "\n",
        "    # Extract embeddings for each file\n",
        "    for file in selected_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "\n",
        "        if program_embedding is not None:\n",
        "            program_embeddings.append(program_embedding)\n",
        "\n",
        "    # Check if we have valid embeddings\n",
        "    if len(program_embeddings) == 0:\n",
        "        print(f\"No valid embeddings for run {run + 1}. Skipping this run.\")\n",
        "        continue\n",
        "\n",
        "    # Convert to NumPy array\n",
        "    program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "    # Calculate the distance matrix\n",
        "    distance_metric = 'euclidean'  # Can switch between 'cosine' or 'euclidean'\n",
        "    distance_matrix = calculate_distance_matrix(program_embeddings, metric=distance_metric)\n",
        "\n",
        "    # Get k-nearest neighbors indices for each program\n",
        "    knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "    # End training time\n",
        "    end_training_time = time.time()\n",
        "    training_time = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "    training_times.append(training_time)\n",
        "\n",
        "    # Start prediction time\n",
        "    start_prediction_time = time.time()\n",
        "\n",
        "    # Predict labels based on neighbors\n",
        "    predicted_labels = []\n",
        "    for indices in knn_indices:\n",
        "        neighbor_labels = [true_labels[i] for i in indices]\n",
        "        predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "        predicted_labels.append(predicted_label)\n",
        "\n",
        "    # End prediction time\n",
        "    end_prediction_time = time.time()\n",
        "    prediction_time = (end_prediction_time - start_prediction_time) * 1000  # Convert to milliseconds\n",
        "    prediction_times.append(prediction_time)\n",
        "\n",
        "    # Calculate precision, recall, and f1-score\n",
        "    predicted_labels = np.array(predicted_labels)\n",
        "    precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "    recall = recall_score(true_labels, predicted_labels)\n",
        "    f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Calculate the mean and standard deviation for training and prediction times\n",
        "mean_training_time = np.mean(training_times)\n",
        "std_training_time = np.std(training_times)\n",
        "mean_prediction_time = np.mean(prediction_times)\n",
        "std_prediction_time = np.std(prediction_times)\n",
        "\n",
        "# Calculate the mean and standard deviation for performance metrics\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "\n",
        "print(f\"\\nMean Training Time: {mean_training_time:.2f} ms ( {std_training_time:.2f})\")\n",
        "print(f\"Mean Prediction Time: {mean_prediction_time:.2f} ms ( {std_prediction_time:.2f})\")\n",
        "print(f\"Mean Precision: {mean_precision:.2f} ( {std_precision:.2f})\")\n",
        "print(f\"Mean Recall: {mean_recall:.2f} ( {std_recall:.2f})\")\n",
        "print(f\"Mean F1 Score: {mean_f1:.2f} ( {std_f1:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmPuXIuwZ5fc",
        "outputId": "3b5729fb-3457-49eb-e057-2afac441a85b"
      },
      "id": "cmPuXIuwZ5fc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1/10\n",
            "Precision: 0.42, Recall: 0.36, F1 Score: 0.38\n",
            "Run 2/10\n",
            "Precision: 0.50, Recall: 0.47, F1 Score: 0.48\n",
            "Run 3/10\n",
            "Precision: 0.50, Recall: 0.64, F1 Score: 0.56\n",
            "Run 4/10\n",
            "Precision: 0.27, Recall: 0.27, F1 Score: 0.27\n",
            "Run 5/10\n",
            "Precision: 0.33, Recall: 0.27, F1 Score: 0.30\n",
            "Run 6/10\n",
            "Precision: 0.64, Recall: 0.69, F1 Score: 0.67\n",
            "Run 7/10\n",
            "Precision: 0.39, Recall: 0.54, F1 Score: 0.45\n",
            "Run 8/10\n",
            "Precision: 0.46, Recall: 0.40, F1 Score: 0.43\n",
            "Run 9/10\n",
            "Precision: 0.75, Recall: 0.46, F1 Score: 0.57\n",
            "Run 10/10\n",
            "Precision: 0.46, Recall: 0.46, F1 Score: 0.46\n",
            "\n",
            "Mean Training Time: 44841.20 ms ( 15131.03)\n",
            "Mean Prediction Time: 0.11 ms ( 0.03)\n",
            "Mean Precision: 0.47 ( 0.13)\n",
            "Mean Recall: 0.46 ( 0.13)\n",
            "Mean F1 Score: 0.46 ( 0.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "\n",
        "# Check if GPU is available and use it; otherwise, use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/singleton\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)  # Move model to the appropriate device\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Unseen examples directory\n",
        "unseen_examples_dir = \"/content/unseen_examples\"  # Modify the path to unseen examples\n",
        "unseen_files = [file for file in os.listdir(unseen_examples_dir) if os.path.isfile(os.path.join(unseen_examples_dir, file))]\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":  # Skip empty lines\n",
        "            continue\n",
        "\n",
        "        # Encode the input using the tokenizer\n",
        "        inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to device\n",
        "\n",
        "        # Forward pass through the encoder model\n",
        "        with torch.no_grad():\n",
        "            encoder_outputs = model.encoder(**inputs)  # Use only the encoder part\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = encoder_outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move output to CPU for NumPy conversion\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    if len(line_embeddings) == 0:  # To handle files with no valid lines\n",
        "        return np.zeros((1, model.config.hidden_size))\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate precision, recall, and F1\n",
        "def calculate_metrics(true_labels, predicted_labels):\n",
        "    precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "    recall = recall_score(true_labels, predicted_labels)\n",
        "    f1 = f1_score(true_labels, predicted_labels)\n",
        "    return precision, recall, f1\n",
        "\n",
        "# Define the number of iterations for the experiment\n",
        "n_runs = 3\n",
        "k = 3  # Number of neighbors to consider\n",
        "train_times = []\n",
        "prediction_times = []\n",
        "precisions, recalls, f1_scores = [], [], []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1}/{n_runs}\")\n",
        "\n",
        "    # Separate positive and negative examples\n",
        "    positive_files = [file for file in java_files if \"singleton\" in file]\n",
        "    negative_files = [file for file in java_files if \"singleton\" not in file]\n",
        "\n",
        "    # Select an approximately equal number of positive and negative examples\n",
        "    num_samples = min(len(positive_files), len(negative_files))\n",
        "\n",
        "    positive_sample = random.sample(positive_files, num_samples)\n",
        "    negative_sample = random.sample(negative_files, num_samples)\n",
        "\n",
        "    selected_files = positive_sample + negative_sample\n",
        "    true_labels = [1] * len(positive_sample) + [0] * len(negative_sample)\n",
        "\n",
        "    program_embeddings = []\n",
        "    for file in selected_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "    program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "    # Split into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(program_embeddings, true_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Start training time\n",
        "    start_train_time = time.time()\n",
        "\n",
        "    # Train kNN\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # End training time\n",
        "    end_train_time = time.time()\n",
        "    train_time = (end_train_time - start_train_time) * 1e6  # Convert to microseconds\n",
        "    train_times.append(train_time)\n",
        "\n",
        "    # Start prediction time\n",
        "    start_prediction_time = time.time()\n",
        "\n",
        "    # Predict on test set\n",
        "    y_pred = knn.predict(X_test)\n",
        "\n",
        "    # End prediction time\n",
        "    end_prediction_time = time.time()\n",
        "    pred_time = (end_prediction_time - start_prediction_time) * 1e6  # Convert to microseconds\n",
        "    prediction_times.append(pred_time)\n",
        "\n",
        "    # Calculate metrics\n",
        "    precision, recall, f1 = calculate_metrics(y_test, y_pred)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Calculate mean and standard deviation for precision, recall, f1-score\n",
        "mean_precision = np.mean(precisions)\n",
        "std_precision = np.std(precisions)\n",
        "mean_recall = np.mean(recalls)\n",
        "std_recall = np.std(recalls)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "\n",
        "# Calculate the mean training and prediction times\n",
        "mean_train_time = np.mean(train_times)\n",
        "mean_prediction_time = np.mean(prediction_times)\n",
        "\n",
        "print(f\"\\nMean Precision: {mean_precision:.2f} ({std_precision:.2f})\")\n",
        "print(f\"Mean Recall: {mean_recall:.2f} ({std_recall:.2f})\")\n",
        "print(f\"Mean F1 Score: {mean_f1:.2f} ({std_f1:.2f})\")\n",
        "print(f\"\\nMean Training Time: {mean_train_time:.2f} s\")\n",
        "print(f\"Mean Prediction Time: {mean_prediction_time:.2f} s\")\n",
        "\n",
        "# Unseen example prediction\n",
        "unseen_embeddings = []\n",
        "for file in unseen_files:\n",
        "    with open(os.path.join(unseen_examples_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        java_code = f.read()\n",
        "    embedding = get_line_embeddings(java_code)\n",
        "    unseen_embeddings.append(embedding)\n",
        "\n",
        "unseen_embeddings = np.vstack(unseen_embeddings)\n",
        "\n",
        "# Start unseen prediction time\n",
        "start_unseen_pred_time = time.time()\n",
        "\n",
        "# Predict on unseen examples\n",
        "unseen_predictions = knn.predict(unseen_embeddings)\n",
        "\n",
        "# End unseen prediction time\n",
        "end_unseen_pred_time = time.time()\n",
        "unseen_pred_time = (end_unseen_pred_time - start_unseen_pred_time) * 1e6  # Convert to microseconds\n",
        "\n",
        "print(f\"\\nUnseen Prediction Time: {unseen_pred_time:.2f} s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CV_mfhBcJOQ",
        "outputId": "8a61d0c0-dc80-4e64-a62c-7da806cc885b"
      },
      "id": "-CV_mfhBcJOQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1/3\n",
            "Precision: 0.88, Recall: 1.00, F1 Score: 0.93\n",
            "Run 2/3\n",
            "Precision: 0.64, Recall: 1.00, F1 Score: 0.78\n",
            "Run 3/3\n",
            "Precision: 0.71, Recall: 0.71, F1 Score: 0.71\n",
            "\n",
            "Mean Precision: 0.74 (0.10)\n",
            "Mean Recall: 0.90 (0.13)\n",
            "Mean F1 Score: 0.81 (0.09)\n",
            "\n",
            "Mean Training Time: 795.36 s\n",
            "Mean Prediction Time: 26303.37 s\n",
            "\n",
            "Unseen Prediction Time: 1308.92 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Singleton Standard deviation and time calculation**"
      ],
      "metadata": {
        "id": "wbiN4HHttUec"
      },
      "id": "wbiN4HHttUec"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import joblib  # To save and load models\n",
        "\n",
        "# Check if GPU is available and use it; otherwise, use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/singleton\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)  # Move model to the appropriate device\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Unseen examples directory\n",
        "unseen_examples_dir = \"/content/unseen_examples\"  # Modify the path to unseen examples\n",
        "unseen_files = [file for file in os.listdir(unseen_examples_dir) if os.path.isfile(os.path.join(unseen_examples_dir, file))]\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":  # Skip empty lines\n",
        "            continue\n",
        "\n",
        "        # Encode the input using the tokenizer\n",
        "        inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to device\n",
        "\n",
        "        # Forward pass through the encoder model\n",
        "        with torch.no_grad():\n",
        "            encoder_outputs = model.encoder(**inputs)  # Use only the encoder part\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = encoder_outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move output to CPU for NumPy conversion\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    if len(line_embeddings) == 0:  # To handle files with no valid lines\n",
        "        return np.zeros((1, model.config.hidden_size))\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate precision, recall, and F1\n",
        "def calculate_metrics(true_labels, predicted_labels):\n",
        "    precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "    recall = recall_score(true_labels, predicted_labels)\n",
        "    f1 = f1_score(true_labels, predicted_labels)\n",
        "    return precision, recall, f1\n",
        "\n",
        "# Define the number of iterations for the experiment\n",
        "n_runs = 3\n",
        "k = 3  # Number of neighbors to consider\n",
        "train_times = []\n",
        "prediction_times = []\n",
        "precisions, recalls, f1_scores = [], [], []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1}/{n_runs}\")\n",
        "\n",
        "    # Separate positive and negative examples\n",
        "    positive_files = [file for file in java_files if \"singleton\" in file]\n",
        "    negative_files = [file for file in java_files if \"singleton\" not in file]\n",
        "\n",
        "    # Select an approximately equal number of positive and negative examples\n",
        "    num_samples = min(len(positive_files), len(negative_files))\n",
        "\n",
        "    positive_sample = random.sample(positive_files, num_samples)\n",
        "    negative_sample = random.sample(negative_files, num_samples)\n",
        "\n",
        "    selected_files = positive_sample + negative_sample\n",
        "    true_labels = [1] * len(positive_sample) + [0] * len(negative_sample)\n",
        "\n",
        "    # Start training time, including tokenization, embedding extraction, and k-NN\n",
        "    start_train_time = time.time()\n",
        "\n",
        "    program_embeddings = []\n",
        "    for file in selected_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "    program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "    # Split into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(program_embeddings, true_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Train kNN\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Save the trained kNN model (Optional)\n",
        "    joblib.dump(knn, f\"knn_model_run_{run}.joblib\")\n",
        "\n",
        "    # End training time after training and model saving\n",
        "    end_train_time = time.time()\n",
        "    train_time = (end_train_time - start_train_time) * 1e6  # Convert to microseconds\n",
        "    train_times.append(train_time)\n",
        "\n",
        "    # Start prediction time\n",
        "    start_prediction_time = time.time()\n",
        "\n",
        "    # Predict on test set\n",
        "    y_pred = knn.predict(X_test)\n",
        "\n",
        "    # End prediction time after prediction\n",
        "    end_prediction_time = time.time()\n",
        "    pred_time = (end_prediction_time - start_prediction_time) * 1e6  # Convert to microseconds\n",
        "    prediction_times.append(pred_time)\n",
        "\n",
        "    # Calculate metrics\n",
        "    precision, recall, f1 = calculate_metrics(y_test, y_pred)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Calculate mean and standard deviation for precision, recall, f1-score\n",
        "mean_precision = np.mean(precisions)\n",
        "std_precision = np.std(precisions)\n",
        "mean_recall = np.mean(recalls)\n",
        "std_recall = np.std(recalls)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "\n",
        "# Calculate the mean training and prediction times\n",
        "mean_train_time = np.mean(train_times)\n",
        "mean_prediction_time = np.mean(prediction_times)\n",
        "\n",
        "print(f\"\\nMean Precision: {mean_precision:.2f} ({std_precision:.2f})\")\n",
        "print(f\"Mean Recall: {mean_recall:.2f} ({std_recall:.2f})\")\n",
        "print(f\"Mean F1 Score: {mean_f1:.2f} ({std_f1:.2f})\")\n",
        "print(f\"\\nMean Training Time: {mean_train_time:.2f} s\")\n",
        "print(f\"Mean Prediction Time: {mean_prediction_time:.2f} s\")\n",
        "\n",
        "# Unseen example prediction\n",
        "unseen_embeddings = []\n",
        "for file in unseen_files:\n",
        "    with open(os.path.join(unseen_examples_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        java_code = f.read()\n",
        "    embedding = get_line_embeddings(java_code)\n",
        "    unseen_embeddings.append(embedding)\n",
        "\n",
        "unseen_embeddings = np.vstack(unseen_embeddings)\n",
        "\n",
        "# Start unseen prediction time\n",
        "start_unseen_pred_time = time.time()\n",
        "\n",
        "# Predict on unseen examples\n",
        "unseen_predictions = knn.predict(unseen_embeddings)\n",
        "\n",
        "# End unseen prediction time\n",
        "end_unseen_pred_time = time.time()\n",
        "unseen_pred_time = (end_unseen_pred_time - start_unseen_pred_time) * 1e6  # Convert to microseconds\n",
        "\n",
        "print(f\"\\nUnseen Prediction Time: {unseen_pred_time:.2f} s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7M0ckOteIdC",
        "outputId": "243daad1-2d77-41cf-bb36-946397a33aa8"
      },
      "id": "t7M0ckOteIdC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1/3\n",
            "Precision: 0.83, Recall: 0.71, F1 Score: 0.77\n",
            "Run 2/3\n",
            "Precision: 1.00, Recall: 0.86, F1 Score: 0.92\n",
            "Run 3/3\n",
            "Precision: 0.78, Recall: 1.00, F1 Score: 0.88\n",
            "\n",
            "Mean Precision: 0.87 (0.09)\n",
            "Mean Recall: 0.86 (0.12)\n",
            "Mean F1 Score: 0.86 (0.06)\n",
            "\n",
            "Mean Training Time: 104153313.16 s\n",
            "Mean Prediction Time: 1282.77 s\n",
            "\n",
            "Unseen Prediction Time: 1743.79 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import joblib  # To save and load models\n",
        "\n",
        "# Check if GPU is available and use it; otherwise, use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/singleton\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)  # Move model to the appropriate device\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Unseen examples directory\n",
        "unseen_examples_dir = \"/content/unseen_examples\"  # Modify the path to unseen examples\n",
        "unseen_files = [file for file in os.listdir(unseen_examples_dir) if os.path.isfile(os.path.join(unseen_examples_dir, file))]\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":  # Skip empty lines\n",
        "            continue\n",
        "\n",
        "        # Encode the input using the tokenizer\n",
        "        inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to device\n",
        "\n",
        "        # Forward pass through the encoder model\n",
        "        with torch.no_grad():\n",
        "            encoder_outputs = model.encoder(**inputs)  # Use only the encoder part\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = encoder_outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move output to CPU for NumPy conversion\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    if len(line_embeddings) == 0:  # To handle files with no valid lines\n",
        "        return np.zeros((1, model.config.hidden_size))\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate precision, recall, and F1\n",
        "def calculate_metrics(true_labels, predicted_labels):\n",
        "    precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "    recall = recall_score(true_labels, predicted_labels)\n",
        "    f1 = f1_score(true_labels, predicted_labels)\n",
        "    return precision, recall, f1\n",
        "\n",
        "# Define the number of iterations for the experiment\n",
        "n_runs = 10\n",
        "k = 3  # Number of neighbors to consider\n",
        "train_times = []\n",
        "prediction_times = []\n",
        "precisions, recalls, f1_scores = [], [], []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1}/{n_runs}\")\n",
        "\n",
        "    # Separate positive and negative examples\n",
        "    positive_files = [file for file in java_files if \"singleton\" in file]\n",
        "    negative_files = [file for file in java_files if \"singleton\" not in file]\n",
        "\n",
        "    # Select an approximately equal number of positive and negative examples\n",
        "    num_samples = min(len(positive_files), len(negative_files))\n",
        "\n",
        "    positive_sample = random.sample(positive_files, num_samples)\n",
        "    negative_sample = random.sample(negative_files, num_samples)\n",
        "\n",
        "    selected_files = positive_sample + negative_sample\n",
        "    true_labels = [1] * len(positive_sample) + [0] * len(negative_sample)\n",
        "\n",
        "    # Start training time, including tokenization, embedding extraction, and k-NN\n",
        "    start_train_time = time.time()\n",
        "\n",
        "    program_embeddings = []\n",
        "    for file in selected_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "    program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "    # Split into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(program_embeddings, true_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Train kNN\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Save the trained kNN model (Optional)\n",
        "    joblib.dump(knn, f\"knn_model_run_{run}.joblib\")\n",
        "\n",
        "    # End training time after training and model saving\n",
        "    end_train_time = time.time()\n",
        "    train_time = (end_train_time - start_train_time) * 1e6  # Convert to microseconds\n",
        "    train_times.append(train_time)\n",
        "\n",
        "    # Start prediction time\n",
        "    start_prediction_time = time.time()\n",
        "\n",
        "    # Predict on test set\n",
        "    y_pred = knn.predict(X_test)\n",
        "\n",
        "    # End prediction time after prediction\n",
        "    end_prediction_time = time.time()\n",
        "    pred_time = (end_prediction_time - start_prediction_time) * 1e6  # Convert to microseconds\n",
        "    prediction_times.append(pred_time)\n",
        "\n",
        "    # Calculate metrics\n",
        "    precision, recall, f1 = calculate_metrics(y_test, y_pred)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Calculate mean and standard deviation for precision, recall, f1-score\n",
        "mean_precision = np.mean(precisions)\n",
        "std_precision = np.std(precisions)\n",
        "mean_recall = np.mean(recalls)\n",
        "std_recall = np.std(recalls)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "\n",
        "# Calculate the mean training and prediction times\n",
        "mean_train_time = np.mean(train_times)\n",
        "mean_prediction_time = np.mean(prediction_times)\n",
        "\n",
        "print(f\"\\nMean Precision: {mean_precision:.2f} ({std_precision:.2f})\")\n",
        "print(f\"Mean Recall: {mean_recall:.2f} ({std_recall:.2f})\")\n",
        "print(f\"Mean F1 Score: {mean_f1:.2f} ({std_f1:.2f})\")\n",
        "print(f\"\\nMean Training Time: {mean_train_time:.2f} s\")\n",
        "print(f\"Mean Prediction Time: {mean_prediction_time:.2f} s\")\n",
        "\n",
        "# Unseen example prediction\n",
        "unseen_embeddings = []\n",
        "for file in unseen_files:\n",
        "    with open(os.path.join(unseen_examples_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        java_code = f.read()\n",
        "    embedding = get_line_embeddings(java_code)\n",
        "    unseen_embeddings.append(embedding)\n",
        "\n",
        "unseen_embeddings = np.vstack(unseen_embeddings)\n",
        "\n",
        "# Start unseen prediction time\n",
        "start_unseen_pred_time = time.time()\n",
        "\n",
        "# Predict on unseen examples\n",
        "unseen_predictions = knn.predict(unseen_embeddings)\n",
        "\n",
        "# End unseen prediction time\n",
        "end_unseen_pred_time = time.time()\n",
        "unseen_pred_time = (end_unseen_pred_time - start_unseen_pred_time) * 1e6  # Convert to microseconds\n",
        "\n",
        "print(f\"\\nUnseen Prediction Time: {unseen_pred_time:.2f} s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNQXMpwZr6A9",
        "outputId": "91140f93-0eb2-4458-dce4-1ab08ed0df43"
      },
      "id": "uNQXMpwZr6A9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1/10\n",
            "Precision: 0.86, Recall: 0.86, F1 Score: 0.86\n",
            "Run 2/10\n",
            "Precision: 0.78, Recall: 1.00, F1 Score: 0.88\n",
            "Run 3/10\n",
            "Precision: 0.83, Recall: 0.71, F1 Score: 0.77\n",
            "Run 4/10\n",
            "Precision: 0.75, Recall: 0.86, F1 Score: 0.80\n",
            "Run 5/10\n",
            "Precision: 0.70, Recall: 1.00, F1 Score: 0.82\n",
            "Run 6/10\n",
            "Precision: 0.62, Recall: 0.71, F1 Score: 0.67\n",
            "Run 7/10\n",
            "Precision: 0.88, Recall: 1.00, F1 Score: 0.93\n",
            "Run 8/10\n",
            "Precision: 0.62, Recall: 0.71, F1 Score: 0.67\n",
            "Run 9/10\n",
            "Precision: 0.57, Recall: 0.57, F1 Score: 0.57\n",
            "Run 10/10\n",
            "Precision: 0.75, Recall: 0.86, F1 Score: 0.80\n",
            "\n",
            "Mean Precision: 0.74 (0.10)\n",
            "Mean Recall: 0.83 (0.14)\n",
            "Mean F1 Score: 0.78 (0.11)\n",
            "\n",
            "Mean Training Time: 93027561.69 s\n",
            "Mean Prediction Time: 1483.44 s\n",
            "\n",
            "Unseen Prediction Time: 1807.93 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Builder Standard deviation and time calculation**"
      ],
      "metadata": {
        "id": "W_9GmVX397Xk"
      },
      "id": "W_9GmVX397Xk"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import joblib  # To save and load models\n",
        "\n",
        "# Check if GPU is available and use it; otherwise, use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/builder\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)  # Move model to the appropriate device\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Unseen examples directory\n",
        "unseen_examples_dir = \"/content/unseen_examples\"  # Modify the path to unseen examples\n",
        "unseen_files = [file for file in os.listdir(unseen_examples_dir) if os.path.isfile(os.path.join(unseen_examples_dir, file))]\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":  # Skip empty lines\n",
        "            continue\n",
        "\n",
        "        # Encode the input using the tokenizer\n",
        "        inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to device\n",
        "\n",
        "        # Forward pass through the encoder model\n",
        "        with torch.no_grad():\n",
        "            encoder_outputs = model.encoder(**inputs)  # Use only the encoder part\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = encoder_outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move output to CPU for NumPy conversion\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    if len(line_embeddings) == 0:  # To handle files with no valid lines\n",
        "        return np.zeros((1, model.config.hidden_size))\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate precision, recall, and F1\n",
        "def calculate_metrics(true_labels, predicted_labels):\n",
        "    precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "    recall = recall_score(true_labels, predicted_labels)\n",
        "    f1 = f1_score(true_labels, predicted_labels)\n",
        "    return precision, recall, f1\n",
        "\n",
        "# Define the number of iterations for the experiment\n",
        "n_runs = 10\n",
        "k = 3  # Number of neighbors to consider\n",
        "train_times = []\n",
        "prediction_times = []\n",
        "precisions, recalls, f1_scores = [], [], []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1}/{n_runs}\")\n",
        "\n",
        "    # Separate positive and negative examples\n",
        "    positive_files = [file for file in java_files if \"builder\" in file]\n",
        "    negative_files = [file for file in java_files if \"builder\" not in file]\n",
        "\n",
        "    # Select an approximately equal number of positive and negative examples\n",
        "    num_samples = min(len(positive_files), len(negative_files))\n",
        "\n",
        "    positive_sample = random.sample(positive_files, num_samples)\n",
        "    negative_sample = random.sample(negative_files, num_samples)\n",
        "\n",
        "    selected_files = positive_sample + negative_sample\n",
        "    true_labels = [1] * len(positive_sample) + [0] * len(negative_sample)\n",
        "\n",
        "    # Start training time, including tokenization, embedding extraction, and k-NN\n",
        "    start_train_time = time.time()\n",
        "\n",
        "    program_embeddings = []\n",
        "    for file in selected_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "    program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "    # Split into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(program_embeddings, true_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Train kNN\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Save the trained kNN model (Optional)\n",
        "    joblib.dump(knn, f\"knn_model_run_{run}.joblib\")\n",
        "\n",
        "    # End training time after training and model saving\n",
        "    end_train_time = time.time()\n",
        "    train_time = (end_train_time - start_train_time) * 1e6  # Convert to microseconds\n",
        "    train_times.append(train_time)\n",
        "\n",
        "    # Start prediction time\n",
        "    start_prediction_time = time.time()\n",
        "\n",
        "    # Predict on test set\n",
        "    y_pred = knn.predict(X_test)\n",
        "\n",
        "    # End prediction time after prediction\n",
        "    end_prediction_time = time.time()\n",
        "    pred_time = (end_prediction_time - start_prediction_time) * 1e6  # Convert to microseconds\n",
        "    prediction_times.append(pred_time)\n",
        "\n",
        "    # Calculate metrics\n",
        "    precision, recall, f1 = calculate_metrics(y_test, y_pred)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Calculate mean and standard deviation for precision, recall, f1-score\n",
        "mean_precision = np.mean(precisions)\n",
        "std_precision = np.std(precisions)\n",
        "mean_recall = np.mean(recalls)\n",
        "std_recall = np.std(recalls)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "\n",
        "# Calculate the mean training and prediction times\n",
        "mean_train_time = np.mean(train_times)\n",
        "mean_prediction_time = np.mean(prediction_times)\n",
        "\n",
        "print(f\"\\nMean Precision: {mean_precision:.2f} ({std_precision:.2f})\")\n",
        "print(f\"Mean Recall: {mean_recall:.2f} ({std_recall:.2f})\")\n",
        "print(f\"Mean F1 Score: {mean_f1:.2f} ({std_f1:.2f})\")\n",
        "print(f\"\\nMean Training Time: {mean_train_time:.2f} s\")\n",
        "print(f\"Mean Prediction Time: {mean_prediction_time:.2f} s\")\n",
        "\n",
        "# Unseen example prediction\n",
        "unseen_embeddings = []\n",
        "for file in unseen_files:\n",
        "    with open(os.path.join(unseen_examples_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        java_code = f.read()\n",
        "    embedding = get_line_embeddings(java_code)\n",
        "    unseen_embeddings.append(embedding)\n",
        "\n",
        "unseen_embeddings = np.vstack(unseen_embeddings)\n",
        "\n",
        "# Start unseen prediction time\n",
        "start_unseen_pred_time = time.time()\n",
        "\n",
        "# Predict on unseen examples\n",
        "unseen_predictions = knn.predict(unseen_embeddings)\n",
        "\n",
        "# End unseen prediction time\n",
        "end_unseen_pred_time = time.time()\n",
        "unseen_pred_time = (end_unseen_pred_time - start_unseen_pred_time) * 1e6  # Convert to microseconds\n",
        "\n",
        "print(f\"\\nUnseen Prediction Time: {unseen_pred_time:.2f} s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMckabOV9-kA",
        "outputId": "cff8a488-a5ac-4bdc-8a1a-0505693641a8"
      },
      "id": "lMckabOV9-kA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1/10\n",
            "Precision: 1.00, Recall: 1.00, F1 Score: 1.00\n",
            "Run 2/10\n",
            "Precision: 1.00, Recall: 0.00, F1 Score: 0.00\n",
            "Run 3/10\n",
            "Precision: 1.00, Recall: 0.40, F1 Score: 0.57\n",
            "Run 4/10\n",
            "Precision: 1.00, Recall: 0.60, F1 Score: 0.75\n",
            "Run 5/10\n",
            "Precision: 0.75, Recall: 0.60, F1 Score: 0.67\n",
            "Run 6/10\n",
            "Precision: 1.00, Recall: 0.40, F1 Score: 0.57\n",
            "Run 7/10\n",
            "Precision: 1.00, Recall: 0.40, F1 Score: 0.57\n",
            "Run 8/10\n",
            "Precision: 1.00, Recall: 0.40, F1 Score: 0.57\n",
            "Run 9/10\n",
            "Precision: 1.00, Recall: 0.40, F1 Score: 0.57\n",
            "Run 10/10\n",
            "Precision: 1.00, Recall: 0.60, F1 Score: 0.75\n",
            "\n",
            "Mean Precision: 0.97 (0.07)\n",
            "Mean Recall: 0.48 (0.24)\n",
            "Mean F1 Score: 0.60 (0.24)\n",
            "\n",
            "Mean Training Time: 44398709.18 s\n",
            "Mean Prediction Time: 5810.69 s\n",
            "\n",
            "Unseen Prediction Time: 1404.05 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Specify the directory path you want to delete\n",
        "dir_path = '/content/builder'\n",
        "\n",
        "# Remove the directory and its contents\n",
        "shutil.rmtree(dir_path)\n",
        "\n",
        "print(f\"Directory '{dir_path}' has been deleted.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBffz_ynBXRz",
        "outputId": "42168e56-2a81-4b04-dd51-a4a39f65337d"
      },
      "id": "VBffz_ynBXRz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory '/content/builder' has been deleted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prototype, Standard devation, mean training and prediction time**"
      ],
      "metadata": {
        "id": "jdK-rCcbA6ji"
      },
      "id": "jdK-rCcbA6ji"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import joblib  # To save and load models\n",
        "\n",
        "# Check if GPU is available and use it; otherwise, use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/prototype\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)  # Move model to the appropriate device\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Unseen examples directory\n",
        "unseen_examples_dir = \"/content/unseen_examples\"  # Modify the path to unseen examples\n",
        "unseen_files = [file for file in os.listdir(unseen_examples_dir) if os.path.isfile(os.path.join(unseen_examples_dir, file))]\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":  # Skip empty lines\n",
        "            continue\n",
        "\n",
        "        # Encode the input using the tokenizer\n",
        "        inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to device\n",
        "\n",
        "        # Forward pass through the encoder model\n",
        "        with torch.no_grad():\n",
        "            encoder_outputs = model.encoder(**inputs)  # Use only the encoder part\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = encoder_outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move output to CPU for NumPy conversion\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    if len(line_embeddings) == 0:  # To handle files with no valid lines\n",
        "        return np.zeros((1, model.config.hidden_size))\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate precision, recall, and F1\n",
        "def calculate_metrics(true_labels, predicted_labels):\n",
        "    precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "    recall = recall_score(true_labels, predicted_labels)\n",
        "    f1 = f1_score(true_labels, predicted_labels)\n",
        "    return precision, recall, f1\n",
        "\n",
        "# Define the number of iterations for the experiment\n",
        "n_runs = 10\n",
        "k = 3  # Number of neighbors to consider\n",
        "train_times = []\n",
        "prediction_times = []\n",
        "precisions, recalls, f1_scores = [], [], []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1}/{n_runs}\")\n",
        "\n",
        "    # Separate positive and negative examples\n",
        "    positive_files = [file for file in java_files if \"prototype\" in file]\n",
        "    negative_files = [file for file in java_files if \"prototype\" not in file]\n",
        "\n",
        "    # Select an approximately equal number of positive and negative examples\n",
        "    num_samples = min(len(positive_files), len(negative_files))\n",
        "\n",
        "    positive_sample = random.sample(positive_files, num_samples)\n",
        "    negative_sample = random.sample(negative_files, num_samples)\n",
        "\n",
        "    selected_files = positive_sample + negative_sample\n",
        "    true_labels = [1] * len(positive_sample) + [0] * len(negative_sample)\n",
        "\n",
        "    # Start training time, including tokenization, embedding extraction, and k-NN\n",
        "    start_train_time = time.time()\n",
        "\n",
        "    program_embeddings = []\n",
        "    for file in selected_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "    program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "    # Split into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(program_embeddings, true_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Train kNN\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Save the trained kNN model (Optional)\n",
        "    joblib.dump(knn, f\"knn_model_run_{run}.joblib\")\n",
        "\n",
        "    # End training time after training and model saving\n",
        "    end_train_time = time.time()\n",
        "    train_time = (end_train_time - start_train_time) * 1e6  # Convert to microseconds\n",
        "    train_times.append(train_time)\n",
        "\n",
        "    # Start prediction time\n",
        "    start_prediction_time = time.time()\n",
        "\n",
        "    # Predict on test set\n",
        "    y_pred = knn.predict(X_test)\n",
        "\n",
        "    # End prediction time after prediction\n",
        "    end_prediction_time = time.time()\n",
        "    pred_time = (end_prediction_time - start_prediction_time) * 1e6  # Convert to microseconds\n",
        "    prediction_times.append(pred_time)\n",
        "\n",
        "    # Calculate metrics\n",
        "    precision, recall, f1 = calculate_metrics(y_test, y_pred)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Calculate mean and standard deviation for precision, recall, f1-score\n",
        "mean_precision = np.mean(precisions)\n",
        "std_precision = np.std(precisions)\n",
        "mean_recall = np.mean(recalls)\n",
        "std_recall = np.std(recalls)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "\n",
        "# Calculate the mean training and prediction times\n",
        "mean_train_time = np.mean(train_times)\n",
        "mean_prediction_time = np.mean(prediction_times)\n",
        "\n",
        "print(f\"\\nMean Precision: {mean_precision:.2f} ({std_precision:.2f})\")\n",
        "print(f\"Mean Recall: {mean_recall:.2f} ({std_recall:.2f})\")\n",
        "print(f\"Mean F1 Score: {mean_f1:.2f} ({std_f1:.2f})\")\n",
        "print(f\"\\nMean Training Time: {mean_train_time:.2f} s\")\n",
        "print(f\"Mean Prediction Time: {mean_prediction_time:.2f} s\")\n",
        "\n",
        "# Unseen example prediction\n",
        "unseen_embeddings = []\n",
        "for file in unseen_files:\n",
        "    with open(os.path.join(unseen_examples_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        java_code = f.read()\n",
        "    embedding = get_line_embeddings(java_code)\n",
        "    unseen_embeddings.append(embedding)\n",
        "\n",
        "unseen_embeddings = np.vstack(unseen_embeddings)\n",
        "\n",
        "# Start unseen prediction time\n",
        "start_unseen_pred_time = time.time()\n",
        "\n",
        "# Predict on unseen examples\n",
        "unseen_predictions = knn.predict(unseen_embeddings)\n",
        "\n",
        "# End unseen prediction time\n",
        "end_unseen_pred_time = time.time()\n",
        "unseen_pred_time = (end_unseen_pred_time - start_unseen_pred_time) * 1e6  # Convert to microseconds\n",
        "\n",
        "print(f\"\\nUnseen Prediction Time: {unseen_pred_time:.2f} s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wfmo64D-ZXM",
        "outputId": "f101e57a-a208-4865-91ea-cbbc894b2eb8"
      },
      "id": "9wfmo64D-ZXM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1/10\n",
            "Precision: 1.00, Recall: 0.90, F1 Score: 0.95\n",
            "Run 2/10\n",
            "Precision: 0.82, Recall: 0.90, F1 Score: 0.86\n",
            "Run 3/10\n",
            "Precision: 1.00, Recall: 0.90, F1 Score: 0.95\n",
            "Run 4/10\n",
            "Precision: 1.00, Recall: 0.70, F1 Score: 0.82\n",
            "Run 5/10\n",
            "Precision: 1.00, Recall: 1.00, F1 Score: 1.00\n",
            "Run 6/10\n",
            "Precision: 0.88, Recall: 0.70, F1 Score: 0.78\n",
            "Run 7/10\n",
            "Precision: 0.71, Recall: 1.00, F1 Score: 0.83\n",
            "Run 8/10\n",
            "Precision: 0.78, Recall: 0.70, F1 Score: 0.74\n",
            "Run 9/10\n",
            "Precision: 1.00, Recall: 0.80, F1 Score: 0.89\n",
            "Run 10/10\n",
            "Precision: 0.91, Recall: 1.00, F1 Score: 0.95\n",
            "\n",
            "Mean Precision: 0.91 (0.10)\n",
            "Mean Recall: 0.86 (0.12)\n",
            "Mean F1 Score: 0.88 (0.08)\n",
            "\n",
            "Mean Training Time: 105866108.61 s\n",
            "Mean Prediction Time: 1460.65 s\n",
            "\n",
            "Unseen Prediction Time: 1691.10 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Specify the directory path you want to delete\n",
        "dir_path = '/content/prototype'\n",
        "\n",
        "# Remove the directory and its contents\n",
        "shutil.rmtree(dir_path)\n",
        "\n",
        "print(f\"Directory '{dir_path}' has been deleted.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfkz-W2lG2u8",
        "outputId": "7af5e18e-d837-42fc-f9a2-4501e53b61b3"
      },
      "id": "tfkz-W2lG2u8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory '/content/prototype' has been deleted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Abstract Factory, Standard deviation, training time, prediction time calculation**"
      ],
      "metadata": {
        "id": "t6J91h-yIMww"
      },
      "id": "t6J91h-yIMww"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import joblib  # To save and load models\n",
        "\n",
        "# Check if GPU is available and use it; otherwise, use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/abstractfactory\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)  # Move model to the appropriate device\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Unseen examples directory\n",
        "unseen_examples_dir = \"/content/unseen_examples\"  # Modify the path to unseen examples\n",
        "unseen_files = [file for file in os.listdir(unseen_examples_dir) if os.path.isfile(os.path.join(unseen_examples_dir, file))]\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":  # Skip empty lines\n",
        "            continue\n",
        "\n",
        "        # Encode the input using the tokenizer\n",
        "        inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to device\n",
        "\n",
        "        # Forward pass through the encoder model\n",
        "        with torch.no_grad():\n",
        "            encoder_outputs = model.encoder(**inputs)  # Use only the encoder part\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = encoder_outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move output to CPU for NumPy conversion\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    if len(line_embeddings) == 0:  # To handle files with no valid lines\n",
        "        return np.zeros((1, model.config.hidden_size))\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate precision, recall, and F1\n",
        "def calculate_metrics(true_labels, predicted_labels):\n",
        "    precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "    recall = recall_score(true_labels, predicted_labels)\n",
        "    f1 = f1_score(true_labels, predicted_labels)\n",
        "    return precision, recall, f1\n",
        "\n",
        "# Define the number of iterations for the experiment\n",
        "n_runs = 10\n",
        "k = 3  # Number of neighbors to consider\n",
        "train_times = []\n",
        "prediction_times = []\n",
        "precisions, recalls, f1_scores = [], [], []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1}/{n_runs}\")\n",
        "\n",
        "    # Separate positive and negative examples\n",
        "    positive_files = [file for file in java_files if \"abstractfactory\" in file]\n",
        "    negative_files = [file for file in java_files if \"abstractfactory\" not in file]\n",
        "\n",
        "    # Select an approximately equal number of positive and negative examples\n",
        "    num_samples = min(len(positive_files), len(negative_files))\n",
        "\n",
        "    positive_sample = random.sample(positive_files, num_samples)\n",
        "    negative_sample = random.sample(negative_files, num_samples)\n",
        "\n",
        "    selected_files = positive_sample + negative_sample\n",
        "    true_labels = [1] * len(positive_sample) + [0] * len(negative_sample)\n",
        "\n",
        "    # Start training time, including tokenization, embedding extraction, and k-NN\n",
        "    start_train_time = time.time()\n",
        "\n",
        "    program_embeddings = []\n",
        "    for file in selected_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "    program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "    # Split into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(program_embeddings, true_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Train kNN\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Save the trained kNN model (Optional)\n",
        "    joblib.dump(knn, f\"knn_model_run_{run}.joblib\")\n",
        "\n",
        "    # End training time after training and model saving\n",
        "    end_train_time = time.time()\n",
        "    train_time = (end_train_time - start_train_time) * 1e6  # Convert to microseconds\n",
        "    train_times.append(train_time)\n",
        "\n",
        "    # Start prediction time\n",
        "    start_prediction_time = time.time()\n",
        "\n",
        "    # Predict on test set\n",
        "    y_pred = knn.predict(X_test)\n",
        "\n",
        "    # End prediction time after prediction\n",
        "    end_prediction_time = time.time()\n",
        "    pred_time = (end_prediction_time - start_prediction_time) * 1e6  # Convert to microseconds\n",
        "    prediction_times.append(pred_time)\n",
        "\n",
        "    # Calculate metrics\n",
        "    precision, recall, f1 = calculate_metrics(y_test, y_pred)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Calculate mean and standard deviation for precision, recall, f1-score\n",
        "mean_precision = np.mean(precisions)\n",
        "std_precision = np.std(precisions)\n",
        "mean_recall = np.mean(recalls)\n",
        "std_recall = np.std(recalls)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "\n",
        "# Calculate the mean training and prediction times\n",
        "mean_train_time = np.mean(train_times)\n",
        "mean_prediction_time = np.mean(prediction_times)\n",
        "\n",
        "print(f\"\\nMean Precision: {mean_precision:.2f} ({std_precision:.2f})\")\n",
        "print(f\"Mean Recall: {mean_recall:.2f} ({std_recall:.2f})\")\n",
        "print(f\"Mean F1 Score: {mean_f1:.2f} ({std_f1:.2f})\")\n",
        "print(f\"\\nMean Training Time: {mean_train_time:.2f} s\")\n",
        "print(f\"Mean Prediction Time: {mean_prediction_time:.2f} s\")\n",
        "\n",
        "# Unseen example prediction\n",
        "unseen_embeddings = []\n",
        "for file in unseen_files:\n",
        "    with open(os.path.join(unseen_examples_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        java_code = f.read()\n",
        "    embedding = get_line_embeddings(java_code)\n",
        "    unseen_embeddings.append(embedding)\n",
        "\n",
        "unseen_embeddings = np.vstack(unseen_embeddings)\n",
        "\n",
        "# Start unseen prediction time\n",
        "start_unseen_pred_time = time.time()\n",
        "\n",
        "# Predict on unseen examples\n",
        "unseen_predictions = knn.predict(unseen_embeddings)\n",
        "\n",
        "# End unseen prediction time\n",
        "end_unseen_pred_time = time.time()\n",
        "unseen_pred_time = (end_unseen_pred_time - start_unseen_pred_time) * 1e6  # Convert to microseconds\n",
        "\n",
        "print(f\"\\nUnseen Prediction Time: {unseen_pred_time:.2f} s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHBosFZgCMoE",
        "outputId": "d0d4db39-dcac-4db4-d6a4-97c72c9b9f4f"
      },
      "id": "QHBosFZgCMoE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1/10\n",
            "Precision: 1.00, Recall: 1.00, F1 Score: 1.00\n",
            "Run 2/10\n",
            "Precision: 1.00, Recall: 1.00, F1 Score: 1.00\n",
            "Run 3/10\n",
            "Precision: 1.00, Recall: 1.00, F1 Score: 1.00\n",
            "Run 4/10\n",
            "Precision: 0.83, Recall: 1.00, F1 Score: 0.91\n",
            "Run 5/10\n",
            "Precision: 1.00, Recall: 1.00, F1 Score: 1.00\n",
            "Run 6/10\n",
            "Precision: 0.83, Recall: 1.00, F1 Score: 0.91\n",
            "Run 7/10\n",
            "Precision: 1.00, Recall: 1.00, F1 Score: 1.00\n",
            "Run 8/10\n",
            "Precision: 0.83, Recall: 1.00, F1 Score: 0.91\n",
            "Run 9/10\n",
            "Precision: 0.67, Recall: 0.80, F1 Score: 0.73\n",
            "Run 10/10\n",
            "Precision: 0.83, Recall: 1.00, F1 Score: 0.91\n",
            "\n",
            "Mean Precision: 0.90 (0.11)\n",
            "Mean Recall: 0.98 (0.06)\n",
            "Mean F1 Score: 0.94 (0.08)\n",
            "\n",
            "Mean Training Time: 52127080.18 s\n",
            "Mean Prediction Time: 1366.95 s\n",
            "\n",
            "Unseen Prediction Time: 1811.50 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Specify the directory path you want to delete\n",
        "dir_path = '/content/abstractfactory'\n",
        "\n",
        "# Remove the directory and its contents\n",
        "shutil.rmtree(dir_path)\n",
        "\n",
        "print(f\"Directory '{dir_path}' has been deleted.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPxNxRr-KttL",
        "outputId": "aa9e0c9f-dc6b-4339-d983-c43ca8685ba7"
      },
      "id": "YPxNxRr-KttL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory '/content/abstractfactory' has been deleted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Factory method, Standard deviation, training time, prediction time calculation**"
      ],
      "metadata": {
        "id": "afZiXZcpKhMw"
      },
      "id": "afZiXZcpKhMw"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import joblib  # To save and load models\n",
        "\n",
        "# Check if GPU is available and use it; otherwise, use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/factorymethod\"  # Modify the directory path to your dataset\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeT5 model and tokenizer\n",
        "model_name = \"Salesforce/codet5-base\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)  # Move model to the appropriate device\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Unseen examples directory\n",
        "unseen_examples_dir = \"/content/unseen_examples\"  # Modify the path to unseen examples\n",
        "unseen_files = [file for file in os.listdir(unseen_examples_dir) if os.path.isfile(os.path.join(unseen_examples_dir, file))]\n",
        "\n",
        "# Function to tokenize and get embeddings for each line\n",
        "def get_line_embeddings(java_code):\n",
        "    lines = java_code.split('\\n')\n",
        "    line_embeddings = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip() == \"\":  # Skip empty lines\n",
        "            continue\n",
        "\n",
        "        # Encode the input using the tokenizer\n",
        "        inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to device\n",
        "\n",
        "        # Forward pass through the encoder model\n",
        "        with torch.no_grad():\n",
        "            encoder_outputs = model.encoder(**inputs)  # Use only the encoder part\n",
        "\n",
        "        # Use the 'last_hidden_state' attribute for embeddings\n",
        "        line_embedding = encoder_outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move output to CPU for NumPy conversion\n",
        "        line_embeddings.append(line_embedding)\n",
        "\n",
        "    if len(line_embeddings) == 0:  # To handle files with no valid lines\n",
        "        return np.zeros((1, model.config.hidden_size))\n",
        "\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Function to calculate precision, recall, and F1\n",
        "def calculate_metrics(true_labels, predicted_labels):\n",
        "    precision = precision_score(true_labels, predicted_labels, zero_division=1)\n",
        "    recall = recall_score(true_labels, predicted_labels)\n",
        "    f1 = f1_score(true_labels, predicted_labels)\n",
        "    return precision, recall, f1\n",
        "\n",
        "# Define the number of iterations for the experiment\n",
        "n_runs = 10\n",
        "k = 3  # Number of neighbors to consider\n",
        "train_times = []\n",
        "prediction_times = []\n",
        "precisions, recalls, f1_scores = [], [], []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1}/{n_runs}\")\n",
        "\n",
        "    # Separate positive and negative examples\n",
        "    positive_files = [file for file in java_files if \"factorymethod\" in file]\n",
        "    negative_files = [file for file in java_files if \"factorymethod\" not in file]\n",
        "\n",
        "    # Select an approximately equal number of positive and negative examples\n",
        "    num_samples = min(len(positive_files), len(negative_files))\n",
        "\n",
        "    positive_sample = random.sample(positive_files, num_samples)\n",
        "    negative_sample = random.sample(negative_files, num_samples)\n",
        "\n",
        "    selected_files = positive_sample + negative_sample\n",
        "    true_labels = [1] * len(positive_sample) + [0] * len(negative_sample)\n",
        "\n",
        "    # Start training time, including tokenization, embedding extraction, and k-NN\n",
        "    start_train_time = time.time()\n",
        "\n",
        "    program_embeddings = []\n",
        "    for file in selected_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            java_code = f.read()\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "    program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "    # Split into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(program_embeddings, true_labels, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Train kNN\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Save the trained kNN model (Optional)\n",
        "    joblib.dump(knn, f\"knn_model_run_{run}.joblib\")\n",
        "\n",
        "    # End training time after training and model saving\n",
        "    end_train_time = time.time()\n",
        "    train_time = (end_train_time - start_train_time) * 1e6  # Convert to microseconds\n",
        "    train_times.append(train_time)\n",
        "\n",
        "    # Start prediction time\n",
        "    start_prediction_time = time.time()\n",
        "\n",
        "    # Predict on test set\n",
        "    y_pred = knn.predict(X_test)\n",
        "\n",
        "    # End prediction time after prediction\n",
        "    end_prediction_time = time.time()\n",
        "    pred_time = (end_prediction_time - start_prediction_time) * 1e6  # Convert to microseconds\n",
        "    prediction_times.append(pred_time)\n",
        "\n",
        "    # Calculate metrics\n",
        "    precision, recall, f1 = calculate_metrics(y_test, y_pred)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Calculate mean and standard deviation for precision, recall, f1-score\n",
        "mean_precision = np.mean(precisions)\n",
        "std_precision = np.std(precisions)\n",
        "mean_recall = np.mean(recalls)\n",
        "std_recall = np.std(recalls)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "\n",
        "# Calculate the mean training and prediction times\n",
        "mean_train_time = np.mean(train_times)\n",
        "mean_prediction_time = np.mean(prediction_times)\n",
        "\n",
        "print(f\"\\nMean Precision: {mean_precision:.2f} ({std_precision:.2f})\")\n",
        "print(f\"Mean Recall: {mean_recall:.2f} ({std_recall:.2f})\")\n",
        "print(f\"Mean F1 Score: {mean_f1:.2f} ({std_f1:.2f})\")\n",
        "print(f\"\\nMean Training Time: {mean_train_time:.2f} s\")\n",
        "print(f\"Mean Prediction Time: {mean_prediction_time:.2f} s\")\n",
        "\n",
        "# Unseen example prediction\n",
        "unseen_embeddings = []\n",
        "for file in unseen_files:\n",
        "    with open(os.path.join(unseen_examples_dir, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        java_code = f.read()\n",
        "    embedding = get_line_embeddings(java_code)\n",
        "    unseen_embeddings.append(embedding)\n",
        "\n",
        "unseen_embeddings = np.vstack(unseen_embeddings)\n",
        "\n",
        "# Start unseen prediction time\n",
        "start_unseen_pred_time = time.time()\n",
        "\n",
        "# Predict on unseen examples\n",
        "unseen_predictions = knn.predict(unseen_embeddings)\n",
        "\n",
        "# End unseen prediction time\n",
        "end_unseen_pred_time = time.time()\n",
        "unseen_pred_time = (end_unseen_pred_time - start_unseen_pred_time) * 1e6  # Convert to microseconds\n",
        "\n",
        "print(f\"\\nUnseen Prediction Time: {unseen_pred_time:.2f} s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31vDCvr7IVlV",
        "outputId": "8cd23f35-169c-48aa-f4b0-03904d696294"
      },
      "id": "31vDCvr7IVlV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1/10\n",
            "Precision: 1.00, Recall: 0.75, F1 Score: 0.86\n",
            "Run 2/10\n",
            "Precision: 0.60, Recall: 0.75, F1 Score: 0.67\n",
            "Run 3/10\n",
            "Precision: 1.00, Recall: 0.50, F1 Score: 0.67\n",
            "Run 4/10\n",
            "Precision: 1.00, Recall: 0.50, F1 Score: 0.67\n",
            "Run 5/10\n",
            "Precision: 0.50, Recall: 0.75, F1 Score: 0.60\n",
            "Run 6/10\n",
            "Precision: 0.50, Recall: 0.50, F1 Score: 0.50\n",
            "Run 7/10\n",
            "Precision: 0.75, Recall: 0.75, F1 Score: 0.75\n",
            "Run 8/10\n",
            "Precision: 1.00, Recall: 0.75, F1 Score: 0.86\n",
            "Run 9/10\n",
            "Precision: 1.00, Recall: 0.75, F1 Score: 0.86\n",
            "Run 10/10\n",
            "Precision: 0.60, Recall: 0.75, F1 Score: 0.67\n",
            "\n",
            "Mean Precision: 0.79 (0.21)\n",
            "Mean Recall: 0.68 (0.11)\n",
            "Mean F1 Score: 0.71 (0.11)\n",
            "\n",
            "Mean Training Time: 51717682.08 s\n",
            "Mean Prediction Time: 1280.50 s\n",
            "\n",
            "Unseen Prediction Time: 1487.49 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RsmzJlmQNskD"
      },
      "id": "RsmzJlmQNskD"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4CSf-oKtLVUi"
      },
      "id": "4CSf-oKtLVUi",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9b250a2ef81f4b3cb512415406711303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d12aa0b1124443189a32f27ce26bca58",
              "IPY_MODEL_ef6b38bd39904e66a5aeef095cb96fdd",
              "IPY_MODEL_e4bc6f7da9a44a05b81b5a391e88f77f"
            ],
            "layout": "IPY_MODEL_696da689d04c43e1972e3bdbfc3c3236"
          }
        },
        "d12aa0b1124443189a32f27ce26bca58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2eb080c4973f4b2499072c3e141e0890",
            "placeholder": "",
            "style": "IPY_MODEL_1650169fd8824b7fb9f6e3f4a14ef360",
            "value": "config.json:100%"
          }
        },
        "ef6b38bd39904e66a5aeef095cb96fdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af7a67476dd846eca3add66b1ff7e3df",
            "max": 1568,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0dff3af71be645568ea246a538d58f91",
            "value": 1568
          }
        },
        "e4bc6f7da9a44a05b81b5a391e88f77f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94e70d77bf9846479e143df73cd04c49",
            "placeholder": "",
            "style": "IPY_MODEL_8f708922453c4152861dca12ee550aba",
            "value": "1.57k/1.57k[00:00&lt;00:00,31.2kB/s]"
          }
        },
        "696da689d04c43e1972e3bdbfc3c3236": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eb080c4973f4b2499072c3e141e0890": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1650169fd8824b7fb9f6e3f4a14ef360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af7a67476dd846eca3add66b1ff7e3df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dff3af71be645568ea246a538d58f91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94e70d77bf9846479e143df73cd04c49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f708922453c4152861dca12ee550aba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "383766ae43494cf3a8e15835afdea21f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_811d4d9dd7df4937b63181262198ac4c",
              "IPY_MODEL_477adaf5bef746deaeea243541796fd3",
              "IPY_MODEL_b4a82c2a81d74f75a0cee586f682f925"
            ],
            "layout": "IPY_MODEL_2fc5d2b9b0f043e0ab15e52b72e83dee"
          }
        },
        "811d4d9dd7df4937b63181262198ac4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_104a8896a2ce45b89c2fb5176cef9595",
            "placeholder": "",
            "style": "IPY_MODEL_9de976e7646d4741a91dc839532f641b",
            "value": "pytorch_model.bin:100%"
          }
        },
        "477adaf5bef746deaeea243541796fd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f5389cdb47a4f4695281651deaa4ff3",
            "max": 891641279,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da54876bfa4a435cbc1642a365e1767c",
            "value": 891641279
          }
        },
        "b4a82c2a81d74f75a0cee586f682f925": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17e0acab31274b12a68fd4f7aa1f57f6",
            "placeholder": "",
            "style": "IPY_MODEL_7565cec1befe4318bfcb36eba79b6b0e",
            "value": "892M/892M[00:12&lt;00:00,80.0MB/s]"
          }
        },
        "2fc5d2b9b0f043e0ab15e52b72e83dee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "104a8896a2ce45b89c2fb5176cef9595": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9de976e7646d4741a91dc839532f641b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f5389cdb47a4f4695281651deaa4ff3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da54876bfa4a435cbc1642a365e1767c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17e0acab31274b12a68fd4f7aa1f57f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7565cec1befe4318bfcb36eba79b6b0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2554f50683b4ccaa3f00a6a4fb3588d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ebac06e0ed94a82ab33bf7b8e0fc924",
              "IPY_MODEL_ef752dad89094c40b34832b4827ee694",
              "IPY_MODEL_24a620a2d0724166b4df02198e06e11b"
            ],
            "layout": "IPY_MODEL_08cc5634b8a9468db79104753d2381d0"
          }
        },
        "9ebac06e0ed94a82ab33bf7b8e0fc924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb549e606d454b93aa5ff2183cdfe19b",
            "placeholder": "",
            "style": "IPY_MODEL_f80411c16cc247f2b28c4b4cb0c8a177",
            "value": "tokenizer_config.json:100%"
          }
        },
        "ef752dad89094c40b34832b4827ee694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed228e13d733479593f7feb1d04cc38d",
            "max": 1477,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d96a885793b141e297a276e1a7ea8201",
            "value": 1477
          }
        },
        "24a620a2d0724166b4df02198e06e11b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d85ce552ee6b49e7991b27c834586d29",
            "placeholder": "",
            "style": "IPY_MODEL_8b5f3cd8234247508235acc3b1d31633",
            "value": "1.48k/1.48k[00:00&lt;00:00,24.3kB/s]"
          }
        },
        "08cc5634b8a9468db79104753d2381d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb549e606d454b93aa5ff2183cdfe19b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f80411c16cc247f2b28c4b4cb0c8a177": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed228e13d733479593f7feb1d04cc38d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d96a885793b141e297a276e1a7ea8201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d85ce552ee6b49e7991b27c834586d29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b5f3cd8234247508235acc3b1d31633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e1040d69c8c4f2d9aa571dce192a988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_660c68bcd9f24d3c93af469ece5af6b3",
              "IPY_MODEL_d1b7b30e56944ab6a86722a25b346510",
              "IPY_MODEL_56c99ee706124ca18f9619e6520101a5"
            ],
            "layout": "IPY_MODEL_11b1664cfbf848d192fc09eacc4e9937"
          }
        },
        "660c68bcd9f24d3c93af469ece5af6b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_572b197c0bd048a9a302a244c9ab6b50",
            "placeholder": "",
            "style": "IPY_MODEL_33c6e322a81c42df888cc121e2578481",
            "value": "vocab.json:100%"
          }
        },
        "d1b7b30e56944ab6a86722a25b346510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d3b1ec9eab648908297dc13154691a3",
            "max": 703051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c3bb8d49c5a4889827d3477bd30db18",
            "value": 703051
          }
        },
        "56c99ee706124ca18f9619e6520101a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_879dd54789d54c63bff62080048bdb7b",
            "placeholder": "",
            "style": "IPY_MODEL_de84b765f8bc449e8e9c05ee1995ada7",
            "value": "703k/703k[00:00&lt;00:00,1.43MB/s]"
          }
        },
        "11b1664cfbf848d192fc09eacc4e9937": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "572b197c0bd048a9a302a244c9ab6b50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33c6e322a81c42df888cc121e2578481": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d3b1ec9eab648908297dc13154691a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c3bb8d49c5a4889827d3477bd30db18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "879dd54789d54c63bff62080048bdb7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de84b765f8bc449e8e9c05ee1995ada7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4afe2b54f702420e9401b9d848f8efc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db39d052a2794a329f1bcf59c29494fc",
              "IPY_MODEL_496de13ee4854173ab74d361bb0c5073",
              "IPY_MODEL_ead4304dc577443c83101fe73930c3b7"
            ],
            "layout": "IPY_MODEL_4d54ab3afec64e5ca3e2550aa383a374"
          }
        },
        "db39d052a2794a329f1bcf59c29494fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7659351a902f4cb9bec834ff6250dc3a",
            "placeholder": "",
            "style": "IPY_MODEL_d10270c536c24e6fa6ae2c79417ba9b1",
            "value": "merges.txt:100%"
          }
        },
        "496de13ee4854173ab74d361bb0c5073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bbede88a6614d979cdaf20eb1272417",
            "max": 294364,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e384ece82520443882bb8d56c7510766",
            "value": 294364
          }
        },
        "ead4304dc577443c83101fe73930c3b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a279306713754e0b8a84e789a38c83f8",
            "placeholder": "",
            "style": "IPY_MODEL_8d553621bfce4e66a3e33e84c3d14eee",
            "value": "294k/294k[00:00&lt;00:00,1.19MB/s]"
          }
        },
        "4d54ab3afec64e5ca3e2550aa383a374": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7659351a902f4cb9bec834ff6250dc3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d10270c536c24e6fa6ae2c79417ba9b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bbede88a6614d979cdaf20eb1272417": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e384ece82520443882bb8d56c7510766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a279306713754e0b8a84e789a38c83f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d553621bfce4e66a3e33e84c3d14eee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee0561c442c0464280d3a5afaf889dc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9a3e9a87c474c4d9ceaaba6f000453e",
              "IPY_MODEL_241283bb4fb14349aee1f9609cbf9f8d",
              "IPY_MODEL_f4b780ebac7d42eb9c6dbae53647b274"
            ],
            "layout": "IPY_MODEL_80629de117f34f7e9450978e03199966"
          }
        },
        "b9a3e9a87c474c4d9ceaaba6f000453e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_317aba6ea917449cad14cedfa4c9b02b",
            "placeholder": "",
            "style": "IPY_MODEL_89eea58eebfc44289fb5a6da4a3a94af",
            "value": "added_tokens.json:100%"
          }
        },
        "241283bb4fb14349aee1f9609cbf9f8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d0e447decb94da0aff5f95cca837fa3",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a77a4be3dd546e1ac586476e2707759",
            "value": 2
          }
        },
        "f4b780ebac7d42eb9c6dbae53647b274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_228de4430715440abe4e6cad5000be07",
            "placeholder": "",
            "style": "IPY_MODEL_8b5dd03a9cf8441e8dc2535643d0c895",
            "value": "2.00/2.00[00:00&lt;00:00,32.9B/s]"
          }
        },
        "80629de117f34f7e9450978e03199966": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "317aba6ea917449cad14cedfa4c9b02b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89eea58eebfc44289fb5a6da4a3a94af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d0e447decb94da0aff5f95cca837fa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a77a4be3dd546e1ac586476e2707759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "228de4430715440abe4e6cad5000be07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b5dd03a9cf8441e8dc2535643d0c895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa1c39c8da254ffa997893d32f9e3c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a6a02404f4b4795889c41dc989ff25a",
              "IPY_MODEL_9247799fdf0f4b65941e8bf4fd4f178c",
              "IPY_MODEL_4c4f9a14b96b4793bdfedc2dc6f46556"
            ],
            "layout": "IPY_MODEL_8f6b2280927941aab803853f202ae96b"
          }
        },
        "0a6a02404f4b4795889c41dc989ff25a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8d54debf8804744ab600afaa96ac822",
            "placeholder": "",
            "style": "IPY_MODEL_f97067a63c2e4cae9f5dc8a638adf9d8",
            "value": "special_tokens_map.json:100%"
          }
        },
        "9247799fdf0f4b65941e8bf4fd4f178c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af337f12cca34c1db5aea4664211a34b",
            "max": 12512,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74f7f95447b5479bb12777b6b38c4331",
            "value": 12512
          }
        },
        "4c4f9a14b96b4793bdfedc2dc6f46556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2287967c9d8d490eb729d9c07146915f",
            "placeholder": "",
            "style": "IPY_MODEL_76427e1858484e4886f98f0e5d604ce8",
            "value": "12.5k/12.5k[00:00&lt;00:00,596kB/s]"
          }
        },
        "8f6b2280927941aab803853f202ae96b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8d54debf8804744ab600afaa96ac822": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f97067a63c2e4cae9f5dc8a638adf9d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af337f12cca34c1db5aea4664211a34b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74f7f95447b5479bb12777b6b38c4331": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2287967c9d8d490eb729d9c07146915f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76427e1858484e4886f98f0e5d604ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c30e83596fd7412abb93b7795359c11a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9152216417b049c7811cb7d540deab61",
              "IPY_MODEL_e897b9d06d1e4ae2a5d29086f2e58a42",
              "IPY_MODEL_1f5e550c9b52499f8ab5a171404921a6"
            ],
            "layout": "IPY_MODEL_f1c4d0fd95ab42feab9567fd35b30369"
          }
        },
        "9152216417b049c7811cb7d540deab61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a607aa03afb44bdebd45f8bdce83c83e",
            "placeholder": "",
            "style": "IPY_MODEL_93862745866b4b779e83024368054979",
            "value": "config.json:100%"
          }
        },
        "e897b9d06d1e4ae2a5d29086f2e58a42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_327c1956189a44cc9ab6cae16f8cad24",
            "max": 1568,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_658ecfb89ffc4c769a56e5203b96b971",
            "value": 1568
          }
        },
        "1f5e550c9b52499f8ab5a171404921a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0db6c09cad9746819c3289b8a4eb1699",
            "placeholder": "",
            "style": "IPY_MODEL_c384f0b4a06948f2af301c09a80a6e61",
            "value": "1.57k/1.57k[00:00&lt;00:00,38.8kB/s]"
          }
        },
        "f1c4d0fd95ab42feab9567fd35b30369": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a607aa03afb44bdebd45f8bdce83c83e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93862745866b4b779e83024368054979": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "327c1956189a44cc9ab6cae16f8cad24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "658ecfb89ffc4c769a56e5203b96b971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0db6c09cad9746819c3289b8a4eb1699": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c384f0b4a06948f2af301c09a80a6e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06a79f69457a41628abd36e3d4a7f7ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30d944a8b9da4f6c9383f3ad28f609a5",
              "IPY_MODEL_45d45318ec4f4b788ee2adbc00984216",
              "IPY_MODEL_26b737c02b41438395104efab176521c"
            ],
            "layout": "IPY_MODEL_ba018e548e6945989e0d70fd9b99dce3"
          }
        },
        "30d944a8b9da4f6c9383f3ad28f609a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_588265bf338a4447b5551c85f81b8df9",
            "placeholder": "",
            "style": "IPY_MODEL_ce221d5498e14e1a8b2cb1dd04eda902",
            "value": "pytorch_model.bin:100%"
          }
        },
        "45d45318ec4f4b788ee2adbc00984216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73ccd90cf2734461ad0054f2edc64b93",
            "max": 891641279,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_229584f190ff4309a5492cccab44bdc3",
            "value": 891641279
          }
        },
        "26b737c02b41438395104efab176521c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a03803ce8eed4ff5b522beb152c35ff5",
            "placeholder": "",
            "style": "IPY_MODEL_8bf4b8878b3b4634a7c86e73e74f0f84",
            "value": "892M/892M[00:15&lt;00:00,91.6MB/s]"
          }
        },
        "ba018e548e6945989e0d70fd9b99dce3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "588265bf338a4447b5551c85f81b8df9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce221d5498e14e1a8b2cb1dd04eda902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73ccd90cf2734461ad0054f2edc64b93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "229584f190ff4309a5492cccab44bdc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a03803ce8eed4ff5b522beb152c35ff5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bf4b8878b3b4634a7c86e73e74f0f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55ffab93822b45faa023dfd1d680153f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9462a6f702b24a97aea8daf21eeadbe0",
              "IPY_MODEL_c06bd4d45faf4099867d6170f37e8b85",
              "IPY_MODEL_dc4d414e4fb947c98df658cfe277dd05"
            ],
            "layout": "IPY_MODEL_942a3237ba494e91b121ca44c6735f9a"
          }
        },
        "9462a6f702b24a97aea8daf21eeadbe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_938ffd053e8f40fb97902a47e44812ef",
            "placeholder": "",
            "style": "IPY_MODEL_03037aa9b1a84c798f9756a6be103f61",
            "value": "tokenizer_config.json:100%"
          }
        },
        "c06bd4d45faf4099867d6170f37e8b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cc79f3d3b86475082264de5dcf4a74a",
            "max": 1477,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_48e50b00e11d47c088b27cb3ead7ef07",
            "value": 1477
          }
        },
        "dc4d414e4fb947c98df658cfe277dd05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cd9ced173c14542bfa70e80fad83239",
            "placeholder": "",
            "style": "IPY_MODEL_d232754bded143aa8f8b5ff4686a5762",
            "value": "1.48k/1.48k[00:00&lt;00:00,31.0kB/s]"
          }
        },
        "942a3237ba494e91b121ca44c6735f9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "938ffd053e8f40fb97902a47e44812ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03037aa9b1a84c798f9756a6be103f61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cc79f3d3b86475082264de5dcf4a74a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48e50b00e11d47c088b27cb3ead7ef07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0cd9ced173c14542bfa70e80fad83239": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d232754bded143aa8f8b5ff4686a5762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "548bafff4052489cbdcf6a487efa8680": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82ca21b1e9e74024b323344b9f09b03b",
              "IPY_MODEL_c2135a9aacd4414f8777ba2ab3810593",
              "IPY_MODEL_4bc47da38b86429d967d19177e11566d"
            ],
            "layout": "IPY_MODEL_8b420ef77bf84ca0bbdb4fa8e4349f58"
          }
        },
        "82ca21b1e9e74024b323344b9f09b03b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af87ac3084d34171be9e17ea015af189",
            "placeholder": "",
            "style": "IPY_MODEL_369f0baca06146c78756f63a30ec6838",
            "value": "vocab.json:100%"
          }
        },
        "c2135a9aacd4414f8777ba2ab3810593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88a14864173545899d18c7c1a44ff771",
            "max": 703051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_393c77192ff543a9813e97e451e88bb1",
            "value": 703051
          }
        },
        "4bc47da38b86429d967d19177e11566d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec50a742746c4e01870d79cf2d4ab16c",
            "placeholder": "",
            "style": "IPY_MODEL_894c787cbc0149b19396b21ea294f52d",
            "value": "703k/703k[00:00&lt;00:00,2.64MB/s]"
          }
        },
        "8b420ef77bf84ca0bbdb4fa8e4349f58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af87ac3084d34171be9e17ea015af189": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "369f0baca06146c78756f63a30ec6838": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88a14864173545899d18c7c1a44ff771": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "393c77192ff543a9813e97e451e88bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec50a742746c4e01870d79cf2d4ab16c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "894c787cbc0149b19396b21ea294f52d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a436c740784046ab8cab0e9e24fc065c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3bb04892e470428cb8c2726ca73cbdb5",
              "IPY_MODEL_48bb24bdff7a4e7a8e235fb41a34014a",
              "IPY_MODEL_e9ad595c766b4609a0077bfe13c5d68a"
            ],
            "layout": "IPY_MODEL_48ff6a1e30d14a44a7c5c4581d3f0970"
          }
        },
        "3bb04892e470428cb8c2726ca73cbdb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a912ed65edec4470b7559bacaa5e8705",
            "placeholder": "",
            "style": "IPY_MODEL_232c367cc55a4231a7b387e254e24034",
            "value": "merges.txt:100%"
          }
        },
        "48bb24bdff7a4e7a8e235fb41a34014a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad478a8cc4994de482dbafefefbf9f2b",
            "max": 294364,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_667137a8ec884343929ab504fc351a44",
            "value": 294364
          }
        },
        "e9ad595c766b4609a0077bfe13c5d68a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed9d129e090041feae62ac3823849b8c",
            "placeholder": "",
            "style": "IPY_MODEL_48c7d4dbea044322b67ce73c5001063c",
            "value": "294k/294k[00:00&lt;00:00,2.16MB/s]"
          }
        },
        "48ff6a1e30d14a44a7c5c4581d3f0970": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a912ed65edec4470b7559bacaa5e8705": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "232c367cc55a4231a7b387e254e24034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad478a8cc4994de482dbafefefbf9f2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "667137a8ec884343929ab504fc351a44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed9d129e090041feae62ac3823849b8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48c7d4dbea044322b67ce73c5001063c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f444e1f4d18c41f8920d85a0ff00dc0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c7f44ade6ac4a5794f23f21708160c6",
              "IPY_MODEL_c39a89944455488e9ef36b91bdf8c2a0",
              "IPY_MODEL_52116dcaa3284154ae10a9260c1047d2"
            ],
            "layout": "IPY_MODEL_87ad63d983af4382a379b8bcc98b416a"
          }
        },
        "6c7f44ade6ac4a5794f23f21708160c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3228bd816090448bbc16a9c066715acb",
            "placeholder": "",
            "style": "IPY_MODEL_0746ede38c724de5b6e3d223f71b30a6",
            "value": "added_tokens.json:100%"
          }
        },
        "c39a89944455488e9ef36b91bdf8c2a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eac8f917e36a471cbf3de196aeb40bc8",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb3fe6edf4fa488da58667bca3630372",
            "value": 2
          }
        },
        "52116dcaa3284154ae10a9260c1047d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_340a61cfc68d4133ad45404f88653b26",
            "placeholder": "",
            "style": "IPY_MODEL_2031be89d5154c8fb551b26e2ba03a32",
            "value": "2.00/2.00[00:00&lt;00:00,38.3B/s]"
          }
        },
        "87ad63d983af4382a379b8bcc98b416a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3228bd816090448bbc16a9c066715acb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0746ede38c724de5b6e3d223f71b30a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eac8f917e36a471cbf3de196aeb40bc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb3fe6edf4fa488da58667bca3630372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "340a61cfc68d4133ad45404f88653b26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2031be89d5154c8fb551b26e2ba03a32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9cbe66e4be94e658d0355604428f873": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2eaaf1bb50e1486791b406e5f003fd11",
              "IPY_MODEL_0d29f71cdf9b487eae8ea1361bcef7cc",
              "IPY_MODEL_f65fb39b822848d8893a845ab6f378b6"
            ],
            "layout": "IPY_MODEL_8c6074dcfa2947dfb3da0ef5520cefae"
          }
        },
        "2eaaf1bb50e1486791b406e5f003fd11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af2d667217e84b248422ae734f5d3e28",
            "placeholder": "",
            "style": "IPY_MODEL_a04f55eaedd44d71b407afd7ce7c7ed2",
            "value": "special_tokens_map.json:100%"
          }
        },
        "0d29f71cdf9b487eae8ea1361bcef7cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da45073e778f4562ae737842d71e93e5",
            "max": 12512,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4bfa38ea1ca49158c3fbaff87d34cf8",
            "value": 12512
          }
        },
        "f65fb39b822848d8893a845ab6f378b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4f60d9a1cd7414cbcad286e889e64f7",
            "placeholder": "",
            "style": "IPY_MODEL_1fadeaa91e73494f9ec81ef931195ac2",
            "value": "12.5k/12.5k[00:00&lt;00:00,301kB/s]"
          }
        },
        "8c6074dcfa2947dfb3da0ef5520cefae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af2d667217e84b248422ae734f5d3e28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a04f55eaedd44d71b407afd7ce7c7ed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da45073e778f4562ae737842d71e93e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4bfa38ea1ca49158c3fbaff87d34cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4f60d9a1cd7414cbcad286e889e64f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fadeaa91e73494f9ec81ef931195ac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}