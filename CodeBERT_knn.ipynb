{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "904b50dd-9152-4385-9f91-832a1a65be0e",
      "metadata": {
        "id": "904b50dd-9152-4385-9f91-832a1a65be0e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"singleton\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"singleton\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3daf9e57-7d27-4171-a637-4e43f44d85e1",
      "metadata": {
        "id": "3daf9e57-7d27-4171-a637-4e43f44d85e1",
        "outputId": "468a8d7c-159a-4a71-b14b-d92cd0034138"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nons (54).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (25).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (25).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (18).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (19).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (55).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (34).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (24).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (68).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (9).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (33).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (53).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (35).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (16).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (22).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (47).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (60).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (46).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (5).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (19).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (65).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (52).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (28).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.78\n",
            "Recall: 0.75\n",
            "F1 Score: 0.73\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"singleton\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"singleton\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e0f7908-0eee-4b84-9fc1-5b42710c547e",
      "metadata": {
        "id": "5e0f7908-0eee-4b84-9fc1-5b42710c547e"
      },
      "outputs": [],
      "source": [
        "Singleton with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "407b036b-84f6-49ea-a291-6dddac6b9bd4",
      "metadata": {
        "id": "407b036b-84f6-49ea-a291-6dddac6b9bd4",
        "outputId": "1be2eb22-161b-423f-e0b6-8b47ee021eb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nons (54).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (25).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (25).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (18).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (19).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (55).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (34).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (24).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (68).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (9).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (33).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (53).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (35).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (16).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (22).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (47).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (60).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (46).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (5).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (19).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (65).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (52).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (28).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.78\n",
            "Recall: 0.75\n",
            "F1 Score: 0.73\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"singleton\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"singleton\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7df516d-6a9a-4043-a1f1-3607601969e9",
      "metadata": {
        "id": "b7df516d-6a9a-4043-a1f1-3607601969e9"
      },
      "outputs": [],
      "source": [
        "Singleton with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdbd23bd-c00c-4152-b3f3-a1e0b9dfe0af",
      "metadata": {
        "id": "bdbd23bd-c00c-4152-b3f3-a1e0b9dfe0af",
        "outputId": "8ecf87ae-d0ec-4307-bd12-37c2df8e70ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nons (50).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (25).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (18).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (4).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (44).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (38).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (41).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (23).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (11).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (2).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (48).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (63).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (40).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (37).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (22).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (51).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (32).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (56).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (62).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (64).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (19).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (2).java, Actual Label: 1, Predicted Label: 1\n",
            "\n",
            "Precision: 0.75\n",
            "Recall: 0.74\n",
            "F1 Score: 0.75\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"singleton\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"singleton\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd90482f-d0ce-4c18-a515-c3e972078c3d",
      "metadata": {
        "id": "dd90482f-d0ce-4c18-a515-c3e972078c3d"
      },
      "outputs": [],
      "source": [
        "Singleton with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e077534-f98e-4869-9d70-88ded1e88973",
      "metadata": {
        "id": "3e077534-f98e-4869-9d70-88ded1e88973",
        "outputId": "7626c7f9-b55a-4e86-fe0e-509fedd4641b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nons (54).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (25).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (18).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (19).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (34).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (9).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (33).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (53).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (16).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (22).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (60).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (46).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (5).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (19).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (28).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.76\n",
            "Recall: 0.71\n",
            "F1 Score: 0.71\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"singleton\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"singleton\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7615078-d8c4-48af-9934-0af845efca16",
      "metadata": {
        "id": "f7615078-d8c4-48af-9934-0af845efca16",
        "outputId": "d37c1826-f769-4a44-9dfd-09ea1742bd44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nons (54).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (25).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (27).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (18).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (19).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (34).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (9).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (53).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (16).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (22).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (60).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (46).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (5).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (19).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (28).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.69\n",
            "Recall: 0.65\n",
            "F1 Score: 0.65\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"singleton\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"singleton\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3fd05c9-dc1c-41c7-aad9-432fcd9bbca1",
      "metadata": {
        "id": "c3fd05c9-dc1c-41c7-aad9-432fcd9bbca1"
      },
      "outputs": [],
      "source": [
        "Builder with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37d5eb4d-3dd8-496b-afa1-7dceec1acdc6",
      "metadata": {
        "id": "37d5eb4d-3dd8-496b-afa1-7dceec1acdc6",
        "outputId": "107184cd-3023-4047-eb89-484d2fa14e1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonb (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (41).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (110).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (85).java, Actual Label: 0, Predicted Label: 1\n",
            "File: builder (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (92).java, Actual Label: 0, Predicted Label: 1\n",
            "File: builder (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (93).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (108).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonb (131).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonb (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (24).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.79\n",
            "Recall: 0.77\n",
            "F1 Score: 0.77\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"builder\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"builder\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb9f2d28-d993-4409-ae7b-f097d6688457",
      "metadata": {
        "id": "cb9f2d28-d993-4409-ae7b-f097d6688457"
      },
      "outputs": [],
      "source": [
        "#Builder with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d9dea7c-1570-48c1-8575-28c11a4da1c2",
      "metadata": {
        "id": "9d9dea7c-1570-48c1-8575-28c11a4da1c2",
        "outputId": "42fe9cc2-022c-4317-e077-e7bd28f27bb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonb (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (5).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (110).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (119).java, Actual Label: 0, Predicted Label: 1\n",
            "File: builder (8).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (93).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (108).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonb (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (7).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.67\n",
            "Recall: 0.67\n",
            "F1 Score: 0.65\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"builder\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"builder\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae3fff63-6ba6-4da4-b17f-13aac52d8d5c",
      "metadata": {
        "id": "ae3fff63-6ba6-4da4-b17f-13aac52d8d5c"
      },
      "outputs": [],
      "source": [
        "#Builder with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f54fb60-8f59-4d97-b879-3d26b6b49bb1",
      "metadata": {
        "id": "4f54fb60-8f59-4d97-b879-3d26b6b49bb1",
        "outputId": "822e473f-d2f6-4033-d519-469c0ef95e93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: builder (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (89).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (49).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (36).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (126).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (44).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (120).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (69).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (129).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (114).java, Actual Label: 0, Predicted Label: 1\n",
            "File: builder (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (33).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.90\n",
            "Recall: 0.90\n",
            "F1 Score: 0.90\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"builder\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"builder\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a351f8ed-ef7f-4345-98eb-7fb254c86c1a",
      "metadata": {
        "id": "a351f8ed-ef7f-4345-98eb-7fb254c86c1a"
      },
      "outputs": [],
      "source": [
        "#Builder with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d17ee28d-d16b-4533-b912-b568933fb86c",
      "metadata": {
        "id": "d17ee28d-d16b-4533-b912-b568933fb86c",
        "outputId": "e3a3d560-14cb-405b-e7ce-5e315b6cc6a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonb (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (5).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (110).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (92).java, Actual Label: 0, Predicted Label: 1\n",
            "File: builder (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (119).java, Actual Label: 0, Predicted Label: 1\n",
            "File: builder (8).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (93).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (108).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonb (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (7).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.63\n",
            "Recall: 0.64\n",
            "F1 Score: 0.63\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"builder\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"builder\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dacb2a99-27d0-40aa-a8f6-3b442b3fb092",
      "metadata": {
        "id": "dacb2a99-27d0-40aa-a8f6-3b442b3fb092"
      },
      "outputs": [],
      "source": [
        "#Builder with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75a20231-7226-4078-bb90-a80384fd282f",
      "metadata": {
        "id": "75a20231-7226-4078-bb90-a80384fd282f",
        "outputId": "371fec3a-e482-4503-c5a4-026e10242d0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: builder (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (50).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (36).java, Actual Label: 0, Predicted Label: 1\n",
            "File: builder (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (87).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (29).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (123).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (129).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (114).java, Actual Label: 0, Predicted Label: 1\n",
            "File: builder (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (62).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.79\n",
            "Recall: 0.79\n",
            "F1 Score: 0.79\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"builder\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"builder\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c06d5cc9-8d88-462d-8203-7d21f6ace3f7",
      "metadata": {
        "id": "c06d5cc9-8d88-462d-8203-7d21f6ace3f7"
      },
      "outputs": [],
      "source": [
        "#abstract factory with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0b5c718-ba8b-4532-bb58-393d619e79fe",
      "metadata": {
        "id": "d0b5c718-ba8b-4532-bb58-393d619e79fe",
        "outputId": "7f0eb9dc-3a0d-4b17-da75-0d4d5a193170"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonfm (34).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (37).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (13).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonfm (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (16).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (49).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (5).java, Actual Label: 1, Predicted Label: 0\n",
            "File: abstractfactory (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: abstractfactory (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (15).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (52).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (6).java, Actual Label: 1, Predicted Label: 1\n",
            "\n",
            "Precision: 0.70\n",
            "Recall: 0.70\n",
            "F1 Score: 0.70\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"abstractfactory\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"abstractfactory\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db7804ed-0c50-4fff-adc1-169cb11817b1",
      "metadata": {
        "id": "db7804ed-0c50-4fff-adc1-169cb11817b1"
      },
      "outputs": [],
      "source": [
        "#abstract factory with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f76c954-e0f0-4ece-8152-37a4a7d666b9",
      "metadata": {
        "id": "1f76c954-e0f0-4ece-8152-37a4a7d666b9",
        "outputId": "59f23179-75db-4ec1-cdef-65782bdea7b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonab (22).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (19).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (70).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: abstractfactory (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (14).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (36).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (42).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (32).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (38).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (4).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (73).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (43).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (54).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonab (64).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (84).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (47).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (6).java, Actual Label: 1, Predicted Label: 1\n",
            "\n",
            "Precision: 0.83\n",
            "Recall: 0.83\n",
            "F1 Score: 0.83\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"abstractfactory\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"abstractfactory\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0114a3a-3add-454b-a978-2c9ea8972070",
      "metadata": {
        "id": "d0114a3a-3add-454b-a978-2c9ea8972070"
      },
      "outputs": [],
      "source": [
        "#abstract factory with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0f29081-8a4d-443a-ab86-021a92e1c0bd",
      "metadata": {
        "id": "f0f29081-8a4d-443a-ab86-021a92e1c0bd",
        "outputId": "4ca6b7cb-c045-4826-fb3b-16fa86c85010"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: abstractfactory (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (65).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: abstractfactory (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (33).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (86).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (29).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (62).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonab (17).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (6).java, Actual Label: 1, Predicted Label: 0\n",
            "\n",
            "Precision: 0.86\n",
            "Recall: 0.85\n",
            "F1 Score: 0.85\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"abstractfactory\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"abstractfactory\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7334bc2-9afb-4eec-9673-6c5fe7b33a56",
      "metadata": {
        "id": "e7334bc2-9afb-4eec-9673-6c5fe7b33a56"
      },
      "outputs": [],
      "source": [
        "#abstract factory with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b733d87-c74c-46ac-a53b-0187b7490a28",
      "metadata": {
        "id": "4b733d87-c74c-46ac-a53b-0187b7490a28",
        "outputId": "96326353-a68a-407b-95e9-fa07a3e1669b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonab (11).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (1).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (4).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: abstractfactory (6).java, Actual Label: 1, Predicted Label: 0\n",
            "\n",
            "Precision: 0.87\n",
            "Recall: 0.87\n",
            "F1 Score: 0.87\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"abstractfactory\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"abstractfactory\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "273845d2-4392-4bfb-9567-1188258cb5f8",
      "metadata": {
        "id": "273845d2-4392-4bfb-9567-1188258cb5f8"
      },
      "outputs": [],
      "source": [
        "#abstract factory with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f2ce492-fcbb-4660-8038-dd46a98bed01",
      "metadata": {
        "id": "4f2ce492-fcbb-4660-8038-dd46a98bed01",
        "outputId": "84f215db-526b-4ade-ed3f-55550118cb6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonab (11).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (22).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (65).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (13).java, Actual Label: 1, Predicted Label: 0\n",
            "File: abstractfactory (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: abstractfactory (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (32).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (38).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (57).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (50).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (45).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (43).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (61).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (54).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (63).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (68).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (20).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (6).java, Actual Label: 1, Predicted Label: 1\n",
            "\n",
            "Precision: 0.82\n",
            "Recall: 0.82\n",
            "F1 Score: 0.82\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"abstractfactory\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"abstractfactory\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6f493c0-ac4f-455d-8b2b-35b2237b7b2a",
      "metadata": {
        "id": "e6f493c0-ac4f-455d-8b2b-35b2237b7b2a"
      },
      "outputs": [],
      "source": [
        "#Prototype with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6dcad75-7269-4818-831e-0c0ebfbaeec3",
      "metadata": {
        "id": "f6dcad75-7269-4818-831e-0c0ebfbaeec3",
        "outputId": "4a991671-f918-448f-ce11-8bbe3104f7d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: prototype (27).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (43).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (35).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (51).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (22).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (29).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (37).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (18).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (22).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (32).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (19).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (32).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (26).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (48).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (45).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (25).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (50).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (29).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (31).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (52).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (10).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (41).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (47).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (23).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (1).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (28).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (30).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (18).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (34).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (26).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (9).java, Actual Label: 1, Predicted Label: 1\n",
            "\n",
            "Precision: 0.81\n",
            "Recall: 0.80\n",
            "F1 Score: 0.79\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"prototype\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"prototype\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33b2dbf7-ff9d-448d-83c7-b702ebf9eb8f",
      "metadata": {
        "id": "33b2dbf7-ff9d-448d-83c7-b702ebf9eb8f"
      },
      "outputs": [],
      "source": [
        "#Prototype with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94771738-fba3-4bbf-a2d7-7edee410909c",
      "metadata": {
        "id": "94771738-fba3-4bbf-a2d7-7edee410909c",
        "outputId": "2078bde5-dfde-4262-a79e-4c8c62e27748"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: prototype (27).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (59).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (22).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (21).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (58).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (18).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (22).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (32).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (19).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (26).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (25).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (4).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (29).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (31).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (19).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (10).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (60).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (56).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (23).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (1).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (28).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (30).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (18).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (57).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (11).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (61).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.77\n",
            "Recall: 0.77\n",
            "F1 Score: 0.77\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"prototype\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"prototype\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ef9daf9-ffd1-4411-9c55-05ea1544128d",
      "metadata": {
        "id": "2ef9daf9-ffd1-4411-9c55-05ea1544128d"
      },
      "outputs": [],
      "source": [
        "#Prototype with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fbf562a-e2de-4f90-87ef-ee892a0ff730",
      "metadata": {
        "id": "5fbf562a-e2de-4f90-87ef-ee892a0ff730",
        "outputId": "2f702629-824b-45e2-826a-21d3fdd0d37f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: prototype (27).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (59).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (22).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (21).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (58).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (18).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (22).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (32).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (19).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (26).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (25).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (4).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (29).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (31).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (19).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (10).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (60).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (56).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (23).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (1).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (28).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (30).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (18).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (57).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (11).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (61).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.77\n",
            "Recall: 0.77\n",
            "F1 Score: 0.77\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"prototype\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"prototype\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b4970f3-70ae-420e-800a-5f5e3b7394fb",
      "metadata": {
        "id": "8b4970f3-70ae-420e-800a-5f5e3b7394fb"
      },
      "outputs": [],
      "source": [
        "#Prototype with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f4b21fb-6d6f-4339-b0c0-f4244eda2456",
      "metadata": {
        "id": "0f4b21fb-6d6f-4339-b0c0-f4244eda2456",
        "outputId": "7d56ec2f-e885-41c3-b4dc-e529ad1fb2fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: prototype (27).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (43).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (59).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (31).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (22).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (44).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (37).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (36).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (58).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (18).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (32).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (19).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (38).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (26).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (48).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (45).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (25).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (33).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (50).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (29).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (31).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (19).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (52).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (10).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (41).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (55).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (56).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (47).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (1).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (28).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (30).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (57).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (34).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (26).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (40).java, Actual Label: 0, Predicted Label: 1\n",
            "\n",
            "Precision: 0.84\n",
            "Recall: 0.81\n",
            "F1 Score: 0.81\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"prototype\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"prototype\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d36871e-385a-467e-909f-c7e9e30ff9ac",
      "metadata": {
        "id": "0d36871e-385a-467e-909f-c7e9e30ff9ac"
      },
      "outputs": [],
      "source": [
        "#Prototype with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea8ecb4a-f14e-41c6-844f-2d556a67a954",
      "metadata": {
        "id": "ea8ecb4a-f14e-41c6-844f-2d556a67a954",
        "outputId": "18f48868-7bb5-4313-c475-0ee25d367f94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: prototype (27).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (43).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (35).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (51).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (22).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (44).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (36).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (58).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (49).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (18).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (22).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (32).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (19).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (38).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (26).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (46).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (42).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (45).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (25).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (4).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (29).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (31).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (19).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (52).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (10).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (55).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (60).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (56).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (47).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (28).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (30).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (34).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (26).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (40).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (61).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.83\n",
            "Recall: 0.82\n",
            "F1 Score: 0.81\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"prototype\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"prototype\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16606c28-cdc0-4a5c-a2a8-2bde64c9eeb9",
      "metadata": {
        "id": "16606c28-cdc0-4a5c-a2a8-2bde64c9eeb9",
        "outputId": "aad26b99-ee04-43df-97ee-bcd7314118d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: prototype (27).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (43).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (35).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (51).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (22).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (44).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (36).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (58).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (49).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (18).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (22).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (32).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (19).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (38).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (26).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (46).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (42).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (45).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (25).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (4).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (29).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (31).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (19).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (52).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (10).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (55).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (60).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (56).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (47).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (28).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (30).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (34).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (26).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (40).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (61).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.83\n",
            "Recall: 0.82\n",
            "F1 Score: 0.81\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"prototype\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"prototype\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4083233-4c47-46be-8655-00a445b80d15",
      "metadata": {
        "id": "e4083233-4c47-46be-8655-00a445b80d15"
      },
      "outputs": [],
      "source": [
        "#Factory Method with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48298074-a16c-4848-8eac-96550f0bfe6b",
      "metadata": {
        "id": "48298074-a16c-4848-8eac-96550f0bfe6b",
        "outputId": "732cf8a9-a028-4548-eadd-16099a848305"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonfm (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (9).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (11).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (17).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (9).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (15).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.71\n",
            "Recall: 0.70\n",
            "F1 Score: 0.69\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"factorymethod\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cccc939-90de-4db6-980f-097fd3227083",
      "metadata": {
        "id": "2cccc939-90de-4db6-980f-097fd3227083"
      },
      "outputs": [],
      "source": [
        "#Factory method with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4c80dfa-e9be-4b31-bb43-d675659301af",
      "metadata": {
        "id": "c4c80dfa-e9be-4b31-bb43-d675659301af",
        "outputId": "2e0e030a-1ff9-4eea-fa1f-9f58ccbd3d30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonfm (77).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (80).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (79).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (75).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (78).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (82).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonfm (74).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (81).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (76).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (73).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.77\n",
            "Recall: 0.76\n",
            "F1 Score: 0.76\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"factorymethod\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eabebac7-6217-4ecb-9b15-f8b6b9593e68",
      "metadata": {
        "id": "eabebac7-6217-4ecb-9b15-f8b6b9593e68"
      },
      "outputs": [],
      "source": [
        "#Factory Method with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e877816-f680-46e2-89b3-8fa3a21bb10b",
      "metadata": {
        "id": "9e877816-f680-46e2-89b3-8fa3a21bb10b",
        "outputId": "9c809e54-46d8-4195-d66c-a1631d8764b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonfm (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (4).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (1).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (8).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (7).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.84\n",
            "Recall: 0.84\n",
            "F1 Score: 0.84\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"factorymethod\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d10a31c1-9028-4d89-90f3-22dbb8a52270",
      "metadata": {
        "id": "d10a31c1-9028-4d89-90f3-22dbb8a52270"
      },
      "outputs": [],
      "source": [
        "#Factory method with different settingsactual_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b130c18a-d8cb-4919-9a20-55f940ddcf5f",
      "metadata": {
        "id": "b130c18a-d8cb-4919-9a20-55f940ddcf5f",
        "outputId": "3707fe5c-3d35-4f67-98f6-1199e02b42a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonfm (77).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (80).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (79).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (75).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (72).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (78).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (74).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (76).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (71).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonfm (73).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.82\n",
            "Recall: 0.81\n",
            "F1 Score: 0.81\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"factorymethod\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fa7d264-22bc-4a2d-8188-b66996258b62",
      "metadata": {
        "id": "4fa7d264-22bc-4a2d-8188-b66996258b62"
      },
      "outputs": [],
      "source": [
        "#Factory method with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b465b38-9d7b-44c4-8e93-7aac5f8a17b1",
      "metadata": {
        "id": "3b465b38-9d7b-44c4-8e93-7aac5f8a17b1",
        "outputId": "6dd18358-0e4e-4813-93d0-f9e53bf7e568"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonfm (77).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (68).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (79).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (75).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (72).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (70).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (82).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (81).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (6).java, Actual Label: 1, Predicted Label: 0\n",
            "\n",
            "Precision: 0.68\n",
            "Recall: 0.68\n",
            "F1 Score: 0.68\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"factorymethod\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ae5e35d-6710-4c5b-85bb-831b48e6e753",
      "metadata": {
        "id": "7ae5e35d-6710-4c5b-85bb-831b48e6e753"
      },
      "outputs": [],
      "source": [
        "#Factory Method with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e133b575-a751-49e2-b2f2-a53aa6cda61e",
      "metadata": {
        "id": "e133b575-a751-49e2-b2f2-a53aa6cda61e",
        "outputId": "f3fac23c-58dd-4e9f-fdad-c0d656b32343"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonfm (77).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (80).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (79).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (75).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (72).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (78).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (82).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonfm (74).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (81).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (76).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (71).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonfm (73).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.74\n",
            "Recall: 0.74\n",
            "F1 Score: 0.74\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"factorymethod\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db1ebd82-b5b1-48e4-a342-14b5c40b61f6",
      "metadata": {
        "id": "db1ebd82-b5b1-48e4-a342-14b5c40b61f6"
      },
      "outputs": [],
      "source": [
        "#To plot t-SNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18bdadc2-36dd-41d1-8a3d-781db4e17998",
      "metadata": {
        "id": "18bdadc2-36dd-41d1-8a3d-781db4e17998",
        "outputId": "e5bcffe9-7a70-4527-fb6a-eee73b6b8149"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting seaborn\n",
            "  Downloading seaborn-0.13.0-py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy!=1.24.0,>=1.20 in /apps/Arch/software/SciPy-bundle/2022.05-foss-2022a/lib/python3.10/site-packages (from seaborn) (1.22.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in /apps/Arch/software/matplotlib/3.5.2-foss-2022a/lib/python3.10/site-packages (from seaborn) (3.5.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /apps/Arch/software/SciPy-bundle/2022.05-foss-2022a/lib/python3.10/site-packages (from seaborn) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /apps/Arch/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /apps/Arch/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (20.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /apps/Arch/software/matplotlib/3.5.2-foss-2022a/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /apps/Arch/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (3.0.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /apps/Arch/software/matplotlib/3.5.2-foss-2022a/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.4.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /apps/Arch/software/Pillow/9.1.1-GCCcore-11.3.0/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (9.1.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /apps/Arch/software/matplotlib/3.5.2-foss-2022a/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (4.34.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /apps/Arch/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /apps/Arch/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.3->seaborn) (1.16.0)\n",
            "Installing collected packages: seaborn\n",
            "Successfully installed seaborn-0.13.0\n",
            "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
            "You should consider upgrading via the '/apps/Arch/software/Python/3.10.4-GCCcore-11.3.0/bin/python3.10 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "100308e0-b77a-4221-8acc-fd7f82d441cc",
      "metadata": {
        "id": "100308e0-b77a-4221-8acc-fd7f82d441cc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Function to get embeddings for a given design pattern\n",
        "def get_embeddings_for_pattern(pattern, model, tokenizer):\n",
        "    directory = os.path.join(\"all_design_patterns\", pattern.lower())\n",
        "    files = [file for file in os.listdir(directory) if os.path.isfile(os.path.join(directory, file))]\n",
        "\n",
        "    embeddings = []\n",
        "    true_labels = []\n",
        "\n",
        "    for file in files:\n",
        "        with open(os.path.join(directory, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "            code = f.read()\n",
        "\n",
        "        # Tokenize and encode the Java program\n",
        "        inputs = tokenizer(code, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        program_embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "\n",
        "        embeddings.append(program_embedding)\n",
        "        true_labels.append(pattern)\n",
        "\n",
        "    return np.array(embeddings), np.array(true_labels)\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Get embeddings for each design pattern\n",
        "patterns = [\"Singleton\", \"Prototype\", \"AbstractFactory\", \"Builder\", \"FactoryMethod\"]\n",
        "all_embeddings = []\n",
        "all_labels = []\n",
        "\n",
        "# Custom color palette for each design pattern with higher contrast\n",
        "color_palette = [\"red\", \"green\", \"orange\", \"blue\", \"purple\"]\n",
        "\n",
        "# Custom markers for each design pattern\n",
        "markers = [\"o\", \"s\", \"D\", \"^\", \"P\"]\n",
        "\n",
        "for i, pattern in enumerate(patterns):\n",
        "    pattern_embeddings, pattern_labels = get_embeddings_for_pattern(pattern, model, tokenizer)\n",
        "    all_embeddings.append(pattern_embeddings)\n",
        "    all_labels.append(pattern_labels)\n",
        "\n",
        "# Concatenate the embeddings and labels\n",
        "all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
        "all_labels = np.concatenate(all_labels)\n",
        "\n",
        "# Perform t-SNE\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "tsne_results = tsne.fit_transform(all_embeddings)\n",
        "\n",
        "# Create a scatter plot for t-SNE visualization with custom symbols\n",
        "plt.figure(figsize=(20, 16))\n",
        "\n",
        "for i, pattern in enumerate(patterns):\n",
        "    indices = all_labels == pattern\n",
        "    sns.scatterplot(x=tsne_results[indices, 0], y=tsne_results[indices, 1], marker=markers[i], color=color_palette[i], s=200, label=pattern)\n",
        "\n",
        "# Increase font sizes for better visibility\n",
        "plt.title('t-SNE Visualization for CodeBERT on Different Design Patterns', fontsize=30)\n",
        "plt.xlabel('t-SNE Dimension 1', fontsize=25)\n",
        "plt.ylabel('t-SNE Dimension 2', fontsize=25)\n",
        "plt.legend(title='Design Pattern', loc='upper right', fontsize=22)\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.grid(True)\n",
        "\n",
        "# Save the t-SNE plot as a PDF file\n",
        "plt.savefig('tsne_plot_updated_symbols_colors.pdf', format='pdf')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "p88WzSc6ogZA",
      "metadata": {
        "id": "p88WzSc6ogZA"
      },
      "source": [
        "testing the time module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c729eb2-a50f-4d0f-a4ff-b714296fd93c",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 368,
          "referenced_widgets": [
            "fbb3a7d54d3f4b979da8a0fb599a5de7",
            "db6e83e495d748f3832fe4f6842abeb4",
            "770ce23b84fe4e419b2fbb19d2ed2d13",
            "9497be65739b4919abea118d344bd4f6",
            "e667eb72729f4cfbbfac941cd3ecb21f",
            "a3f6c7e8f4fa41a2b209b80a85456158",
            "288553384e4541abbdcf55e1003c8cf5",
            "7c7b1e1fc23b4643b0346651b247438d",
            "cc4f1a5759e54b1ca200d354d37b99c7",
            "8c83c857ea7c49289ab85ed3736d2558",
            "0f5f1c475bc4483e9be3e6d5e00d491b",
            "8d17f81b4b884012bdcc8c53e6cc7d74",
            "ba13e71bca71463b9bc1548aaf49e352",
            "f8a346924c644c8f9631b9f86daaf73e",
            "d728658f24914208a3e107b8d6d0973f",
            "af8e45438afd4672967c9817435a0ed4",
            "f3b552e728ce41f7a555e650269d736b",
            "542d184132e546d8a005d7a11a1045d5",
            "3512aab0fc6f4e3db3e9847684ea6639",
            "69fb4505d7464d4092c8d543ee596c61",
            "64e57361b5944b2a91112225696c0490",
            "069364f5a1be40ae978ba2c9b7a95291",
            "81356b11043c4ef081fb196bc00db57b",
            "c187cb5e29224545bacbb57f89078dfb",
            "a41e6faf3bf94cfdb875dd2575d61720",
            "a51ecdec6d384172bbb9627a4c8f85fa",
            "cdc7ca4fa7e44c42acd49042505133ca",
            "784bdcecc2304b3ea0d049ab9b4636da",
            "66eb1acdc50040d6b5a098ae00035610",
            "02b627e68f4a421ba09ba15b9ab08dca",
            "53314f68b919408eb7bd21d31241a7b6",
            "c3dfd3d0b5444676b863f4d174018255",
            "8b628394476340688c29a9a5f42e825f",
            "e71aacc132b44a2b9537042d2acee67d",
            "fa833aef462f49ac9f5de3d43d60432d",
            "75a52a6867754aa790c4fa0011a4d86b",
            "8596e8a719f6402199e14d5c78127405",
            "37f1382bde094b37bfd597ac8be0c4f7",
            "4f78fc52fb2a418c87770ba3fb041990",
            "b2b134a3cdfd4176afb896313ec427a8",
            "43a9d3c5cde042af84ecb5c5dbf94065",
            "dbd1eae035b44e758f3033ffeef65847",
            "069cfab2125844a58cbcc8c5164bb2ca",
            "97e9c9d72f184fc39d0b8dd121f7e351",
            "f66d5e14400a4b22862fdfe1d821305d",
            "990c38df28e443dd94ab0b9f8ac7d36e",
            "d0c2dd25680d4139b5581c6da5f06049",
            "eed0003fa6ca4a5085def1f17daa547f",
            "f0a7f19611d54ebfa4ffacccd79c91ec",
            "0e706a81e337422fbc7fba5096679a2c",
            "4dfe97c2b40a449ebcbb0b35cd84f7af",
            "183973f08d6f41b5bc97cc594ef6d5dc",
            "6b82c85c2b3b4ba3b2c82540f1dac4db",
            "df56c6c33fe4465d9e7ceec2f78eb045",
            "1091411f109f4a168a27a1ce4011d1ff",
            "f66166883b294dddbf0125787eec3866",
            "62a4ac8655de4477839e5e121b225b1a",
            "8327eb9accd443b5aa9dbff743e0065d",
            "7328e328f2eb4fd68619159748eb3540",
            "ffaabcb4e78043a19a630270d709447a",
            "34dc93f2356b4b0d80c9621dea9f24f0",
            "f306098093cf4f54bb99a66e43699a69",
            "3e0dfff6c8c44447b9182344c7cac666",
            "083fe7730cb740c7b50dfeddede172d6",
            "d500e7de70e34c67af5a3aac614b2622",
            "dbb19fbfaa8e40cfa1523f3210144828"
          ]
        },
        "id": "0c729eb2-a50f-4d0f-a4ff-b714296fd93c",
        "outputId": "8c7b07a6-8beb-49cf-909b-9bb1de014480"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbb3a7d54d3f4b979da8a0fb599a5de7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d17f81b4b884012bdcc8c53e6cc7d74",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81356b11043c4ef081fb196bc00db57b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e71aacc132b44a2b9537042d2acee67d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f66d5e14400a4b22862fdfe1d821305d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f66166883b294dddbf0125787eec3866",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 1280426.65 ms\n",
            "Prediction Time: 187.51 ms\n",
            "File: nonfm (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (4).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (11).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (1).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (9).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (2).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.88\n",
            "Recall: 0.85\n",
            "F1 Score: 0.84\n",
            "Total Execution Time: 1280664.10 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"factorymethod\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure overall execution time\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time: {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Factory method time calcution with different settings**"
      ],
      "metadata": {
        "id": "Tvn3xc_EPIKR"
      },
      "id": "Tvn3xc_EPIKR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tF3GJteUo0o3",
      "metadata": {
        "id": "tF3GJteUo0o3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888,
          "referenced_widgets": [
            "5907ebb8962d41269e8b790132be3200",
            "b4a0917627e146cb920637a654862c89",
            "5df0656f326d4adeaca6dbf477f6c5f0",
            "b70ea907b945487699a1136c23f18150",
            "a532e7986bbd42328ec25474fab7654b",
            "390e89587a10429fb923114e9246fce6",
            "067dcdd227b74c0b90042e9536cf87ac",
            "35689df6cbaa415e8339a85527800bf1",
            "2a6d2ba3a56c43fa83f3957e451bd3a9",
            "8a11a4f5e04443ca94769314d5ca58bb",
            "3d01efc07acb4f1da8b0eadc4781638c",
            "0ee01b02d6c64eec998940f865277aa6",
            "25102ffcf8b54de2849628f1b25e3ec7",
            "b84c022598c24735a9eeb1e4ad7fab77",
            "dae344eee7424907aa02b0c729b2887f",
            "7744fe4224fa4757bdae65ac3704f249",
            "a92e02484c8c42dc9c2efa4b38be1163",
            "c647c9d66a2f46c69d5e0ca332496f68",
            "248c8fd066f249829e8ff741b44b9b92",
            "a4fca2b9be304de984d5460b8fc72367",
            "7ff94a11c31a47a09228f2f9b662318a",
            "49fd5d28bad14dafb77a25ce5badc759",
            "9c5732a354ec40ae919d917b98314f2b",
            "c87e1e31a2b84a9dac6a54eba85413d7",
            "25a4d8b8319e4ce8a9faa8541b1946eb",
            "3d4ca38f1a6a4473a589188fa038dd10",
            "3e0d4b26ccd7424cb3abaf96cf80bdf2",
            "72cd107feb67478e90d92162add6c261",
            "7060a98ce8e24e988e78dd87906bade5",
            "bf500391e9dc4b8399796cfa9bcb758c",
            "adc080130c554507b21c1efe26ee93a7",
            "a2ad85ad1a0e4cc5ab055f123c4339f9",
            "06d0475cb393469781586318d84b4df6",
            "efdbde77bb3e4dee8c997bcf39ffae98",
            "cb3ac662a20740bc890b7a15dd35ae3b",
            "d7eebb5c6cd74a9d9901d9eab71a6a39",
            "4dff183204c541d3989f22e7e0b03dd8",
            "c6070bea59504e2ea266d52ac85f0f20",
            "08d7dfaa2b71403a9c8117d46396869b",
            "86ffef4a494d4a2ba427ce3622399b5a",
            "9123abd540ca44509adc6e189a6fe14f",
            "4f0a5d8a186744b8914ae9978726e2e2",
            "812f69994d4f4b09beef13af48108d68",
            "d0ec6e98a08b483f88fc3a13a666af91",
            "74d65ad56aba4db28066ed3c5a8fb048",
            "4dfad4af40354dfcb41567e32f527fb2",
            "1333d801046f4f1d997e2f1088b1580d",
            "80946a3b82f648c3827bfba6702fff02",
            "e6626ebeab394b35ab4c715961959eef",
            "5e27634be5cf4e59b42b086b14160f79",
            "c304ffe74f92430394d29e61b59bed7d",
            "fb9a0aa90c8e4cfeb5d754964d35333d",
            "6456c11a56174f23a4a205a16bf0b44a",
            "bc2a5116e0fd43ae8cf6d0fce3d5c651",
            "4043a7a7182b451b987566dca1af8e67",
            "8dca732697b543f4853b4a3371aa3c26",
            "093579bea7a64e26a3fc145ffcbff278",
            "c5a037ffd0424927936caa0711379c1b",
            "4a19bc50728340f9a4c7b23f8ff18294",
            "af8fc74b36ef4db38466f59575ba2988",
            "869934883ee34d3eb7724e99708766cc",
            "a8a64b6cc4e54bee8192f734e0765727",
            "45d1fabc784c4ac0a0dd507af3f58fe2",
            "5dcfcd189dda4f69922c16c20c68c69a",
            "deddf28b7f834d09aedcd06a964ce5c1",
            "176527e43438462b9646c74138242339"
          ]
        },
        "outputId": "c2416e66-d148-44a3-c5fb-cd93c2f204bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5907ebb8962d41269e8b790132be3200"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ee01b02d6c64eec998940f865277aa6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c5732a354ec40ae919d917b98314f2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efdbde77bb3e4dee8c997bcf39ffae98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74d65ad56aba4db28066ed3c5a8fb048"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8dca732697b543f4853b4a3371aa3c26"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 364704.67 ms\n",
            "Prediction Time: 101.21 ms\n",
            "File: factorymethod (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (77).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (82).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonfm (81).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (72).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (74).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (73).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (79).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (76).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (80).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (71).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonfm (78).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (75).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.79\n",
            "Recall: 0.78\n",
            "F1 Score: 0.78\n",
            "Total Execution Time: 364848.23 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"factorymethod\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure overall execution time\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time: {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Time for singleton**"
      ],
      "metadata": {
        "id": "fpAx7PR6GZfn"
      },
      "id": "fpAx7PR6GZfn"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"singleton\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure overall execution time\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time: {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGM46481DLQ2",
        "outputId": "7bdec21a-13cc-4394-94e2-74e27f93101c"
      },
      "id": "EGM46481DLQ2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 376635.22 ms\n",
            "Prediction Time: 3.27 ms\n",
            "File: factorymethod (4).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (77).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (82).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (81).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (1).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (72).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (74).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (73).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (79).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (76).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (11).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (80).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (71).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (78).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (75).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 1.00\n",
            "Recall: 1.00\n",
            "F1 Score: 1.00\n",
            "Total Execution Time: 376647.07 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Singleton time calculation with different settings**"
      ],
      "metadata": {
        "id": "qIEmYxoOOvI9"
      },
      "id": "qIEmYxoOOvI9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Singleton with different settings**"
      ],
      "metadata": {
        "id": "8uKKfSeIRX2i"
      },
      "id": "8uKKfSeIRX2i"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/singleton\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"singleton\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2DVpOSBO_or",
        "outputId": "fedeb5ee-c285-41fc-84b8-1b951cb55cc3"
      },
      "id": "z2DVpOSBO_or",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 122461.56 ms\n",
            "Prediction Time: 8.67 ms\n",
            "File: singleton (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (45).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (24).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (64).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (16).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (18).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (37).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (62).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (33).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (4).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (19).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (52).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (42).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (56).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (19).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (22).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (49).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (5).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (65).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (61).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (29).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (25).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (7).java, Actual Label: 1, Predicted Label: 0\n",
            "\n",
            "Precision: 0.68\n",
            "Recall: 0.67\n",
            "F1 Score: 0.66\n",
            "Total Execution Time (Training + Prediction + Misc.): 122478.56 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Singleton time calculation with different settings**"
      ],
      "metadata": {
        "id": "HzWiSDosVCGC"
      },
      "id": "HzWiSDosVCGC"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/singleton\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"singleton\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Xo7SFJZRjiN",
        "outputId": "542881b7-65d6-43ca-a6db-968a161ff42e"
      },
      "id": "1Xo7SFJZRjiN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 97906.88 ms\n",
            "Prediction Time: 3.52 ms\n",
            "File: singleton (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (45).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (53).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (16).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (18).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (37).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (54).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (48).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (34).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (33).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (19).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (52).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (42).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (38).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (51).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (22).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (35).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (50).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (49).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (5).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (47).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (43).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (41).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (44).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (36).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (25).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (40).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (46).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (7).java, Actual Label: 1, Predicted Label: 0\n",
            "\n",
            "Precision: 0.67\n",
            "Recall: 0.66\n",
            "F1 Score: 0.66\n",
            "Total Execution Time (Training + Prediction + Misc.): 97930.34 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Singleton time calculation with different settings**"
      ],
      "metadata": {
        "id": "gMVxti_-Z4h3"
      },
      "id": "gMVxti_-Z4h3"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/singleton\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"singleton\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaMSS9BIVlvh",
        "outputId": "021c2da5-4541-4f05-94b4-d6c4713fd7bc"
      },
      "id": "AaMSS9BIVlvh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 107471.01 ms\n",
            "Prediction Time: 3.39 ms\n",
            "File: singleton (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (53).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (60).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (16).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (18).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (63).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (55).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (37).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (62).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (19).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (57).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (11).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (51).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (22).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (35).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (5).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (1).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (9).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (66).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (41).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (44).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (25).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (25).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (46).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (7).java, Actual Label: 1, Predicted Label: 0\n",
            "\n",
            "Precision: 0.74\n",
            "Recall: 0.71\n",
            "F1 Score: 0.71\n",
            "Total Execution Time (Training + Prediction + Misc.): 107483.17 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Factory method time calculation using different settings**"
      ],
      "metadata": {
        "id": "aKOQkmDHa1O5"
      },
      "id": "aKOQkmDHa1O5"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"factorymethod\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uB7V3MeuZ_JX",
        "outputId": "d6f8b9c0-94c8-43f6-fee3-667c1db7cb0b"
      },
      "id": "uB7V3MeuZ_JX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Training (Embedding Generation) Time: 84570.35 ms\n",
            "Prediction Time: 2.57 ms\n",
            "File: factorymethod (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (20).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (16).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonfm (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (4).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (25).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (8).java, Actual Label: 1, Predicted Label: 1\n",
            "\n",
            "Precision: 0.84\n",
            "Recall: 0.84\n",
            "F1 Score: 0.84\n",
            "Total Execution Time (Training + Prediction + Misc.): 84587.95 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Factory method with different settings **"
      ],
      "metadata": {
        "id": "zeQgcZr-cPoT"
      },
      "id": "zeQgcZr-cPoT"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"factorymethod\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U42-4oncLpO",
        "outputId": "50792abb-6da5-4970-c3ff-b3e360a15024"
      },
      "id": "1U42-4oncLpO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 46214.70 ms\n",
            "Prediction Time: 3.54 ms\n",
            "File: factorymethod (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (77).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (68).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (42).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (49).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (76).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (32).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (67).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (70).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (71).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (78).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (26).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (69).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (38).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (51).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (47).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (8).java, Actual Label: 1, Predicted Label: 1\n",
            "\n",
            "Precision: 0.85\n",
            "Recall: 0.85\n",
            "F1 Score: 0.85\n",
            "Total Execution Time (Training + Prediction + Misc.): 46234.43 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Factory method with different settings**"
      ],
      "metadata": {
        "id": "KJUnYLMCdK_y"
      },
      "id": "KJUnYLMCdK_y"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"factorymethod\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "id": "XGD8jtIibXQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40215059-aa0f-463f-cc0d-2adb969f334b"
      },
      "id": "XGD8jtIibXQy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 78577.67 ms\n",
            "Prediction Time: 2.81 ms\n",
            "File: factorymethod (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (35).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonfm (34).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (29).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (32).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (11).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (33).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonfm (25).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (26).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (31).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (8).java, Actual Label: 1, Predicted Label: 1\n",
            "\n",
            "Precision: 0.63\n",
            "Recall: 0.62\n",
            "F1 Score: 0.63\n",
            "Total Execution Time (Training + Prediction + Misc.): 78591.68 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Factory method with different settings**"
      ],
      "metadata": {
        "id": "DFDSlImNmUcY"
      },
      "id": "DFDSlImNmUcY"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"factorymethod\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEcVUvR9fX6d",
        "outputId": "7385fca0-4873-4153-e9b3-147ebeb89e60"
      },
      "id": "aEcVUvR9fX6d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 79601.84 ms\n",
            "Prediction Time: 3.21 ms\n",
            "File: factorymethod (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (20).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (22).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (29).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (16).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonfm (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (19).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (25).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (26).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (8).java, Actual Label: 1, Predicted Label: 1\n",
            "\n",
            "Precision: 0.83\n",
            "Recall: 0.82\n",
            "F1 Score: 0.82\n",
            "Total Execution Time (Training + Prediction + Misc.): 79613.18 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Singleton with different settings**"
      ],
      "metadata": {
        "id": "NjvqzO5_mM8H"
      },
      "id": "NjvqzO5_mM8H"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/singleton\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"singleton\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2AEUllOoxDT",
        "outputId": "bf7f1142-5729-4fd0-ca46-74755f74efbf"
      },
      "id": "T2AEUllOoxDT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 195491.85 ms\n",
            "Prediction Time: 4.71 ms\n",
            "File: singleton (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (45).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (64).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (16).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (18).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (63).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (62).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (34).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (33).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (19).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (42).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (32).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (19).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (22).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (67).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (22).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (5).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (65).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (9).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (66).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (43).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (44).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (25).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (46).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (31).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (7).java, Actual Label: 1, Predicted Label: 0\n",
            "\n",
            "Precision: 0.66\n",
            "Recall: 0.64\n",
            "F1 Score: 0.63\n",
            "Total Execution Time (Training + Prediction + Misc.): 195511.11 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Singleton time calcultion with different settings**"
      ],
      "metadata": {
        "id": "8T7sK6OwqLc7"
      },
      "id": "8T7sK6OwqLc7"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"factorymethod\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eISBall3oyB1",
        "outputId": "fdbd9d84-a888-49c7-8a6a-ee989acf460d"
      },
      "id": "eISBall3oyB1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 98509.27 ms\n",
            "Prediction Time: 5.50 ms\n",
            "File: factorymethod (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (20).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (22).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (29).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (16).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonfm (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (19).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (25).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (26).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (8).java, Actual Label: 1, Predicted Label: 1\n",
            "\n",
            "Precision: 0.83\n",
            "Recall: 0.82\n",
            "F1 Score: 0.82\n",
            "Total Execution Time (Training + Prediction + Misc.): 98531.75 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Factory method time calculation with different settings**"
      ],
      "metadata": {
        "id": "_QZZr4CUrrFa"
      },
      "id": "_QZZr4CUrrFa"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"factorymethod\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4JWV8KmqQUb",
        "outputId": "7ef0ded7-d98c-47f4-a788-16df241770fa"
      },
      "id": "Q4JWV8KmqQUb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 95059.75 ms\n",
            "Prediction Time: 2.87 ms\n",
            "File: factorymethod (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (20).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (22).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (29).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (16).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonfm (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (19).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (25).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (26).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (8).java, Actual Label: 1, Predicted Label: 1\n",
            "\n",
            "Precision: 0.83\n",
            "Recall: 0.82\n",
            "F1 Score: 0.82\n",
            "Total Execution Time (Training + Prediction + Misc.): 95069.99 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Singleton with different settings**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oNJnXRKVs9YH"
      },
      "id": "oNJnXRKVs9YH"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/singleton\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"singleton\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3E-5iYbrx1_",
        "outputId": "62a72d44-d66a-4e45-f194-f11b473a68f8"
      },
      "id": "A3E-5iYbrx1_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 133244.40 ms\n",
            "Prediction Time: 3.41 ms\n",
            "File: singleton (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (68).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (24).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (64).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (16).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (18).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (26).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (48).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (19).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (42).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (38).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (51).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (19).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (22).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (50).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (67).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (49).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (5).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (65).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (9).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (47).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (66).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (41).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (25).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (25).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (40).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (24).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (27).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (7).java, Actual Label: 1, Predicted Label: 0\n",
            "\n",
            "Precision: 0.60\n",
            "Recall: 0.58\n",
            "F1 Score: 0.57\n",
            "Total Execution Time (Training + Prediction + Misc.): 133256.73 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Builder with settings**"
      ],
      "metadata": {
        "id": "XiZOpjuNxA6c"
      },
      "id": "XiZOpjuNxA6c"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/builder\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"builder\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WkeU7q_xEv3",
        "outputId": "cc4e1127-d258-43a9-dd35-d08c77095a97"
      },
      "id": "9WkeU7q_xEv3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 75283.62 ms\n",
            "Prediction Time: 2.94 ms\n",
            "File: nonb (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (11).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (16).java, Actual Label: 0, Predicted Label: 1\n",
            "File: builder (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (12).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.84\n",
            "Recall: 0.83\n",
            "F1 Score: 0.83\n",
            "Total Execution Time (Training + Prediction + Misc.): 75293.55 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Builder time calculation with different settings**"
      ],
      "metadata": {
        "id": "kaGVyNzbx1d8"
      },
      "id": "kaGVyNzbx1d8"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/builder\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"builder\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819,
          "referenced_widgets": [
            "727b8510d4ab460fa6061119ae7636f2",
            "8102aa727066499e90e4afa59ed88f99",
            "26652166ee2e4c289bf4f47c1eb2f57f",
            "38b9e17c1eb64cc6954d9286a9d8b916",
            "88d598437ce74979aa7383ccbcfd4d86",
            "3d2c725bbb9c40f9a256303467eefd87",
            "4ac8dc3f637144088040304f53d17604",
            "5766d5fc03064de69cacabcef689336c",
            "b4e67002c7494fe48c3663e075f024ff",
            "3039a34550ae4ac690b7019d3d03a80d",
            "352d2ce09dce4eb68f7c8af13db4791b",
            "9ed22cb538594777a328111f6a14b84b",
            "a422160c58ff47c0bd3a599511599076",
            "1252b99ee1b14f6ebec527c36c673044",
            "ddd84975ba3743b4b1d68dc88e9bbca5",
            "3d123770cc92497d851afdfe0b46a80e",
            "752b1d31e3324aa0a8c00e1856aa78e2",
            "e577e207cda54e939d20a8ca7e86d721",
            "94ba75acd1434ed4b791aa83a91bdfeb",
            "2205c44b144e45cba30f3bde7caa0f3e",
            "a8dfac5df8ef4315a37e4bcefc25902e",
            "750225f407e640808ccabe29221e4b2d",
            "1d0a035aa95e4d17893f2fc8123f2e84",
            "e69f775a51134f8db786cfa83ab7d557",
            "ba4bd4494eb34c8999fb6e9c27dde41e",
            "fb4e9bdefed143e0a7cf54b5957bec4f",
            "527bcbc98e4d492d87c2edecfeed7979",
            "514a89e105f64ce7ad4e3d63e8768259",
            "e0e038ec9ab94480bdf722160c35ddad",
            "fb90e164238c495d80f85df3d3486407",
            "55b553fecf3943d48474d1c5dbc608fa",
            "cb471ac99b1d4f288fba0e997493e82c",
            "951655ab30284914acbb21393ed98655",
            "6a13f5d9e3034c60b8db1d512d507971",
            "27459b775c0f4c2788325c1b6b7267a2",
            "407aeeb0f0034feaacdae64f186c8045",
            "e4d70e9bdeef43edb4bffae6c7b06cf4",
            "3b5aea119777494f995f99ca3e44e3ac",
            "2ed29106065e4f909e63daf380c783ab",
            "a6f508988bfb4871b543c78f25c38b8b",
            "db0b368c1a2942fca050b477b18e6feb",
            "faa3279aaf4b46e7b7de865b12730f1d",
            "14792133286a4a4d8dc1d3f2bd589ead",
            "72291a608b8443c8acf6abf06c8753e8",
            "6cc85f34154a43d3965e3f2b0166a936",
            "effd9f74cf9141e38aceac60efdc3742",
            "7a8b6bfe90ed4c14adce23d5e0631711",
            "29ec4a59b1c843c687fb12ea29c3878e",
            "15bd8236e608410b88cb38d6710d8962",
            "c2f9b055f60c4596bfb958998443d5ce",
            "bd5d543825ce4d318d4e586ef1b9266e",
            "55cf4187a01344dbbf4af4d16a148a82",
            "c7c7f79570d84667b72913f79d0def6f",
            "b2f024ad905c4f68a272ba9a89d8ee19",
            "8868c9d1e2ee4078a0387a8e1c26e8d7",
            "4609b2d80963451db2bfb61687830391",
            "51074d03825c4a608109357d88c33e7e",
            "c350a42f47b64f74a18fbe971c1f5ad8",
            "d264453bb3864d26a8615fb05cf718f6",
            "e804483d6fa04040a4d04f518c422ecc",
            "3138a201a11a4c9c8e00cacdfd0cd4f0",
            "47b7ee25a40647139540842772a670aa",
            "bd9466475a2046d79f8b010c6acef4b2",
            "b3fc0f4e42504654b315ca9d5ed75258",
            "cda51966c77f45e396647ce7e587712e",
            "048224c2fc4d4442ab4ac789c3abe4b6"
          ]
        },
        "id": "_EAdDekZxPCc",
        "outputId": "1f71c6df-a0d7-49e3-f26f-5dcbeb126570"
      },
      "id": "_EAdDekZxPCc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "727b8510d4ab460fa6061119ae7636f2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ed22cb538594777a328111f6a14b84b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d0a035aa95e4d17893f2fc8123f2e84"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a13f5d9e3034c60b8db1d512d507971"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cc85f34154a43d3965e3f2b0166a936"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4609b2d80963451db2bfb61687830391"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 45103.20 ms\n",
            "Prediction Time: 49.39 ms\n",
            "File: builder (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (1).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonb (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (4).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (8).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.84\n",
            "Recall: 0.83\n",
            "F1 Score: 0.83\n",
            "Total Execution Time (Training + Prediction + Misc.): 45160.55 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Builder with different seetings**"
      ],
      "metadata": {
        "id": "C0y0hvSSwWYX"
      },
      "id": "C0y0hvSSwWYX"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/builder\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"builder\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "id": "YqNuhpE4yGy9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b42153e-cad1-416e-dbc8-6a7854fe3d0e"
      },
      "id": "YqNuhpE4yGy9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 80378.07 ms\n",
            "Prediction Time: 3.09 ms\n",
            "File: builder (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (1).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonb (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (4).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (8).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.84\n",
            "Recall: 0.83\n",
            "F1 Score: 0.83\n",
            "Total Execution Time (Training + Prediction + Misc.): 80390.35 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Builder with different settings**"
      ],
      "metadata": {
        "id": "AACqRSdhGyHt"
      },
      "id": "AACqRSdhGyHt"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/builder\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"builder\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqhT4rOzHBKL",
        "outputId": "365b9249-55d9-4014-926e-2b37bb749388"
      },
      "id": "nqhT4rOzHBKL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 69154.35 ms\n",
            "Prediction Time: 2.89 ms\n",
            "File: nonb (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (9).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (27).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonb (34).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonb (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (26).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (35).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (8).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (5).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (32).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (29).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (31).java, Actual Label: 0, Predicted Label: 1\n",
            "\n",
            "Precision: 0.20\n",
            "Recall: 0.33\n",
            "F1 Score: 0.25\n",
            "Total Execution Time (Training + Prediction + Misc.): 69172.41 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Builder with different settings**"
      ],
      "metadata": {
        "id": "WuzLlOmaIBQH"
      },
      "id": "WuzLlOmaIBQH"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/builder\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"builder\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fSQvce-Hjz4",
        "outputId": "39994c7b-e8d8-4b7e-e092-0db2b89fc091"
      },
      "id": "5fSQvce-Hjz4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 67862.53 ms\n",
            "Prediction Time: 3.15 ms\n",
            "File: nonb (128).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (129).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (131).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (130).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (125).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (132).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (133).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (134).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (127).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.88\n",
            "Recall: 0.83\n",
            "F1 Score: 0.83\n",
            "Total Execution Time (Training + Prediction + Misc.): 67876.22 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Builder with different settings**"
      ],
      "metadata": {
        "id": "0uvj3KrfJhVl"
      },
      "id": "0uvj3KrfJhVl"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/builder\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"builder\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-eDPk8nILun",
        "outputId": "276b80bd-e7f7-478a-a29b-18b9761b79e7"
      },
      "id": "c-eDPk8nILun",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 127342.93 ms\n",
            "Prediction Time: 3.13 ms\n",
            "File: nonb (92).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (93).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (108).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonb (131).java, Actual Label: 0, Predicted Label: 1\n",
            "File: builder (8).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (5).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (116).java, Actual Label: 0, Predicted Label: 1\n",
            "File: builder (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (119).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonb (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (99).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonb (81).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (41).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.44\n",
            "Recall: 0.45\n",
            "F1 Score: 0.45\n",
            "Total Execution Time (Training + Prediction + Misc.): 127355.14 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prototyope with different settings**"
      ],
      "metadata": {
        "id": "PnlP4XD0KuI9"
      },
      "id": "PnlP4XD0KuI9"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/prototype\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"prototype\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lxAWoanJkP2",
        "outputId": "1221f1fb-7f4a-4589-dd6b-32cdf1622468"
      },
      "id": "5lxAWoanJkP2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 152617.35 ms\n",
            "Prediction Time: 10.73 ms\n",
            "File: prototype (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (22).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (27).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (31).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (19).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (29).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (4).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (29).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (25).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (18).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (33).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (32).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (28).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (26).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (19).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (32).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (31).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (23).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (11).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (30).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (10).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (22).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (26).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (25).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.90\n",
            "Recall: 0.89\n",
            "F1 Score: 0.89\n",
            "Total Execution Time (Training + Prediction + Misc.): 152636.11 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prototype with different settings**"
      ],
      "metadata": {
        "id": "VSEH0b6zL4O_"
      },
      "id": "VSEH0b6zL4O_"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/prototype\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"prototype\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SUMos7tK8nf",
        "outputId": "686cbac1-a7fd-4de2-b94c-16d2865bbf85"
      },
      "id": "8SUMos7tK8nf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 153786.84 ms\n",
            "Prediction Time: 3.82 ms\n",
            "File: prototype (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (22).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (27).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (31).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (19).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (42).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (29).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (48).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (35).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (36).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (29).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (45).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (52).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (34).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (60).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (55).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (25).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (18).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (37).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (44).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (33).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (49).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (32).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (58).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (47).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (28).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (26).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (41).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (32).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (57).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (59).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (31).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (46).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (56).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (43).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (30).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (53).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (10).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (54).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (50).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (51).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (40).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (38).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (61).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.79\n",
            "Recall: 0.77\n",
            "F1 Score: 0.76\n",
            "Total Execution Time (Training + Prediction + Misc.): 153811.65 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prototype with different settings**"
      ],
      "metadata": {
        "id": "cWHZS9ViOIlO"
      },
      "id": "cWHZS9ViOIlO"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/prototype\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"prototype\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD581WRFMJgy",
        "outputId": "8239f7ef-22ec-4284-e773-cfb6d44c1401"
      },
      "id": "tD581WRFMJgy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 164954.88 ms\n",
            "Prediction Time: 3.67 ms\n",
            "File: prototype (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (22).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (27).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (31).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (19).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (29).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (35).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (36).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (29).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (34).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (25).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (18).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (37).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (33).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (32).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (28).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (26).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (19).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (41).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (32).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (31).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (30).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (10).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (40).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (38).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (22).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (26).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (25).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.82\n",
            "Recall: 0.81\n",
            "F1 Score: 0.81\n",
            "Total Execution Time (Training + Prediction + Misc.): 164968.45 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prototype with different settings**"
      ],
      "metadata": {
        "id": "ySsPJliZPTKS"
      },
      "id": "ySsPJliZPTKS"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/prototype\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"prototype\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wa4mnC3mOZBy",
        "outputId": "6f2d9ba2-d13f-42a0-a351-68e3ddd227c7"
      },
      "id": "Wa4mnC3mOZBy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 175072.66 ms\n",
            "Prediction Time: 4.65 ms\n",
            "File: prototype (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (22).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (27).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (31).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (19).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (29).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (35).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (36).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (29).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (25).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (18).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (37).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (44).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (32).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (28).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (26).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (19).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (21).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (32).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (31).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (23).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (43).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (11).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (30).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (10).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (38).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (26).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (25).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.84\n",
            "Recall: 0.83\n",
            "F1 Score: 0.83\n",
            "Total Execution Time (Training + Prediction + Misc.): 175094.36 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prototype with different settings**"
      ],
      "metadata": {
        "id": "TiLJv3gbRszG"
      },
      "id": "TiLJv3gbRszG"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/prototype\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"prototype\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_7idRQBPoPo",
        "outputId": "c99a55b0-0c11-4dcc-bdad-92ef1f52a4b5"
      },
      "id": "b_7idRQBPoPo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 134111.86 ms\n",
            "Prediction Time: 3.49 ms\n",
            "File: prototype (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (22).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (27).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (31).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (19).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (42).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (29).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (29).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (45).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (52).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (55).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (25).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (18).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (24).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (44).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (32).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (58).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (28).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (26).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (41).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (57).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (31).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (46).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (23).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (56).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (43).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (11).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (30).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (53).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (10).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (54).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (51).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (40).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (38).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (22).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (26).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (25).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.77\n",
            "Recall: 0.75\n",
            "F1 Score: 0.75\n",
            "Total Execution Time (Training + Prediction + Misc.): 134129.34 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Abstract Factory with different settings**"
      ],
      "metadata": {
        "id": "H-3J1PXwTtDs"
      },
      "id": "H-3J1PXwTtDs"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/abstractfactory\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"abstractfactory\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MobeEixhSBSO",
        "outputId": "d7486839-1f12-4a26-af94-e61faa91d18a"
      },
      "id": "MobeEixhSBSO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 133009.30 ms\n",
            "Prediction Time: 3.20 ms\n",
            "File: nonab (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (4).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (13).java, Actual Label: 1, Predicted Label: 0\n",
            "File: abstractfactory (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (1).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonab (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (11).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: abstractfactory (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (5).java, Actual Label: 1, Predicted Label: 1\n",
            "\n",
            "Precision: 0.85\n",
            "Recall: 0.85\n",
            "F1 Score: 0.85\n",
            "Total Execution Time (Training + Prediction + Misc.): 133022.20 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Abstract Factory with different settings**"
      ],
      "metadata": {
        "id": "rgkRDqMCVLf_"
      },
      "id": "rgkRDqMCVLf_"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/abstractfactory\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"abstractfactory\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZReovEhVQy4",
        "outputId": "499ceaf5-4c06-485e-bdaa-64e94f7a2039"
      },
      "id": "nZReovEhVQy4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 85384.84 ms\n",
            "Prediction Time: 3.83 ms\n",
            "File: nonab (76).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (73).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (71).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (70).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (74).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (69).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (67).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (75).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (72).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonab (77).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (64).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (68).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (65).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (66).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.93\n",
            "Recall: 0.93\n",
            "F1 Score: 0.93\n",
            "Total Execution Time (Training + Prediction + Misc.): 85403.24 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Abstract factory with different settings**"
      ],
      "metadata": {
        "id": "QYDVQNE6jLr3"
      },
      "id": "QYDVQNE6jLr3"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/abstractfactory\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"abstractfactory\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW2TJPXUjpZc",
        "outputId": "284381b4-8cc8-494f-ca00-e13404ae45c8"
      },
      "id": "ZW2TJPXUjpZc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 95415.50 ms\n",
            "Prediction Time: 3.61 ms\n",
            "File: nonab (83).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (76).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (80).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (81).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (86).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (74).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (87).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (75).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (1).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (78).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (82).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (77).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (79).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (84).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (85).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (5).java, Actual Label: 1, Predicted Label: 1\n",
            "\n",
            "Precision: 0.88\n",
            "Recall: 0.84\n",
            "F1 Score: 0.84\n",
            "Total Execution Time (Training + Prediction + Misc.): 95431.30 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Abstract Factory using different settings**"
      ],
      "metadata": {
        "id": "wCgZFj2QlOVj"
      },
      "id": "wCgZFj2QlOVj"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/abstractfactory\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"abstractfactory\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gkqcjdLkh_s",
        "outputId": "06084ad5-d3c3-4e44-db1f-a245d34e67b1"
      },
      "id": "4gkqcjdLkh_s",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 98124.97 ms\n",
            "Prediction Time: 2.91 ms\n",
            "File: nonab (76).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (63).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (81).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (34).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (74).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (69).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (52).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (57).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (72).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (79).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (84).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (37).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (44).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (5).java, Actual Label: 1, Predicted Label: 1\n",
            "\n",
            "Precision: 0.92\n",
            "Recall: 0.90\n",
            "F1 Score: 0.90\n",
            "Total Execution Time (Training + Prediction + Misc.): 98155.65 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**abstract factory with different settings**"
      ],
      "metadata": {
        "id": "tyjUM5ksmFdP"
      },
      "id": "tyjUM5ksmFdP"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/abstractfactory\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"abstractfactory\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uu6IXZb7lcvU",
        "outputId": "ec8a25d1-83ed-4149-bcf0-37a9386c8e87"
      },
      "id": "Uu6IXZb7lcvU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 50682.77 ms\n",
            "Prediction Time: 3.28 ms\n",
            "File: nonab (50).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (33).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (51).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (34).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (52).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (49).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (36).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (31).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (40).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (54).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (35).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonab (37).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (32).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (38).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (29).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (53).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.89\n",
            "Recall: 0.88\n",
            "F1 Score: 0.88\n",
            "Total Execution Time (Training + Prediction + Misc.): 50695.22 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Abstract Factory with different settiings**"
      ],
      "metadata": {
        "id": "o4DRpNQFmmw1"
      },
      "id": "o4DRpNQFmmw1"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/abstractfactory\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"abstractfactory\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkm2Om29mSGc",
        "outputId": "5d9e8ec8-cec2-4326-8ade-e81e3808aed6"
      },
      "id": "bkm2Om29mSGc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training (Embedding Generation) Time: 96412.41 ms\n",
            "Prediction Time: 3.07 ms\n",
            "File: nonab (83).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (80).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (73).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (71).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (70).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (81).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (86).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (74).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (69).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (67).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (78).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (82).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (72).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonab (79).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (84).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (85).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (68).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (66).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.87\n",
            "Recall: 0.85\n",
            "F1 Score: 0.85\n",
            "Total Execution Time (Training + Prediction + Misc.): 96431.34 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Function to calculate standard deviation\n",
        "def calculate_std(values):\n",
        "    return np.std(values)\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"abstractfactory\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Running the experiment multiple times to calculate mean and standard deviation\n",
        "n_runs = 10  # Change this value to 10-30 based on reviewer comment\n",
        "precision_values = []\n",
        "recall_values = []\n",
        "f1_values = []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1} of {n_runs}\")\n",
        "\n",
        "    program_embeddings = []\n",
        "    true_labels = []\n",
        "\n",
        "    # Measure training time for each run\n",
        "    start_training_time = time.time()\n",
        "\n",
        "    for file in java_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "            java_code = f.read()\n",
        "\n",
        "            # Get the embedding of the program by taking the mean of line embeddings\n",
        "            program_embedding = get_line_embeddings(java_code)\n",
        "            program_embeddings.append(program_embedding)\n",
        "\n",
        "            # Define true labels based on the file names\n",
        "            true_labels.append(1 if \"abstractfactory\" in file else 0)\n",
        "\n",
        "    # Convert program_embeddings to a NumPy array\n",
        "    program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "    # Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "    k = 5  # Adjust this value as needed\n",
        "    neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "    neighbors.fit(program_embeddings)\n",
        "    _, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "    # Initialize arrays to store actual and predicted labels\n",
        "    actual_labels = np.array(true_labels)\n",
        "    predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "    # Predict labels for each program\n",
        "    for i in range(len(java_files)):\n",
        "        # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "        neighbor_indices = indices[i, 1:]\n",
        "\n",
        "        # Get the labels of the neighbors\n",
        "        neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "        # Assign the majority label to the program\n",
        "        predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "        predicted_labels[i] = predicted_label\n",
        "\n",
        "    # Calculate precision, recall, and F1 score for this run\n",
        "    precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "    recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "    f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "    precision_values.append(precision)\n",
        "    recall_values.append(recall)\n",
        "    f1_values.append(f1)\n",
        "\n",
        "# Calculate mean and standard deviation for precision, recall, and F1 score\n",
        "precision_mean = np.mean(precision_values)\n",
        "recall_mean = np.mean(recall_values)\n",
        "f1_mean = np.mean(f1_values)\n",
        "\n",
        "precision_std = calculate_std(precision_values)\n",
        "recall_std = calculate_std(recall_values)\n",
        "f1_std = calculate_std(f1_values)\n",
        "\n",
        "# Print results\n",
        "print(f\"\\nMean Precision: {precision_mean:.2f} (±{precision_std:.2f})\")\n",
        "print(f\"Mean Recall: {recall_mean:.2f} (±{recall_std:.2f})\")\n",
        "print(f\"Mean F1 Score: {f1_mean:.2f} (±{f1_std:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wscEm99Cn6hb",
        "outputId": "d05f028d-e1d7-45a2-8445-a9ffa7886676"
      },
      "id": "wscEm99Cn6hb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1 of 10\n",
            "Run 2 of 10\n",
            "Run 3 of 10\n",
            "Run 4 of 10\n",
            "Run 5 of 10\n",
            "Run 6 of 10\n",
            "Run 7 of 10\n",
            "Run 8 of 10\n",
            "Run 9 of 10\n",
            "Run 10 of 10\n",
            "\n",
            "Mean Precision: 0.87 (±0.00)\n",
            "Mean Recall: 0.85 (±0.00)\n",
            "Mean F1 Score: 0.85 (±0.00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import random\n",
        "\n",
        "# Function to calculate standard deviation\n",
        "def calculate_std(values):\n",
        "    return np.std(values)\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/builder\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Separate positive and negative class files\n",
        "positive_files = [file for file in java_files if \"builder\" in file.lower()]  # Positive class contains 'builder'\n",
        "negative_files = [file for file in java_files if \"builder\" not in file.lower()]  # Negative class\n",
        "\n",
        "# Running the experiment multiple times to calculate mean and standard deviation\n",
        "n_runs = 10  # Number of iterations (adjust as needed)\n",
        "precision_values = []\n",
        "recall_values = []\n",
        "f1_values = []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1} of {n_runs}\")\n",
        "\n",
        "    # Randomly sample the same number of positive and negative examples\n",
        "    num_positive = len(positive_files)\n",
        "    sampled_negative_files = random.sample(negative_files, num_positive)\n",
        "\n",
        "    sampled_files = positive_files + sampled_negative_files\n",
        "    random.shuffle(sampled_files)  # Shuffle to avoid any ordering bias\n",
        "\n",
        "    program_embeddings = []\n",
        "    true_labels = []\n",
        "\n",
        "    # Measure the total execution time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Measure the training time (embedding generation)\n",
        "    start_training_time = time.time()\n",
        "\n",
        "    for file in sampled_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "            java_code = f.read()\n",
        "\n",
        "            # Get the embedding of the program by taking the mean of line embeddings\n",
        "            program_embedding = get_line_embeddings(java_code)\n",
        "            program_embeddings.append(program_embedding)\n",
        "\n",
        "            # Define true labels (1 for positive, 0 for negative)\n",
        "            true_labels.append(1 if \"builder\" in file.lower() else 0)\n",
        "\n",
        "    # Convert program_embeddings to a NumPy array\n",
        "    program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "    # Measure the end of training time\n",
        "    end_training_time = time.time()\n",
        "    training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "    print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "    # Measure the prediction time\n",
        "    prediction_start_time = time.time()\n",
        "\n",
        "    # Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "    k = 5  # Adjust this value as needed\n",
        "    neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "    neighbors.fit(program_embeddings)\n",
        "    _, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "    # Initialize arrays to store actual and predicted labels\n",
        "    actual_labels = np.array(true_labels)\n",
        "    predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "    # Predict labels for each program\n",
        "    for i in range(len(sampled_files)):\n",
        "        # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "        neighbor_indices = indices[i, 1:]\n",
        "\n",
        "        # Get the labels of the neighbors\n",
        "        neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "        # Assign the majority label to the program\n",
        "        predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "        predicted_labels[i] = predicted_label\n",
        "\n",
        "    # Measure the end of prediction time\n",
        "    prediction_end_time = time.time()\n",
        "    prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "    print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "    # Calculate precision, recall, and F1 score for this run\n",
        "    precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "    recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "    f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "    precision_values.append(precision)\n",
        "    recall_values.append(recall)\n",
        "    f1_values.append(f1)\n",
        "\n",
        "    # Measure total execution time (from the start of the script to the end of prediction)\n",
        "    overall_end_time = time.time()\n",
        "    execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "    print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate mean and standard deviation for precision, recall, and F1 score\n",
        "precision_mean = np.mean(precision_values)\n",
        "recall_mean = np.mean(recall_values)\n",
        "f1_mean = np.mean(f1_values)\n",
        "\n",
        "precision_std = calculate_std(precision_values)\n",
        "recall_std = calculate_std(recall_values)\n",
        "f1_std = calculate_std(f1_values)\n",
        "\n",
        "# Print results\n",
        "print(f\"\\nMean Precision: {precision_mean:.2f} (±{precision_std:.2f})\")\n",
        "print(f\"Mean Recall: {recall_mean:.2f} (±{recall_std:.2f})\")\n",
        "print(f\"Mean F1 Score: {f1_mean:.2f} (±{f1_std:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTiRxfcXqOe8",
        "outputId": "085fe9a9-b18d-44e1-9e0c-57c1e46bb30b"
      },
      "id": "KTiRxfcXqOe8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1 of 10\n",
            "Training (Embedding Generation) Time: 44903.97 ms\n",
            "Prediction Time: 1.49 ms\n",
            "Total Execution Time (Training + Prediction + Misc.): 44913.16 ms\n",
            "Run 2 of 10\n",
            "Training (Embedding Generation) Time: 40218.23 ms\n",
            "Prediction Time: 2.11 ms\n",
            "Total Execution Time (Training + Prediction + Misc.): 40226.85 ms\n",
            "Run 3 of 10\n",
            "Training (Embedding Generation) Time: 42333.74 ms\n",
            "Prediction Time: 2.63 ms\n",
            "Total Execution Time (Training + Prediction + Misc.): 42342.60 ms\n",
            "Run 4 of 10\n",
            "Training (Embedding Generation) Time: 39591.39 ms\n",
            "Prediction Time: 1.60 ms\n",
            "Total Execution Time (Training + Prediction + Misc.): 39601.08 ms\n",
            "Run 5 of 10\n",
            "Training (Embedding Generation) Time: 40380.98 ms\n",
            "Prediction Time: 2.48 ms\n",
            "Total Execution Time (Training + Prediction + Misc.): 40390.18 ms\n",
            "Run 6 of 10\n",
            "Training (Embedding Generation) Time: 39603.42 ms\n",
            "Prediction Time: 2.06 ms\n",
            "Total Execution Time (Training + Prediction + Misc.): 39614.12 ms\n",
            "Run 7 of 10\n",
            "Training (Embedding Generation) Time: 38297.19 ms\n",
            "Prediction Time: 2.64 ms\n",
            "Total Execution Time (Training + Prediction + Misc.): 38306.09 ms\n",
            "Run 8 of 10\n",
            "Training (Embedding Generation) Time: 40640.58 ms\n",
            "Prediction Time: 2.77 ms\n",
            "Total Execution Time (Training + Prediction + Misc.): 40648.74 ms\n",
            "Run 9 of 10\n",
            "Training (Embedding Generation) Time: 41107.14 ms\n",
            "Prediction Time: 2.00 ms\n",
            "Total Execution Time (Training + Prediction + Misc.): 41117.02 ms\n",
            "Run 10 of 10\n",
            "Training (Embedding Generation) Time: 43048.64 ms\n",
            "Prediction Time: 2.28 ms\n",
            "Total Execution Time (Training + Prediction + Misc.): 43057.81 ms\n",
            "\n",
            "Mean Precision: 0.69 (±0.16)\n",
            "Mean Recall: 0.68 (±0.15)\n",
            "Mean F1 Score: 0.67 (±0.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Replace 'your_directory_path' with the path to the directory you want to delete\n",
        "shutil.rmtree('/content/builder')\n"
      ],
      "metadata": {
        "id": "FpEpu76TuQHS"
      },
      "id": "FpEpu76TuQHS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import random\n",
        "from sklearn.decomposition import PCA  # Optional for dimensionality reduction\n",
        "\n",
        "# Function to calculate standard deviation\n",
        "def calculate_std(values):\n",
        "    return np.std(values)\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/builder\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Separate positive and negative class files\n",
        "positive_files = [file for file in java_files if \"builder\" in file.lower()]  # Positive class contains 'builder'\n",
        "negative_files = [file for file in java_files if \"builder\" not in file.lower()]  # Negative class\n",
        "\n",
        "# Running the experiment multiple times to calculate mean and standard deviation\n",
        "n_runs = 50  # Increase the number of iterations to reduce variance\n",
        "precision_values = []\n",
        "recall_values = []\n",
        "f1_values = []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1} of {n_runs}\")\n",
        "\n",
        "    # Randomly sample the same number of positive and negative examples\n",
        "    num_positive = len(positive_files)\n",
        "    sampled_negative_files = random.sample(negative_files, num_positive)\n",
        "\n",
        "    sampled_files = positive_files + sampled_negative_files\n",
        "    random.shuffle(sampled_files)  # Shuffle to avoid any ordering bias\n",
        "\n",
        "    program_embeddings = []\n",
        "    true_labels = []\n",
        "\n",
        "    # Measure the total execution time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Measure the training time (embedding generation)\n",
        "    start_training_time = time.time()\n",
        "\n",
        "    for file in sampled_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "            java_code = f.read()\n",
        "\n",
        "            # Get the embedding of the program by taking the mean of line embeddings\n",
        "            program_embedding = get_line_embeddings(java_code)\n",
        "            program_embeddings.append(program_embedding)\n",
        "\n",
        "            # Define true labels (1 for positive, 0 for negative)\n",
        "            true_labels.append(1 if \"builder\" in file.lower() else 0)\n",
        "\n",
        "    # Convert program_embeddings to a NumPy array\n",
        "    program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "    # Optional: Apply PCA to reduce the dimensionality of the embeddings\n",
        "    pca = PCA(n_components=50)  # Reduce to 50 dimensions (adjust based on experiments)\n",
        "    program_embeddings = pca.fit_transform(program_embeddings)\n",
        "\n",
        "    # Measure the end of training time\n",
        "    end_training_time = time.time()\n",
        "    training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "    print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "    # Measure the prediction time\n",
        "    prediction_start_time = time.time()\n",
        "\n",
        "    # Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "    k = 5  # Adjust this value as needed\n",
        "    neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "    neighbors.fit(program_embeddings)\n",
        "    _, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "    # Initialize arrays to store actual and predicted labels\n",
        "    actual_labels = np.array(true_labels)\n",
        "    predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "    # Predict labels for each program\n",
        "    for i in range(len(sampled_files)):\n",
        "        # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "        neighbor_indices = indices[i, 1:]\n",
        "\n",
        "        # Get the labels of the neighbors\n",
        "        neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "        # Assign the majority label to the program\n",
        "        predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "        predicted_labels[i] = predicted_label\n",
        "\n",
        "    # Measure the end of prediction time\n",
        "    prediction_end_time = time.time()\n",
        "    prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "    print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "    # Calculate precision, recall, and F1 score for this run\n",
        "    precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "    recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "    f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "    precision_values.append(precision)\n",
        "    recall_values.append(recall)\n",
        "    f1_values.append(f1)\n",
        "\n",
        "    # Measure total execution time (from the start of the script to the end of prediction)\n",
        "    overall_end_time = time.time()\n",
        "    execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "    print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate mean and standard deviation for precision, recall, and F1 score\n",
        "precision_mean = np.mean(precision_values)\n",
        "recall_mean = np.mean(recall_values)\n",
        "f1_mean = np.mean(f1_values)\n",
        "\n",
        "precision_std = calculate_std(precision_values)\n",
        "recall_std = calculate_std(recall_values)\n",
        "f1_std = calculate_std(f1_values)\n",
        "\n",
        "# Print results\n",
        "print(f\"\\nMean Precision: {precision_mean:.2f} (±{precision_std:.2f})\")\n",
        "print(f\"Mean Recall: {recall_mean:.2f} (±{recall_std:.2f})\")\n",
        "print(f\"Mean F1 Score: {f1_mean:.2f} (±{f1_std:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 794,
          "referenced_widgets": [
            "35af0008335447e7aed7f36441da7647",
            "8ccee66d22ec4b87851086c2e5ed6cb4",
            "f34d36ddaafe40979c007904284127ca",
            "54ecb68e84134b31bac8c2a18c1b6f0d",
            "6030267932844fe1a6b5231cf616a39f",
            "77df3bb66b6e42deb495b90749a8d88a",
            "96f547f0a42346cfa2932b6720041a58",
            "06e2849cc0a5466a99e353cbf00e19b2",
            "806242f42bc447dc8ab60f0939970573",
            "012b1705ad2f4d0d956ac17ce66d6de3",
            "e6a9152b8ba04d5cb7ee7fef4580aff0",
            "b26e7bfcf419468898df02b1eaf9a4ed",
            "6e17ed600fd4448690190752f8ff0196",
            "0257368dd3304fb191386c80913805b3",
            "a11dc9d41e1e4cc2a516ba61b20c0cc8",
            "aee71369964f4ec09c535b6d345bb28f",
            "56a027826f8a44689f5ad0b6b185b228",
            "9eec6f6d81eb4c1d93153930e549f566",
            "48244532cc694799b5f6bda53ed480ae",
            "8a85917dcda64740b31c061a81395ffb",
            "91ae80b3036a488db7d4ee2599d721b4",
            "707efcb769734d189a0f816bf00b0933",
            "c808ac24af37459398e4dff7da36a918",
            "a14eb8038d164cd184db478282efd908",
            "8e00335156254d138fdb03c204c3c16c",
            "11bd7133dbbb441684e9c38fd6fcb431",
            "82a39a0a0b1d432380c62fdabf535be4",
            "418debcbd5c3492a89a6df78dcc6a24f",
            "9bc0706e7bca4739a4dd0cf3ac7b4780",
            "e6fd3332b1c9490ea8b85b6ea18ad979",
            "63b11feb8f744335b9412b711dd8b176",
            "97214464aee5494cbeae380e7d6def64",
            "5819e0e6a7af443392e1d7a0e3cf8ef1",
            "61d4683149584722bacc0d327386604d",
            "8581528c104146888eeefc96588820bc",
            "3826994300c848cb8fceddc46a915fb6",
            "49ff3199b0eb4f3baec6f1dc95e82b74",
            "9f7ccdefca0a4d2297ffcbc702b8b488",
            "d17fc8bd13054ff5a1415d5a8abbf386",
            "54658cb1b9204a748bb81c7b58fdf82e",
            "42136e3210a14c9797f0d4fa152b77a7",
            "51ace324628a4d00943cc357da82df4e",
            "bf8bc26aa05d45e9b020d61226ae9097",
            "5865138159fc40a59624a8d1964cf1c1",
            "f7b6a522987f4dc9a3f2c2446d0892a1",
            "be36240f9cf849d9945002caa83e3bd8",
            "c3a1fe12ffa545af951474a299fc1f59",
            "07a9d488197440a0a7779834e97684bd",
            "e577117798924868bcc541075ef988b5",
            "2da69ff6a0484f1885c699cbebdb7a0f",
            "e2d029949aed4e4eaba6f7abea838e45",
            "96acc73e51e14e278a24790b5415f555",
            "bf3e0d6a202b4ab28624b4752fd01eef",
            "c728ad393a4f48b7bfaf9f13f57daf10",
            "35b2725b5e3a49c5b6c4dfa26775a55f",
            "bf24fc88a41e42709c11ce94e7d6f023",
            "1747434280a649f7bf24d7f99f549de7",
            "46a7e2d493bf4d9eb9c1e53b4eeb60a3",
            "97ff21851cb64c3d8bbb2d2a942ced89",
            "c9aba26899ce4afaa76ae09f02cd729d",
            "a86c9bef263345d1be3e329f462dbb0e",
            "0b08fa260e544b42a861f13a6d774189",
            "bbd3f5d3a0de4da6b56dc416fce01617",
            "b598bc6d33404754b2ab030f9550d702",
            "f17e745eee5944f2b16caf60c82f87d0",
            "ffd4a09e5db445699852befbc9900918"
          ]
        },
        "id": "oVZBPaK7z-y2",
        "outputId": "5b8d9104-0b49-43d0-b4b7-534a08965513"
      },
      "id": "oVZBPaK7z-y2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35af0008335447e7aed7f36441da7647"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b26e7bfcf419468898df02b1eaf9a4ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c808ac24af37459398e4dff7da36a918"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61d4683149584722bacc0d327386604d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7b6a522987f4dc9a3f2c2446d0892a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf24fc88a41e42709c11ce94e7d6f023"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1 of 50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "n_components=50 must be between 0 and min(n_samples, n_features)=18 with svd_solver='full'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-415c824aa85a>\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# Optional: Apply PCA to reduce the dimensionality of the embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Reduce to 50 dimensions (adjust based on experiments)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mprogram_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogram_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;31m# Measure the end of training time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 )\n\u001b[1;32m   1151\u001b[0m             ):\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0mC\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m \u001b[0;34m'np.ascontiguousarray'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \"\"\"\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;31m# Call different fits for either full or truncated SVD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"full\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"arpack\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"randomized\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit_full\u001b[0;34m(self, X, n_components)\u001b[0m\n\u001b[1;32m    522\u001b[0m                 )\n\u001b[1;32m    523\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn_components\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    525\u001b[0m                 \u001b[0;34m\"n_components=%r must be between 0 and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                 \u001b[0;34m\"min(n_samples, n_features)=%r with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: n_components=50 must be between 0 and min(n_samples, n_features)=18 with svd_solver='full'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6latz1cZyAEj"
      },
      "id": "6latz1cZyAEj",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02b627e68f4a421ba09ba15b9ab08dca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "069364f5a1be40ae978ba2c9b7a95291": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "069cfab2125844a58cbcc8c5164bb2ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "083fe7730cb740c7b50dfeddede172d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e706a81e337422fbc7fba5096679a2c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f5f1c475bc4483e9be3e6d5e00d491b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1091411f109f4a168a27a1ce4011d1ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "183973f08d6f41b5bc97cc594ef6d5dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "288553384e4541abbdcf55e1003c8cf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34dc93f2356b4b0d80c9621dea9f24f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3512aab0fc6f4e3db3e9847684ea6639": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37f1382bde094b37bfd597ac8be0c4f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e0dfff6c8c44447b9182344c7cac666": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43a9d3c5cde042af84ecb5c5dbf94065": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dfe97c2b40a449ebcbb0b35cd84f7af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f78fc52fb2a418c87770ba3fb041990": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53314f68b919408eb7bd21d31241a7b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "542d184132e546d8a005d7a11a1045d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62a4ac8655de4477839e5e121b225b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34dc93f2356b4b0d80c9621dea9f24f0",
            "placeholder": "​",
            "style": "IPY_MODEL_f306098093cf4f54bb99a66e43699a69",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "64e57361b5944b2a91112225696c0490": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66eb1acdc50040d6b5a098ae00035610": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69fb4505d7464d4092c8d543ee596c61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b82c85c2b3b4ba3b2c82540f1dac4db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7328e328f2eb4fd68619159748eb3540": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d500e7de70e34c67af5a3aac614b2622",
            "placeholder": "​",
            "style": "IPY_MODEL_dbb19fbfaa8e40cfa1523f3210144828",
            "value": " 150/150 [00:00&lt;00:00, 3.16kB/s]"
          }
        },
        "75a52a6867754aa790c4fa0011a4d86b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43a9d3c5cde042af84ecb5c5dbf94065",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbd1eae035b44e758f3033ffeef65847",
            "value": 898822
          }
        },
        "770ce23b84fe4e419b2fbb19d2ed2d13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c7b1e1fc23b4643b0346651b247438d",
            "max": 498,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc4f1a5759e54b1ca200d354d37b99c7",
            "value": 498
          }
        },
        "784bdcecc2304b3ea0d049ab9b4636da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c7b1e1fc23b4643b0346651b247438d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81356b11043c4ef081fb196bc00db57b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c187cb5e29224545bacbb57f89078dfb",
              "IPY_MODEL_a41e6faf3bf94cfdb875dd2575d61720",
              "IPY_MODEL_a51ecdec6d384172bbb9627a4c8f85fa"
            ],
            "layout": "IPY_MODEL_cdc7ca4fa7e44c42acd49042505133ca"
          }
        },
        "8327eb9accd443b5aa9dbff743e0065d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e0dfff6c8c44447b9182344c7cac666",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_083fe7730cb740c7b50dfeddede172d6",
            "value": 150
          }
        },
        "8596e8a719f6402199e14d5c78127405": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_069cfab2125844a58cbcc8c5164bb2ca",
            "placeholder": "​",
            "style": "IPY_MODEL_97e9c9d72f184fc39d0b8dd121f7e351",
            "value": " 899k/899k [00:00&lt;00:00, 2.72MB/s]"
          }
        },
        "8b628394476340688c29a9a5f42e825f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c83c857ea7c49289ab85ed3736d2558": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d17f81b4b884012bdcc8c53e6cc7d74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba13e71bca71463b9bc1548aaf49e352",
              "IPY_MODEL_f8a346924c644c8f9631b9f86daaf73e",
              "IPY_MODEL_d728658f24914208a3e107b8d6d0973f"
            ],
            "layout": "IPY_MODEL_af8e45438afd4672967c9817435a0ed4"
          }
        },
        "9497be65739b4919abea118d344bd4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c83c857ea7c49289ab85ed3736d2558",
            "placeholder": "​",
            "style": "IPY_MODEL_0f5f1c475bc4483e9be3e6d5e00d491b",
            "value": " 498/498 [00:00&lt;00:00, 7.54kB/s]"
          }
        },
        "97e9c9d72f184fc39d0b8dd121f7e351": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "990c38df28e443dd94ab0b9f8ac7d36e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e706a81e337422fbc7fba5096679a2c",
            "placeholder": "​",
            "style": "IPY_MODEL_4dfe97c2b40a449ebcbb0b35cd84f7af",
            "value": "merges.txt: 100%"
          }
        },
        "a3f6c7e8f4fa41a2b209b80a85456158": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a41e6faf3bf94cfdb875dd2575d61720": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02b627e68f4a421ba09ba15b9ab08dca",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53314f68b919408eb7bd21d31241a7b6",
            "value": 25
          }
        },
        "a51ecdec6d384172bbb9627a4c8f85fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3dfd3d0b5444676b863f4d174018255",
            "placeholder": "​",
            "style": "IPY_MODEL_8b628394476340688c29a9a5f42e825f",
            "value": " 25.0/25.0 [00:00&lt;00:00, 372B/s]"
          }
        },
        "af8e45438afd4672967c9817435a0ed4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2b134a3cdfd4176afb896313ec427a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba13e71bca71463b9bc1548aaf49e352": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3b552e728ce41f7a555e650269d736b",
            "placeholder": "​",
            "style": "IPY_MODEL_542d184132e546d8a005d7a11a1045d5",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "c187cb5e29224545bacbb57f89078dfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_784bdcecc2304b3ea0d049ab9b4636da",
            "placeholder": "​",
            "style": "IPY_MODEL_66eb1acdc50040d6b5a098ae00035610",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "c3dfd3d0b5444676b863f4d174018255": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc4f1a5759e54b1ca200d354d37b99c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cdc7ca4fa7e44c42acd49042505133ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0c2dd25680d4139b5581c6da5f06049": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_183973f08d6f41b5bc97cc594ef6d5dc",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b82c85c2b3b4ba3b2c82540f1dac4db",
            "value": 456318
          }
        },
        "d500e7de70e34c67af5a3aac614b2622": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d728658f24914208a3e107b8d6d0973f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64e57361b5944b2a91112225696c0490",
            "placeholder": "​",
            "style": "IPY_MODEL_069364f5a1be40ae978ba2c9b7a95291",
            "value": " 499M/499M [00:05&lt;00:00, 107MB/s]"
          }
        },
        "db6e83e495d748f3832fe4f6842abeb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3f6c7e8f4fa41a2b209b80a85456158",
            "placeholder": "​",
            "style": "IPY_MODEL_288553384e4541abbdcf55e1003c8cf5",
            "value": "config.json: 100%"
          }
        },
        "dbb19fbfaa8e40cfa1523f3210144828": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbd1eae035b44e758f3033ffeef65847": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df56c6c33fe4465d9e7ceec2f78eb045": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e667eb72729f4cfbbfac941cd3ecb21f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e71aacc132b44a2b9537042d2acee67d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa833aef462f49ac9f5de3d43d60432d",
              "IPY_MODEL_75a52a6867754aa790c4fa0011a4d86b",
              "IPY_MODEL_8596e8a719f6402199e14d5c78127405"
            ],
            "layout": "IPY_MODEL_37f1382bde094b37bfd597ac8be0c4f7"
          }
        },
        "eed0003fa6ca4a5085def1f17daa547f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df56c6c33fe4465d9e7ceec2f78eb045",
            "placeholder": "​",
            "style": "IPY_MODEL_1091411f109f4a168a27a1ce4011d1ff",
            "value": " 456k/456k [00:00&lt;00:00, 1.85MB/s]"
          }
        },
        "f0a7f19611d54ebfa4ffacccd79c91ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f306098093cf4f54bb99a66e43699a69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3b552e728ce41f7a555e650269d736b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f66166883b294dddbf0125787eec3866": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62a4ac8655de4477839e5e121b225b1a",
              "IPY_MODEL_8327eb9accd443b5aa9dbff743e0065d",
              "IPY_MODEL_7328e328f2eb4fd68619159748eb3540"
            ],
            "layout": "IPY_MODEL_ffaabcb4e78043a19a630270d709447a"
          }
        },
        "f66d5e14400a4b22862fdfe1d821305d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_990c38df28e443dd94ab0b9f8ac7d36e",
              "IPY_MODEL_d0c2dd25680d4139b5581c6da5f06049",
              "IPY_MODEL_eed0003fa6ca4a5085def1f17daa547f"
            ],
            "layout": "IPY_MODEL_f0a7f19611d54ebfa4ffacccd79c91ec"
          }
        },
        "f8a346924c644c8f9631b9f86daaf73e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3512aab0fc6f4e3db3e9847684ea6639",
            "max": 498627950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69fb4505d7464d4092c8d543ee596c61",
            "value": 498627950
          }
        },
        "fa833aef462f49ac9f5de3d43d60432d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f78fc52fb2a418c87770ba3fb041990",
            "placeholder": "​",
            "style": "IPY_MODEL_b2b134a3cdfd4176afb896313ec427a8",
            "value": "vocab.json: 100%"
          }
        },
        "fbb3a7d54d3f4b979da8a0fb599a5de7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db6e83e495d748f3832fe4f6842abeb4",
              "IPY_MODEL_770ce23b84fe4e419b2fbb19d2ed2d13",
              "IPY_MODEL_9497be65739b4919abea118d344bd4f6"
            ],
            "layout": "IPY_MODEL_e667eb72729f4cfbbfac941cd3ecb21f"
          }
        },
        "ffaabcb4e78043a19a630270d709447a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5907ebb8962d41269e8b790132be3200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4a0917627e146cb920637a654862c89",
              "IPY_MODEL_5df0656f326d4adeaca6dbf477f6c5f0",
              "IPY_MODEL_b70ea907b945487699a1136c23f18150"
            ],
            "layout": "IPY_MODEL_a532e7986bbd42328ec25474fab7654b"
          }
        },
        "b4a0917627e146cb920637a654862c89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_390e89587a10429fb923114e9246fce6",
            "placeholder": "​",
            "style": "IPY_MODEL_067dcdd227b74c0b90042e9536cf87ac",
            "value": "config.json: 100%"
          }
        },
        "5df0656f326d4adeaca6dbf477f6c5f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35689df6cbaa415e8339a85527800bf1",
            "max": 498,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a6d2ba3a56c43fa83f3957e451bd3a9",
            "value": 498
          }
        },
        "b70ea907b945487699a1136c23f18150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a11a4f5e04443ca94769314d5ca58bb",
            "placeholder": "​",
            "style": "IPY_MODEL_3d01efc07acb4f1da8b0eadc4781638c",
            "value": " 498/498 [00:00&lt;00:00, 10.3kB/s]"
          }
        },
        "a532e7986bbd42328ec25474fab7654b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "390e89587a10429fb923114e9246fce6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "067dcdd227b74c0b90042e9536cf87ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35689df6cbaa415e8339a85527800bf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a6d2ba3a56c43fa83f3957e451bd3a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a11a4f5e04443ca94769314d5ca58bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d01efc07acb4f1da8b0eadc4781638c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ee01b02d6c64eec998940f865277aa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25102ffcf8b54de2849628f1b25e3ec7",
              "IPY_MODEL_b84c022598c24735a9eeb1e4ad7fab77",
              "IPY_MODEL_dae344eee7424907aa02b0c729b2887f"
            ],
            "layout": "IPY_MODEL_7744fe4224fa4757bdae65ac3704f249"
          }
        },
        "25102ffcf8b54de2849628f1b25e3ec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a92e02484c8c42dc9c2efa4b38be1163",
            "placeholder": "​",
            "style": "IPY_MODEL_c647c9d66a2f46c69d5e0ca332496f68",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "b84c022598c24735a9eeb1e4ad7fab77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_248c8fd066f249829e8ff741b44b9b92",
            "max": 498627950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4fca2b9be304de984d5460b8fc72367",
            "value": 498627950
          }
        },
        "dae344eee7424907aa02b0c729b2887f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ff94a11c31a47a09228f2f9b662318a",
            "placeholder": "​",
            "style": "IPY_MODEL_49fd5d28bad14dafb77a25ce5badc759",
            "value": " 499M/499M [00:05&lt;00:00, 69.3MB/s]"
          }
        },
        "7744fe4224fa4757bdae65ac3704f249": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a92e02484c8c42dc9c2efa4b38be1163": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c647c9d66a2f46c69d5e0ca332496f68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "248c8fd066f249829e8ff741b44b9b92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4fca2b9be304de984d5460b8fc72367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ff94a11c31a47a09228f2f9b662318a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49fd5d28bad14dafb77a25ce5badc759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c5732a354ec40ae919d917b98314f2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c87e1e31a2b84a9dac6a54eba85413d7",
              "IPY_MODEL_25a4d8b8319e4ce8a9faa8541b1946eb",
              "IPY_MODEL_3d4ca38f1a6a4473a589188fa038dd10"
            ],
            "layout": "IPY_MODEL_3e0d4b26ccd7424cb3abaf96cf80bdf2"
          }
        },
        "c87e1e31a2b84a9dac6a54eba85413d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72cd107feb67478e90d92162add6c261",
            "placeholder": "​",
            "style": "IPY_MODEL_7060a98ce8e24e988e78dd87906bade5",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "25a4d8b8319e4ce8a9faa8541b1946eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf500391e9dc4b8399796cfa9bcb758c",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_adc080130c554507b21c1efe26ee93a7",
            "value": 25
          }
        },
        "3d4ca38f1a6a4473a589188fa038dd10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2ad85ad1a0e4cc5ab055f123c4339f9",
            "placeholder": "​",
            "style": "IPY_MODEL_06d0475cb393469781586318d84b4df6",
            "value": " 25.0/25.0 [00:00&lt;00:00, 529B/s]"
          }
        },
        "3e0d4b26ccd7424cb3abaf96cf80bdf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72cd107feb67478e90d92162add6c261": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7060a98ce8e24e988e78dd87906bade5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf500391e9dc4b8399796cfa9bcb758c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adc080130c554507b21c1efe26ee93a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2ad85ad1a0e4cc5ab055f123c4339f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06d0475cb393469781586318d84b4df6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efdbde77bb3e4dee8c997bcf39ffae98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb3ac662a20740bc890b7a15dd35ae3b",
              "IPY_MODEL_d7eebb5c6cd74a9d9901d9eab71a6a39",
              "IPY_MODEL_4dff183204c541d3989f22e7e0b03dd8"
            ],
            "layout": "IPY_MODEL_c6070bea59504e2ea266d52ac85f0f20"
          }
        },
        "cb3ac662a20740bc890b7a15dd35ae3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08d7dfaa2b71403a9c8117d46396869b",
            "placeholder": "​",
            "style": "IPY_MODEL_86ffef4a494d4a2ba427ce3622399b5a",
            "value": "vocab.json: 100%"
          }
        },
        "d7eebb5c6cd74a9d9901d9eab71a6a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9123abd540ca44509adc6e189a6fe14f",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f0a5d8a186744b8914ae9978726e2e2",
            "value": 898822
          }
        },
        "4dff183204c541d3989f22e7e0b03dd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_812f69994d4f4b09beef13af48108d68",
            "placeholder": "​",
            "style": "IPY_MODEL_d0ec6e98a08b483f88fc3a13a666af91",
            "value": " 899k/899k [00:00&lt;00:00, 17.3MB/s]"
          }
        },
        "c6070bea59504e2ea266d52ac85f0f20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08d7dfaa2b71403a9c8117d46396869b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86ffef4a494d4a2ba427ce3622399b5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9123abd540ca44509adc6e189a6fe14f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f0a5d8a186744b8914ae9978726e2e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "812f69994d4f4b09beef13af48108d68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0ec6e98a08b483f88fc3a13a666af91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74d65ad56aba4db28066ed3c5a8fb048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4dfad4af40354dfcb41567e32f527fb2",
              "IPY_MODEL_1333d801046f4f1d997e2f1088b1580d",
              "IPY_MODEL_80946a3b82f648c3827bfba6702fff02"
            ],
            "layout": "IPY_MODEL_e6626ebeab394b35ab4c715961959eef"
          }
        },
        "4dfad4af40354dfcb41567e32f527fb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e27634be5cf4e59b42b086b14160f79",
            "placeholder": "​",
            "style": "IPY_MODEL_c304ffe74f92430394d29e61b59bed7d",
            "value": "merges.txt: 100%"
          }
        },
        "1333d801046f4f1d997e2f1088b1580d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb9a0aa90c8e4cfeb5d754964d35333d",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6456c11a56174f23a4a205a16bf0b44a",
            "value": 456318
          }
        },
        "80946a3b82f648c3827bfba6702fff02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc2a5116e0fd43ae8cf6d0fce3d5c651",
            "placeholder": "​",
            "style": "IPY_MODEL_4043a7a7182b451b987566dca1af8e67",
            "value": " 456k/456k [00:00&lt;00:00, 16.2MB/s]"
          }
        },
        "e6626ebeab394b35ab4c715961959eef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e27634be5cf4e59b42b086b14160f79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c304ffe74f92430394d29e61b59bed7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb9a0aa90c8e4cfeb5d754964d35333d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6456c11a56174f23a4a205a16bf0b44a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc2a5116e0fd43ae8cf6d0fce3d5c651": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4043a7a7182b451b987566dca1af8e67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8dca732697b543f4853b4a3371aa3c26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_093579bea7a64e26a3fc145ffcbff278",
              "IPY_MODEL_c5a037ffd0424927936caa0711379c1b",
              "IPY_MODEL_4a19bc50728340f9a4c7b23f8ff18294"
            ],
            "layout": "IPY_MODEL_af8fc74b36ef4db38466f59575ba2988"
          }
        },
        "093579bea7a64e26a3fc145ffcbff278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_869934883ee34d3eb7724e99708766cc",
            "placeholder": "​",
            "style": "IPY_MODEL_a8a64b6cc4e54bee8192f734e0765727",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "c5a037ffd0424927936caa0711379c1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45d1fabc784c4ac0a0dd507af3f58fe2",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5dcfcd189dda4f69922c16c20c68c69a",
            "value": 150
          }
        },
        "4a19bc50728340f9a4c7b23f8ff18294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_deddf28b7f834d09aedcd06a964ce5c1",
            "placeholder": "​",
            "style": "IPY_MODEL_176527e43438462b9646c74138242339",
            "value": " 150/150 [00:00&lt;00:00, 3.37kB/s]"
          }
        },
        "af8fc74b36ef4db38466f59575ba2988": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "869934883ee34d3eb7724e99708766cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8a64b6cc4e54bee8192f734e0765727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45d1fabc784c4ac0a0dd507af3f58fe2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dcfcd189dda4f69922c16c20c68c69a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "deddf28b7f834d09aedcd06a964ce5c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "176527e43438462b9646c74138242339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "727b8510d4ab460fa6061119ae7636f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8102aa727066499e90e4afa59ed88f99",
              "IPY_MODEL_26652166ee2e4c289bf4f47c1eb2f57f",
              "IPY_MODEL_38b9e17c1eb64cc6954d9286a9d8b916"
            ],
            "layout": "IPY_MODEL_88d598437ce74979aa7383ccbcfd4d86"
          }
        },
        "8102aa727066499e90e4afa59ed88f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d2c725bbb9c40f9a256303467eefd87",
            "placeholder": "​",
            "style": "IPY_MODEL_4ac8dc3f637144088040304f53d17604",
            "value": "config.json: 100%"
          }
        },
        "26652166ee2e4c289bf4f47c1eb2f57f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5766d5fc03064de69cacabcef689336c",
            "max": 498,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4e67002c7494fe48c3663e075f024ff",
            "value": 498
          }
        },
        "38b9e17c1eb64cc6954d9286a9d8b916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3039a34550ae4ac690b7019d3d03a80d",
            "placeholder": "​",
            "style": "IPY_MODEL_352d2ce09dce4eb68f7c8af13db4791b",
            "value": " 498/498 [00:00&lt;00:00, 24.5kB/s]"
          }
        },
        "88d598437ce74979aa7383ccbcfd4d86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d2c725bbb9c40f9a256303467eefd87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ac8dc3f637144088040304f53d17604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5766d5fc03064de69cacabcef689336c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4e67002c7494fe48c3663e075f024ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3039a34550ae4ac690b7019d3d03a80d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "352d2ce09dce4eb68f7c8af13db4791b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ed22cb538594777a328111f6a14b84b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a422160c58ff47c0bd3a599511599076",
              "IPY_MODEL_1252b99ee1b14f6ebec527c36c673044",
              "IPY_MODEL_ddd84975ba3743b4b1d68dc88e9bbca5"
            ],
            "layout": "IPY_MODEL_3d123770cc92497d851afdfe0b46a80e"
          }
        },
        "a422160c58ff47c0bd3a599511599076": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_752b1d31e3324aa0a8c00e1856aa78e2",
            "placeholder": "​",
            "style": "IPY_MODEL_e577e207cda54e939d20a8ca7e86d721",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "1252b99ee1b14f6ebec527c36c673044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94ba75acd1434ed4b791aa83a91bdfeb",
            "max": 498627950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2205c44b144e45cba30f3bde7caa0f3e",
            "value": 498627950
          }
        },
        "ddd84975ba3743b4b1d68dc88e9bbca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8dfac5df8ef4315a37e4bcefc25902e",
            "placeholder": "​",
            "style": "IPY_MODEL_750225f407e640808ccabe29221e4b2d",
            "value": " 499M/499M [00:16&lt;00:00, 34.3MB/s]"
          }
        },
        "3d123770cc92497d851afdfe0b46a80e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "752b1d31e3324aa0a8c00e1856aa78e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e577e207cda54e939d20a8ca7e86d721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94ba75acd1434ed4b791aa83a91bdfeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2205c44b144e45cba30f3bde7caa0f3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8dfac5df8ef4315a37e4bcefc25902e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "750225f407e640808ccabe29221e4b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d0a035aa95e4d17893f2fc8123f2e84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e69f775a51134f8db786cfa83ab7d557",
              "IPY_MODEL_ba4bd4494eb34c8999fb6e9c27dde41e",
              "IPY_MODEL_fb4e9bdefed143e0a7cf54b5957bec4f"
            ],
            "layout": "IPY_MODEL_527bcbc98e4d492d87c2edecfeed7979"
          }
        },
        "e69f775a51134f8db786cfa83ab7d557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_514a89e105f64ce7ad4e3d63e8768259",
            "placeholder": "​",
            "style": "IPY_MODEL_e0e038ec9ab94480bdf722160c35ddad",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "ba4bd4494eb34c8999fb6e9c27dde41e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb90e164238c495d80f85df3d3486407",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55b553fecf3943d48474d1c5dbc608fa",
            "value": 25
          }
        },
        "fb4e9bdefed143e0a7cf54b5957bec4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb471ac99b1d4f288fba0e997493e82c",
            "placeholder": "​",
            "style": "IPY_MODEL_951655ab30284914acbb21393ed98655",
            "value": " 25.0/25.0 [00:00&lt;00:00, 968B/s]"
          }
        },
        "527bcbc98e4d492d87c2edecfeed7979": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "514a89e105f64ce7ad4e3d63e8768259": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0e038ec9ab94480bdf722160c35ddad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb90e164238c495d80f85df3d3486407": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55b553fecf3943d48474d1c5dbc608fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb471ac99b1d4f288fba0e997493e82c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "951655ab30284914acbb21393ed98655": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a13f5d9e3034c60b8db1d512d507971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27459b775c0f4c2788325c1b6b7267a2",
              "IPY_MODEL_407aeeb0f0034feaacdae64f186c8045",
              "IPY_MODEL_e4d70e9bdeef43edb4bffae6c7b06cf4"
            ],
            "layout": "IPY_MODEL_3b5aea119777494f995f99ca3e44e3ac"
          }
        },
        "27459b775c0f4c2788325c1b6b7267a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ed29106065e4f909e63daf380c783ab",
            "placeholder": "​",
            "style": "IPY_MODEL_a6f508988bfb4871b543c78f25c38b8b",
            "value": "vocab.json: 100%"
          }
        },
        "407aeeb0f0034feaacdae64f186c8045": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db0b368c1a2942fca050b477b18e6feb",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_faa3279aaf4b46e7b7de865b12730f1d",
            "value": 898822
          }
        },
        "e4d70e9bdeef43edb4bffae6c7b06cf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14792133286a4a4d8dc1d3f2bd589ead",
            "placeholder": "​",
            "style": "IPY_MODEL_72291a608b8443c8acf6abf06c8753e8",
            "value": " 899k/899k [00:00&lt;00:00, 12.3MB/s]"
          }
        },
        "3b5aea119777494f995f99ca3e44e3ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ed29106065e4f909e63daf380c783ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6f508988bfb4871b543c78f25c38b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db0b368c1a2942fca050b477b18e6feb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faa3279aaf4b46e7b7de865b12730f1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14792133286a4a4d8dc1d3f2bd589ead": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72291a608b8443c8acf6abf06c8753e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cc85f34154a43d3965e3f2b0166a936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_effd9f74cf9141e38aceac60efdc3742",
              "IPY_MODEL_7a8b6bfe90ed4c14adce23d5e0631711",
              "IPY_MODEL_29ec4a59b1c843c687fb12ea29c3878e"
            ],
            "layout": "IPY_MODEL_15bd8236e608410b88cb38d6710d8962"
          }
        },
        "effd9f74cf9141e38aceac60efdc3742": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2f9b055f60c4596bfb958998443d5ce",
            "placeholder": "​",
            "style": "IPY_MODEL_bd5d543825ce4d318d4e586ef1b9266e",
            "value": "merges.txt: 100%"
          }
        },
        "7a8b6bfe90ed4c14adce23d5e0631711": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55cf4187a01344dbbf4af4d16a148a82",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7c7f79570d84667b72913f79d0def6f",
            "value": 456318
          }
        },
        "29ec4a59b1c843c687fb12ea29c3878e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2f024ad905c4f68a272ba9a89d8ee19",
            "placeholder": "​",
            "style": "IPY_MODEL_8868c9d1e2ee4078a0387a8e1c26e8d7",
            "value": " 456k/456k [00:00&lt;00:00, 22.7MB/s]"
          }
        },
        "15bd8236e608410b88cb38d6710d8962": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2f9b055f60c4596bfb958998443d5ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd5d543825ce4d318d4e586ef1b9266e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55cf4187a01344dbbf4af4d16a148a82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7c7f79570d84667b72913f79d0def6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2f024ad905c4f68a272ba9a89d8ee19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8868c9d1e2ee4078a0387a8e1c26e8d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4609b2d80963451db2bfb61687830391": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51074d03825c4a608109357d88c33e7e",
              "IPY_MODEL_c350a42f47b64f74a18fbe971c1f5ad8",
              "IPY_MODEL_d264453bb3864d26a8615fb05cf718f6"
            ],
            "layout": "IPY_MODEL_e804483d6fa04040a4d04f518c422ecc"
          }
        },
        "51074d03825c4a608109357d88c33e7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3138a201a11a4c9c8e00cacdfd0cd4f0",
            "placeholder": "​",
            "style": "IPY_MODEL_47b7ee25a40647139540842772a670aa",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "c350a42f47b64f74a18fbe971c1f5ad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd9466475a2046d79f8b010c6acef4b2",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3fc0f4e42504654b315ca9d5ed75258",
            "value": 150
          }
        },
        "d264453bb3864d26a8615fb05cf718f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cda51966c77f45e396647ce7e587712e",
            "placeholder": "​",
            "style": "IPY_MODEL_048224c2fc4d4442ab4ac789c3abe4b6",
            "value": " 150/150 [00:00&lt;00:00, 9.41kB/s]"
          }
        },
        "e804483d6fa04040a4d04f518c422ecc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3138a201a11a4c9c8e00cacdfd0cd4f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47b7ee25a40647139540842772a670aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd9466475a2046d79f8b010c6acef4b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3fc0f4e42504654b315ca9d5ed75258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cda51966c77f45e396647ce7e587712e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "048224c2fc4d4442ab4ac789c3abe4b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35af0008335447e7aed7f36441da7647": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ccee66d22ec4b87851086c2e5ed6cb4",
              "IPY_MODEL_f34d36ddaafe40979c007904284127ca",
              "IPY_MODEL_54ecb68e84134b31bac8c2a18c1b6f0d"
            ],
            "layout": "IPY_MODEL_6030267932844fe1a6b5231cf616a39f"
          }
        },
        "8ccee66d22ec4b87851086c2e5ed6cb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77df3bb66b6e42deb495b90749a8d88a",
            "placeholder": "​",
            "style": "IPY_MODEL_96f547f0a42346cfa2932b6720041a58",
            "value": "config.json: 100%"
          }
        },
        "f34d36ddaafe40979c007904284127ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06e2849cc0a5466a99e353cbf00e19b2",
            "max": 498,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_806242f42bc447dc8ab60f0939970573",
            "value": 498
          }
        },
        "54ecb68e84134b31bac8c2a18c1b6f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_012b1705ad2f4d0d956ac17ce66d6de3",
            "placeholder": "​",
            "style": "IPY_MODEL_e6a9152b8ba04d5cb7ee7fef4580aff0",
            "value": " 498/498 [00:00&lt;00:00, 9.59kB/s]"
          }
        },
        "6030267932844fe1a6b5231cf616a39f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77df3bb66b6e42deb495b90749a8d88a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96f547f0a42346cfa2932b6720041a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06e2849cc0a5466a99e353cbf00e19b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "806242f42bc447dc8ab60f0939970573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "012b1705ad2f4d0d956ac17ce66d6de3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6a9152b8ba04d5cb7ee7fef4580aff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b26e7bfcf419468898df02b1eaf9a4ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e17ed600fd4448690190752f8ff0196",
              "IPY_MODEL_0257368dd3304fb191386c80913805b3",
              "IPY_MODEL_a11dc9d41e1e4cc2a516ba61b20c0cc8"
            ],
            "layout": "IPY_MODEL_aee71369964f4ec09c535b6d345bb28f"
          }
        },
        "6e17ed600fd4448690190752f8ff0196": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56a027826f8a44689f5ad0b6b185b228",
            "placeholder": "​",
            "style": "IPY_MODEL_9eec6f6d81eb4c1d93153930e549f566",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "0257368dd3304fb191386c80913805b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48244532cc694799b5f6bda53ed480ae",
            "max": 498627950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a85917dcda64740b31c061a81395ffb",
            "value": 498627950
          }
        },
        "a11dc9d41e1e4cc2a516ba61b20c0cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91ae80b3036a488db7d4ee2599d721b4",
            "placeholder": "​",
            "style": "IPY_MODEL_707efcb769734d189a0f816bf00b0933",
            "value": " 499M/499M [00:18&lt;00:00, 28.0MB/s]"
          }
        },
        "aee71369964f4ec09c535b6d345bb28f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56a027826f8a44689f5ad0b6b185b228": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9eec6f6d81eb4c1d93153930e549f566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48244532cc694799b5f6bda53ed480ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a85917dcda64740b31c061a81395ffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91ae80b3036a488db7d4ee2599d721b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "707efcb769734d189a0f816bf00b0933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c808ac24af37459398e4dff7da36a918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a14eb8038d164cd184db478282efd908",
              "IPY_MODEL_8e00335156254d138fdb03c204c3c16c",
              "IPY_MODEL_11bd7133dbbb441684e9c38fd6fcb431"
            ],
            "layout": "IPY_MODEL_82a39a0a0b1d432380c62fdabf535be4"
          }
        },
        "a14eb8038d164cd184db478282efd908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_418debcbd5c3492a89a6df78dcc6a24f",
            "placeholder": "​",
            "style": "IPY_MODEL_9bc0706e7bca4739a4dd0cf3ac7b4780",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "8e00335156254d138fdb03c204c3c16c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6fd3332b1c9490ea8b85b6ea18ad979",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63b11feb8f744335b9412b711dd8b176",
            "value": 25
          }
        },
        "11bd7133dbbb441684e9c38fd6fcb431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97214464aee5494cbeae380e7d6def64",
            "placeholder": "​",
            "style": "IPY_MODEL_5819e0e6a7af443392e1d7a0e3cf8ef1",
            "value": " 25.0/25.0 [00:00&lt;00:00, 1.04kB/s]"
          }
        },
        "82a39a0a0b1d432380c62fdabf535be4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "418debcbd5c3492a89a6df78dcc6a24f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bc0706e7bca4739a4dd0cf3ac7b4780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6fd3332b1c9490ea8b85b6ea18ad979": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63b11feb8f744335b9412b711dd8b176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97214464aee5494cbeae380e7d6def64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5819e0e6a7af443392e1d7a0e3cf8ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61d4683149584722bacc0d327386604d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8581528c104146888eeefc96588820bc",
              "IPY_MODEL_3826994300c848cb8fceddc46a915fb6",
              "IPY_MODEL_49ff3199b0eb4f3baec6f1dc95e82b74"
            ],
            "layout": "IPY_MODEL_9f7ccdefca0a4d2297ffcbc702b8b488"
          }
        },
        "8581528c104146888eeefc96588820bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d17fc8bd13054ff5a1415d5a8abbf386",
            "placeholder": "​",
            "style": "IPY_MODEL_54658cb1b9204a748bb81c7b58fdf82e",
            "value": "vocab.json: 100%"
          }
        },
        "3826994300c848cb8fceddc46a915fb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42136e3210a14c9797f0d4fa152b77a7",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51ace324628a4d00943cc357da82df4e",
            "value": 898822
          }
        },
        "49ff3199b0eb4f3baec6f1dc95e82b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf8bc26aa05d45e9b020d61226ae9097",
            "placeholder": "​",
            "style": "IPY_MODEL_5865138159fc40a59624a8d1964cf1c1",
            "value": " 899k/899k [00:00&lt;00:00, 11.6MB/s]"
          }
        },
        "9f7ccdefca0a4d2297ffcbc702b8b488": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d17fc8bd13054ff5a1415d5a8abbf386": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54658cb1b9204a748bb81c7b58fdf82e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42136e3210a14c9797f0d4fa152b77a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51ace324628a4d00943cc357da82df4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf8bc26aa05d45e9b020d61226ae9097": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5865138159fc40a59624a8d1964cf1c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7b6a522987f4dc9a3f2c2446d0892a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be36240f9cf849d9945002caa83e3bd8",
              "IPY_MODEL_c3a1fe12ffa545af951474a299fc1f59",
              "IPY_MODEL_07a9d488197440a0a7779834e97684bd"
            ],
            "layout": "IPY_MODEL_e577117798924868bcc541075ef988b5"
          }
        },
        "be36240f9cf849d9945002caa83e3bd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2da69ff6a0484f1885c699cbebdb7a0f",
            "placeholder": "​",
            "style": "IPY_MODEL_e2d029949aed4e4eaba6f7abea838e45",
            "value": "merges.txt: 100%"
          }
        },
        "c3a1fe12ffa545af951474a299fc1f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96acc73e51e14e278a24790b5415f555",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf3e0d6a202b4ab28624b4752fd01eef",
            "value": 456318
          }
        },
        "07a9d488197440a0a7779834e97684bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c728ad393a4f48b7bfaf9f13f57daf10",
            "placeholder": "​",
            "style": "IPY_MODEL_35b2725b5e3a49c5b6c4dfa26775a55f",
            "value": " 456k/456k [00:00&lt;00:00, 21.4MB/s]"
          }
        },
        "e577117798924868bcc541075ef988b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2da69ff6a0484f1885c699cbebdb7a0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2d029949aed4e4eaba6f7abea838e45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96acc73e51e14e278a24790b5415f555": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf3e0d6a202b4ab28624b4752fd01eef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c728ad393a4f48b7bfaf9f13f57daf10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35b2725b5e3a49c5b6c4dfa26775a55f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf24fc88a41e42709c11ce94e7d6f023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1747434280a649f7bf24d7f99f549de7",
              "IPY_MODEL_46a7e2d493bf4d9eb9c1e53b4eeb60a3",
              "IPY_MODEL_97ff21851cb64c3d8bbb2d2a942ced89"
            ],
            "layout": "IPY_MODEL_c9aba26899ce4afaa76ae09f02cd729d"
          }
        },
        "1747434280a649f7bf24d7f99f549de7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a86c9bef263345d1be3e329f462dbb0e",
            "placeholder": "​",
            "style": "IPY_MODEL_0b08fa260e544b42a861f13a6d774189",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "46a7e2d493bf4d9eb9c1e53b4eeb60a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbd3f5d3a0de4da6b56dc416fce01617",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b598bc6d33404754b2ab030f9550d702",
            "value": 150
          }
        },
        "97ff21851cb64c3d8bbb2d2a942ced89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f17e745eee5944f2b16caf60c82f87d0",
            "placeholder": "​",
            "style": "IPY_MODEL_ffd4a09e5db445699852befbc9900918",
            "value": " 150/150 [00:00&lt;00:00, 8.02kB/s]"
          }
        },
        "c9aba26899ce4afaa76ae09f02cd729d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a86c9bef263345d1be3e329f462dbb0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b08fa260e544b42a861f13a6d774189": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbd3f5d3a0de4da6b56dc416fce01617": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b598bc6d33404754b2ab030f9550d702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f17e745eee5944f2b16caf60c82f87d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffd4a09e5db445699852befbc9900918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}