{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21436028-c505-4770-97ce-f8f97aed7cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: nons (54).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (29).java, Predicted Label: 1, True Label: 0\n",
      "File: nons (25).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (27).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (34).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (61).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 0.7777777777777778, Recall: 0.7777777777777778, F-score: 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize the RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Function to extract embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Function to calculate the distance matrix based on the chosen metric\n",
    "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
    "    if metric == 'cosine':\n",
    "        return cosine_distances(embeddings)\n",
    "    elif metric == 'euclidean':\n",
    "        return euclidean_distances(embeddings)\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
    "\n",
    "# Switch between 'cosine' and 'euclidean'\n",
    "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
    "\n",
    "# Initialize lists to store Java programs and their corresponding labels\n",
    "java_programs = []\n",
    "program_labels = []\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_text = f.read()\n",
    "            java_programs.append(program_text)\n",
    "\n",
    "            # Check if the keyword \"singleton\" is present in the filename\n",
    "            if \"singleton\" in program_file:\n",
    "                program_labels.append(1)  # Positive class (implements singleton)\n",
    "            else:\n",
    "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
    "\n",
    "# Calculate embeddings for the Java programs line by line and take the mean\n",
    "program_embeddings = []\n",
    "for program in java_programs:\n",
    "    lines = program.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Apply standard scaling to normalize the embeddings\n",
    "scaler = StandardScaler()\n",
    "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
    "\n",
    "# Calculate the distance matrix based on the chosen metric\n",
    "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
    "\n",
    "# Get k-nearest neighbors indices for each program\n",
    "k = 5  # Number of neighbors to consider\n",
    "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
    "\n",
    "# Initialize an array to store predicted labels\n",
    "predicted_labels = []\n",
    "\n",
    "# Predict labels for each program based on the majority label of neighbors\n",
    "for indices in knn_indices:\n",
    "    neighbor_labels = [program_labels[i] for i in indices]\n",
    "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert predicted_labels to NumPy array for further analysis\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# Apply k-nearest neighbor classification\n",
    "n_neighbors = 3  # Number of neighbors to consider\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and f-score\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# Print the classification results and performance metrics\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87af8eb-ed17-49fa-ada0-ea9f06bb92a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Singleton on different setting of programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81b05c02-96c0-42f8-80db-a5ff1883f035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: nons (54).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (25).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (25).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (27).java, Predicted Label: 1, True Label: 0\n",
      "File: singleton (18).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (19).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (55).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (34).java, Predicted Label: 1, True Label: 0\n",
      "File: singleton (24).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize the RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Function to extract embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Function to calculate the distance matrix based on the chosen metric\n",
    "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
    "    if metric == 'cosine':\n",
    "        return cosine_distances(embeddings)\n",
    "    elif metric == 'euclidean':\n",
    "        return euclidean_distances(embeddings)\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
    "\n",
    "# Switch between 'cosine' and 'euclidean'\n",
    "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
    "\n",
    "# Initialize lists to store Java programs and their corresponding labels\n",
    "java_programs = []\n",
    "program_labels = []\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_text = f.read()\n",
    "            java_programs.append(program_text)\n",
    "\n",
    "            # Check if the keyword \"singleton\" is present in the filename\n",
    "            if \"singleton\" in program_file:\n",
    "                program_labels.append(1)  # Positive class (implements singleton)\n",
    "            else:\n",
    "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
    "\n",
    "# Calculate embeddings for the Java programs line by line and take the mean\n",
    "program_embeddings = []\n",
    "for program in java_programs:\n",
    "    lines = program.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Apply standard scaling to normalize the embeddings\n",
    "scaler = StandardScaler()\n",
    "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
    "\n",
    "# Calculate the distance matrix based on the chosen metric\n",
    "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
    "\n",
    "# Get k-nearest neighbors indices for each program\n",
    "k = 5  # Number of neighbors to consider\n",
    "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
    "\n",
    "# Initialize an array to store predicted labels\n",
    "predicted_labels = []\n",
    "\n",
    "# Predict labels for each program based on the majority label of neighbors\n",
    "for indices in knn_indices:\n",
    "    neighbor_labels = [program_labels[i] for i in indices]\n",
    "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert predicted_labels to NumPy array for further analysis\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# Apply k-nearest neighbor classification\n",
    "n_neighbors = 3  # Number of neighbors to consider\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and f-score\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# Print the classification results and performance metrics\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ced25be-d014-4bb9-9eb9-e6aa02c54196",
   "metadata": {},
   "outputs": [],
   "source": [
    "Singleton on different setting of programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c71c07d-90ac-4ace-a0f2-59cfa49dbd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: nons (12).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (50).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (25).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (24).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (4).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (44).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (38).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (14).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize the RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Function to extract embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Function to calculate the distance matrix based on the chosen metric\n",
    "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
    "    if metric == 'cosine':\n",
    "        return cosine_distances(embeddings)\n",
    "    elif metric == 'euclidean':\n",
    "        return euclidean_distances(embeddings)\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
    "\n",
    "# Switch between 'cosine' and 'euclidean'\n",
    "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
    "\n",
    "# Initialize lists to store Java programs and their corresponding labels\n",
    "java_programs = []\n",
    "program_labels = []\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_text = f.read()\n",
    "            java_programs.append(program_text)\n",
    "\n",
    "            # Check if the keyword \"singleton\" is present in the filename\n",
    "            if \"singleton\" in program_file:\n",
    "                program_labels.append(1)  # Positive class (implements singleton)\n",
    "            else:\n",
    "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
    "\n",
    "# Calculate embeddings for the Java programs line by line and take the mean\n",
    "program_embeddings = []\n",
    "for program in java_programs:\n",
    "    lines = program.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Apply standard scaling to normalize the embeddings\n",
    "scaler = StandardScaler()\n",
    "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
    "\n",
    "# Calculate the distance matrix based on the chosen metric\n",
    "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
    "\n",
    "# Get k-nearest neighbors indices for each program\n",
    "k = 5  # Number of neighbors to consider\n",
    "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
    "\n",
    "# Initialize an array to store predicted labels\n",
    "predicted_labels = []\n",
    "\n",
    "# Predict labels for each program based on the majority label of neighbors\n",
    "for indices in knn_indices:\n",
    "    neighbor_labels = [program_labels[i] for i in indices]\n",
    "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert predicted_labels to NumPy array for further analysis\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# Apply k-nearest neighbor classification\n",
    "n_neighbors = 3  # Number of neighbors to consider\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and f-score\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# Print the classification results and performance metrics\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e78e397-4cc7-417f-a4eb-7dc11c33f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "Singleton with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f05d34b7-a97c-44a7-a882-0fadab8450fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: nons (54).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (25).java, Predicted Label: 1, True Label: 0\n",
      "File: nons (42).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (27).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (18).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (55).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (34).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (61).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 0.9142857142857143, Recall: 0.9, F-score: 0.8967032967032967\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize the RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Function to extract embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Function to calculate the distance matrix based on the chosen metric\n",
    "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
    "    if metric == 'cosine':\n",
    "        return cosine_distances(embeddings)\n",
    "    elif metric == 'euclidean':\n",
    "        return euclidean_distances(embeddings)\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
    "\n",
    "# Switch between 'cosine' and 'euclidean'\n",
    "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
    "\n",
    "# Initialize lists to store Java programs and their corresponding labels\n",
    "java_programs = []\n",
    "program_labels = []\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_text = f.read()\n",
    "            java_programs.append(program_text)\n",
    "\n",
    "            # Check if the keyword \"singleton\" is present in the filename\n",
    "            if \"singleton\" in program_file:\n",
    "                program_labels.append(1)  # Positive class (implements singleton)\n",
    "            else:\n",
    "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
    "\n",
    "# Calculate embeddings for the Java programs line by line and take the mean\n",
    "program_embeddings = []\n",
    "for program in java_programs:\n",
    "    lines = program.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Apply standard scaling to normalize the embeddings\n",
    "scaler = StandardScaler()\n",
    "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
    "\n",
    "# Calculate the distance matrix based on the chosen metric\n",
    "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
    "\n",
    "# Get k-nearest neighbors indices for each program\n",
    "k = 5  # Number of neighbors to consider\n",
    "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
    "\n",
    "# Initialize an array to store predicted labels\n",
    "predicted_labels = []\n",
    "\n",
    "# Predict labels for each program based on the majority label of neighbors\n",
    "for indices in knn_indices:\n",
    "    neighbor_labels = [program_labels[i] for i in indices]\n",
    "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert predicted_labels to NumPy array for further analysis\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# Apply k-nearest neighbor classification\n",
    "n_neighbors = 3  # Number of neighbors to consider\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and f-score\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# Print the classification results and performance metrics\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1172090d-21fc-4445-81e0-d7cfc1fbc01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Builder with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8449196d-4a54-4705-adb8-46f17ab3d14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: builder (2).java, Predicted Label: 1, True Label: 1\n",
      "File: builder (5).java, Predicted Label: 1, True Label: 1\n",
      "File: nonbuilder (55).java, Predicted Label: 1, True Label: 1\n",
      "File: builder (6).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'builder'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize the RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Function to extract embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Function to calculate the distance matrix based on the chosen metric\n",
    "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
    "    if metric == 'cosine':\n",
    "        return cosine_distances(embeddings)\n",
    "    elif metric == 'euclidean':\n",
    "        return euclidean_distances(embeddings)\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
    "\n",
    "# Switch between 'cosine' and 'euclidean'\n",
    "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
    "\n",
    "# Initialize lists to store Java programs and their corresponding labels\n",
    "java_programs = []\n",
    "program_labels = []\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_text = f.read()\n",
    "            java_programs.append(program_text)\n",
    "\n",
    "            # Check if the keyword \"singleton\" is present in the filename\n",
    "            if \"builder\" in program_file:\n",
    "                program_labels.append(1)  # Positive class (implements singleton)\n",
    "            else:\n",
    "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
    "\n",
    "# Calculate embeddings for the Java programs line by line and take the mean\n",
    "program_embeddings = []\n",
    "for program in java_programs:\n",
    "    lines = program.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Apply standard scaling to normalize the embeddings\n",
    "scaler = StandardScaler()\n",
    "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
    "\n",
    "# Calculate the distance matrix based on the chosen metric\n",
    "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
    "\n",
    "# Get k-nearest neighbors indices for each program\n",
    "k = 5  # Number of neighbors to consider\n",
    "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
    "\n",
    "# Initialize an array to store predicted labels\n",
    "predicted_labels = []\n",
    "\n",
    "# Predict labels for each program based on the majority label of neighbors\n",
    "for indices in knn_indices:\n",
    "    neighbor_labels = [program_labels[i] for i in indices]\n",
    "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert predicted_labels to NumPy array for further analysis\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# Apply k-nearest neighbor classification\n",
    "n_neighbors = 3  # Number of neighbors to consider\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and f-score\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# Print the classification results and performance metrics\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47daabed-0321-432b-b8ec-52b2ecd41c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Builder with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "570aad8c-5fc9-476b-83c2-043a2d0adbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: nonb (14).java, Predicted Label: 1, True Label: 1\n",
      "File: builder (2).java, Predicted Label: 1, True Label: 1\n",
      "File: builder (5).java, Predicted Label: 0, True Label: 0\n",
      "File: builder (6).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'builder'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize the RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Function to extract embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Function to calculate the distance matrix based on the chosen metric\n",
    "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
    "    if metric == 'cosine':\n",
    "        return cosine_distances(embeddings)\n",
    "    elif metric == 'euclidean':\n",
    "        return euclidean_distances(embeddings)\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
    "\n",
    "# Switch between 'cosine' and 'euclidean'\n",
    "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
    "\n",
    "# Initialize lists to store Java programs and their corresponding labels\n",
    "java_programs = []\n",
    "program_labels = []\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_text = f.read()\n",
    "            java_programs.append(program_text)\n",
    "\n",
    "            # Check if the keyword \"singleton\" is present in the filename\n",
    "            if \"builder\" in program_file:\n",
    "                program_labels.append(1)  # Positive class (implements singleton)\n",
    "            else:\n",
    "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
    "\n",
    "# Calculate embeddings for the Java programs line by line and take the mean\n",
    "program_embeddings = []\n",
    "for program in java_programs:\n",
    "    lines = program.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Apply standard scaling to normalize the embeddings\n",
    "scaler = StandardScaler()\n",
    "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
    "\n",
    "# Calculate the distance matrix based on the chosen metric\n",
    "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
    "\n",
    "# Get k-nearest neighbors indices for each program\n",
    "k = 5  # Number of neighbors to consider\n",
    "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
    "\n",
    "# Initialize an array to store predicted labels\n",
    "predicted_labels = []\n",
    "\n",
    "# Predict labels for each program based on the majority label of neighbors\n",
    "for indices in knn_indices:\n",
    "    neighbor_labels = [program_labels[i] for i in indices]\n",
    "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert predicted_labels to NumPy array for further analysis\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# Apply k-nearest neighbor classification\n",
    "n_neighbors = 3  # Number of neighbors to consider\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and f-score\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# Print the classification results and performance metrics\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28af0c9-077b-4b56-9a64-c2dd0d6ed102",
   "metadata": {},
   "outputs": [],
   "source": [
    "Builder with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd7079f5-2b8d-4817-b8c1-ba13893aa180",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: builder (2).java, Predicted Label: 1, True Label: 1\n",
      "File: nonb (89).java, Predicted Label: 0, True Label: 0\n",
      "File: nonb (49).java, Predicted Label: 1, True Label: 1\n",
      "File: nonb (28).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'builder'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize the RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Function to extract embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Function to calculate the distance matrix based on the chosen metric\n",
    "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
    "    if metric == 'cosine':\n",
    "        return cosine_distances(embeddings)\n",
    "    elif metric == 'euclidean':\n",
    "        return euclidean_distances(embeddings)\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
    "\n",
    "# Switch between 'cosine' and 'euclidean'\n",
    "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
    "\n",
    "# Initialize lists to store Java programs and their corresponding labels\n",
    "java_programs = []\n",
    "program_labels = []\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_text = f.read()\n",
    "            java_programs.append(program_text)\n",
    "\n",
    "            # Check if the keyword \"singleton\" is present in the filename\n",
    "            if \"builder\" in program_file:\n",
    "                program_labels.append(1)  # Positive class (implements singleton)\n",
    "            else:\n",
    "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
    "\n",
    "# Calculate embeddings for the Java programs line by line and take the mean\n",
    "program_embeddings = []\n",
    "for program in java_programs:\n",
    "    lines = program.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Apply standard scaling to normalize the embeddings\n",
    "scaler = StandardScaler()\n",
    "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
    "\n",
    "# Calculate the distance matrix based on the chosen metric\n",
    "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
    "\n",
    "# Get k-nearest neighbors indices for each program\n",
    "k = 5  # Number of neighbors to consider\n",
    "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
    "\n",
    "# Initialize an array to store predicted labels\n",
    "predicted_labels = []\n",
    "\n",
    "# Predict labels for each program based on the majority label of neighbors\n",
    "for indices in knn_indices:\n",
    "    neighbor_labels = [program_labels[i] for i in indices]\n",
    "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert predicted_labels to NumPy array for further analysis\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# Apply k-nearest neighbor classification\n",
    "n_neighbors = 3  # Number of neighbors to consider\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and f-score\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# Print the classification results and performance metrics\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a358eaca-23b2-4601-ab2b-732b209efafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Builder with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87258ad9-eeaa-4d7c-b030-23a9ca1a00cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: nonb (14).java, Predicted Label: 1, True Label: 1\n",
      "File: builder (2).java, Predicted Label: 0, True Label: 0\n",
      "File: nonb (133).java, Predicted Label: 0, True Label: 0\n",
      "File: builder (5).java, Predicted Label: 1, True Label: 1\n",
      "File: builder (6).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'builder'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize the RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Function to extract embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Function to calculate the distance matrix based on the chosen metric\n",
    "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
    "    if metric == 'cosine':\n",
    "        return cosine_distances(embeddings)\n",
    "    elif metric == 'euclidean':\n",
    "        return euclidean_distances(embeddings)\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
    "\n",
    "# Switch between 'cosine' and 'euclidean'\n",
    "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
    "\n",
    "# Initialize lists to store Java programs and their corresponding labels\n",
    "java_programs = []\n",
    "program_labels = []\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_text = f.read()\n",
    "            java_programs.append(program_text)\n",
    "\n",
    "            # Check if the keyword \"singleton\" is present in the filename\n",
    "            if \"builder\" in program_file:\n",
    "                program_labels.append(1)  # Positive class (implements singleton)\n",
    "            else:\n",
    "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
    "\n",
    "# Calculate embeddings for the Java programs line by line and take the mean\n",
    "program_embeddings = []\n",
    "for program in java_programs:\n",
    "    lines = program.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Apply standard scaling to normalize the embeddings\n",
    "scaler = StandardScaler()\n",
    "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
    "\n",
    "# Calculate the distance matrix based on the chosen metric\n",
    "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
    "\n",
    "# Get k-nearest neighbors indices for each program\n",
    "k = 5  # Number of neighbors to consider\n",
    "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
    "\n",
    "# Initialize an array to store predicted labels\n",
    "predicted_labels = []\n",
    "\n",
    "# Predict labels for each program based on the majority label of neighbors\n",
    "for indices in knn_indices:\n",
    "    neighbor_labels = [program_labels[i] for i in indices]\n",
    "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert predicted_labels to NumPy array for further analysis\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# Apply k-nearest neighbor classification\n",
    "n_neighbors = 3  # Number of neighbors to consider\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and f-score\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# Print the classification results and performance metrics\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fc3bd2-3e21-48eb-b17c-eb1937cb082e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Builder with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81c72d51-0f6e-4109-810b-ebdeae1e970d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: builder (2).java, Predicted Label: 1, True Label: 1\n",
      "File: builder (5).java, Predicted Label: 1, True Label: 1\n",
      "File: builder (6).java, Predicted Label: 1, True Label: 1\n",
      "File: nonb (18).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'builder'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize the RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Function to extract embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Function to calculate the distance matrix based on the chosen metric\n",
    "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
    "    if metric == 'cosine':\n",
    "        return cosine_distances(embeddings)\n",
    "    elif metric == 'euclidean':\n",
    "        return euclidean_distances(embeddings)\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
    "\n",
    "# Switch between 'cosine' and 'euclidean'\n",
    "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
    "\n",
    "# Initialize lists to store Java programs and their corresponding labels\n",
    "java_programs = []\n",
    "program_labels = []\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_text = f.read()\n",
    "            java_programs.append(program_text)\n",
    "\n",
    "            # Check if the keyword \"singleton\" is present in the filename\n",
    "            if \"builder\" in program_file:\n",
    "                program_labels.append(1)  # Positive class (implements singleton)\n",
    "            else:\n",
    "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
    "\n",
    "# Calculate embeddings for the Java programs line by line and take the mean\n",
    "program_embeddings = []\n",
    "for program in java_programs:\n",
    "    lines = program.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Apply standard scaling to normalize the embeddings\n",
    "scaler = StandardScaler()\n",
    "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
    "\n",
    "# Calculate the distance matrix based on the chosen metric\n",
    "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
    "\n",
    "# Get k-nearest neighbors indices for each program\n",
    "k = 5  # Number of neighbors to consider\n",
    "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
    "\n",
    "# Initialize an array to store predicted labels\n",
    "predicted_labels = []\n",
    "\n",
    "# Predict labels for each program based on the majority label of neighbors\n",
    "for indices in knn_indices:\n",
    "    neighbor_labels = [program_labels[i] for i in indices]\n",
    "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert predicted_labels to NumPy array for further analysis\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# Apply k-nearest neighbor classification\n",
    "n_neighbors = 3  # Number of neighbors to consider\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and f-score\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# Print the classification results and performance metrics\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ec4c6d-3d26-41c4-8e22-3621ccb40c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "Abstract Factory with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c126b144-af14-42d5-9c4b-f12848c020d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: nonab (11).java, Predicted Label: 0, True Label: 0\n",
      "File: abstractfactory (2).java, Predicted Label: 0, True Label: 0\n",
      "File: nonab (5).java, Predicted Label: 0, True Label: 0\n",
      "File: nonab (81).java, Predicted Label: 1, True Label: 1\n",
      "File: nonab (7).java, Predicted Label: 1, True Label: 1\n",
      "File: abstractfactory (10).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'abstractfactory'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize the RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Function to extract embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Function to calculate the distance matrix based on the chosen metric\n",
    "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
    "    if metric == 'cosine':\n",
    "        return cosine_distances(embeddings)\n",
    "    elif metric == 'euclidean':\n",
    "        return euclidean_distances(embeddings)\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
    "\n",
    "# Switch between 'cosine' and 'euclidean'\n",
    "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
    "\n",
    "# Initialize lists to store Java programs and their corresponding labels\n",
    "java_programs = []\n",
    "program_labels = []\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_text = f.read()\n",
    "            java_programs.append(program_text)\n",
    "\n",
    "            # Check if the keyword \"singleton\" is present in the filename\n",
    "            if \"abstractfactory\" in program_file:\n",
    "                program_labels.append(1)  # Positive class (implements singleton)\n",
    "            else:\n",
    "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
    "\n",
    "# Calculate embeddings for the Java programs line by line and take the mean\n",
    "program_embeddings = []\n",
    "for program in java_programs:\n",
    "    lines = program.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Apply standard scaling to normalize the embeddings\n",
    "scaler = StandardScaler()\n",
    "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
    "\n",
    "# Calculate the distance matrix based on the chosen metric\n",
    "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
    "\n",
    "# Get k-nearest neighbors indices for each program\n",
    "k = 5  # Number of neighbors to consider\n",
    "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
    "\n",
    "# Initialize an array to store predicted labels\n",
    "predicted_labels = []\n",
    "\n",
    "# Predict labels for each program based on the majority label of neighbors\n",
    "for indices in knn_indices:\n",
    "    neighbor_labels = [program_labels[i] for i in indices]\n",
    "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert predicted_labels to NumPy array for further analysis\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# Apply k-nearest neighbor classification\n",
    "n_neighbors = 5  # Number of neighbors to consider\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and f-score\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# Print the classification results and performance metrics\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c896cc7-6d40-4867-b577-aeee54460984",
   "metadata": {},
   "outputs": [],
   "source": [
    "Abstract Factory with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d693a8b5-5bd0-4328-bc94-479703243122",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: nonab (11).java, Predicted Label: 1, True Label: 1\n",
      "File: nonab (48).java, Predicted Label: 1, True Label: 1\n",
      "File: abstractfactory (2).java, Predicted Label: 0, True Label: 0\n",
      "File: nonab (5).java, Predicted Label: 1, True Label: 1\n",
      "File: nonab (65).java, Predicted Label: 0, True Label: 0\n",
      "File: nonab (7).java, Predicted Label: 1, True Label: 1\n",
      "File: abstractfactory (10).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'abstractfactory'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize the RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Function to extract embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Function to calculate the distance matrix based on the chosen metric\n",
    "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
    "    if metric == 'cosine':\n",
    "        return cosine_distances(embeddings)\n",
    "    elif metric == 'euclidean':\n",
    "        return euclidean_distances(embeddings)\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
    "\n",
    "# Switch between 'cosine' and 'euclidean'\n",
    "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
    "\n",
    "# Initialize lists to store Java programs and their corresponding labels\n",
    "java_programs = []\n",
    "program_labels = []\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_text = f.read()\n",
    "            java_programs.append(program_text)\n",
    "\n",
    "            # Check if the keyword \"singleton\" is present in the filename\n",
    "            if \"abstractfactory\" in program_file:\n",
    "                program_labels.append(1)  # Positive class (implements singleton)\n",
    "            else:\n",
    "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
    "\n",
    "# Calculate embeddings for the Java programs line by line and take the mean\n",
    "program_embeddings = []\n",
    "for program in java_programs:\n",
    "    lines = program.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Apply standard scaling to normalize the embeddings\n",
    "scaler = StandardScaler()\n",
    "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
    "\n",
    "# Calculate the distance matrix based on the chosen metric\n",
    "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
    "\n",
    "# Get k-nearest neighbors indices for each program\n",
    "k = 5  # Number of neighbors to consider\n",
    "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
    "\n",
    "# Initialize an array to store predicted labels\n",
    "predicted_labels = []\n",
    "\n",
    "# Predict labels for each program based on the majority label of neighbors\n",
    "for indices in knn_indices:\n",
    "    neighbor_labels = [program_labels[i] for i in indices]\n",
    "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert predicted_labels to NumPy array for further analysis\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# Apply k-nearest neighbor classification\n",
    "n_neighbors = 5  # Number of neighbors to consider\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and f-score\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# Print the classification results and performance metrics\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3224b654-a186-4728-bc1b-f71552e980cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Abstract Factory with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebf17313-5717-4580-a791-3e95058b2af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: nonab (11).java, Predicted Label: 1, True Label: 1\n",
      "File: nonab (48).java, Predicted Label: 1, True Label: 1\n",
      "File: abstractfactory (2).java, Predicted Label: 0, True Label: 0\n",
      "File: nonab (5).java, Predicted Label: 1, True Label: 1\n",
      "File: nonab (65).java, Predicted Label: 0, True Label: 0\n",
      "File: nonab (7).java, Predicted Label: 1, True Label: 1\n",
      "File: abstractfactory (10).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'abstractfactory'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize the RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Function to extract embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Function to calculate the distance matrix based on the chosen metric\n",
    "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
    "    if metric == 'cosine':\n",
    "        return cosine_distances(embeddings)\n",
    "    elif metric == 'euclidean':\n",
    "        return euclidean_distances(embeddings)\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
    "\n",
    "# Switch between 'cosine' and 'euclidean'\n",
    "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
    "\n",
    "# Initialize lists to store Java programs and their corresponding labels\n",
    "java_programs = []\n",
    "program_labels = []\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_text = f.read()\n",
    "            java_programs.append(program_text)\n",
    "\n",
    "            # Check if the keyword \"singleton\" is present in the filename\n",
    "            if \"abstractfactory\" in program_file:\n",
    "                program_labels.append(1)  # Positive class (implements singleton)\n",
    "            else:\n",
    "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
    "\n",
    "# Calculate embeddings for the Java programs line by line and take the mean\n",
    "program_embeddings = []\n",
    "for program in java_programs:\n",
    "    lines = program.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Apply standard scaling to normalize the embeddings\n",
    "scaler = StandardScaler()\n",
    "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
    "\n",
    "# Calculate the distance matrix based on the chosen metric\n",
    "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
    "\n",
    "# Get k-nearest neighbors indices for each program\n",
    "k = 5  # Number of neighbors to consider\n",
    "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
    "\n",
    "# Initialize an array to store predicted labels\n",
    "predicted_labels = []\n",
    "\n",
    "# Predict labels for each program based on the majority label of neighbors\n",
    "for indices in knn_indices:\n",
    "    neighbor_labels = [program_labels[i] for i in indices]\n",
    "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert predicted_labels to NumPy array for further analysis\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# Apply k-nearest neighbor classification\n",
    "n_neighbors = 5  # Number of neighbors to consider\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and f-score\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# Print the classification results and performance metrics\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96efb97f-49f3-4893-9863-3b6c5d0bd40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Abstract Factory with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85703b70-e65c-4aae-8a8f-12bc6a13e577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: non-DP (37).java, Predicted Label: 0, True Label: 0\n",
      "File: abstractfactory (2).java, Predicted Label: 0, True Label: 0\n",
      "File: non-DP (43).java, Predicted Label: 1, True Label: 1\n",
      "File: non-DP (42).java, Predicted Label: 1, True Label: 1\n",
      "File: non-DP (39).java, Predicted Label: 0, True Label: 0\n",
      "File: non-DP (31).java, Predicted Label: 1, True Label: 1\n",
      "File: non-DP (38).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'abstractfactory'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize the RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Function to extract embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Function to calculate the distance matrix based on the chosen metric\n",
    "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
    "    if metric == 'cosine':\n",
    "        return cosine_distances(embeddings)\n",
    "    elif metric == 'euclidean':\n",
    "        return euclidean_distances(embeddings)\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
    "\n",
    "# Switch between 'cosine' and 'euclidean'\n",
    "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
    "\n",
    "# Initialize lists to store Java programs and their corresponding labels\n",
    "java_programs = []\n",
    "program_labels = []\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_text = f.read()\n",
    "            java_programs.append(program_text)\n",
    "\n",
    "            # Check if the keyword \"singleton\" is present in the filename\n",
    "            if \"abstractfactory\" in program_file:\n",
    "                program_labels.append(1)  # Positive class (implements singleton)\n",
    "            else:\n",
    "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
    "\n",
    "# Calculate embeddings for the Java programs line by line and take the mean\n",
    "program_embeddings = []\n",
    "for program in java_programs:\n",
    "    lines = program.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Apply standard scaling to normalize the embeddings\n",
    "scaler = StandardScaler()\n",
    "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
    "\n",
    "# Calculate the distance matrix based on the chosen metric\n",
    "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
    "\n",
    "# Get k-nearest neighbors indices for each program\n",
    "k = 5  # Number of neighbors to consider\n",
    "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
    "\n",
    "# Initialize an array to store predicted labels\n",
    "predicted_labels = []\n",
    "\n",
    "# Predict labels for each program based on the majority label of neighbors\n",
    "for indices in knn_indices:\n",
    "    neighbor_labels = [program_labels[i] for i in indices]\n",
    "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert predicted_labels to NumPy array for further analysis\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# Apply k-nearest neighbor classification\n",
    "n_neighbors = 5  # Number of neighbors to consider\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and f-score\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# Print the classification results and performance metrics\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c959c6-96e9-4ac8-a6b9-cca5a65688e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Abstract Factory with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2e7f42a-8f7c-4317-9f98-36be0efa6180",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: nondp (18).java, Predicted Label: 0, True Label: 0\n",
      "File: abstractfactory (2).java, Predicted Label: 1, True Label: 1\n",
      "File: nondp (29).java, Predicted Label: 1, True Label: 1\n",
      "File: nondp (31).java, Predicted Label: 1, True Label: 1\n",
      "File: nondp (11).java, Predicted Label: 1, True Label: 1\n",
      "File: nondp (23).java, Predicted Label: 1, True Label: 1\n",
      "File: nondp (38).java, Predicted Label: 0, True Label: 0\n",
      "File: nondp (30).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'abstractfactory'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize the RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Function to extract embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Function to calculate the distance matrix based on the chosen metric\n",
    "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
    "    if metric == 'cosine':\n",
    "        return cosine_distances(embeddings)\n",
    "    elif metric == 'euclidean':\n",
    "        return euclidean_distances(embeddings)\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
    "\n",
    "# Switch between 'cosine' and 'euclidean'\n",
    "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
    "\n",
    "# Initialize lists to store Java programs and their corresponding labels\n",
    "java_programs = []\n",
    "program_labels = []\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_text = f.read()\n",
    "            java_programs.append(program_text)\n",
    "\n",
    "            # Check if the keyword \"singleton\" is present in the filename\n",
    "            if \"abstractfactory\" in program_file:\n",
    "                program_labels.append(1)  # Positive class (implements singleton)\n",
    "            else:\n",
    "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
    "\n",
    "# Calculate embeddings for the Java programs line by line and take the mean\n",
    "program_embeddings = []\n",
    "for program in java_programs:\n",
    "    lines = program.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Apply standard scaling to normalize the embeddings\n",
    "scaler = StandardScaler()\n",
    "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
    "\n",
    "# Calculate the distance matrix based on the chosen metric\n",
    "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
    "\n",
    "# Get k-nearest neighbors indices for each program\n",
    "k = 5  # Number of neighbors to consider\n",
    "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
    "\n",
    "# Initialize an array to store predicted labels\n",
    "predicted_labels = []\n",
    "\n",
    "# Predict labels for each program based on the majority label of neighbors\n",
    "for indices in knn_indices:\n",
    "    neighbor_labels = [program_labels[i] for i in indices]\n",
    "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert predicted_labels to NumPy array for further analysis\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# Apply k-nearest neighbor classification\n",
    "n_neighbors = 5  # Number of neighbors to consider\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and f-score\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# Print the classification results and performance metrics\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c016ba81-1606-41b7-9f4b-a166928ac068",
   "metadata": {},
   "outputs": [],
   "source": [
    "Abstract Factory with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4942a7f4-553d-4805-bef6-c744b1093841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: nondp (7).java, Predicted Label: 0, True Label: 0\n",
      "File: nondp (2).java, Predicted Label: 0, True Label: 0\n",
      "File: abstractfactory (2).java, Predicted Label: 1, True Label: 1\n",
      "File: nondp (33).java, Predicted Label: 0, True Label: 0\n",
      "File: nondp (39).java, Predicted Label: 1, True Label: 0\n",
      "File: nondp (45).java, Predicted Label: 1, True Label: 1\n",
      "File: nondp (19).java, Predicted Label: 0, True Label: 0\n",
      "File: nondp (26).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 0.90625, Recall: 0.875, F-score: 0.876984126984127\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'abstractfactory'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize the RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Function to extract embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Function to calculate the distance matrix based on the chosen metric\n",
    "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
    "    if metric == 'cosine':\n",
    "        return cosine_distances(embeddings)\n",
    "    elif metric == 'euclidean':\n",
    "        return euclidean_distances(embeddings)\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
    "\n",
    "# Switch between 'cosine' and 'euclidean'\n",
    "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
    "\n",
    "# Initialize lists to store Java programs and their corresponding labels\n",
    "java_programs = []\n",
    "program_labels = []\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_text = f.read()\n",
    "            java_programs.append(program_text)\n",
    "\n",
    "            # Check if the keyword \"singleton\" is present in the filename\n",
    "            if \"abstractfactory\" in program_file:\n",
    "                program_labels.append(1)  # Positive class (implements singleton)\n",
    "            else:\n",
    "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
    "\n",
    "# Calculate embeddings for the Java programs line by line and take the mean\n",
    "program_embeddings = []\n",
    "for program in java_programs:\n",
    "    lines = program.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Apply standard scaling to normalize the embeddings\n",
    "scaler = StandardScaler()\n",
    "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
    "\n",
    "# Calculate the distance matrix based on the chosen metric\n",
    "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
    "\n",
    "# Get k-nearest neighbors indices for each program\n",
    "k = 5  # Number of neighbors to consider\n",
    "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
    "\n",
    "# Initialize an array to store predicted labels\n",
    "predicted_labels = []\n",
    "\n",
    "# Predict labels for each program based on the majority label of neighbors\n",
    "for indices in knn_indices:\n",
    "    neighbor_labels = [program_labels[i] for i in indices]\n",
    "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert predicted_labels to NumPy array for further analysis\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# Apply k-nearest neighbor classification\n",
    "n_neighbors = 5  # Number of neighbors to consider\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and f-score\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# Print the classification results and performance metrics\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6d0d0f-ab86-4aa1-82d6-effde98580ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Abstract Factory with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "842e1325-240e-439d-ad34-86713bb50772",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: nondp (7).java, Predicted Label: 0, True Label: 0\n",
      "File: nondp (2).java, Predicted Label: 1, True Label: 1\n",
      "File: nondp (18).java, Predicted Label: 0, True Label: 1\n",
      "File: abstractfactory (2).java, Predicted Label: 0, True Label: 0\n",
      "File: nondp (33).java, Predicted Label: 1, True Label: 1\n",
      "File: nondp (29).java, Predicted Label: 0, True Label: 0\n",
      "File: nondp (31).java, Predicted Label: 1, True Label: 1\n",
      "File: nondp (11).java, Predicted Label: 0, True Label: 0\n",
      "File: nondp (39).java, Predicted Label: 0, True Label: 0\n",
      "File: nondp (45).java, Predicted Label: 0, True Label: 0\n",
      "File: nondp (19).java, Predicted Label: 1, True Label: 1\n",
      "File: nondp (23).java, Predicted Label: 0, True Label: 0\n",
      "File: nondp (38).java, Predicted Label: 0, True Label: 0\n",
      "File: nondp (30).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.9357142857142857, Recall: 0.9285714285714286, F-score: 0.926482873851295\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'abstractfactory'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize the RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Function to extract embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Function to calculate the distance matrix based on the chosen metric\n",
    "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
    "    if metric == 'cosine':\n",
    "        return cosine_distances(embeddings)\n",
    "    elif metric == 'euclidean':\n",
    "        return euclidean_distances(embeddings)\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
    "\n",
    "# Switch between 'cosine' and 'euclidean'\n",
    "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
    "\n",
    "# Initialize lists to store Java programs and their corresponding labels\n",
    "java_programs = []\n",
    "program_labels = []\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_text = f.read()\n",
    "            java_programs.append(program_text)\n",
    "\n",
    "            # Check if the keyword \"singleton\" is present in the filename\n",
    "            if \"abstractfactory\" in program_file:\n",
    "                program_labels.append(1)  # Positive class (implements singleton)\n",
    "            else:\n",
    "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
    "\n",
    "# Calculate embeddings for the Java programs line by line and take the mean\n",
    "program_embeddings = []\n",
    "for program in java_programs:\n",
    "    lines = program.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Apply standard scaling to normalize the embeddings\n",
    "scaler = StandardScaler()\n",
    "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
    "\n",
    "# Calculate the distance matrix based on the chosen metric\n",
    "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
    "\n",
    "# Get k-nearest neighbors indices for each program\n",
    "k = 5  # Number of neighbors to consider\n",
    "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
    "\n",
    "# Initialize an array to store predicted labels\n",
    "predicted_labels = []\n",
    "\n",
    "# Predict labels for each program based on the majority label of neighbors\n",
    "for indices in knn_indices:\n",
    "    neighbor_labels = [program_labels[i] for i in indices]\n",
    "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert predicted_labels to NumPy array for further analysis\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# Apply k-nearest neighbor classification\n",
    "n_neighbors = 5  # Number of neighbors to consider\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and f-score\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# Print the classification results and performance metrics\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f38ed5-850e-48d6-b8c9-cc4bf91c7174",
   "metadata": {},
   "outputs": [],
   "source": [
    "Factory Method with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "032c2bbe-cbc6-4fdf-81cc-1ea4d13ac177",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: nondp (33).java, Predicted Label: 1, True Label: 1\n",
      "File: nondp (5).java, Predicted Label: 1, True Label: 1\n",
      "File: nondp (4).java, Predicted Label: 1, True Label: 1\n",
      "File: nondp (1).java, Predicted Label: 0, True Label: 0\n",
      "File: nondp (15).java, Predicted Label: 0, True Label: 0\n",
      "File: nondp (34).java, Predicted Label: 1, True Label: 1\n",
      "File: factorymethod (1).java, Predicted Label: 0, True Label: 0\n",
      "File: factorymethod (9).java, Predicted Label: 0, True Label: 0\n",
      "File: nondp (26).java, Predicted Label: 0, True Label: 0\n",
      "File: nondp (8).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'factorymethod'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize the RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Function to extract embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Function to calculate the distance matrix based on the chosen metric\n",
    "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
    "    if metric == 'cosine':\n",
    "        return cosine_distances(embeddings)\n",
    "    elif metric == 'euclidean':\n",
    "        return euclidean_distances(embeddings)\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
    "\n",
    "# Switch between 'cosine' and 'euclidean'\n",
    "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
    "\n",
    "# Initialize lists to store Java programs and their corresponding labels\n",
    "java_programs = []\n",
    "program_labels = []\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_text = f.read()\n",
    "            java_programs.append(program_text)\n",
    "\n",
    "            # Check if the keyword \"singleton\" is present in the filename\n",
    "            if \"factorymethod\" in program_file:\n",
    "                program_labels.append(1)  # Positive class (implements singleton)\n",
    "            else:\n",
    "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
    "\n",
    "# Calculate embeddings for the Java programs line by line and take the mean\n",
    "program_embeddings = []\n",
    "for program in java_programs:\n",
    "    lines = program.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Apply standard scaling to normalize the embeddings\n",
    "scaler = StandardScaler()\n",
    "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
    "\n",
    "# Calculate the distance matrix based on the chosen metric\n",
    "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
    "\n",
    "# Get k-nearest neighbors indices for each program\n",
    "k = 5  # Number of neighbors to consider\n",
    "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
    "\n",
    "# Initialize an array to store predicted labels\n",
    "predicted_labels = []\n",
    "\n",
    "# Predict labels for each program based on the majority label of neighbors\n",
    "for indices in knn_indices:\n",
    "    neighbor_labels = [program_labels[i] for i in indices]\n",
    "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert predicted_labels to NumPy array for further analysis\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# Apply k-nearest neighbor classification\n",
    "n_neighbors = 5  # Number of neighbors to consider\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and f-score\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# Print the classification results and performance metrics\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f79379e-07c0-4a22-a940-5b7a3a4dde7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Factory Method with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb184d59-1b0a-4630-8357-ffcff1324769",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: nonfm (6).java, Predicted Label: 1, True Label: 0\n",
      "File: nonfm (5).java, Predicted Label: 0, True Label: 0\n",
      "File: nonfm (13).java, Predicted Label: 0, True Label: 0\n",
      "File: factorymethod (1).java, Predicted Label: 1, True Label: 0\n",
      "File: factorymethod (9).java, Predicted Label: 1, True Label: 0\n",
      "File: nonfm (4).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 0.875, Recall: 0.5, F-score: 0.5428571428571429\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'factorymethod'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize the RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Function to extract embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Function to calculate the distance matrix based on the chosen metric\n",
    "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
    "    if metric == 'cosine':\n",
    "        return cosine_distances(embeddings)\n",
    "    elif metric == 'euclidean':\n",
    "        return euclidean_distances(embeddings)\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
    "\n",
    "# Switch between 'cosine' and 'euclidean'\n",
    "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
    "\n",
    "# Initialize lists to store Java programs and their corresponding labels\n",
    "java_programs = []\n",
    "program_labels = []\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_text = f.read()\n",
    "            java_programs.append(program_text)\n",
    "\n",
    "            # Check if the keyword \"singleton\" is present in the filename\n",
    "            if \"factorymethod\" in program_file:\n",
    "                program_labels.append(1)  # Positive class (implements singleton)\n",
    "            else:\n",
    "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
    "\n",
    "# Calculate embeddings for the Java programs line by line and take the mean\n",
    "program_embeddings = []\n",
    "for program in java_programs:\n",
    "    lines = program.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Apply standard scaling to normalize the embeddings\n",
    "scaler = StandardScaler()\n",
    "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
    "\n",
    "# Calculate the distance matrix based on the chosen metric\n",
    "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
    "\n",
    "# Get k-nearest neighbors indices for each program\n",
    "k = 5  # Number of neighbors to consider\n",
    "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
    "\n",
    "# Initialize an array to store predicted labels\n",
    "predicted_labels = []\n",
    "\n",
    "# Predict labels for each program based on the majority label of neighbors\n",
    "for indices in knn_indices:\n",
    "    neighbor_labels = [program_labels[i] for i in indices]\n",
    "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert predicted_labels to NumPy array for further analysis\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# Apply k-nearest neighbor classification\n",
    "n_neighbors = 5  # Number of neighbors to consider\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and f-score\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# Print the classification results and performance metrics\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e10a505-bf93-4d4c-b565-d14766aef2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Factory Method with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ab54f55-5dd7-42ea-a8cf-ffb1c98b10bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: nonfm (38).java, Predicted Label: 0, True Label: 0\n",
      "File: nonfm (52).java, Predicted Label: 1, True Label: 1\n",
      "File: nonfm (68).java, Predicted Label: 1, True Label: 1\n",
      "File: nonfm (37).java, Predicted Label: 1, True Label: 0\n",
      "File: nonfm (29).java, Predicted Label: 1, True Label: 1\n",
      "File: factorymethod (1).java, Predicted Label: 1, True Label: 1\n",
      "File: factorymethod (9).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 0.880952380952381, Recall: 0.8571428571428571, F-score: 0.8398268398268397\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'factorymethod'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize the RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Function to extract embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Function to calculate the distance matrix based on the chosen metric\n",
    "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
    "    if metric == 'cosine':\n",
    "        return cosine_distances(embeddings)\n",
    "    elif metric == 'euclidean':\n",
    "        return euclidean_distances(embeddings)\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
    "\n",
    "# Switch between 'cosine' and 'euclidean'\n",
    "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
    "\n",
    "# Initialize lists to store Java programs and their corresponding labels\n",
    "java_programs = []\n",
    "program_labels = []\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_text = f.read()\n",
    "            java_programs.append(program_text)\n",
    "\n",
    "            # Check if the keyword \"singleton\" is present in the filename\n",
    "            if \"factorymethod\" in program_file:\n",
    "                program_labels.append(1)  # Positive class (implements singleton)\n",
    "            else:\n",
    "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
    "\n",
    "# Calculate embeddings for the Java programs line by line and take the mean\n",
    "program_embeddings = []\n",
    "for program in java_programs:\n",
    "    lines = program.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Apply standard scaling to normalize the embeddings\n",
    "scaler = StandardScaler()\n",
    "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
    "\n",
    "# Calculate the distance matrix based on the chosen metric\n",
    "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
    "\n",
    "# Get k-nearest neighbors indices for each program\n",
    "k = 5  # Number of neighbors to consider\n",
    "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
    "\n",
    "# Initialize an array to store predicted labels\n",
    "predicted_labels = []\n",
    "\n",
    "# Predict labels for each program based on the majority label of neighbors\n",
    "for indices in knn_indices:\n",
    "    neighbor_labels = [program_labels[i] for i in indices]\n",
    "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert predicted_labels to NumPy array for further analysis\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# Apply k-nearest neighbor classification\n",
    "n_neighbors = 5  # Number of neighbors to consider\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and f-score\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# Print the classification results and performance metrics\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af7df81-0820-4111-8d37-227205b88c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prototype with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84e6ae3f-14f8-4e0e-b484-cf7a89951b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: prototype (27).java, Predicted Label: 1, True Label: 1\n",
      "File: nonp (23).java, Predicted Label: 0, True Label: 1\n",
      "File: nonp (5).java, Predicted Label: 0, True Label: 0\n",
      "File: prototype (13).java, Predicted Label: 0, True Label: 0\n",
      "File: prototype (22).java, Predicted Label: 0, True Label: 1\n",
      "File: nonp (7).java, Predicted Label: 1, True Label: 1\n",
      "File: nonp (13).java, Predicted Label: 0, True Label: 0\n",
      "File: nonp (29).java, Predicted Label: 0, True Label: 0\n",
      "File: prototype (15).java, Predicted Label: 1, True Label: 1\n",
      "File: nonp (44).java, Predicted Label: 0, True Label: 0\n",
      "File: nonp (58).java, Predicted Label: 1, True Label: 1\n",
      "File: prototype (14).java, Predicted Label: 1, True Label: 1\n",
      "File: prototype (16).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.8846153846153846, Recall: 0.8461538461538461, F-score: 0.8443223443223442\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'prototype'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize the RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Function to extract embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Function to calculate the distance matrix based on the chosen metric\n",
    "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
    "    if metric == 'cosine':\n",
    "        return cosine_distances(embeddings)\n",
    "    elif metric == 'euclidean':\n",
    "        return euclidean_distances(embeddings)\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
    "\n",
    "# Switch between 'cosine' and 'euclidean'\n",
    "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
    "\n",
    "# Initialize lists to store Java programs and their corresponding labels\n",
    "java_programs = []\n",
    "program_labels = []\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_text = f.read()\n",
    "            java_programs.append(program_text)\n",
    "\n",
    "            # Check if the keyword \"singleton\" is present in the filename\n",
    "            if \"prototype\" in program_file:\n",
    "                program_labels.append(1)  # Positive class (implements singleton)\n",
    "            else:\n",
    "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
    "\n",
    "# Calculate embeddings for the Java programs line by line and take the mean\n",
    "program_embeddings = []\n",
    "for program in java_programs:\n",
    "    lines = program.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Apply standard scaling to normalize the embeddings\n",
    "scaler = StandardScaler()\n",
    "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
    "\n",
    "# Calculate the distance matrix based on the chosen metric\n",
    "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
    "\n",
    "# Get k-nearest neighbors indices for each program\n",
    "k = 5  # Number of neighbors to consider\n",
    "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
    "\n",
    "# Initialize an array to store predicted labels\n",
    "predicted_labels = []\n",
    "\n",
    "# Predict labels for each program based on the majority label of neighbors\n",
    "for indices in knn_indices:\n",
    "    neighbor_labels = [program_labels[i] for i in indices]\n",
    "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert predicted_labels to NumPy array for further analysis\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# Apply k-nearest neighbor classification\n",
    "n_neighbors = 5  # Number of neighbors to consider\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and f-score\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# Print the classification results and performance metrics\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c663fbf6-cc93-43d0-953d-7f1b2265afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prototype with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e782893-0f0c-4609-a2d3-f5b6e0bcd25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: prototype (27).java, Predicted Label: 0, True Label: 0\n",
      "File: nonp (53).java, Predicted Label: 0, True Label: 1\n",
      "File: nonp (23).java, Predicted Label: 1, True Label: 1\n",
      "File: nonp (43).java, Predicted Label: 0, True Label: 0\n",
      "File: nonp (35).java, Predicted Label: 0, True Label: 0\n",
      "File: nonp (51).java, Predicted Label: 0, True Label: 0\n",
      "File: nonp (59).java, Predicted Label: 0, True Label: 0\n",
      "File: nonp (5).java, Predicted Label: 0, True Label: 0\n",
      "File: nonp (31).java, Predicted Label: 0, True Label: 0\n",
      "File: prototype (13).java, Predicted Label: 0, True Label: 0\n",
      "File: prototype (22).java, Predicted Label: 0, True Label: 1\n",
      "File: nonp (7).java, Predicted Label: 0, True Label: 0\n",
      "File: nonp (13).java, Predicted Label: 1, True Label: 1\n",
      "File: nonp (29).java, Predicted Label: 1, True Label: 1\n",
      "File: prototype (15).java, Predicted Label: 0, True Label: 0\n",
      "File: nonp (44).java, Predicted Label: 0, True Label: 0\n",
      "File: nonp (8).java, Predicted Label: 0, True Label: 0\n",
      "File: nonp (37).java, Predicted Label: 0, True Label: 0\n",
      "File: nonp (21).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 0.9087719298245613, Recall: 0.8947368421052632, F-score: 0.8879699248120302\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'prototype'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize the RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Function to extract embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Function to calculate the distance matrix based on the chosen metric\n",
    "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
    "    if metric == 'cosine':\n",
    "        return cosine_distances(embeddings)\n",
    "    elif metric == 'euclidean':\n",
    "        return euclidean_distances(embeddings)\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
    "\n",
    "# Switch between 'cosine' and 'euclidean'\n",
    "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
    "\n",
    "# Initialize lists to store Java programs and their corresponding labels\n",
    "java_programs = []\n",
    "program_labels = []\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_text = f.read()\n",
    "            java_programs.append(program_text)\n",
    "\n",
    "            # Check if the keyword \"singleton\" is present in the filename\n",
    "            if \"prototype\" in program_file:\n",
    "                program_labels.append(1)  # Positive class (implements singleton)\n",
    "            else:\n",
    "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
    "\n",
    "# Calculate embeddings for the Java programs line by line and take the mean\n",
    "program_embeddings = []\n",
    "for program in java_programs:\n",
    "    lines = program.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Apply standard scaling to normalize the embeddings\n",
    "scaler = StandardScaler()\n",
    "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
    "\n",
    "# Calculate the distance matrix based on the chosen metric\n",
    "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
    "\n",
    "# Get k-nearest neighbors indices for each program\n",
    "k = 5  # Number of neighbors to consider\n",
    "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
    "\n",
    "# Initialize an array to store predicted labels\n",
    "predicted_labels = []\n",
    "\n",
    "# Predict labels for each program based on the majority label of neighbors\n",
    "for indices in knn_indices:\n",
    "    neighbor_labels = [program_labels[i] for i in indices]\n",
    "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert predicted_labels to NumPy array for further analysis\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# Apply k-nearest neighbor classification\n",
    "n_neighbors = 5  # Number of neighbors to consider\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and f-score\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# Print the classification results and performance metrics\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511f0d9f-88ea-4f50-92ae-901fd7bdfea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prototype with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeb6eed-6f74-42ef-9576-c3640da21daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'prototype'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize the RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Function to extract embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Function to calculate the distance matrix based on the chosen metric\n",
    "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
    "    if metric == 'cosine':\n",
    "        return cosine_distances(embeddings)\n",
    "    elif metric == 'euclidean':\n",
    "        return euclidean_distances(embeddings)\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
    "\n",
    "# Switch between 'cosine' and 'euclidean'\n",
    "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
    "\n",
    "# Initialize lists to store Java programs and their corresponding labels\n",
    "java_programs = []\n",
    "program_labels = []\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_text = f.read()\n",
    "            java_programs.append(program_text)\n",
    "\n",
    "            # Check if the keyword \"singleton\" is present in the filename\n",
    "            if \"prototype\" in program_file:\n",
    "                program_labels.append(1)  # Positive class (implements singleton)\n",
    "            else:\n",
    "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
    "\n",
    "# Calculate embeddings for the Java programs line by line and take the mean\n",
    "program_embeddings = []\n",
    "for program in java_programs:\n",
    "    lines = program.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Apply standard scaling to normalize the embeddings\n",
    "scaler = StandardScaler()\n",
    "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
    "\n",
    "# Calculate the distance matrix based on the chosen metric\n",
    "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
    "\n",
    "# Get k-nearest neighbors indices for each program\n",
    "k = 5  # Number of neighbors to consider\n",
    "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
    "\n",
    "# Initialize an array to store predicted labels\n",
    "predicted_labels = []\n",
    "\n",
    "# Predict labels for each program based on the majority label of neighbors\n",
    "for indices in knn_indices:\n",
    "    neighbor_labels = [program_labels[i] for i in indices]\n",
    "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert predicted_labels to NumPy array for further analysis\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# Apply k-nearest neighbor classification\n",
    "n_neighbors = 5  # Number of neighbors to consider\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and f-score\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# Print the classification results and performance metrics\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a181ed9-013f-4038-ad3a-2d8c201d9422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Function to get embeddings for a given design pattern\n",
    "def get_embeddings_for_pattern(pattern, model, tokenizer):\n",
    "    directory = os.path.join(\"all_design_patterns\", pattern.lower())\n",
    "    files = [file for file in os.listdir(directory) if os.path.isfile(os.path.join(directory, file))]\n",
    "\n",
    "    embeddings = []\n",
    "    true_labels = []\n",
    "\n",
    "    for file in files:\n",
    "        with open(os.path.join(directory, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
    "            code = f.read()\n",
    "\n",
    "        # Tokenize and encode the Java program\n",
    "        inputs = tokenizer(code, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        program_embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "        embeddings.append(program_embedding)\n",
    "        true_labels.append(pattern)\n",
    "\n",
    "    return np.array(embeddings), np.array(true_labels)\n",
    "\n",
    "# Load the RoBERTa model and tokenizer\n",
    "model_name = \"microsoft/codebert-base\"  # Replace with the correct RoBERTa model name\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Get embeddings for each design pattern\n",
    "patterns = [\"Singleton\", \"Prototype\", \"AbstractFactory\", \"Builder\", \"FactoryMethod\"]\n",
    "all_embeddings = []\n",
    "all_labels = []\n",
    "\n",
    "# Custom color palette for each design pattern with higher contrast\n",
    "color_palette = [\"red\", \"green\", \"orange\", \"blue\", \"purple\"]\n",
    "\n",
    "# Custom markers for each design pattern\n",
    "markers = [\"o\", \"s\", \"D\", \"^\", \"P\"]\n",
    "\n",
    "for i, pattern in enumerate(patterns):\n",
    "    pattern_embeddings, pattern_labels = get_embeddings_for_pattern(pattern, model, tokenizer)\n",
    "    all_embeddings.append(pattern_embeddings)\n",
    "    all_labels.append(pattern_labels)\n",
    "\n",
    "# Concatenate the embeddings and labels\n",
    "all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "\n",
    "# Perform t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_results = tsne.fit_transform(all_embeddings)\n",
    "\n",
    "# Create a scatter plot for t-SNE visualization with custom symbols\n",
    "plt.figure(figsize=(20, 16))\n",
    "\n",
    "for i, pattern in enumerate(patterns):\n",
    "    indices = all_labels == pattern\n",
    "    sns.scatterplot(x=tsne_results[indices, 0], y=tsne_results[indices, 1], marker=markers[i], color=color_palette[i], s=200, label=pattern)\n",
    "\n",
    "# Increase font sizes for better visibility\n",
    "plt.title('t-SNE Visualization for RoBERTa on Different Design Patterns', fontsize=30)\n",
    "plt.xlabel('t-SNE Dimension 1', fontsize=25)\n",
    "plt.ylabel('t-SNE Dimension 2', fontsize=25)\n",
    "plt.legend(title='Design Pattern', loc='upper right', fontsize=22)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the t-SNE plot as a PDF file\n",
    "plt.savefig('tsne_plot_roberta.pdf', format='pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a3e7fb-9651-4405-8dd0-bbf03a44dc48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd3e2b8d-48b1-4873-a998-f38ce55a6d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Singleton with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9e5b476-be5d-4b0a-b978-a15fab02afd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: nons (12).java, Predicted Label: 1, True Label: 0\n",
      "File: nons (50).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (25).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (27).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (19).java, Predicted Label: 1, True Label: 0\n",
      "File: singleton (24).java, Predicted Label: 1, True Label: 0\n",
      "File: nons (4).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (44).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (38).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 0.5289256198347108, Recall: 0.7272727272727273, F-score: 0.6124401913875599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephyr/users/sushantk/Alvis/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
    "\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize the RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Function to extract embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Function to calculate the distance matrix based on the chosen metric\n",
    "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
    "    if metric == 'cosine':\n",
    "        return cosine_distances(embeddings)\n",
    "    elif metric == 'euclidean':\n",
    "        return euclidean_distances(embeddings)\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
    "\n",
    "# Switch between 'cosine' and 'euclidean'\n",
    "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
    "\n",
    "# Initialize lists to store Java programs and their corresponding labels\n",
    "java_programs = []\n",
    "program_labels = []\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_text = f.read()\n",
    "            java_programs.append(program_text)\n",
    "\n",
    "            # Check if the keyword \"singleton\" is present in the filename\n",
    "            if \"singleton\" in program_file:\n",
    "                program_labels.append(1)  # Positive class (implements singleton)\n",
    "            else:\n",
    "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
    "\n",
    "# Calculate embeddings for the Java programs line by line and take the mean\n",
    "program_embeddings = []\n",
    "for program in java_programs:\n",
    "    lines = program.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Apply standard scaling to normalize the embeddings\n",
    "scaler = StandardScaler()\n",
    "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
    "\n",
    "# Calculate the distance matrix based on the chosen metric\n",
    "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
    "\n",
    "# Get k-nearest neighbors indices for each program\n",
    "k = 5  # Number of neighbors to consider\n",
    "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
    "\n",
    "# Initialize an array to store predicted labels\n",
    "predicted_labels = []\n",
    "\n",
    "# Predict labels for each program based on the majority label of neighbors\n",
    "for indices in knn_indices:\n",
    "    neighbor_labels = [program_labels[i] for i in indices]\n",
    "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert predicted_labels to NumPy array for further analysis\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# Apply k-nearest neighbor classification\n",
    "n_neighbors = 3  # Number of neighbors to consider\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and f-score\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# Print the classification results and performance metrics\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4807a0b1-24f5-4205-8cb6-55964e16cc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Singleton with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f35a9f3-1537-4352-bf66-9df8de09a0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: nons (12).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (50).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (25).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (27).java, Predicted Label: 1, True Label: 0\n",
      "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (19).java, Predicted Label: 0, True Label: 1\n",
      "File: singleton (24).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (4).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (44).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (38).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 0.7467532467532467, Recall: 0.6363636363636364, F-score: 0.6742424242424243\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize the RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Function to extract embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Function to label programs as positive (1) or negative (0) based on the file name\n",
    "def label_program(file_name):\n",
    "    if \"singleton\" in file_name:\n",
    "        return 1  # Positive class (implements singleton)\n",
    "    else:\n",
    "        return 0  # Negative class (does not implement singleton)\n",
    "\n",
    "# Initialize lists to store Java programs and their corresponding labels\n",
    "java_programs = []\n",
    "program_labels = []\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_text = f.read()\n",
    "            java_programs.append(program_text)\n",
    "\n",
    "            # Label the program using the provided function\n",
    "            program_labels.append(label_program(program_file))\n",
    "\n",
    "# Calculate embeddings for the Java programs line by line and take the mean\n",
    "program_embeddings = []\n",
    "for program in java_programs:\n",
    "    lines = program.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Apply standard scaling to normalize the embeddings\n",
    "scaler = StandardScaler()\n",
    "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, program_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "# Apply k-nearest neighbor classification\n",
    "n_neighbors = 3  # Number of neighbors to consider\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and f-score\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# Print the classification results and performance metrics\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2041ca8b-57df-4cd0-9a97-3e3d6f79ba86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and contents saved to singleton/sin.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize lists to store program names, labels, and contents\n",
    "program_names = []\n",
    "labels = []\n",
    "contents = []\n",
    "\n",
    "# Function to label programs as positive (1) or negative (0) based on the file name\n",
    "def label_program(file_name):\n",
    "    return 1 if \"singleton\" in file_name.lower() else 0\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_content = f.read()\n",
    "            program_names.append(program_file)\n",
    "            labels.append(label_program(program_file))\n",
    "            contents.append(program_content)\n",
    "\n",
    "# Create a DataFrame to store the data\n",
    "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_path = 'singleton/sin.csv'  # Replace with the desired CSV file path\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Labels and contents saved to {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc24e9e4-ba0c-4f9a-b9f1-4c1ad863cf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 54/54 [06:34<00:00,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: nons (12).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (50).java, Predicted Label: 0, True Label: 1\n",
      "File: singleton (25).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (27).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (19).java, Predicted Label: 0, True Label: 1\n",
      "File: singleton (24).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (4).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (44).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (38).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 0.890909090909091, Recall: 0.7272727272727273, F-score: 0.7584415584415585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the path to the CSV file containing program names, labels, and content\n",
    "csv_path = 'singleton/sin.csv'  # Replace with the actual CSV file path\n",
    "\n",
    "# Initialize RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Load the DataFrame from the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Function to calculate embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Calculate embeddings for each program by considering embeddings of individual lines\n",
    "program_embeddings = []\n",
    "for content in tqdm(df['Content']):\n",
    "    lines = content.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Convert program_embeddings to NumPy array\n",
    "program_embeddings = np.vstack(program_embeddings)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(program_embeddings, df['Label'], test_size=0.2, random_state=0)\n",
    "\n",
    "# Apply k-nearest neighbor classification\n",
    "n_neighbors = 3  # Number of neighbors to consider\n",
    "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and f-score\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# Print the classification results and performance metrics\n",
    "for i in range(len(X_test)):\n",
    "    print(f\"File: {df['File Name'].iloc[i]}, Predicted Label: {predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
    "\n",
    "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dae1008-36fd-49f8-a1ab-506025c896e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8e844af-2aae-4820-bc9d-6d2c99879b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 54/54 [06:37<00:00,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Precision: 0.9242424242424243, Recall: 0.9090909090909091, F-score: 0.9090909090909091\n",
      "Fold 2: Precision: 0.7393939393939394, Recall: 0.7272727272727273, F-score: 0.7272727272727272\n",
      "Fold 3: Precision: 0.8701298701298701, Recall: 0.8181818181818182, F-score: 0.8151515151515152\n",
      "Fold 4: Precision: 0.5303030303030304, Recall: 0.5454545454545454, F-score: 0.4935064935064935\n",
      "Fold 5: Precision: 0.8571428571428571, Recall: 0.8, F-score: 0.7916666666666666\n",
      "Overall Precision: 0.7589506172839506, Recall: 0.7592592592592593, F-score: 0.7588428968574248\n",
      "Fold 1, File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
      "Fold 1, File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "Fold 1, File: nons (44).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1, File: nons (38).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1, File: nons (33).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1, File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
      "Fold 1, File: nons (21).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1, File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
      "Fold 1, File: nons (9).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1, File: singleton (7).java, Predicted Label: 1, True Label: 1\n",
      "Fold 2, File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
      "Fold 2, File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "Fold 2, File: nons (44).java, Predicted Label: 0, True Label: 0\n",
      "Fold 2, File: nons (38).java, Predicted Label: 0, True Label: 0\n",
      "Fold 2, File: nons (33).java, Predicted Label: 0, True Label: 0\n",
      "Fold 2, File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
      "Fold 2, File: nons (21).java, Predicted Label: 0, True Label: 0\n",
      "Fold 2, File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
      "Fold 2, File: nons (9).java, Predicted Label: 0, True Label: 0\n",
      "Fold 2, File: singleton (7).java, Predicted Label: 1, True Label: 1\n",
      "Fold 3, File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
      "Fold 3, File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "Fold 3, File: nons (44).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3, File: nons (38).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3, File: nons (33).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3, File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
      "Fold 3, File: nons (21).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3, File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
      "Fold 3, File: nons (9).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3, File: singleton (7).java, Predicted Label: 1, True Label: 1\n",
      "Fold 4, File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
      "Fold 4, File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "Fold 4, File: nons (44).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4, File: nons (38).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4, File: nons (33).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4, File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
      "Fold 4, File: nons (21).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4, File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
      "Fold 4, File: nons (9).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4, File: singleton (7).java, Predicted Label: 1, True Label: 1\n",
      "Fold 5, File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
      "Fold 5, File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "Fold 5, File: nons (44).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5, File: nons (38).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5, File: nons (33).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5, File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
      "Fold 5, File: nons (21).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5, File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
      "Fold 5, File: nons (9).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5, File: singleton (7).java, Predicted Label: 1, True Label: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the path to the CSV file containing program names, labels, and content\n",
    "csv_path = 'singleton/sin.csv'  # Replace with the actual CSV file path\n",
    "\n",
    "# Initialize RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Load the DataFrame from the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Function to calculate embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Calculate embeddings for each program by considering embeddings of individual lines\n",
    "program_embeddings = []\n",
    "for content in tqdm(df['Content']):\n",
    "    lines = content.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Convert program_embeddings to NumPy array\n",
    "program_embeddings = np.vstack(program_embeddings)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "\n",
    "# Initialize an array to store predicted labels for each program in every fold\n",
    "all_fold_predictions = np.zeros_like(df['Label'])\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
    "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
    "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
    "\n",
    "    # Apply k-nearest neighbor classification\n",
    "    n_neighbors = 3  # Number of neighbors to consider\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "    fold_predictions = knn.predict(X_test)\n",
    "\n",
    "    # Store fold predictions in the array\n",
    "    all_fold_predictions[test_index] = fold_predictions\n",
    "\n",
    "    # Calculate precision, recall, and f-score for the current fold\n",
    "    precision = precision_score(y_test, fold_predictions, average='weighted')\n",
    "    recall = recall_score(y_test, fold_predictions, average='weighted')\n",
    "    f1 = f1_score(y_test, fold_predictions, average='weighted')\n",
    "\n",
    "    print(f\"Fold {fold + 1}: Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
    "\n",
    "# Calculate overall precision, recall, and f-score\n",
    "precision = precision_score(df['Label'], all_fold_predictions, average='weighted')\n",
    "recall = recall_score(df['Label'], all_fold_predictions, average='weighted')\n",
    "f1 = f1_score(df['Label'], all_fold_predictions, average='weighted')\n",
    "\n",
    "print(f\"Overall Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
    "\n",
    "# Print the classification results for each program in every fold\n",
    "for fold in range(n_splits):\n",
    "    fold_predictions = all_fold_predictions[test_index]\n",
    "    true_labels = df['Label'][test_index]\n",
    "\n",
    "    for i in range(len(fold_predictions)):\n",
    "        print(f\"Fold {fold + 1}, File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {fold_predictions[i]}, True Label: {true_labels.iloc[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "894036dd-177d-4936-9efe-1eeb05084cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 54/54 [06:39<00:00,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Precision: 0.9242424242424243, Recall: 0.9090909090909091, F-score: 0.9090909090909091\n",
      "Fold 2: Precision: 0.7393939393939394, Recall: 0.7272727272727273, F-score: 0.7272727272727272\n",
      "Fold 3: Precision: 0.8701298701298701, Recall: 0.8181818181818182, F-score: 0.8151515151515152\n",
      "Fold 4: Precision: 0.5303030303030304, Recall: 0.5454545454545454, F-score: 0.4935064935064935\n",
      "Fold 5: Precision: 0.8571428571428571, Recall: 0.8, F-score: 0.7916666666666666\n",
      "Overall Precision: 0.7589506172839506, Recall: 0.7592592592592593, F-score: 0.7588428968574248\n",
      "Fold 1, File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
      "Fold 1, File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "Fold 1, File: nons (44).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1, File: nons (38).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1, File: nons (33).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1, File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
      "Fold 1, File: nons (21).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1, File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
      "Fold 1, File: nons (9).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1, File: singleton (7).java, Predicted Label: 1, True Label: 1\n",
      "Fold 2, File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
      "Fold 2, File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "Fold 2, File: nons (44).java, Predicted Label: 0, True Label: 0\n",
      "Fold 2, File: nons (38).java, Predicted Label: 0, True Label: 0\n",
      "Fold 2, File: nons (33).java, Predicted Label: 0, True Label: 0\n",
      "Fold 2, File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
      "Fold 2, File: nons (21).java, Predicted Label: 0, True Label: 0\n",
      "Fold 2, File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
      "Fold 2, File: nons (9).java, Predicted Label: 0, True Label: 0\n",
      "Fold 2, File: singleton (7).java, Predicted Label: 1, True Label: 1\n",
      "Fold 3, File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
      "Fold 3, File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "Fold 3, File: nons (44).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3, File: nons (38).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3, File: nons (33).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3, File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
      "Fold 3, File: nons (21).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3, File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
      "Fold 3, File: nons (9).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3, File: singleton (7).java, Predicted Label: 1, True Label: 1\n",
      "Fold 4, File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
      "Fold 4, File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "Fold 4, File: nons (44).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4, File: nons (38).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4, File: nons (33).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4, File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
      "Fold 4, File: nons (21).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4, File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
      "Fold 4, File: nons (9).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4, File: singleton (7).java, Predicted Label: 1, True Label: 1\n",
      "Fold 5, File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
      "Fold 5, File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "Fold 5, File: nons (44).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5, File: nons (38).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5, File: nons (33).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5, File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
      "Fold 5, File: nons (21).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5, File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
      "Fold 5, File: nons (9).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5, File: singleton (7).java, Predicted Label: 1, True Label: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the path to the CSV file containing program names, labels, and content\n",
    "csv_path = 'singleton/sin.csv'  # Replace with the actual CSV file path\n",
    "\n",
    "# Initialize RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Load the DataFrame from the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Function to calculate embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Calculate embeddings for each program by considering embeddings of individual lines\n",
    "program_embeddings = []\n",
    "for content in tqdm(df['Content']):\n",
    "    lines = content.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Convert program_embeddings to NumPy array\n",
    "program_embeddings = np.vstack(program_embeddings)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "\n",
    "# Initialize an array to store predicted labels for each program in every fold\n",
    "all_fold_predictions = np.zeros_like(df['Label'])\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
    "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
    "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
    "\n",
    "    # Apply k-nearest neighbor classification\n",
    "    n_neighbors = 3  # Number of neighbors to consider\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "    fold_predictions = knn.predict(X_test)\n",
    "\n",
    "    # Store fold predictions in the array\n",
    "    all_fold_predictions[test_index] = fold_predictions\n",
    "\n",
    "    # Calculate precision, recall, and f-score for the current fold\n",
    "    precision = precision_score(y_test, fold_predictions, average='weighted')\n",
    "    recall = recall_score(y_test, fold_predictions, average='weighted')\n",
    "    f1 = f1_score(y_test, fold_predictions, average='weighted')\n",
    "\n",
    "    print(f\"Fold {fold + 1}: Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
    "\n",
    "# Calculate overall precision, recall, and f-score\n",
    "precision = precision_score(df['Label'], all_fold_predictions, average='weighted')\n",
    "recall = recall_score(df['Label'], all_fold_predictions, average='weighted')\n",
    "f1 = f1_score(df['Label'], all_fold_predictions, average='weighted')\n",
    "\n",
    "print(f\"Overall Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
    "\n",
    "# Print the classification results for each program in every fold\n",
    "for fold in range(n_splits):\n",
    "    fold_predictions = all_fold_predictions[test_index]\n",
    "    true_labels = df['Label'][test_index]\n",
    "\n",
    "    for i in range(len(fold_predictions)):\n",
    "        print(f\"Fold {fold + 1}, File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {fold_predictions[i]}, True Label: {true_labels.iloc[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a85509c5-41ad-4370-9fbd-43753e8d37d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#singleton with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "260b4089-249f-430c-85de-56240cc93015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and contents saved to embeddings/sin1.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize lists to store program names, labels, and contents\n",
    "program_names = []\n",
    "labels = []\n",
    "contents = []\n",
    "\n",
    "# Function to label programs as positive (1) or negative (0) based on the file name\n",
    "def label_program(file_name):\n",
    "    return 1 if \"singleton\" in file_name.lower() else 0\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_content = f.read()\n",
    "            program_names.append(program_file)\n",
    "            labels.append(label_program(program_file))\n",
    "            contents.append(program_content)\n",
    "\n",
    "# Create a DataFrame to store the data\n",
    "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_path = 'embeddings/sin1.csv'  # Replace with the desired CSV file path\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Labels and contents saved to {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "094f939c-f71a-4bb4-a7a0-6522fcd19ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 52/52 [10:05<00:00, 11.65s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (Train), File: nons (29).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1 (Train), File: nons (25).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1 (Train), File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
      "Fold 1 (Train), File: nons (42).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1 (Train), File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
      "Fold 1 (Train), File: nons (34).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1 (Train), File: nons (49).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1 (Train), File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "Fold 1 (Train), File: nons (44).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1 (Train), File: nons (38).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1 (Train), File: singleton (14).java, Predicted Label: 0, True Label: 1\n",
      "Fold 1 (Train), File: nons (33).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1 (Train), File: nons (41).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1 (Train), File: singleton (1).java, Predicted Label: 1, True Label: 1\n",
      "Fold 1 (Train), File: sin.csv, Predicted Label: 0, True Label: 0\n",
      "Fold 1 (Train), File: singleton (3).java, Predicted Label: 0, True Label: 1\n",
      "Fold 1 (Train), File: singleton (23).java, Predicted Label: 1, True Label: 1\n",
      "Fold 1 (Train), File: nons (35).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1 (Train), File: nons (43).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1 (Train), File: singleton (16).java, Predicted Label: 1, True Label: 1\n",
      "Fold 1 (Train), File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
      "Fold 1 (Train), File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
      "Fold 1 (Train), File: nons (48).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1 (Train), File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
      "Fold 1 (Train), File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
      "Fold 1 (Train), File: nons (26).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1 (Train), File: singleton (12).java, Predicted Label: 1, True Label: 1\n",
      "Fold 1 (Train), File: nons (31).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1 (Train), File: nons (37).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1 (Train), File: singleton (22).java, Predicted Label: 1, True Label: 1\n",
      "Fold 1 (Train), File: nons (47).java, Predicted Label: 1, True Label: 0\n",
      "Fold 1 (Train), File: singleton (4).java, Predicted Label: 0, True Label: 1\n",
      "Fold 1 (Train), File: nons (32).java, Predicted Label: 1, True Label: 0\n",
      "Fold 1 (Train), File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
      "Fold 1 (Train), File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
      "Fold 1 (Train), File: singleton (7).java, Predicted Label: 1, True Label: 1\n",
      "Fold 1 (Train), File: nons (45).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1 (Train), File: singleton (19).java, Predicted Label: 1, True Label: 1\n",
      "Fold 1 (Train), File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
      "Fold 1 (Train), File: nons (28).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1 (Train), File: nons (36).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1 (Test), File: nons (50).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1 (Test), File: nons (27).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1 (Test), File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
      "Fold 1 (Test), File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
      "Fold 1 (Test), File: nons (30).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1 (Test), File: nons (40).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1 (Test), File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
      "Fold 1 (Test), File: singleton (6).java, Predicted Label: 0, True Label: 1\n",
      "Fold 1 (Test), File: singleton (21).java, Predicted Label: 0, True Label: 1\n",
      "Fold 1 (Test), File: nons (46).java, Predicted Label: 1, True Label: 0\n",
      "Fold 1 (Test), File: nons (39).java, Predicted Label: 0, True Label: 0\n",
      "Fold 1: Precision: 0.7305194805194805, Recall: 0.7272727272727273, F-score: 0.7226107226107225\n",
      "Fold 2 (Train), File: nons (50).java, Predicted Label: 1, True Label: 0\n",
      "Fold 2 (Train), File: nons (29).java, Predicted Label: 0, True Label: 0\n",
      "Fold 2 (Train), File: nons (25).java, Predicted Label: 0, True Label: 0\n",
      "Fold 2 (Train), File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
      "Fold 2 (Train), File: nons (42).java, Predicted Label: 1, True Label: 0\n",
      "Fold 2 (Train), File: nons (27).java, Predicted Label: 0, True Label: 0\n",
      "Fold 2 (Train), File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
      "Fold 2 (Train), File: nons (49).java, Predicted Label: 0, True Label: 0\n",
      "Fold 2 (Train), File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "Fold 2 (Train), File: nons (44).java, Predicted Label: 0, True Label: 0\n",
      "Fold 2 (Train), File: nons (38).java, Predicted Label: 0, True Label: 0\n",
      "Fold 2 (Train), File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
      "Fold 2 (Train), File: nons (33).java, Predicted Label: 0, True Label: 0\n",
      "Fold 2 (Train), File: nons (41).java, Predicted Label: 0, True Label: 0\n",
      "Fold 2 (Train), File: nons (30).java, Predicted Label: 0, True Label: 0\n",
      "Fold 2 (Train), File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
      "Fold 2 (Train), File: singleton (3).java, Predicted Label: 0, True Label: 1\n",
      "Fold 2 (Train), File: singleton (23).java, Predicted Label: 0, True Label: 1\n",
      "Fold 2 (Train), File: nons (35).java, Predicted Label: 0, True Label: 0\n",
      "Fold 2 (Train), File: nons (43).java, Predicted Label: 0, True Label: 0\n",
      "Fold 2 (Train), File: singleton (16).java, Predicted Label: 1, True Label: 1\n",
      "Fold 2 (Train), File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
      "Fold 2 (Train), File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
      "Fold 2 (Train), File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
      "Fold 2 (Train), File: nons (40).java, Predicted Label: 0, True Label: 0\n",
      "Fold 2 (Train), File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
      "Fold 2 (Train), File: nons (31).java, Predicted Label: 0, True Label: 0\n",
      "Fold 2 (Train), File: singleton (6).java, Predicted Label: 0, True Label: 1\n",
      "Fold 2 (Train), File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
      "Fold 2 (Train), File: singleton (22).java, Predicted Label: 1, True Label: 1\n",
      "Fold 2 (Train), File: singleton (4).java, Predicted Label: 0, True Label: 1\n",
      "Fold 2 (Train), File: nons (32).java, Predicted Label: 1, True Label: 0\n",
      "Fold 2 (Train), File: nons (46).java, Predicted Label: 0, True Label: 0\n",
      "Fold 2 (Train), File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
      "Fold 2 (Train), File: nons (39).java, Predicted Label: 0, True Label: 0\n",
      "Fold 2 (Train), File: singleton (7).java, Predicted Label: 1, True Label: 1\n",
      "Fold 2 (Train), File: nons (45).java, Predicted Label: 0, True Label: 0\n",
      "Fold 2 (Train), File: singleton (19).java, Predicted Label: 0, True Label: 1\n",
      "Fold 2 (Train), File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
      "Fold 2 (Train), File: nons (28).java, Predicted Label: 0, True Label: 0\n",
      "Fold 2 (Train), File: nons (36).java, Predicted Label: 0, True Label: 0\n",
      "Fold 2 (Test), File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
      "Fold 2 (Test), File: nons (34).java, Predicted Label: 1, True Label: 0\n",
      "Fold 2 (Test), File: singleton (14).java, Predicted Label: 0, True Label: 1\n",
      "Fold 2 (Test), File: sin.csv, Predicted Label: 1, True Label: 0\n",
      "Fold 2 (Test), File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
      "Fold 2 (Test), File: nons (48).java, Predicted Label: 1, True Label: 0\n",
      "Fold 2 (Test), File: nons (26).java, Predicted Label: 1, True Label: 0\n",
      "Fold 2 (Test), File: singleton (12).java, Predicted Label: 1, True Label: 1\n",
      "Fold 2 (Test), File: nons (37).java, Predicted Label: 1, True Label: 0\n",
      "Fold 2 (Test), File: nons (47).java, Predicted Label: 1, True Label: 0\n",
      "Fold 2 (Test), File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
      "Fold 2: Precision: 0.1515151515151515, Recall: 0.2727272727272727, F-score: 0.1948051948051948\n",
      "Fold 3 (Train), File: nons (50).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3 (Train), File: nons (29).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3 (Train), File: nons (42).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3 (Train), File: nons (27).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3 (Train), File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
      "Fold 3 (Train), File: nons (34).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3 (Train), File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
      "Fold 3 (Train), File: nons (49).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3 (Train), File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "Fold 3 (Train), File: nons (38).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3 (Train), File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
      "Fold 3 (Train), File: singleton (14).java, Predicted Label: 1, True Label: 1\n",
      "Fold 3 (Train), File: nons (33).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3 (Train), File: nons (30).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3 (Train), File: sin.csv, Predicted Label: 1, True Label: 0\n",
      "Fold 3 (Train), File: singleton (3).java, Predicted Label: 1, True Label: 1\n",
      "Fold 3 (Train), File: nons (35).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3 (Train), File: nons (43).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3 (Train), File: singleton (16).java, Predicted Label: 1, True Label: 1\n",
      "Fold 3 (Train), File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
      "Fold 3 (Train), File: nons (48).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3 (Train), File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
      "Fold 3 (Train), File: nons (26).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3 (Train), File: nons (40).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3 (Train), File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
      "Fold 3 (Train), File: singleton (12).java, Predicted Label: 1, True Label: 1\n",
      "Fold 3 (Train), File: nons (31).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3 (Train), File: singleton (6).java, Predicted Label: 1, True Label: 1\n",
      "Fold 3 (Train), File: nons (37).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3 (Train), File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
      "Fold 3 (Train), File: singleton (22).java, Predicted Label: 1, True Label: 1\n",
      "Fold 3 (Train), File: nons (47).java, Predicted Label: 1, True Label: 0\n",
      "Fold 3 (Train), File: singleton (4).java, Predicted Label: 1, True Label: 1\n",
      "Fold 3 (Train), File: nons (32).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3 (Train), File: nons (46).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3 (Train), File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
      "Fold 3 (Train), File: singleton (17).java, Predicted Label: 0, True Label: 1\n",
      "Fold 3 (Train), File: nons (39).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3 (Train), File: singleton (7).java, Predicted Label: 0, True Label: 1\n",
      "Fold 3 (Train), File: nons (45).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3 (Train), File: singleton (19).java, Predicted Label: 1, True Label: 1\n",
      "Fold 3 (Train), File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
      "Fold 3 (Test), File: nons (25).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3 (Test), File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
      "Fold 3 (Test), File: nons (44).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3 (Test), File: nons (41).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3 (Test), File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
      "Fold 3 (Test), File: singleton (23).java, Predicted Label: 0, True Label: 1\n",
      "Fold 3 (Test), File: singleton (11).java, Predicted Label: 0, True Label: 1\n",
      "Fold 3 (Test), File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
      "Fold 3 (Test), File: nons (28).java, Predicted Label: 1, True Label: 0\n",
      "Fold 3 (Test), File: nons (36).java, Predicted Label: 0, True Label: 0\n",
      "Fold 3: Precision: 0.5, Recall: 0.5, F-score: 0.45054945054945056\n",
      "Fold 4 (Train), File: nons (50).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4 (Train), File: nons (29).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4 (Train), File: nons (25).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4 (Train), File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
      "Fold 4 (Train), File: nons (27).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4 (Train), File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
      "Fold 4 (Train), File: nons (34).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4 (Train), File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
      "Fold 4 (Train), File: nons (49).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4 (Train), File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "Fold 4 (Train), File: nons (44).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4 (Train), File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
      "Fold 4 (Train), File: singleton (14).java, Predicted Label: 1, True Label: 1\n",
      "Fold 4 (Train), File: nons (41).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4 (Train), File: nons (30).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4 (Train), File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
      "Fold 4 (Train), File: sin.csv, Predicted Label: 0, True Label: 0\n",
      "Fold 4 (Train), File: singleton (23).java, Predicted Label: 1, True Label: 1\n",
      "Fold 4 (Train), File: nons (35).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4 (Train), File: nons (43).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4 (Train), File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
      "Fold 4 (Train), File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
      "Fold 4 (Train), File: nons (48).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4 (Train), File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
      "Fold 4 (Train), File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
      "Fold 4 (Train), File: nons (26).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4 (Train), File: nons (40).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4 (Train), File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
      "Fold 4 (Train), File: singleton (12).java, Predicted Label: 1, True Label: 1\n",
      "Fold 4 (Train), File: singleton (6).java, Predicted Label: 1, True Label: 1\n",
      "Fold 4 (Train), File: nons (37).java, Predicted Label: 1, True Label: 0\n",
      "Fold 4 (Train), File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
      "Fold 4 (Train), File: singleton (22).java, Predicted Label: 1, True Label: 1\n",
      "Fold 4 (Train), File: nons (47).java, Predicted Label: 1, True Label: 0\n",
      "Fold 4 (Train), File: nons (32).java, Predicted Label: 1, True Label: 0\n",
      "Fold 4 (Train), File: nons (46).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4 (Train), File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
      "Fold 4 (Train), File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
      "Fold 4 (Train), File: nons (39).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4 (Train), File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
      "Fold 4 (Train), File: nons (28).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4 (Train), File: nons (36).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4 (Test), File: nons (42).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4 (Test), File: nons (38).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4 (Test), File: nons (33).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4 (Test), File: singleton (3).java, Predicted Label: 0, True Label: 1\n",
      "Fold 4 (Test), File: singleton (16).java, Predicted Label: 0, True Label: 1\n",
      "Fold 4 (Test), File: nons (31).java, Predicted Label: 1, True Label: 0\n",
      "Fold 4 (Test), File: singleton (4).java, Predicted Label: 0, True Label: 1\n",
      "Fold 4 (Test), File: singleton (7).java, Predicted Label: 0, True Label: 1\n",
      "Fold 4 (Test), File: nons (45).java, Predicted Label: 0, True Label: 0\n",
      "Fold 4 (Test), File: singleton (19).java, Predicted Label: 0, True Label: 1\n",
      "Fold 4: Precision: 0.22222222222222224, Recall: 0.4, F-score: 0.2857142857142857\n",
      "Fold 5 (Train), File: nons (50).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5 (Train), File: nons (25).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5 (Train), File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
      "Fold 5 (Train), File: nons (42).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5 (Train), File: nons (27).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5 (Train), File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
      "Fold 5 (Train), File: nons (34).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5 (Train), File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
      "Fold 5 (Train), File: nons (44).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5 (Train), File: nons (38).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5 (Train), File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
      "Fold 5 (Train), File: singleton (14).java, Predicted Label: 1, True Label: 1\n",
      "Fold 5 (Train), File: nons (33).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5 (Train), File: nons (41).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5 (Train), File: nons (30).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5 (Train), File: singleton (1).java, Predicted Label: 1, True Label: 1\n",
      "Fold 5 (Train), File: sin.csv, Predicted Label: 0, True Label: 0\n",
      "Fold 5 (Train), File: singleton (3).java, Predicted Label: 0, True Label: 1\n",
      "Fold 5 (Train), File: singleton (23).java, Predicted Label: 1, True Label: 1\n",
      "Fold 5 (Train), File: singleton (16).java, Predicted Label: 1, True Label: 1\n",
      "Fold 5 (Train), File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
      "Fold 5 (Train), File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
      "Fold 5 (Train), File: nons (48).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5 (Train), File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
      "Fold 5 (Train), File: nons (26).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5 (Train), File: nons (40).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5 (Train), File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
      "Fold 5 (Train), File: singleton (12).java, Predicted Label: 1, True Label: 1\n",
      "Fold 5 (Train), File: nons (31).java, Predicted Label: 1, True Label: 0\n",
      "Fold 5 (Train), File: singleton (6).java, Predicted Label: 1, True Label: 1\n",
      "Fold 5 (Train), File: nons (37).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5 (Train), File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
      "Fold 5 (Train), File: nons (47).java, Predicted Label: 1, True Label: 0\n",
      "Fold 5 (Train), File: singleton (4).java, Predicted Label: 0, True Label: 1\n",
      "Fold 5 (Train), File: nons (46).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5 (Train), File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
      "Fold 5 (Train), File: nons (39).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5 (Train), File: singleton (7).java, Predicted Label: 1, True Label: 1\n",
      "Fold 5 (Train), File: nons (45).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5 (Train), File: singleton (19).java, Predicted Label: 1, True Label: 1\n",
      "Fold 5 (Train), File: nons (28).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5 (Train), File: nons (36).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5 (Test), File: nons (29).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5 (Test), File: nons (49).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5 (Test), File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "Fold 5 (Test), File: nons (35).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5 (Test), File: nons (43).java, Predicted Label: 0, True Label: 0\n",
      "Fold 5 (Test), File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
      "Fold 5 (Test), File: singleton (22).java, Predicted Label: 0, True Label: 1\n",
      "Fold 5 (Test), File: nons (32).java, Predicted Label: 1, True Label: 0\n",
      "Fold 5 (Test), File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
      "Fold 5 (Test), File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
      "Fold 5: Precision: 0.8, Recall: 0.8, F-score: 0.8000000000000002\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the path to the CSV file containing program names, labels, and content\n",
    "csv_path = 'embeddings/sin1.csv'  # Replace with the actual CSV file path\n",
    "\n",
    "# Initialize RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Load the DataFrame from the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Function to calculate embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Calculate embeddings for each program by considering embeddings of individual lines\n",
    "program_embeddings = []\n",
    "for content in tqdm(df['Content']):\n",
    "    lines = content.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Convert program_embeddings to NumPy array\n",
    "program_embeddings = np.vstack(program_embeddings)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
    "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
    "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
    "\n",
    "    # Apply k-nearest neighbor classification\n",
    "    n_neighbors = 3  # Number of neighbors to consider\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the training set\n",
    "    train_predictions = knn.predict(X_train)\n",
    "    for i in range(len(train_predictions)):\n",
    "        print(f\"Fold {fold + 1} (Train), File: {df['File Name'].iloc[train_index[i]]}, Predicted Label: {train_predictions[i]}, True Label: {y_train.iloc[i]}\")\n",
    "\n",
    "    # Predictions on the test set\n",
    "    test_predictions = knn.predict(X_test)\n",
    "    for i in range(len(test_predictions)):\n",
    "        print(f\"Fold {fold + 1} (Test), File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
    "\n",
    "    # Calculate precision, recall, and f-score for the current fold\n",
    "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
    "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
    "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
    "\n",
    "    print(f\"Fold {fold + 1}: Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "390576f6-c38f-4dcc-81aa-b6b98fd7e81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 52/52 [09:51<00:00, 11.38s/it]   \n",
      "/cephyr/users/sushantk/Alvis/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (Test):\n",
      "File: nons (50).java, Predicted Label: 1, True Label: 0\n",
      "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (30).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (39).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.875, Recall: 0.8333333333333334, F-score: 0.8285714285714286\n",
      "Fold 3 (Test):\n",
      "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (48).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (26).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (47).java, Predicted Label: 1, True Label: 0\n",
      "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
      "Fold 10 (Test):\n",
      "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (35).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (43).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (17).java, Predicted Label: 0, True Label: 1\n",
      "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the path to the CSV file containing program names, labels, and content\n",
    "csv_path = 'embeddings/sin1.csv'  # Replace with the actual CSV file path\n",
    "\n",
    "# Initialize RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Load the DataFrame from the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Function to calculate embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Calculate embeddings for each program by considering embeddings of individual lines\n",
    "program_embeddings = []\n",
    "for content in tqdm(df['Content']):\n",
    "    lines = content.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Convert program_embeddings to NumPy array\n",
    "program_embeddings = np.vstack(program_embeddings)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
    "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
    "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
    "\n",
    "    # Apply k-nearest neighbor classification\n",
    "    n_neighbors = 3  # Number of neighbors to consider\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set\n",
    "    test_predictions = knn.predict(X_test)\n",
    "    \n",
    "    # Calculate precision, recall, and f-score for the current fold\n",
    "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
    "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
    "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
    "\n",
    "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
    "    if precision >= 0.7 and recall >= 0.7 and f1 >= 0.7:\n",
    "        print(f\"Fold {fold + 1} (Test):\")\n",
    "        for i in range(len(test_predictions)):\n",
    "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
    "        \n",
    "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22ab1ff5-701c-4518-92b8-25d17322e90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Singleton with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ae2b717-3780-43e1-acd7-6f3579ef705d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and contents saved to embeddings/sin2.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize lists to store program names, labels, and contents\n",
    "program_names = []\n",
    "labels = []\n",
    "contents = []\n",
    "\n",
    "# Function to label programs as positive (1) or negative (0) based on the file name\n",
    "def label_program(file_name):\n",
    "    return 1 if \"singleton\" in file_name.lower() else 0\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_content = f.read()\n",
    "            program_names.append(program_file)\n",
    "            labels.append(label_program(program_file))\n",
    "            contents.append(program_content)\n",
    "\n",
    "# Create a DataFrame to store the data\n",
    "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_path = 'embeddings/sin2.csv'  # Replace with the desired CSV file path\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Labels and contents saved to {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9d22662-caca-4847-9901-3d7569ac7b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 50/50 [03:10<00:00,  3.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 (Test):\n",
      "File: nons (55).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (3).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (16).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (6).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n",
      "Fold 8 (Test):\n",
      "File: nons (29).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (6).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (9).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
      "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
      "Fold 9 (Test):\n",
      "File: nons (34).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (4).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (7).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (45).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the path to the CSV file containing program names, labels, and content\n",
    "csv_path = 'embeddings/sin2.csv'  # Replace with the actual CSV file path\n",
    "\n",
    "# Initialize RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Load the DataFrame from the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Function to calculate embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Calculate embeddings for each program by considering embeddings of individual lines\n",
    "program_embeddings = []\n",
    "for content in tqdm(df['Content']):\n",
    "    lines = content.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Convert program_embeddings to NumPy array\n",
    "program_embeddings = np.vstack(program_embeddings)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
    "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
    "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
    "\n",
    "    # Apply k-nearest neighbor classification\n",
    "    n_neighbors = 3  # Number of neighbors to consider\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set\n",
    "    test_predictions = knn.predict(X_test)\n",
    "    \n",
    "    # Calculate precision, recall, and f-score for the current fold\n",
    "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
    "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
    "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
    "\n",
    "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
    "    if precision >= 0.7 and recall >= 0.7 and f1 >= 0.7:\n",
    "        print(f\"Fold {fold + 1} (Test):\")\n",
    "        for i in range(len(test_predictions)):\n",
    "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
    "        \n",
    "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "757aeffb-81da-4d6c-b8b5-0b67434f733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Singleton with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a44c1985-0561-4ee2-b9f4-e060c82bf950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and contents saved to embeddings/sin3.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize lists to store program names, labels, and contents\n",
    "program_names = []\n",
    "labels = []\n",
    "contents = []\n",
    "\n",
    "# Function to label programs as positive (1) or negative (0) based on the file name\n",
    "def label_program(file_name):\n",
    "    return 1 if \"singleton\" in file_name.lower() else 0\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_content = f.read()\n",
    "            program_names.append(program_file)\n",
    "            labels.append(label_program(program_file))\n",
    "            contents.append(program_content)\n",
    "\n",
    "# Create a DataFrame to store the data\n",
    "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_path = 'embeddings/sin3.csv'  # Replace with the desired CSV file path\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Labels and contents saved to {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a15b2f86-5ca3-439d-bcc1-a3ed2608170c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 52/52 [03:22<00:00,  3.89s/it]\n",
      "/cephyr/users/sushantk/Alvis/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (Test):\n",
      "File: nons (25).java, Predicted Label: 1, True Label: 0\n",
      "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (53).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (64).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.875, Recall: 0.8333333333333334, F-score: 0.8285714285714286\n",
      "Fold 6 (Test):\n",
      "File: nons (61).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (41).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (28).java, Predicted Label: 1, True Label: 0\n",
      "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
      "Fold 9 (Test):\n",
      "File: nons (42).java, Predicted Label: 1, True Label: 0\n",
      "File: nons (38).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (22).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (19).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n",
      "Fold 10 (Test):\n",
      "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (20).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (14).java, Predicted Label: 1, True Label: 0\n",
      "File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the path to the CSV file containing program names, labels, and content\n",
    "csv_path = 'embeddings/sin3.csv'  # Replace with the actual CSV file path\n",
    "\n",
    "# Initialize RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Load the DataFrame from the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Function to calculate embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Calculate embeddings for each program by considering embeddings of individual lines\n",
    "program_embeddings = []\n",
    "for content in tqdm(df['Content']):\n",
    "    lines = content.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Convert program_embeddings to NumPy array\n",
    "program_embeddings = np.vstack(program_embeddings)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
    "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
    "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
    "\n",
    "    # Apply k-nearest neighbor classification\n",
    "    n_neighbors = 3  # Number of neighbors to consider\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set\n",
    "    test_predictions = knn.predict(X_test)\n",
    "    \n",
    "    # Calculate precision, recall, and f-score for the current fold\n",
    "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
    "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
    "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
    "\n",
    "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
    "    if precision >= 0.7 and recall >= 0.7 and f1 >= 0.7:\n",
    "        print(f\"Fold {fold + 1} (Test):\")\n",
    "        for i in range(len(test_predictions)):\n",
    "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
    "        \n",
    "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4ee0c32-b38e-495a-909f-96b1c3fb68f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Singleton with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "affc5909-48a0-4bed-86e7-64692d10445e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and contents saved to embeddings/sin4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 55/55 [03:27<00:00,  3.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 (Test):\n",
      "File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
      "File: singleton (3).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (16).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (51).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (58).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.875, Recall: 0.8333333333333334, F-score: 0.8285714285714286\n",
      "Fold 6 (Test):\n",
      "File: nons (44).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (48).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (52).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 1.0, Recall: 1.0, F-score: 1.0\n",
      "Fold 7 (Test):\n",
      "File: nons (21).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (10).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (4).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (60).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from tqdm import tqdm\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize lists to store program names, labels, and contents\n",
    "program_names = []\n",
    "labels = []\n",
    "contents = []\n",
    "\n",
    "# Function to label programs as positive (1) or negative (0) based on the file name\n",
    "def label_program(file_name):\n",
    "    return 1 if \"singleton\" in file_name.lower() else 0\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_content = f.read()\n",
    "            program_names.append(program_file)\n",
    "            labels.append(label_program(program_file))\n",
    "            contents.append(program_content)\n",
    "\n",
    "# Create a DataFrame to store the data\n",
    "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_path = 'embeddings/sin4.csv'  # Replace with the desired CSV file path\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Labels and contents saved to {csv_path}\")\n",
    "\n",
    "\n",
    "# Define the path to the CSV file containing program names, labels, and content\n",
    "csv_path = 'embeddings/sin4.csv'  # Replace with the actual CSV file path\n",
    "\n",
    "# Initialize RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Load the DataFrame from the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Function to calculate embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Calculate embeddings for each program by considering embeddings of individual lines\n",
    "program_embeddings = []\n",
    "for content in tqdm(df['Content']):\n",
    "    lines = content.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Convert program_embeddings to NumPy array\n",
    "program_embeddings = np.vstack(program_embeddings)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
    "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
    "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
    "\n",
    "    # Apply k-nearest neighbor classification\n",
    "    n_neighbors = 3  # Number of neighbors to consider\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set\n",
    "    test_predictions = knn.predict(X_test)\n",
    "    \n",
    "    # Calculate precision, recall, and f-score for the current fold\n",
    "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
    "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
    "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
    "\n",
    "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
    "    if precision >= 0.7 and recall >= 0.7 and f1 >= 0.7:\n",
    "        print(f\"Fold {fold + 1} (Test):\")\n",
    "        for i in range(len(test_predictions)):\n",
    "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
    "        \n",
    "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52188409-e3c9-4d8b-841b-1dcd8f33817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Singleton using different setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19ecbd31-67f3-4bec-bd27-10192606297b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and contents saved to embeddings/sin5.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 49/49 [03:17<00:00,  4.03s/it]\n",
      "/cephyr/users/sushantk/Alvis/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 (Test):\n",
      "File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (63).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (67).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (58).java, Predicted Label: 1, True Label: 0\n",
      "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
      "Fold 3 (Test):\n",
      "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (53).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (14).java, Predicted Label: 1, True Label: 0\n",
      "File: singleton (22).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (15).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
      "Fold 6 (Test):\n",
      "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (49).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (14).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (65).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 1.0, Recall: 1.0, F-score: 1.0\n",
      "Fold 7 (Test):\n",
      "File: singleton (25).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (1).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (11).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (4).java, Predicted Label: 0, True Label: 1\n",
      "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
      "Fold 10 (Test):\n",
      "File: nons (19).java, Predicted Label: 1, True Label: 0\n",
      "File: nons (41).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 0.8333333333333333, Recall: 0.75, F-score: 0.7333333333333334\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from tqdm import tqdm\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize lists to store program names, labels, and contents\n",
    "program_names = []\n",
    "labels = []\n",
    "contents = []\n",
    "\n",
    "# Function to label programs as positive (1) or negative (0) based on the file name\n",
    "def label_program(file_name):\n",
    "    return 1 if \"singleton\" in file_name.lower() else 0\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_content = f.read()\n",
    "            program_names.append(program_file)\n",
    "            labels.append(label_program(program_file))\n",
    "            contents.append(program_content)\n",
    "\n",
    "# Create a DataFrame to store the data\n",
    "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_path = 'embeddings/sin5.csv'  # Replace with the desired CSV file path\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Labels and contents saved to {csv_path}\")\n",
    "\n",
    "\n",
    "# Define the path to the CSV file containing program names, labels, and content\n",
    "csv_path = 'embeddings/sin5.csv'  # Replace with the actual CSV file path\n",
    "\n",
    "# Initialize RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Load the DataFrame from the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Function to calculate embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Calculate embeddings for each program by considering embeddings of individual lines\n",
    "program_embeddings = []\n",
    "for content in tqdm(df['Content']):\n",
    "    lines = content.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Convert program_embeddings to NumPy array\n",
    "program_embeddings = np.vstack(program_embeddings)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
    "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
    "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
    "\n",
    "    # Apply k-nearest neighbor classification\n",
    "    n_neighbors = 3  # Number of neighbors to consider\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set\n",
    "    test_predictions = knn.predict(X_test)\n",
    "    \n",
    "    # Calculate precision, recall, and f-score for the current fold\n",
    "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
    "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
    "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
    "\n",
    "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
    "    if precision >= 0.5 and recall >= 0.5 and f1 >= 0.5:\n",
    "        print(f\"Fold {fold + 1} (Test):\")\n",
    "        for i in range(len(test_predictions)):\n",
    "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
    "        \n",
    "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22618cc6-c1df-4639-a901-998439321067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and contents saved to embeddings/sin6.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 51/51 [03:07<00:00,  3.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (Test):\n",
      "File: nons (50).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (63).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (21).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (64).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.875, Recall: 0.8333333333333334, F-score: 0.8285714285714286\n",
      "Fold 2 (Test):\n",
      "File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (61).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (6).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (46).java, Predicted Label: 1, True Label: 0\n",
      "File: nons (45).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
      "Fold 3 (Test):\n",
      "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (47).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (60).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (56).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n",
      "Fold 5 (Test):\n",
      "File: nons (55).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (14).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (59).java, Predicted Label: 1, True Label: 0\n",
      "File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (57).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.6, Recall: 0.6, F-score: 0.6\n",
      "Fold 6 (Test):\n",
      "File: singleton (25).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (49).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (48).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (52).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 1.0, Recall: 1.0, F-score: 1.0\n",
      "Fold 7 (Test):\n",
      "File: nons (53).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (23).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (43).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (4).java, Predicted Label: 0, True Label: 1\n",
      "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
      "Fold 9 (Test):\n",
      "File: nons (44).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (22).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (62).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (19).java, Predicted Label: 0, True Label: 1\n",
      "File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 0.8, Recall: 0.6, F-score: 0.5666666666666667\n",
      "Fold 10 (Test):\n",
      "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (67).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (51).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from tqdm import tqdm\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize lists to store program names, labels, and contents\n",
    "program_names = []\n",
    "labels = []\n",
    "contents = []\n",
    "\n",
    "# Function to label programs as positive (1) or negative (0) based on the file name\n",
    "def label_program(file_name):\n",
    "    return 1 if \"singleton\" in file_name.lower() else 0\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_content = f.read()\n",
    "            program_names.append(program_file)\n",
    "            labels.append(label_program(program_file))\n",
    "            contents.append(program_content)\n",
    "\n",
    "# Create a DataFrame to store the data\n",
    "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_path = 'embeddings/sin6.csv'  # Replace with the desired CSV file path\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Labels and contents saved to {csv_path}\")\n",
    "\n",
    "\n",
    "# Define the path to the CSV file containing program names, labels, and content\n",
    "csv_path = 'embeddings/sin6.csv'  # Replace with the actual CSV file path\n",
    "\n",
    "# Initialize RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Load the DataFrame from the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Function to calculate embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Calculate embeddings for each program by considering embeddings of individual lines\n",
    "program_embeddings = []\n",
    "for content in tqdm(df['Content']):\n",
    "    lines = content.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Convert program_embeddings to NumPy array\n",
    "program_embeddings = np.vstack(program_embeddings)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
    "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
    "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
    "\n",
    "    # Apply k-nearest neighbor classification\n",
    "    n_neighbors = 3  # Number of neighbors to consider\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set\n",
    "    test_predictions = knn.predict(X_test)\n",
    "    \n",
    "    # Calculate precision, recall, and f-score for the current fold\n",
    "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
    "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
    "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
    "\n",
    "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
    "    if precision >= 0.5 and recall >= 0.5 and f1 >= 0.5:\n",
    "        print(f\"Fold {fold + 1} (Test):\")\n",
    "        for i in range(len(test_predictions)):\n",
    "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
    "        \n",
    "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2e9c8f-c10b-449d-82f8-00be476a65ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Singleton with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c23c7525-6b23-49ff-8b4d-3cc30097c97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and contents saved to embeddings/sin7.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 53/53 [04:45<00:00,  5.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (Test):\n",
      "File: nons (54).java, Predicted Label: 1, True Label: 0\n",
      "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (17).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (65).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.875, Recall: 0.8333333333333334, F-score: 0.8285714285714286\n",
      "Fold 2 (Test):\n",
      "File: nons (55).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (6).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (6).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (24).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.875, Recall: 0.8333333333333334, F-score: 0.8285714285714286\n",
      "Fold 3 (Test):\n",
      "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (8).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (21).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (46).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.875, Recall: 0.8333333333333334, F-score: 0.8285714285714286\n",
      "Fold 4 (Test):\n",
      "File: nons (34).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (14).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (20).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (60).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n",
      "Fold 5 (Test):\n",
      "File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (27).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (3).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (28).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n",
      "Fold 6 (Test):\n",
      "File: nons (19).java, Predicted Label: 1, True Label: 0\n",
      "File: singleton (23).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (35).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (52).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.6, Recall: 0.6, F-score: 0.6\n",
      "Fold 9 (Test):\n",
      "File: nons (33).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (53).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (22).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (19).java, Predicted Label: 0, True Label: 1\n",
      "File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
      "Fold 10 (Test):\n",
      "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (14).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (16).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from tqdm import tqdm\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize lists to store program names, labels, and contents\n",
    "program_names = []\n",
    "labels = []\n",
    "contents = []\n",
    "\n",
    "# Function to label programs as positive (1) or negative (0) based on the file name\n",
    "def label_program(file_name):\n",
    "    return 1 if \"singleton\" in file_name.lower() else 0\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_content = f.read()\n",
    "            program_names.append(program_file)\n",
    "            labels.append(label_program(program_file))\n",
    "            contents.append(program_content)\n",
    "\n",
    "# Create a DataFrame to store the data\n",
    "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_path = 'embeddings/sin7.csv'  # Replace with the desired CSV file path\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Labels and contents saved to {csv_path}\")\n",
    "\n",
    "\n",
    "# Define the path to the CSV file containing program names, labels, and content\n",
    "csv_path = 'embeddings/sin7.csv'  # Replace with the actual CSV file path\n",
    "\n",
    "# Initialize RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Load the DataFrame from the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Function to calculate embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Calculate embeddings for each program by considering embeddings of individual lines\n",
    "program_embeddings = []\n",
    "for content in tqdm(df['Content']):\n",
    "    lines = content.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Convert program_embeddings to NumPy array\n",
    "program_embeddings = np.vstack(program_embeddings)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
    "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
    "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
    "\n",
    "    # Apply k-nearest neighbor classification\n",
    "    n_neighbors = 3  # Number of neighbors to consider\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set\n",
    "    test_predictions = knn.predict(X_test)\n",
    "    \n",
    "    # Calculate precision, recall, and f-score for the current fold\n",
    "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
    "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
    "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
    "\n",
    "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
    "    if precision >= 0.5 and recall >= 0.5 and f1 >= 0.5:\n",
    "        print(f\"Fold {fold + 1} (Test):\")\n",
    "        for i in range(len(test_predictions)):\n",
    "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
    "        \n",
    "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ebe769-5ac1-4d87-b6b1-4bb41018f92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Singleton with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce01d1b9-eb5c-4776-b458-2c62acd7163a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and contents saved to embeddings/sin8.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 51/51 [04:31<00:00,  5.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (Test):\n",
      "File: nons (54).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (17).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (24).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 1.0, Recall: 1.0, F-score: 1.0\n",
      "Fold 2 (Test):\n",
      "File: nons (55).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (6).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (6).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (23).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 1.0, Recall: 1.0, F-score: 1.0\n",
      "Fold 3 (Test):\n",
      "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (8).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (21).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (60).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
      "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n",
      "Fold 4 (Test):\n",
      "File: nons (34).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (20).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (15).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n",
      "Fold 5 (Test):\n",
      "File: nons (27).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (14).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (3).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (28).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n",
      "Fold 6 (Test):\n",
      "File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (19).java, Predicted Label: 1, True Label: 0\n",
      "File: nons (35).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (52).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.6, Recall: 0.6, F-score: 0.6\n",
      "Fold 7 (Test):\n",
      "File: nons (30).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (53).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (23).java, Predicted Label: 0, True Label: 1\n",
      "File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (4).java, Predicted Label: 0, True Label: 1\n",
      "Precision: 0.8, Recall: 0.6, F-score: 0.5666666666666667\n",
      "Fold 9 (Test):\n",
      "File: nons (33).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (22).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (46).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (19).java, Predicted Label: 0, True Label: 1\n",
      "File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
      "Fold 10 (Test):\n",
      "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (14).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (16).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from tqdm import tqdm\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize lists to store program names, labels, and contents\n",
    "program_names = []\n",
    "labels = []\n",
    "contents = []\n",
    "\n",
    "# Function to label programs as positive (1) or negative (0) based on the file name\n",
    "def label_program(file_name):\n",
    "    return 1 if \"singleton\" in file_name.lower() else 0\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_content = f.read()\n",
    "            program_names.append(program_file)\n",
    "            labels.append(label_program(program_file))\n",
    "            contents.append(program_content)\n",
    "\n",
    "# Create a DataFrame to store the data\n",
    "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_path = 'embeddings/sin8.csv'  # Replace with the desired CSV file path\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Labels and contents saved to {csv_path}\")\n",
    "\n",
    "\n",
    "# Define the path to the CSV file containing program names, labels, and content\n",
    "csv_path = 'embeddings/sin8.csv'  # Replace with the actual CSV file path\n",
    "\n",
    "# Initialize RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Load the DataFrame from the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Function to calculate embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Calculate embeddings for each program by considering embeddings of individual lines\n",
    "program_embeddings = []\n",
    "for content in tqdm(df['Content']):\n",
    "    lines = content.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Convert program_embeddings to NumPy array\n",
    "program_embeddings = np.vstack(program_embeddings)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
    "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
    "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
    "\n",
    "    # Apply k-nearest neighbor classification\n",
    "    n_neighbors = 3  # Number of neighbors to consider\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set\n",
    "    test_predictions = knn.predict(X_test)\n",
    "    \n",
    "    # Calculate precision, recall, and f-score for the current fold\n",
    "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
    "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
    "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
    "\n",
    "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
    "    if precision >= 0.4 and recall >= 0.4 and f1 >= 0.4:\n",
    "        print(f\"Fold {fold + 1} (Test):\")\n",
    "        for i in range(len(test_predictions)):\n",
    "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
    "        \n",
    "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b6ec30b-4031-4be6-8da1-ca587db5dddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and contents saved to embeddings/sin9.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 51/51 [03:32<00:00,  4.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (Test):\n",
      "File: nons (12).java, Predicted Label: 1, True Label: 0\n",
      "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (1).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (32).java, Predicted Label: 1, True Label: 0\n",
      "Precision: 0.7999999999999999, Recall: 0.6666666666666666, F-score: 0.6249999999999999\n",
      "Fold 2 (Test):\n",
      "File: nons (27).java, Predicted Label: 1, True Label: 0\n",
      "File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (40).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (6).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (15).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.6, Recall: 0.6, F-score: 0.6\n",
      "Fold 3 (Test):\n",
      "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (11).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (26).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (21).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
      "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n",
      "Fold 4 (Test):\n",
      "File: nons (19).java, Predicted Label: 1, True Label: 0\n",
      "File: nons (22).java, Predicted Label: 1, True Label: 0\n",
      "File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (67).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
      "Precision: 0.4333333333333333, Recall: 0.4, F-score: 0.4\n",
      "Fold 5 (Test):\n",
      "File: nons (29).java, Predicted Label: 1, True Label: 0\n",
      "File: nons (38).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (14).java, Predicted Label: 0, True Label: 1\n",
      "File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (36).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.3, Recall: 0.4, F-score: 0.34285714285714286\n",
      "Fold 6 (Test):\n",
      "File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (42).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (3).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (24).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n",
      "Fold 7 (Test):\n",
      "File: nons (59).java, Predicted Label: 1, True Label: 0\n",
      "File: nons (33).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (23).java, Predicted Label: 0, True Label: 1\n",
      "File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (4).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 0.6, Recall: 0.6, F-score: 0.6\n",
      "Fold 8 (Test):\n",
      "File: nons (54).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (3).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (16).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (23).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (7).java, Predicted Label: 0, True Label: 1\n",
      "Precision: 0.8, Recall: 0.6, F-score: 0.5666666666666667\n",
      "Fold 9 (Test):\n",
      "File: nons (61).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (37).java, Predicted Label: 1, True Label: 0\n",
      "File: singleton (22).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (19).java, Predicted Label: 0, True Label: 1\n",
      "File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 0.6, Recall: 0.6, F-score: 0.6\n",
      "Fold 10 (Test):\n",
      "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (20).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (2).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from tqdm import tqdm\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize lists to store program names, labels, and contents\n",
    "program_names = []\n",
    "labels = []\n",
    "contents = []\n",
    "\n",
    "# Function to label programs as positive (1) or negative (0) based on the file name\n",
    "def label_program(file_name):\n",
    "    return 1 if \"singleton\" in file_name.lower() else 0\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_content = f.read()\n",
    "            program_names.append(program_file)\n",
    "            labels.append(label_program(program_file))\n",
    "            contents.append(program_content)\n",
    "\n",
    "# Create a DataFrame to store the data\n",
    "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_path = 'embeddings/sin9.csv'  # Replace with the desired CSV file path\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Labels and contents saved to {csv_path}\")\n",
    "\n",
    "\n",
    "# Define the path to the CSV file containing program names, labels, and content\n",
    "csv_path = 'embeddings/sin9.csv'  # Replace with the actual CSV file path\n",
    "\n",
    "# Initialize RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Load the DataFrame from the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Function to calculate embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Calculate embeddings for each program by considering embeddings of individual lines\n",
    "program_embeddings = []\n",
    "for content in tqdm(df['Content']):\n",
    "    lines = content.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Convert program_embeddings to NumPy array\n",
    "program_embeddings = np.vstack(program_embeddings)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
    "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
    "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
    "\n",
    "    # Apply k-nearest neighbor classification\n",
    "    n_neighbors = 3  # Number of neighbors to consider\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set\n",
    "    test_predictions = knn.predict(X_test)\n",
    "    \n",
    "    # Calculate precision, recall, and f-score for the current fold\n",
    "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
    "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
    "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
    "\n",
    "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
    "    if precision >= 0.1 and recall >= 0.1 and f1 >= 0.1:\n",
    "        print(f\"Fold {fold + 1} (Test):\")\n",
    "        for i in range(len(test_predictions)):\n",
    "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
    "        \n",
    "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c38f346a-4318-4a27-b4e5-73a6647d2cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and contents saved to embeddings/sin10.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 54/54 [04:37<00:00,  5.14s/it]\n",
      "/cephyr/users/sushantk/Alvis/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (Test):\n",
      "File: nons (54).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (17).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (23).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 1.0, Recall: 1.0, F-score: 1.0\n",
      "Fold 2 (Test):\n",
      "File: nons (68).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (16).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (26).java, Predicted Label: 1, True Label: 0\n",
      "File: singleton (4).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (46).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 0.5, Recall: 0.5, F-score: 0.48571428571428577\n",
      "Fold 3 (Test):\n",
      "File: singleton (14).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (3).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (16).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (6).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (15).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.875, Recall: 0.8333333333333334, F-score: 0.8285714285714286\n",
      "Fold 4 (Test):\n",
      "File: nons (27).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (20).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (6).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 1.0, Recall: 1.0, F-score: 1.0\n",
      "Fold 5 (Test):\n",
      "File: nons (42).java, Predicted Label: 1, True Label: 0\n",
      "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (33).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (28).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
      "Fold 6 (Test):\n",
      "File: nons (30).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (35).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (19).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (65).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n",
      "Fold 7 (Test):\n",
      "File: nons (25).java, Predicted Label: 1, True Label: 0\n",
      "File: singleton (23).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (8).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (21).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (22).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 0.6, Recall: 0.6, F-score: 0.6\n",
      "Fold 8 (Test):\n",
      "File: nons (18).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (3).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (53).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (24).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.36, Recall: 0.6, F-score: 0.4499999999999999\n",
      "Fold 9 (Test):\n",
      "File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (19).java, Predicted Label: 1, True Label: 0\n",
      "File: nons (34).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (60).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.3, Recall: 0.4, F-score: 0.34285714285714286\n",
      "Fold 10 (Test):\n",
      "File: nons (55).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (14).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (7).java, Predicted Label: 0, True Label: 1\n",
      "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from tqdm import tqdm\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize lists to store program names, labels, and contents\n",
    "program_names = []\n",
    "labels = []\n",
    "contents = []\n",
    "\n",
    "# Function to label programs as positive (1) or negative (0) based on the file name\n",
    "def label_program(file_name):\n",
    "    return 1 if \"singleton\" in file_name.lower() else 0\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_content = f.read()\n",
    "            program_names.append(program_file)\n",
    "            labels.append(label_program(program_file))\n",
    "            contents.append(program_content)\n",
    "\n",
    "# Create a DataFrame to store the data\n",
    "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_path = 'embeddings/sin10.csv'  # Replace with the desired CSV file path\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Labels and contents saved to {csv_path}\")\n",
    "\n",
    "\n",
    "# Define the path to the CSV file containing program names, labels, and content\n",
    "csv_path = 'embeddings/sin10.csv'  # Replace with the actual CSV file path\n",
    "\n",
    "# Initialize RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Load the DataFrame from the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Function to calculate embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Calculate embeddings for each program by considering embeddings of individual lines\n",
    "program_embeddings = []\n",
    "for content in tqdm(df['Content']):\n",
    "    lines = content.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Convert program_embeddings to NumPy array\n",
    "program_embeddings = np.vstack(program_embeddings)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
    "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
    "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
    "\n",
    "    # Apply k-nearest neighbor classification\n",
    "    n_neighbors = 3  # Number of neighbors to consider\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set\n",
    "    test_predictions = knn.predict(X_test)\n",
    "    \n",
    "    # Calculate precision, recall, and f-score for the current fold\n",
    "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
    "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
    "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
    "\n",
    "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
    "    if precision >= 0.1 and recall >= 0.1 and f1 >= 0.1:\n",
    "        print(f\"Fold {fold + 1} (Test):\")\n",
    "        for i in range(len(test_predictions)):\n",
    "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
    "        \n",
    "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef605068-0d99-4064-b730-8847d11b886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Singleton using different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b235d8bb-bf14-474f-af5f-1c2329dfc296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and contents saved to embeddings/sin11.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 50/50 [03:23<00:00,  4.07s/it]\n",
      "/cephyr/users/sushantk/Alvis/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (Test):\n",
      "File: nons (18).java, Predicted Label: 1, True Label: 0\n",
      "File: nons (22).java, Predicted Label: 1, True Label: 0\n",
      "File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (39).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.4333333333333333, Recall: 0.4, F-score: 0.4\n",
      "Fold 2 (Test):\n",
      "File: nons (12).java, Predicted Label: 1, True Label: 0\n",
      "File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (13).java, Predicted Label: 1, True Label: 0\n",
      "File: nons (23).java, Predicted Label: 1, True Label: 0\n",
      "Precision: 0.16, Recall: 0.4, F-score: 0.2285714285714286\n",
      "Fold 3 (Test):\n",
      "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (63).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (8).java, Predicted Label: 1, True Label: 0\n",
      "File: singleton (22).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (60).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
      "Fold 4 (Test):\n",
      "File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (68).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (3).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (35).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (51).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n",
      "Fold 5 (Test):\n",
      "File: nons (30).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (14).java, Predicted Label: 1, True Label: 0\n",
      "File: singleton (19).java, Predicted Label: 0, True Label: 1\n",
      "File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (36).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.6, Recall: 0.6, F-score: 0.6\n",
      "Fold 6 (Test):\n",
      "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (55).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (14).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (16).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (52).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
      "Fold 7 (Test):\n",
      "File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (7).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (67).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
      "Fold 8 (Test):\n",
      "File: nons (19).java, Predicted Label: 1, True Label: 0\n",
      "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (6).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (46).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
      "Precision: 0.6, Recall: 0.6, F-score: 0.6\n",
      "Fold 9 (Test):\n",
      "File: nons (4).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (4).java, Predicted Label: 0, True Label: 1\n",
      "File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (62).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (7).java, Predicted Label: 0, True Label: 1\n",
      "Precision: 0.8, Recall: 0.6, F-score: 0.5666666666666667\n",
      "Fold 10 (Test):\n",
      "File: nons (59).java, Predicted Label: 1, True Label: 0\n",
      "File: nons (33).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
      "File: singleton (23).java, Predicted Label: 0, True Label: 1\n",
      "File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 0.4333333333333333, Recall: 0.4, F-score: 0.4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from tqdm import tqdm\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize lists to store program names, labels, and contents\n",
    "program_names = []\n",
    "labels = []\n",
    "contents = []\n",
    "\n",
    "# Function to label programs as positive (1) or negative (0) based on the file name\n",
    "def label_program(file_name):\n",
    "    return 1 if \"singleton\" in file_name.lower() else 0\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_content = f.read()\n",
    "            program_names.append(program_file)\n",
    "            labels.append(label_program(program_file))\n",
    "            contents.append(program_content)\n",
    "\n",
    "# Create a DataFrame to store the data\n",
    "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_path = 'embeddings/sin11.csv'  # Replace with the desired CSV file path\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Labels and contents saved to {csv_path}\")\n",
    "\n",
    "\n",
    "# Define the path to the CSV file containing program names, labels, and content\n",
    "csv_path = 'embeddings/sin11.csv'  # Replace with the actual CSV file path\n",
    "\n",
    "# Initialize RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Load the DataFrame from the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Function to calculate embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Calculate embeddings for each program by considering embeddings of individual lines\n",
    "program_embeddings = []\n",
    "for content in tqdm(df['Content']):\n",
    "    lines = content.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Convert program_embeddings to NumPy array\n",
    "program_embeddings = np.vstack(program_embeddings)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
    "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
    "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
    "\n",
    "    # Apply k-nearest neighbor classification\n",
    "    n_neighbors = 3  # Number of neighbors to consider\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set\n",
    "    test_predictions = knn.predict(X_test)\n",
    "    \n",
    "    # Calculate precision, recall, and f-score for the current fold\n",
    "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
    "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
    "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
    "\n",
    "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
    "    if precision >= 0.1 and recall >= 0.1 and f1 >= 0.1:\n",
    "        print(f\"Fold {fold + 1} (Test):\")\n",
    "        for i in range(len(test_predictions)):\n",
    "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
    "        \n",
    "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd1818e-e930-4a1c-bcfb-ee1c1386494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Singleton with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47391837-18fe-4522-93c2-2337403d2e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and contents saved to embeddings/sin12.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 51/51 [03:28<00:00,  4.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (Test):\n",
      "File: nons (12).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (2).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (23).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 1.0, Recall: 1.0, F-score: 1.0\n",
      "Fold 2 (Test):\n",
      "File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (4).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (21).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (6).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (15).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 1.0, Recall: 1.0, F-score: 1.0\n",
      "Fold 3 (Test):\n",
      "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (26).java, Predicted Label: 1, True Label: 0\n",
      "File: nons (8).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (13).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
      "Precision: 0.6, Recall: 0.6, F-score: 0.6\n",
      "Fold 4 (Test):\n",
      "File: nons (7).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (14).java, Predicted Label: 1, True Label: 0\n",
      "File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (6).java, Predicted Label: 1, True Label: 0\n",
      "Precision: 0.4333333333333333, Recall: 0.4, F-score: 0.4\n",
      "Fold 5 (Test):\n",
      "File: nons (18).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (14).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (1).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (5).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n",
      "Fold 6 (Test):\n",
      "File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (19).java, Predicted Label: 1, True Label: 0\n",
      "File: nons (20).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (24).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.6, Recall: 0.6, F-score: 0.6\n",
      "Fold 7 (Test):\n",
      "File: nons (22).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (23).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (17).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (4).java, Predicted Label: 0, True Label: 1\n",
      "Precision: 0.8, Recall: 0.6, F-score: 0.5666666666666667\n",
      "Fold 8 (Test):\n",
      "File: nons (25).java, Predicted Label: 1, True Label: 0\n",
      "File: singleton (3).java, Predicted Label: 0, True Label: 1\n",
      "File: singleton (16).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (9).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (7).java, Predicted Label: 0, True Label: 1\n",
      "Precision: 0.1, Recall: 0.2, F-score: 0.13333333333333333\n",
      "Fold 9 (Test):\n",
      "File: nons (3).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (22).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (10).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (19).java, Predicted Label: 0, True Label: 1\n",
      "File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
      "Fold 10 (Test):\n",
      "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (16).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (11).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from tqdm import tqdm\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize lists to store program names, labels, and contents\n",
    "program_names = []\n",
    "labels = []\n",
    "contents = []\n",
    "\n",
    "# Function to label programs as positive (1) or negative (0) based on the file name\n",
    "def label_program(file_name):\n",
    "    return 1 if \"singleton\" in file_name.lower() else 0\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_content = f.read()\n",
    "            program_names.append(program_file)\n",
    "            labels.append(label_program(program_file))\n",
    "            contents.append(program_content)\n",
    "\n",
    "# Create a DataFrame to store the data\n",
    "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_path = 'embeddings/sin12.csv'  # Replace with the desired CSV file path\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Labels and contents saved to {csv_path}\")\n",
    "\n",
    "\n",
    "# Define the path to the CSV file containing program names, labels, and content\n",
    "csv_path = 'embeddings/sin12.csv'  # Replace with the actual CSV file path\n",
    "\n",
    "# Initialize RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Load the DataFrame from the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Function to calculate embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Calculate embeddings for each program by considering embeddings of individual lines\n",
    "program_embeddings = []\n",
    "for content in tqdm(df['Content']):\n",
    "    lines = content.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Convert program_embeddings to NumPy array\n",
    "program_embeddings = np.vstack(program_embeddings)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
    "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
    "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
    "\n",
    "    # Apply k-nearest neighbor classification\n",
    "    n_neighbors = 3  # Number of neighbors to consider\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set\n",
    "    test_predictions = knn.predict(X_test)\n",
    "    \n",
    "    # Calculate precision, recall, and f-score for the current fold\n",
    "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
    "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
    "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
    "\n",
    "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
    "    if precision >= 0.1 and recall >= 0.1 and f1 >= 0.1:\n",
    "        print(f\"Fold {fold + 1} (Test):\")\n",
    "        for i in range(len(test_predictions)):\n",
    "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
    "        \n",
    "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0c2142af-96d7-498d-a518-773271117efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Singleton using different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4781086f-4d12-40e8-b0b2-1f91d73711c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and contents saved to embeddings/sin13.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 51/51 [03:23<00:00,  4.00s/it]\n",
      "/cephyr/users/sushantk/Alvis/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (Test):\n",
      "File: nons (54).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (17).java, Predicted Label: 1, True Label: 0\n",
      "File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (23).java, Predicted Label: 1, True Label: 0\n",
      "Precision: 0.7999999999999999, Recall: 0.6666666666666666, F-score: 0.6249999999999999\n",
      "Fold 2 (Test):\n",
      "File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (68).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (67).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (6).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (32).java, Predicted Label: 1, True Label: 0\n",
      "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
      "Fold 3 (Test):\n",
      "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (26).java, Predicted Label: 1, True Label: 0\n",
      "File: nons (66).java, Predicted Label: 1, True Label: 0\n",
      "File: nons (51).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
      "Precision: 0.4333333333333333, Recall: 0.4, F-score: 0.4\n",
      "Fold 4 (Test):\n",
      "File: nons (4).java, Predicted Label: 1, True Label: 0\n",
      "File: nons (43).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (31).java, Predicted Label: 1, True Label: 0\n",
      "Precision: 0.4333333333333333, Recall: 0.4, F-score: 0.4\n",
      "Fold 5 (Test):\n",
      "File: nons (42).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (44).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (14).java, Predicted Label: 0, True Label: 1\n",
      "File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (52).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.36, Recall: 0.6, F-score: 0.4499999999999999\n",
      "Fold 6 (Test):\n",
      "File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (34).java, Predicted Label: 1, True Label: 0\n",
      "File: nons (53).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (11).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (65).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.3, Recall: 0.4, F-score: 0.34285714285714286\n",
      "Fold 7 (Test):\n",
      "File: nons (33).java, Predicted Label: 0, True Label: 0\n",
      "File: nons (41).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (23).java, Predicted Label: 0, True Label: 1\n",
      "File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (4).java, Predicted Label: 0, True Label: 1\n",
      "Precision: 0.8, Recall: 0.6, F-score: 0.5666666666666667\n",
      "Fold 8 (Test):\n",
      "File: nons (25).java, Predicted Label: 1, True Label: 0\n",
      "File: singleton (3).java, Predicted Label: 0, True Label: 1\n",
      "File: singleton (16).java, Predicted Label: 0, True Label: 1\n",
      "File: nons (24).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (7).java, Predicted Label: 0, True Label: 1\n",
      "Precision: 0.1, Recall: 0.2, F-score: 0.13333333333333333\n",
      "Fold 9 (Test):\n",
      "File: nons (7).java, Predicted Label: 1, True Label: 0\n",
      "File: singleton (22).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (15).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (19).java, Predicted Label: 0, True Label: 1\n",
      "File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 0.6, Recall: 0.6, F-score: 0.6\n",
      "Fold 10 (Test):\n",
      "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
      "File: nons (14).java, Predicted Label: 1, True Label: 0\n",
      "File: nons (16).java, Predicted Label: 0, True Label: 0\n",
      "File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
      "File: singleton (17).java, Predicted Label: 0, True Label: 1\n",
      "Precision: 0.6, Recall: 0.6, F-score: 0.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from tqdm import tqdm\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize lists to store program names, labels, and contents\n",
    "program_names = []\n",
    "labels = []\n",
    "contents = []\n",
    "\n",
    "# Function to label programs as positive (1) or negative (0) based on the file name\n",
    "def label_program(file_name):\n",
    "    return 1 if \"singleton\" in file_name.lower() else 0\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_content = f.read()\n",
    "            program_names.append(program_file)\n",
    "            labels.append(label_program(program_file))\n",
    "            contents.append(program_content)\n",
    "\n",
    "# Create a DataFrame to store the data\n",
    "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_path = 'embeddings/sin13.csv'  # Replace with the desired CSV file path\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Labels and contents saved to {csv_path}\")\n",
    "\n",
    "\n",
    "# Define the path to the CSV file containing program names, labels, and content\n",
    "csv_path = 'embeddings/sin13.csv'  # Replace with the actual CSV file path\n",
    "\n",
    "# Initialize RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Load the DataFrame from the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Function to calculate embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Calculate embeddings for each program by considering embeddings of individual lines\n",
    "program_embeddings = []\n",
    "for content in tqdm(df['Content']):\n",
    "    lines = content.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Convert program_embeddings to NumPy array\n",
    "program_embeddings = np.vstack(program_embeddings)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 10\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
    "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
    "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
    "\n",
    "    # Apply k-nearest neighbor classification\n",
    "    n_neighbors = 3  # Number of neighbors to consider\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set\n",
    "    test_predictions = knn.predict(X_test)\n",
    "    \n",
    "    # Calculate precision, recall, and f-score for the current fold\n",
    "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
    "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
    "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
    "\n",
    "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
    "    if precision >= 0.1 and recall >= 0.1 and f1 >= 0.1:\n",
    "        print(f\"Fold {fold + 1} (Test):\")\n",
    "        for i in range(len(test_predictions)):\n",
    "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
    "        \n",
    "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "513ee4a4-4d42-4bcc-b0f5-be95126127e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abstract Factory with different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "77a73089-0a73-41f6-a06e-c2c1861c11d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and contents saved to embeddings/af1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 33/33 [02:42<00:00,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (Test):\n",
      "File: nonab (72).java, Predicted Label: 0, True Label: 0\n",
      "File: abstractfactory (2).java, Predicted Label: 1, True Label: 1\n",
      "File: nonab (2).java, Predicted Label: 0, True Label: 0\n",
      "File: abstractfactory (16).java, Predicted Label: 1, True Label: 1\n",
      "File: nonab (67).java, Predicted Label: 0, True Label: 0\n",
      "File: nonab (12).java, Predicted Label: 0, True Label: 0\n",
      "File: abstractfactory (6).java, Predicted Label: 0, True Label: 1\n",
      "Precision: 0.8857142857142858, Recall: 0.8571428571428571, F-score: 0.8507936507936508\n",
      "Fold 2 (Test):\n",
      "File: nonab (11).java, Predicted Label: 0, True Label: 0\n",
      "File: nonab (1).java, Predicted Label: 1, True Label: 0\n",
      "File: abstractfactory (4).java, Predicted Label: 1, True Label: 1\n",
      "File: abstractfactory (5).java, Predicted Label: 1, True Label: 1\n",
      "File: abstractfactory (3).java, Predicted Label: 1, True Label: 1\n",
      "File: nonab (74).java, Predicted Label: 0, True Label: 0\n",
      "File: nonab (9).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.8928571428571429, Recall: 0.8571428571428571, F-score: 0.8571428571428571\n",
      "Fold 3 (Test):\n",
      "File: nonab (19).java, Predicted Label: 0, True Label: 0\n",
      "File: nonab (5).java, Predicted Label: 0, True Label: 0\n",
      "File: abstractfactory (13).java, Predicted Label: 0, True Label: 1\n",
      "File: nonab (83).java, Predicted Label: 0, True Label: 0\n",
      "File: abstractfactory (11).java, Predicted Label: 1, True Label: 1\n",
      "File: abstractfactory (8).java, Predicted Label: 1, True Label: 1\n",
      "File: abstractfactory (14).java, Predicted Label: 0, True Label: 1\n",
      "Precision: 0.8285714285714285, Recall: 0.7142857142857143, F-score: 0.7023809523809523\n",
      "Fold 4 (Test):\n",
      "File: nonab (7).java, Predicted Label: 0, True Label: 0\n",
      "File: abstractfactory (9).java, Predicted Label: 1, True Label: 1\n",
      "File: abstractfactory (1).java, Predicted Label: 1, True Label: 1\n",
      "File: abstractfactory (12).java, Predicted Label: 1, True Label: 1\n",
      "File: nonab (85).java, Predicted Label: 1, True Label: 0\n",
      "File: nonab (18).java, Predicted Label: 1, True Label: 0\n",
      "Precision: 0.7999999999999999, Recall: 0.6666666666666666, F-score: 0.6249999999999999\n",
      "Fold 5 (Test):\n",
      "File: abstractfactory (10).java, Predicted Label: 1, True Label: 1\n",
      "File: nonab (8).java, Predicted Label: 0, True Label: 0\n",
      "File: abstractfactory (15).java, Predicted Label: 1, True Label: 1\n",
      "File: abstractfactory (7).java, Predicted Label: 1, True Label: 1\n",
      "File: nonab (54).java, Predicted Label: 0, True Label: 0\n",
      "File: nonab (49).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from tqdm import tqdm\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'abstractfactory'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize lists to store program names, labels, and contents\n",
    "program_names = []\n",
    "labels = []\n",
    "contents = []\n",
    "\n",
    "# Function to label programs as positive (1) or negative (0) based on the file name\n",
    "def label_program(file_name):\n",
    "    return 1 if \"abstractfactory\" in file_name.lower() else 0\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_content = f.read()\n",
    "            program_names.append(program_file)\n",
    "            labels.append(label_program(program_file))\n",
    "            contents.append(program_content)\n",
    "\n",
    "# Create a DataFrame to store the data\n",
    "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_path = 'embeddings/af1.csv'  # Replace with the desired CSV file path\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Labels and contents saved to {csv_path}\")\n",
    "\n",
    "\n",
    "# Define the path to the CSV file containing program names, labels, and content\n",
    "csv_path = 'embeddings/af1.csv'  # Replace with the actual CSV file path\n",
    "\n",
    "# Initialize RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Load the DataFrame from the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Function to calculate embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Calculate embeddings for each program by considering embeddings of individual lines\n",
    "program_embeddings = []\n",
    "for content in tqdm(df['Content']):\n",
    "    lines = content.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Convert program_embeddings to NumPy array\n",
    "program_embeddings = np.vstack(program_embeddings)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
    "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
    "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
    "\n",
    "    # Apply k-nearest neighbor classification\n",
    "    n_neighbors = 3  # Number of neighbors to consider\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set\n",
    "    test_predictions = knn.predict(X_test)\n",
    "    \n",
    "    # Calculate precision, recall, and f-score for the current fold\n",
    "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
    "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
    "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
    "\n",
    "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
    "    if precision >= 0.1 and recall >= 0.1 and f1 >= 0.1:\n",
    "        print(f\"Fold {fold + 1} (Test):\")\n",
    "        for i in range(len(test_predictions)):\n",
    "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
    "        \n",
    "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e646d60-ed06-40e2-bd41-494dee25b9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abstract Factory using different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4db74ca4-2b59-42f5-aaae-66b2d1ca2040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and contents saved to embeddings/af2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 32/32 [02:20<00:00,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (Test):\n",
      "File: nonab (11).java, Predicted Label: 1, True Label: 0\n",
      "File: abstractfactory (2).java, Predicted Label: 1, True Label: 1\n",
      "File: nonab (2).java, Predicted Label: 0, True Label: 0\n",
      "File: abstractfactory (16).java, Predicted Label: 1, True Label: 1\n",
      "File: nonab (6).java, Predicted Label: 0, True Label: 0\n",
      "File: nonab (16).java, Predicted Label: 0, True Label: 0\n",
      "File: abstractfactory (6).java, Predicted Label: 0, True Label: 1\n",
      "Precision: 0.7142857142857143, Recall: 0.7142857142857143, F-score: 0.7142857142857143\n",
      "Fold 2 (Test):\n",
      "File: nonab (5).java, Predicted Label: 0, True Label: 0\n",
      "File: nonab (10).java, Predicted Label: 0, True Label: 0\n",
      "File: abstractfactory (4).java, Predicted Label: 1, True Label: 1\n",
      "File: abstractfactory (5).java, Predicted Label: 1, True Label: 1\n",
      "File: abstractfactory (3).java, Predicted Label: 1, True Label: 1\n",
      "File: nonab (12).java, Predicted Label: 0, True Label: 0\n",
      "File: abstractfactory (14).java, Predicted Label: 0, True Label: 1\n",
      "Precision: 0.8928571428571429, Recall: 0.8571428571428571, F-score: 0.8571428571428571\n",
      "Fold 3 (Test):\n",
      "File: nonab (7).java, Predicted Label: 0, True Label: 0\n",
      "File: nonab (15).java, Predicted Label: 0, True Label: 0\n",
      "File: abstractfactory (13).java, Predicted Label: 0, True Label: 1\n",
      "File: nonab (13).java, Predicted Label: 0, True Label: 0\n",
      "File: abstractfactory (11).java, Predicted Label: 1, True Label: 1\n",
      "File: abstractfactory (8).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 0.875, Recall: 0.8333333333333334, F-score: 0.8285714285714286\n",
      "Fold 4 (Test):\n",
      "File: abstractfactory (9).java, Predicted Label: 1, True Label: 1\n",
      "File: nonab (3).java, Predicted Label: 0, True Label: 0\n",
      "File: abstractfactory (1).java, Predicted Label: 1, True Label: 1\n",
      "File: abstractfactory (12).java, Predicted Label: 1, True Label: 1\n",
      "File: nonab (4).java, Predicted Label: 1, True Label: 0\n",
      "File: nonab (9).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.875, Recall: 0.8333333333333334, F-score: 0.8285714285714286\n",
      "Fold 5 (Test):\n",
      "File: nonab (1).java, Predicted Label: 1, True Label: 0\n",
      "File: abstractfactory (10).java, Predicted Label: 1, True Label: 1\n",
      "File: nonab (8).java, Predicted Label: 0, True Label: 0\n",
      "File: nonab (14).java, Predicted Label: 1, True Label: 0\n",
      "File: abstractfactory (15).java, Predicted Label: 1, True Label: 1\n",
      "File: abstractfactory (7).java, Predicted Label: 1, True Label: 1\n",
      "Precision: 0.7999999999999999, Recall: 0.6666666666666666, F-score: 0.6249999999999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from tqdm import tqdm\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'abstractfactory'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize lists to store program names, labels, and contents\n",
    "program_names = []\n",
    "labels = []\n",
    "contents = []\n",
    "\n",
    "# Function to label programs as positive (1) or negative (0) based on the file name\n",
    "def label_program(file_name):\n",
    "    return 1 if \"abstractfactory\" in file_name.lower() else 0\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_content = f.read()\n",
    "            program_names.append(program_file)\n",
    "            labels.append(label_program(program_file))\n",
    "            contents.append(program_content)\n",
    "\n",
    "# Create a DataFrame to store the data\n",
    "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_path = 'embeddings/af2.csv'  # Replace with the desired CSV file path\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Labels and contents saved to {csv_path}\")\n",
    "\n",
    "\n",
    "# Define the path to the CSV file containing program names, labels, and content\n",
    "csv_path = 'embeddings/af2.csv'  # Replace with the actual CSV file path\n",
    "\n",
    "# Initialize RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Load the DataFrame from the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Function to calculate embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Calculate embeddings for each program by considering embeddings of individual lines\n",
    "program_embeddings = []\n",
    "for content in tqdm(df['Content']):\n",
    "    lines = content.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Convert program_embeddings to NumPy array\n",
    "program_embeddings = np.vstack(program_embeddings)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
    "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
    "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
    "\n",
    "    # Apply k-nearest neighbor classification\n",
    "    n_neighbors = 3  # Number of neighbors to consider\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set\n",
    "    test_predictions = knn.predict(X_test)\n",
    "    \n",
    "    # Calculate precision, recall, and f-score for the current fold\n",
    "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
    "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
    "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
    "\n",
    "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
    "    if precision >= 0.1 and recall >= 0.1 and f1 >= 0.1:\n",
    "        print(f\"Fold {fold + 1} (Test):\")\n",
    "        for i in range(len(test_predictions)):\n",
    "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
    "        \n",
    "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dffd5d6a-fb1a-48e5-93fe-09f8fcbe6b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abstract Factory using different settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fe26f1e2-a2ec-41e8-b11f-4a34b7312784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and contents saved to embeddings/af3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 32/32 [03:27<00:00,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 (Test):\n",
      "File: nonab (11).java, Predicted Label: 1, True Label: 0\n",
      "File: nonab (48).java, Predicted Label: 0, True Label: 0\n",
      "File: abstractfactory (2).java, Predicted Label: 0, True Label: 1\n",
      "File: abstractfactory (16).java, Predicted Label: 0, True Label: 1\n",
      "File: nonab (8).java, Predicted Label: 0, True Label: 0\n",
      "File: abstractfactory (4).java, Predicted Label: 1, True Label: 1\n",
      "File: abstractfactory (5).java, Predicted Label: 0, True Label: 1\n",
      "File: nonab (3).java, Predicted Label: 0, True Label: 0\n",
      "File: abstractfactory (3).java, Predicted Label: 0, True Label: 1\n",
      "File: nonab (4).java, Predicted Label: 0, True Label: 0\n",
      "File: abstractfactory (8).java, Predicted Label: 0, True Label: 1\n",
      "File: abstractfactory (14).java, Predicted Label: 0, True Label: 1\n",
      "File: nonab (63).java, Predicted Label: 0, True Label: 0\n",
      "File: nonab (17).java, Predicted Label: 1, True Label: 0\n",
      "File: nonab (18).java, Predicted Label: 0, True Label: 0\n",
      "File: abstractfactory (6).java, Predicted Label: 0, True Label: 1\n",
      "Precision: 0.39743589743589747, Recall: 0.4375, F-score: 0.37662337662337664\n",
      "Fold 2 (Test):\n",
      "File: nonab (5).java, Predicted Label: 0, True Label: 0\n",
      "File: nonab (65).java, Predicted Label: 1, True Label: 0\n",
      "File: nonab (7).java, Predicted Label: 0, True Label: 0\n",
      "File: abstractfactory (10).java, Predicted Label: 0, True Label: 1\n",
      "File: abstractfactory (9).java, Predicted Label: 0, True Label: 1\n",
      "File: abstractfactory (13).java, Predicted Label: 0, True Label: 1\n",
      "File: abstractfactory (1).java, Predicted Label: 1, True Label: 1\n",
      "File: abstractfactory (12).java, Predicted Label: 0, True Label: 1\n",
      "File: nonab (14).java, Predicted Label: 0, True Label: 0\n",
      "File: nonab (74).java, Predicted Label: 0, True Label: 0\n",
      "File: abstractfactory (15).java, Predicted Label: 1, True Label: 1\n",
      "File: nonab (40).java, Predicted Label: 0, True Label: 0\n",
      "File: abstractfactory (11).java, Predicted Label: 0, True Label: 1\n",
      "File: abstractfactory (7).java, Predicted Label: 0, True Label: 1\n",
      "File: nonab (12).java, Predicted Label: 1, True Label: 0\n",
      "File: nonab (47).java, Predicted Label: 0, True Label: 0\n",
      "Precision: 0.5, Recall: 0.5, F-score: 0.4666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "from tqdm import tqdm\n",
    "# Define the path to the folder containing your Java programs\n",
    "java_programs_folder = 'abstractfactory'  # Replace with the actual folder path\n",
    "\n",
    "# Initialize lists to store program names, labels, and contents\n",
    "program_names = []\n",
    "labels = []\n",
    "contents = []\n",
    "\n",
    "# Function to label programs as positive (1) or negative (0) based on the file name\n",
    "def label_program(file_name):\n",
    "    return 1 if \"abstractfactory\" in file_name.lower() else 0\n",
    "\n",
    "# Load Java programs from the folder and classify them as positive or negative\n",
    "for program_file in os.listdir(java_programs_folder):\n",
    "    file_path = os.path.join(java_programs_folder, program_file)\n",
    "\n",
    "    # Check if the item is a file, not a directory\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
    "            program_content = f.read()\n",
    "            program_names.append(program_file)\n",
    "            labels.append(label_program(program_file))\n",
    "            contents.append(program_content)\n",
    "\n",
    "# Create a DataFrame to store the data\n",
    "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_path = 'embeddings/af3.csv'  # Replace with the desired CSV file path\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Labels and contents saved to {csv_path}\")\n",
    "\n",
    "\n",
    "# Define the path to the CSV file containing program names, labels, and content\n",
    "csv_path = 'embeddings/af3.csv'  # Replace with the actual CSV file path\n",
    "\n",
    "# Initialize RoBERTa tokenizer and model\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Load the DataFrame from the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Function to calculate embeddings from text\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Calculate embeddings for each program by considering embeddings of individual lines\n",
    "program_embeddings = []\n",
    "for content in tqdm(df['Content']):\n",
    "    lines = content.split('\\n')\n",
    "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
    "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
    "\n",
    "# Convert program_embeddings to NumPy array\n",
    "program_embeddings = np.vstack(program_embeddings)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "n_splits = 2\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
    "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
    "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
    "\n",
    "    # Apply k-nearest neighbor classification\n",
    "    n_neighbors = 3  # Number of neighbors to consider\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions on the test set\n",
    "    test_predictions = knn.predict(X_test)\n",
    "    \n",
    "    # Calculate precision, recall, and f-score for the current fold\n",
    "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
    "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
    "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
    "\n",
    "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
    "    if precision >= 0.1 and recall >= 0.1 and f1 >= 0.1:\n",
    "        print(f\"Fold {fold + 1} (Test):\")\n",
    "        for i in range(len(test_predictions)):\n",
    "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
    "        \n",
    "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3605f92c-a527-4394-9078-e571f961ec69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
