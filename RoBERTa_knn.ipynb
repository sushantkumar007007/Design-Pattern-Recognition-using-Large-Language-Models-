{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21436028-c505-4770-97ce-f8f97aed7cdf",
      "metadata": {
        "id": "21436028-c505-4770-97ce-f8f97aed7cdf",
        "outputId": "a3e78bbd-99a6-40be-ccd7-7e9a29dc0c49"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nons (54).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (29).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (25).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (27).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (34).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (61).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.7777777777777778, Recall: 0.7777777777777778, F-score: 0.7777777777777778\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize the RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Function to extract embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Initialize lists to store Java programs and their corresponding labels\n",
        "java_programs = []\n",
        "program_labels = []\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_text = f.read()\n",
        "            java_programs.append(program_text)\n",
        "\n",
        "            # Check if the keyword \"singleton\" is present in the filename\n",
        "            if \"singleton\" in program_file:\n",
        "                program_labels.append(1)  # Positive class (implements singleton)\n",
        "            else:\n",
        "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
        "\n",
        "# Calculate embeddings for the Java programs line by line and take the mean\n",
        "program_embeddings = []\n",
        "for program in java_programs:\n",
        "    lines = program.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Apply standard scaling to normalize the embeddings\n",
        "scaler = StandardScaler()\n",
        "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 5  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [program_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
        "\n",
        "# Apply k-nearest neighbor classification\n",
        "n_neighbors = 3  # Number of neighbors to consider\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "predictions = knn.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print the classification results and performance metrics\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f87af8eb-ed17-49fa-ada0-ea9f06bb92a1",
      "metadata": {
        "id": "f87af8eb-ed17-49fa-ada0-ea9f06bb92a1"
      },
      "outputs": [],
      "source": [
        "Singleton on different setting of programs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81b05c02-96c0-42f8-80db-a5ff1883f035",
      "metadata": {
        "id": "81b05c02-96c0-42f8-80db-a5ff1883f035",
        "outputId": "884ea911-ea9a-4ec0-da1a-828a123ac640"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nons (54).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (25).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (25).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (27).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (18).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (19).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (55).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (34).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (24).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize the RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Function to extract embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Initialize lists to store Java programs and their corresponding labels\n",
        "java_programs = []\n",
        "program_labels = []\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_text = f.read()\n",
        "            java_programs.append(program_text)\n",
        "\n",
        "            # Check if the keyword \"singleton\" is present in the filename\n",
        "            if \"singleton\" in program_file:\n",
        "                program_labels.append(1)  # Positive class (implements singleton)\n",
        "            else:\n",
        "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
        "\n",
        "# Calculate embeddings for the Java programs line by line and take the mean\n",
        "program_embeddings = []\n",
        "for program in java_programs:\n",
        "    lines = program.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Apply standard scaling to normalize the embeddings\n",
        "scaler = StandardScaler()\n",
        "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 5  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [program_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
        "\n",
        "# Apply k-nearest neighbor classification\n",
        "n_neighbors = 3  # Number of neighbors to consider\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "predictions = knn.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print the classification results and performance metrics\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ced25be-d014-4bb9-9eb9-e6aa02c54196",
      "metadata": {
        "id": "1ced25be-d014-4bb9-9eb9-e6aa02c54196"
      },
      "outputs": [],
      "source": [
        "Singleton on different setting of programs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c71c07d-90ac-4ace-a0f2-59cfa49dbd1c",
      "metadata": {
        "id": "5c71c07d-90ac-4ace-a0f2-59cfa49dbd1c",
        "outputId": "1a5f05e5-8cc9-40e9-d7e0-a2c8deb3ae01"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nons (12).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (50).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (25).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (24).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (4).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (44).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (38).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (14).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize the RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Function to extract embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Initialize lists to store Java programs and their corresponding labels\n",
        "java_programs = []\n",
        "program_labels = []\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_text = f.read()\n",
        "            java_programs.append(program_text)\n",
        "\n",
        "            # Check if the keyword \"singleton\" is present in the filename\n",
        "            if \"singleton\" in program_file:\n",
        "                program_labels.append(1)  # Positive class (implements singleton)\n",
        "            else:\n",
        "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
        "\n",
        "# Calculate embeddings for the Java programs line by line and take the mean\n",
        "program_embeddings = []\n",
        "for program in java_programs:\n",
        "    lines = program.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Apply standard scaling to normalize the embeddings\n",
        "scaler = StandardScaler()\n",
        "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 5  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [program_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
        "\n",
        "# Apply k-nearest neighbor classification\n",
        "n_neighbors = 3  # Number of neighbors to consider\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "predictions = knn.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print the classification results and performance metrics\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e78e397-4cc7-417f-a4eb-7dc11c33f028",
      "metadata": {
        "id": "8e78e397-4cc7-417f-a4eb-7dc11c33f028"
      },
      "outputs": [],
      "source": [
        "Singleton with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f05d34b7-a97c-44a7-a882-0fadab8450fd",
      "metadata": {
        "id": "f05d34b7-a97c-44a7-a882-0fadab8450fd",
        "outputId": "f09bf16a-913b-455c-a3c6-050547d0fc5a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nons (54).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (25).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (42).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (27).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (18).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (55).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (34).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (61).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.9142857142857143, Recall: 0.9, F-score: 0.8967032967032967\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize the RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Function to extract embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Initialize lists to store Java programs and their corresponding labels\n",
        "java_programs = []\n",
        "program_labels = []\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_text = f.read()\n",
        "            java_programs.append(program_text)\n",
        "\n",
        "            # Check if the keyword \"singleton\" is present in the filename\n",
        "            if \"singleton\" in program_file:\n",
        "                program_labels.append(1)  # Positive class (implements singleton)\n",
        "            else:\n",
        "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
        "\n",
        "# Calculate embeddings for the Java programs line by line and take the mean\n",
        "program_embeddings = []\n",
        "for program in java_programs:\n",
        "    lines = program.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Apply standard scaling to normalize the embeddings\n",
        "scaler = StandardScaler()\n",
        "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 5  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [program_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
        "\n",
        "# Apply k-nearest neighbor classification\n",
        "n_neighbors = 3  # Number of neighbors to consider\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "predictions = knn.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print the classification results and performance metrics\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1172090d-21fc-4445-81e0-d7cfc1fbc01f",
      "metadata": {
        "id": "1172090d-21fc-4445-81e0-d7cfc1fbc01f"
      },
      "outputs": [],
      "source": [
        "Builder with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8449196d-4a54-4705-adb8-46f17ab3d14c",
      "metadata": {
        "id": "8449196d-4a54-4705-adb8-46f17ab3d14c",
        "outputId": "ba236e82-7b0c-4f23-db36-8c0e82938947"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: builder (2).java, Predicted Label: 1, True Label: 1\n",
            "File: builder (5).java, Predicted Label: 1, True Label: 1\n",
            "File: nonbuilder (55).java, Predicted Label: 1, True Label: 1\n",
            "File: builder (6).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'builder'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize the RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Function to extract embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Initialize lists to store Java programs and their corresponding labels\n",
        "java_programs = []\n",
        "program_labels = []\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_text = f.read()\n",
        "            java_programs.append(program_text)\n",
        "\n",
        "            # Check if the keyword \"singleton\" is present in the filename\n",
        "            if \"builder\" in program_file:\n",
        "                program_labels.append(1)  # Positive class (implements singleton)\n",
        "            else:\n",
        "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
        "\n",
        "# Calculate embeddings for the Java programs line by line and take the mean\n",
        "program_embeddings = []\n",
        "for program in java_programs:\n",
        "    lines = program.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Apply standard scaling to normalize the embeddings\n",
        "scaler = StandardScaler()\n",
        "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 5  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [program_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
        "\n",
        "# Apply k-nearest neighbor classification\n",
        "n_neighbors = 3  # Number of neighbors to consider\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "predictions = knn.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print the classification results and performance metrics\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47daabed-0321-432b-b8ec-52b2ecd41c2c",
      "metadata": {
        "id": "47daabed-0321-432b-b8ec-52b2ecd41c2c"
      },
      "outputs": [],
      "source": [
        "Builder with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "570aad8c-5fc9-476b-83c2-043a2d0adbee",
      "metadata": {
        "id": "570aad8c-5fc9-476b-83c2-043a2d0adbee",
        "outputId": "9c3cb635-d2e7-4a0c-ee7a-80189c259546"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonb (14).java, Predicted Label: 1, True Label: 1\n",
            "File: builder (2).java, Predicted Label: 1, True Label: 1\n",
            "File: builder (5).java, Predicted Label: 0, True Label: 0\n",
            "File: builder (6).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'builder'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize the RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Function to extract embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Initialize lists to store Java programs and their corresponding labels\n",
        "java_programs = []\n",
        "program_labels = []\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_text = f.read()\n",
        "            java_programs.append(program_text)\n",
        "\n",
        "            # Check if the keyword \"singleton\" is present in the filename\n",
        "            if \"builder\" in program_file:\n",
        "                program_labels.append(1)  # Positive class (implements singleton)\n",
        "            else:\n",
        "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
        "\n",
        "# Calculate embeddings for the Java programs line by line and take the mean\n",
        "program_embeddings = []\n",
        "for program in java_programs:\n",
        "    lines = program.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Apply standard scaling to normalize the embeddings\n",
        "scaler = StandardScaler()\n",
        "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 5  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [program_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
        "\n",
        "# Apply k-nearest neighbor classification\n",
        "n_neighbors = 3  # Number of neighbors to consider\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "predictions = knn.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print the classification results and performance metrics\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d28af0c9-077b-4b56-9a64-c2dd0d6ed102",
      "metadata": {
        "id": "d28af0c9-077b-4b56-9a64-c2dd0d6ed102"
      },
      "outputs": [],
      "source": [
        "Builder with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd7079f5-2b8d-4817-b8c1-ba13893aa180",
      "metadata": {
        "id": "bd7079f5-2b8d-4817-b8c1-ba13893aa180",
        "outputId": "b9dccb2b-4ac1-4e60-c5ed-ff42b2faa64c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: builder (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nonb (89).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (49).java, Predicted Label: 1, True Label: 1\n",
            "File: nonb (28).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'builder'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize the RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Function to extract embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Initialize lists to store Java programs and their corresponding labels\n",
        "java_programs = []\n",
        "program_labels = []\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_text = f.read()\n",
        "            java_programs.append(program_text)\n",
        "\n",
        "            # Check if the keyword \"singleton\" is present in the filename\n",
        "            if \"builder\" in program_file:\n",
        "                program_labels.append(1)  # Positive class (implements singleton)\n",
        "            else:\n",
        "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
        "\n",
        "# Calculate embeddings for the Java programs line by line and take the mean\n",
        "program_embeddings = []\n",
        "for program in java_programs:\n",
        "    lines = program.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Apply standard scaling to normalize the embeddings\n",
        "scaler = StandardScaler()\n",
        "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 5  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [program_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
        "\n",
        "# Apply k-nearest neighbor classification\n",
        "n_neighbors = 3  # Number of neighbors to consider\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "predictions = knn.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print the classification results and performance metrics\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a358eaca-23b2-4601-ab2b-732b209efafc",
      "metadata": {
        "id": "a358eaca-23b2-4601-ab2b-732b209efafc"
      },
      "outputs": [],
      "source": [
        "Builder with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87258ad9-eeaa-4d7c-b030-23a9ca1a00cd",
      "metadata": {
        "id": "87258ad9-eeaa-4d7c-b030-23a9ca1a00cd",
        "outputId": "ffb763bd-68f1-46f3-87c0-2d929ff8ba90"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonb (14).java, Predicted Label: 1, True Label: 1\n",
            "File: builder (2).java, Predicted Label: 0, True Label: 0\n",
            "File: nonb (133).java, Predicted Label: 0, True Label: 0\n",
            "File: builder (5).java, Predicted Label: 1, True Label: 1\n",
            "File: builder (6).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'builder'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize the RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Function to extract embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Initialize lists to store Java programs and their corresponding labels\n",
        "java_programs = []\n",
        "program_labels = []\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_text = f.read()\n",
        "            java_programs.append(program_text)\n",
        "\n",
        "            # Check if the keyword \"singleton\" is present in the filename\n",
        "            if \"builder\" in program_file:\n",
        "                program_labels.append(1)  # Positive class (implements singleton)\n",
        "            else:\n",
        "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
        "\n",
        "# Calculate embeddings for the Java programs line by line and take the mean\n",
        "program_embeddings = []\n",
        "for program in java_programs:\n",
        "    lines = program.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Apply standard scaling to normalize the embeddings\n",
        "scaler = StandardScaler()\n",
        "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 5  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [program_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
        "\n",
        "# Apply k-nearest neighbor classification\n",
        "n_neighbors = 3  # Number of neighbors to consider\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "predictions = knn.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print the classification results and performance metrics\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08fc3bd2-3e21-48eb-b17c-eb1937cb082e",
      "metadata": {
        "id": "08fc3bd2-3e21-48eb-b17c-eb1937cb082e"
      },
      "outputs": [],
      "source": [
        "Builder with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81c72d51-0f6e-4109-810b-ebdeae1e970d",
      "metadata": {
        "id": "81c72d51-0f6e-4109-810b-ebdeae1e970d",
        "outputId": "b8143eb8-47c3-40b1-cbdc-d05c8f186915"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: builder (2).java, Predicted Label: 1, True Label: 1\n",
            "File: builder (5).java, Predicted Label: 1, True Label: 1\n",
            "File: builder (6).java, Predicted Label: 1, True Label: 1\n",
            "File: nonb (18).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'builder'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize the RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Function to extract embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Initialize lists to store Java programs and their corresponding labels\n",
        "java_programs = []\n",
        "program_labels = []\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_text = f.read()\n",
        "            java_programs.append(program_text)\n",
        "\n",
        "            # Check if the keyword \"singleton\" is present in the filename\n",
        "            if \"builder\" in program_file:\n",
        "                program_labels.append(1)  # Positive class (implements singleton)\n",
        "            else:\n",
        "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
        "\n",
        "# Calculate embeddings for the Java programs line by line and take the mean\n",
        "program_embeddings = []\n",
        "for program in java_programs:\n",
        "    lines = program.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Apply standard scaling to normalize the embeddings\n",
        "scaler = StandardScaler()\n",
        "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 5  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [program_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
        "\n",
        "# Apply k-nearest neighbor classification\n",
        "n_neighbors = 3  # Number of neighbors to consider\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "predictions = knn.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print the classification results and performance metrics\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16ec4c6d-3d26-41c4-8e22-3621ccb40c56",
      "metadata": {
        "id": "16ec4c6d-3d26-41c4-8e22-3621ccb40c56"
      },
      "outputs": [],
      "source": [
        "Abstract Factory with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c126b144-af14-42d5-9c4b-f12848c020d6",
      "metadata": {
        "id": "c126b144-af14-42d5-9c4b-f12848c020d6",
        "outputId": "7684dc39-5dc6-4f7d-84ad-f8cdd0f1404e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonab (11).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (2).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (5).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (81).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (7).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (10).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'abstractfactory'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize the RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Function to extract embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Initialize lists to store Java programs and their corresponding labels\n",
        "java_programs = []\n",
        "program_labels = []\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_text = f.read()\n",
        "            java_programs.append(program_text)\n",
        "\n",
        "            # Check if the keyword \"singleton\" is present in the filename\n",
        "            if \"abstractfactory\" in program_file:\n",
        "                program_labels.append(1)  # Positive class (implements singleton)\n",
        "            else:\n",
        "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
        "\n",
        "# Calculate embeddings for the Java programs line by line and take the mean\n",
        "program_embeddings = []\n",
        "for program in java_programs:\n",
        "    lines = program.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Apply standard scaling to normalize the embeddings\n",
        "scaler = StandardScaler()\n",
        "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 5  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [program_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
        "\n",
        "# Apply k-nearest neighbor classification\n",
        "n_neighbors = 5  # Number of neighbors to consider\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "predictions = knn.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print the classification results and performance metrics\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c896cc7-6d40-4867-b577-aeee54460984",
      "metadata": {
        "id": "4c896cc7-6d40-4867-b577-aeee54460984"
      },
      "outputs": [],
      "source": [
        "Abstract Factory with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d693a8b5-5bd0-4328-bc94-479703243122",
      "metadata": {
        "id": "d693a8b5-5bd0-4328-bc94-479703243122",
        "outputId": "11d69dc6-5f3d-42da-c181-2725d0e75dfa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonab (11).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (48).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (2).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (5).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (65).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (7).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (10).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'abstractfactory'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize the RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Function to extract embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Initialize lists to store Java programs and their corresponding labels\n",
        "java_programs = []\n",
        "program_labels = []\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_text = f.read()\n",
        "            java_programs.append(program_text)\n",
        "\n",
        "            # Check if the keyword \"singleton\" is present in the filename\n",
        "            if \"abstractfactory\" in program_file:\n",
        "                program_labels.append(1)  # Positive class (implements singleton)\n",
        "            else:\n",
        "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
        "\n",
        "# Calculate embeddings for the Java programs line by line and take the mean\n",
        "program_embeddings = []\n",
        "for program in java_programs:\n",
        "    lines = program.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Apply standard scaling to normalize the embeddings\n",
        "scaler = StandardScaler()\n",
        "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 5  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [program_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
        "\n",
        "# Apply k-nearest neighbor classification\n",
        "n_neighbors = 5  # Number of neighbors to consider\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "predictions = knn.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print the classification results and performance metrics\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3224b654-a186-4728-bc1b-f71552e980cd",
      "metadata": {
        "id": "3224b654-a186-4728-bc1b-f71552e980cd"
      },
      "outputs": [],
      "source": [
        "Abstract Factory with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebf17313-5717-4580-a791-3e95058b2af5",
      "metadata": {
        "id": "ebf17313-5717-4580-a791-3e95058b2af5",
        "outputId": "7a2029f1-390a-4aaf-b539-418bc5cb4306"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonab (11).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (48).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (2).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (5).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (65).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (7).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (10).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'abstractfactory'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize the RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Function to extract embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Initialize lists to store Java programs and their corresponding labels\n",
        "java_programs = []\n",
        "program_labels = []\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_text = f.read()\n",
        "            java_programs.append(program_text)\n",
        "\n",
        "            # Check if the keyword \"singleton\" is present in the filename\n",
        "            if \"abstractfactory\" in program_file:\n",
        "                program_labels.append(1)  # Positive class (implements singleton)\n",
        "            else:\n",
        "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
        "\n",
        "# Calculate embeddings for the Java programs line by line and take the mean\n",
        "program_embeddings = []\n",
        "for program in java_programs:\n",
        "    lines = program.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Apply standard scaling to normalize the embeddings\n",
        "scaler = StandardScaler()\n",
        "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 5  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [program_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
        "\n",
        "# Apply k-nearest neighbor classification\n",
        "n_neighbors = 5  # Number of neighbors to consider\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "predictions = knn.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print the classification results and performance metrics\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96efb97f-49f3-4893-9863-3b6c5d0bd40c",
      "metadata": {
        "id": "96efb97f-49f3-4893-9863-3b6c5d0bd40c"
      },
      "outputs": [],
      "source": [
        "Abstract Factory with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85703b70-e65c-4aae-8a8f-12bc6a13e577",
      "metadata": {
        "id": "85703b70-e65c-4aae-8a8f-12bc6a13e577",
        "outputId": "60324cd7-e908-4674-89f0-801017fea4e9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: non-DP (37).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (2).java, Predicted Label: 0, True Label: 0\n",
            "File: non-DP (43).java, Predicted Label: 1, True Label: 1\n",
            "File: non-DP (42).java, Predicted Label: 1, True Label: 1\n",
            "File: non-DP (39).java, Predicted Label: 0, True Label: 0\n",
            "File: non-DP (31).java, Predicted Label: 1, True Label: 1\n",
            "File: non-DP (38).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'abstractfactory'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize the RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Function to extract embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Initialize lists to store Java programs and their corresponding labels\n",
        "java_programs = []\n",
        "program_labels = []\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_text = f.read()\n",
        "            java_programs.append(program_text)\n",
        "\n",
        "            # Check if the keyword \"singleton\" is present in the filename\n",
        "            if \"abstractfactory\" in program_file:\n",
        "                program_labels.append(1)  # Positive class (implements singleton)\n",
        "            else:\n",
        "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
        "\n",
        "# Calculate embeddings for the Java programs line by line and take the mean\n",
        "program_embeddings = []\n",
        "for program in java_programs:\n",
        "    lines = program.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Apply standard scaling to normalize the embeddings\n",
        "scaler = StandardScaler()\n",
        "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 5  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [program_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
        "\n",
        "# Apply k-nearest neighbor classification\n",
        "n_neighbors = 5  # Number of neighbors to consider\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "predictions = knn.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print the classification results and performance metrics\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89c959c6-96e9-4ac8-a6b9-cca5a65688e9",
      "metadata": {
        "id": "89c959c6-96e9-4ac8-a6b9-cca5a65688e9"
      },
      "outputs": [],
      "source": [
        "Abstract Factory with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2e7f42a-8f7c-4317-9f98-36be0efa6180",
      "metadata": {
        "id": "a2e7f42a-8f7c-4317-9f98-36be0efa6180",
        "outputId": "6e555698-71e5-43f8-b4e1-dd4ac9f3cb9a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nondp (18).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nondp (29).java, Predicted Label: 1, True Label: 1\n",
            "File: nondp (31).java, Predicted Label: 1, True Label: 1\n",
            "File: nondp (11).java, Predicted Label: 1, True Label: 1\n",
            "File: nondp (23).java, Predicted Label: 1, True Label: 1\n",
            "File: nondp (38).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (30).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'abstractfactory'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize the RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Function to extract embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Initialize lists to store Java programs and their corresponding labels\n",
        "java_programs = []\n",
        "program_labels = []\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_text = f.read()\n",
        "            java_programs.append(program_text)\n",
        "\n",
        "            # Check if the keyword \"singleton\" is present in the filename\n",
        "            if \"abstractfactory\" in program_file:\n",
        "                program_labels.append(1)  # Positive class (implements singleton)\n",
        "            else:\n",
        "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
        "\n",
        "# Calculate embeddings for the Java programs line by line and take the mean\n",
        "program_embeddings = []\n",
        "for program in java_programs:\n",
        "    lines = program.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Apply standard scaling to normalize the embeddings\n",
        "scaler = StandardScaler()\n",
        "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 5  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [program_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
        "\n",
        "# Apply k-nearest neighbor classification\n",
        "n_neighbors = 5  # Number of neighbors to consider\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "predictions = knn.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print the classification results and performance metrics\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c016ba81-1606-41b7-9f4b-a166928ac068",
      "metadata": {
        "id": "c016ba81-1606-41b7-9f4b-a166928ac068"
      },
      "outputs": [],
      "source": [
        "Abstract Factory with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4942a7f4-553d-4805-bef6-c744b1093841",
      "metadata": {
        "id": "4942a7f4-553d-4805-bef6-c744b1093841",
        "outputId": "8df55204-9112-42c5-c6a4-5208ae31b84e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nondp (7).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (2).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nondp (33).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (39).java, Predicted Label: 1, True Label: 0\n",
            "File: nondp (45).java, Predicted Label: 1, True Label: 1\n",
            "File: nondp (19).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (26).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.90625, Recall: 0.875, F-score: 0.876984126984127\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'abstractfactory'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize the RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Function to extract embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Initialize lists to store Java programs and their corresponding labels\n",
        "java_programs = []\n",
        "program_labels = []\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_text = f.read()\n",
        "            java_programs.append(program_text)\n",
        "\n",
        "            # Check if the keyword \"singleton\" is present in the filename\n",
        "            if \"abstractfactory\" in program_file:\n",
        "                program_labels.append(1)  # Positive class (implements singleton)\n",
        "            else:\n",
        "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
        "\n",
        "# Calculate embeddings for the Java programs line by line and take the mean\n",
        "program_embeddings = []\n",
        "for program in java_programs:\n",
        "    lines = program.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Apply standard scaling to normalize the embeddings\n",
        "scaler = StandardScaler()\n",
        "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 5  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [program_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
        "\n",
        "# Apply k-nearest neighbor classification\n",
        "n_neighbors = 5  # Number of neighbors to consider\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "predictions = knn.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print the classification results and performance metrics\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d6d0d0f-ab86-4aa1-82d6-effde98580ff",
      "metadata": {
        "id": "6d6d0d0f-ab86-4aa1-82d6-effde98580ff"
      },
      "outputs": [],
      "source": [
        "Abstract Factory with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "842e1325-240e-439d-ad34-86713bb50772",
      "metadata": {
        "id": "842e1325-240e-439d-ad34-86713bb50772",
        "outputId": "09a93182-6483-41d7-dc32-d56712cdf01e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nondp (7).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nondp (18).java, Predicted Label: 0, True Label: 1\n",
            "File: abstractfactory (2).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (33).java, Predicted Label: 1, True Label: 1\n",
            "File: nondp (29).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (31).java, Predicted Label: 1, True Label: 1\n",
            "File: nondp (11).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (39).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (45).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (19).java, Predicted Label: 1, True Label: 1\n",
            "File: nondp (23).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (38).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (30).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.9357142857142857, Recall: 0.9285714285714286, F-score: 0.926482873851295\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'abstractfactory'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize the RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Function to extract embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Initialize lists to store Java programs and their corresponding labels\n",
        "java_programs = []\n",
        "program_labels = []\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_text = f.read()\n",
        "            java_programs.append(program_text)\n",
        "\n",
        "            # Check if the keyword \"singleton\" is present in the filename\n",
        "            if \"abstractfactory\" in program_file:\n",
        "                program_labels.append(1)  # Positive class (implements singleton)\n",
        "            else:\n",
        "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
        "\n",
        "# Calculate embeddings for the Java programs line by line and take the mean\n",
        "program_embeddings = []\n",
        "for program in java_programs:\n",
        "    lines = program.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Apply standard scaling to normalize the embeddings\n",
        "scaler = StandardScaler()\n",
        "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 5  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [program_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
        "\n",
        "# Apply k-nearest neighbor classification\n",
        "n_neighbors = 5  # Number of neighbors to consider\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "predictions = knn.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print the classification results and performance metrics\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9f38ed5-850e-48d6-b8c9-cc4bf91c7174",
      "metadata": {
        "id": "a9f38ed5-850e-48d6-b8c9-cc4bf91c7174"
      },
      "outputs": [],
      "source": [
        "Factory Method with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "032c2bbe-cbc6-4fdf-81cc-1ea4d13ac177",
      "metadata": {
        "id": "032c2bbe-cbc6-4fdf-81cc-1ea4d13ac177",
        "outputId": "88aefbf8-be20-4676-ccbf-b2ba09e21698"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nondp (33).java, Predicted Label: 1, True Label: 1\n",
            "File: nondp (5).java, Predicted Label: 1, True Label: 1\n",
            "File: nondp (4).java, Predicted Label: 1, True Label: 1\n",
            "File: nondp (1).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (15).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (34).java, Predicted Label: 1, True Label: 1\n",
            "File: factorymethod (1).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (9).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (26).java, Predicted Label: 0, True Label: 0\n",
            "File: nondp (8).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'factorymethod'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize the RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Function to extract embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Initialize lists to store Java programs and their corresponding labels\n",
        "java_programs = []\n",
        "program_labels = []\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_text = f.read()\n",
        "            java_programs.append(program_text)\n",
        "\n",
        "            # Check if the keyword \"singleton\" is present in the filename\n",
        "            if \"factorymethod\" in program_file:\n",
        "                program_labels.append(1)  # Positive class (implements singleton)\n",
        "            else:\n",
        "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
        "\n",
        "# Calculate embeddings for the Java programs line by line and take the mean\n",
        "program_embeddings = []\n",
        "for program in java_programs:\n",
        "    lines = program.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Apply standard scaling to normalize the embeddings\n",
        "scaler = StandardScaler()\n",
        "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 5  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [program_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
        "\n",
        "# Apply k-nearest neighbor classification\n",
        "n_neighbors = 5  # Number of neighbors to consider\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "predictions = knn.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print the classification results and performance metrics\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f79379e-07c0-4a22-a940-5b7a3a4dde7b",
      "metadata": {
        "id": "7f79379e-07c0-4a22-a940-5b7a3a4dde7b"
      },
      "outputs": [],
      "source": [
        "Factory Method with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb184d59-1b0a-4630-8357-ffcff1324769",
      "metadata": {
        "id": "fb184d59-1b0a-4630-8357-ffcff1324769",
        "outputId": "76d291da-b2d0-4307-ef80-60fb173d8ba0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonfm (6).java, Predicted Label: 1, True Label: 0\n",
            "File: nonfm (5).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (13).java, Predicted Label: 0, True Label: 0\n",
            "File: factorymethod (1).java, Predicted Label: 1, True Label: 0\n",
            "File: factorymethod (9).java, Predicted Label: 1, True Label: 0\n",
            "File: nonfm (4).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.875, Recall: 0.5, F-score: 0.5428571428571429\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'factorymethod'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize the RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Function to extract embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Initialize lists to store Java programs and their corresponding labels\n",
        "java_programs = []\n",
        "program_labels = []\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_text = f.read()\n",
        "            java_programs.append(program_text)\n",
        "\n",
        "            # Check if the keyword \"singleton\" is present in the filename\n",
        "            if \"factorymethod\" in program_file:\n",
        "                program_labels.append(1)  # Positive class (implements singleton)\n",
        "            else:\n",
        "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
        "\n",
        "# Calculate embeddings for the Java programs line by line and take the mean\n",
        "program_embeddings = []\n",
        "for program in java_programs:\n",
        "    lines = program.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Apply standard scaling to normalize the embeddings\n",
        "scaler = StandardScaler()\n",
        "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 5  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [program_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
        "\n",
        "# Apply k-nearest neighbor classification\n",
        "n_neighbors = 5  # Number of neighbors to consider\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "predictions = knn.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print the classification results and performance metrics\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e10a505-bf93-4d4c-b565-d14766aef2bf",
      "metadata": {
        "id": "3e10a505-bf93-4d4c-b565-d14766aef2bf"
      },
      "outputs": [],
      "source": [
        "Factory Method with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ab54f55-5dd7-42ea-a8cf-ffb1c98b10bc",
      "metadata": {
        "id": "1ab54f55-5dd7-42ea-a8cf-ffb1c98b10bc",
        "outputId": "3a3f3750-0553-44dd-84ad-37f5065aa6c6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonfm (38).java, Predicted Label: 0, True Label: 0\n",
            "File: nonfm (52).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (68).java, Predicted Label: 1, True Label: 1\n",
            "File: nonfm (37).java, Predicted Label: 1, True Label: 0\n",
            "File: nonfm (29).java, Predicted Label: 1, True Label: 1\n",
            "File: factorymethod (1).java, Predicted Label: 1, True Label: 1\n",
            "File: factorymethod (9).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.880952380952381, Recall: 0.8571428571428571, F-score: 0.8398268398268397\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'factorymethod'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize the RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Function to extract embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Initialize lists to store Java programs and their corresponding labels\n",
        "java_programs = []\n",
        "program_labels = []\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_text = f.read()\n",
        "            java_programs.append(program_text)\n",
        "\n",
        "            # Check if the keyword \"singleton\" is present in the filename\n",
        "            if \"factorymethod\" in program_file:\n",
        "                program_labels.append(1)  # Positive class (implements singleton)\n",
        "            else:\n",
        "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
        "\n",
        "# Calculate embeddings for the Java programs line by line and take the mean\n",
        "program_embeddings = []\n",
        "for program in java_programs:\n",
        "    lines = program.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Apply standard scaling to normalize the embeddings\n",
        "scaler = StandardScaler()\n",
        "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 5  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [program_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
        "\n",
        "# Apply k-nearest neighbor classification\n",
        "n_neighbors = 5  # Number of neighbors to consider\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "predictions = knn.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print the classification results and performance metrics\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2af7df81-0820-4111-8d37-227205b88c40",
      "metadata": {
        "id": "2af7df81-0820-4111-8d37-227205b88c40"
      },
      "outputs": [],
      "source": [
        "Prototype with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84e6ae3f-14f8-4e0e-b484-cf7a89951b34",
      "metadata": {
        "id": "84e6ae3f-14f8-4e0e-b484-cf7a89951b34",
        "outputId": "5d2fcbee-e4b9-4eb7-9e83-879accff2415"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: prototype (27).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (23).java, Predicted Label: 0, True Label: 1\n",
            "File: nonp (5).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (13).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (22).java, Predicted Label: 0, True Label: 1\n",
            "File: nonp (7).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (13).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (29).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (15).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (44).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (58).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (14).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (16).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.8846153846153846, Recall: 0.8461538461538461, F-score: 0.8443223443223442\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'prototype'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize the RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Function to extract embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Initialize lists to store Java programs and their corresponding labels\n",
        "java_programs = []\n",
        "program_labels = []\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_text = f.read()\n",
        "            java_programs.append(program_text)\n",
        "\n",
        "            # Check if the keyword \"singleton\" is present in the filename\n",
        "            if \"prototype\" in program_file:\n",
        "                program_labels.append(1)  # Positive class (implements singleton)\n",
        "            else:\n",
        "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
        "\n",
        "# Calculate embeddings for the Java programs line by line and take the mean\n",
        "program_embeddings = []\n",
        "for program in java_programs:\n",
        "    lines = program.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Apply standard scaling to normalize the embeddings\n",
        "scaler = StandardScaler()\n",
        "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 5  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [program_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
        "\n",
        "# Apply k-nearest neighbor classification\n",
        "n_neighbors = 5  # Number of neighbors to consider\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "predictions = knn.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print the classification results and performance metrics\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c663fbf6-cc93-43d0-953d-7f1b2265afac",
      "metadata": {
        "id": "c663fbf6-cc93-43d0-953d-7f1b2265afac"
      },
      "outputs": [],
      "source": [
        "Prototype with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e782893-0f0c-4609-a2d3-f5b6e0bcd25f",
      "metadata": {
        "id": "3e782893-0f0c-4609-a2d3-f5b6e0bcd25f",
        "outputId": "e9de1896-297f-4b24-b09d-6167044a5adc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: prototype (27).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (53).java, Predicted Label: 0, True Label: 1\n",
            "File: nonp (23).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (43).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (35).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (51).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (59).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (5).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (31).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (13).java, Predicted Label: 0, True Label: 0\n",
            "File: prototype (22).java, Predicted Label: 0, True Label: 1\n",
            "File: nonp (7).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (13).java, Predicted Label: 1, True Label: 1\n",
            "File: nonp (29).java, Predicted Label: 1, True Label: 1\n",
            "File: prototype (15).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (44).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (8).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (37).java, Predicted Label: 0, True Label: 0\n",
            "File: nonp (21).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.9087719298245613, Recall: 0.8947368421052632, F-score: 0.8879699248120302\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'prototype'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize the RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Function to extract embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Initialize lists to store Java programs and their corresponding labels\n",
        "java_programs = []\n",
        "program_labels = []\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_text = f.read()\n",
        "            java_programs.append(program_text)\n",
        "\n",
        "            # Check if the keyword \"singleton\" is present in the filename\n",
        "            if \"prototype\" in program_file:\n",
        "                program_labels.append(1)  # Positive class (implements singleton)\n",
        "            else:\n",
        "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
        "\n",
        "# Calculate embeddings for the Java programs line by line and take the mean\n",
        "program_embeddings = []\n",
        "for program in java_programs:\n",
        "    lines = program.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Apply standard scaling to normalize the embeddings\n",
        "scaler = StandardScaler()\n",
        "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 5  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [program_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
        "\n",
        "# Apply k-nearest neighbor classification\n",
        "n_neighbors = 5  # Number of neighbors to consider\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "predictions = knn.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print the classification results and performance metrics\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "511f0d9f-88ea-4f50-92ae-901fd7bdfea2",
      "metadata": {
        "id": "511f0d9f-88ea-4f50-92ae-901fd7bdfea2"
      },
      "outputs": [],
      "source": [
        "Prototype with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddeb6eed-6f74-42ef-9576-c3640da21daf",
      "metadata": {
        "id": "ddeb6eed-6f74-42ef-9576-c3640da21daf",
        "outputId": "cca0f8bf-831b-40f8-a0bd-d04944b18c29"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'prototype'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize the RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Function to extract embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Initialize lists to store Java programs and their corresponding labels\n",
        "java_programs = []\n",
        "program_labels = []\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_text = f.read()\n",
        "            java_programs.append(program_text)\n",
        "\n",
        "            # Check if the keyword \"singleton\" is present in the filename\n",
        "            if \"prototype\" in program_file:\n",
        "                program_labels.append(1)  # Positive class (implements singleton)\n",
        "            else:\n",
        "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
        "\n",
        "# Calculate embeddings for the Java programs line by line and take the mean\n",
        "program_embeddings = []\n",
        "for program in java_programs:\n",
        "    lines = program.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Apply standard scaling to normalize the embeddings\n",
        "scaler = StandardScaler()\n",
        "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 5  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [program_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
        "\n",
        "# Apply k-nearest neighbor classification\n",
        "n_neighbors = 5  # Number of neighbors to consider\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "predictions = knn.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print the classification results and performance metrics\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a181ed9-013f-4038-ad3a-2d8c201d9422",
      "metadata": {
        "id": "8a181ed9-013f-4038-ad3a-2d8c201d9422"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Function to get embeddings for a given design pattern\n",
        "def get_embeddings_for_pattern(pattern, model, tokenizer):\n",
        "    directory = os.path.join(\"all_design_patterns\", pattern.lower())\n",
        "    files = [file for file in os.listdir(directory) if os.path.isfile(os.path.join(directory, file))]\n",
        "\n",
        "    embeddings = []\n",
        "    true_labels = []\n",
        "\n",
        "    for file in files:\n",
        "        with open(os.path.join(directory, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "            code = f.read()\n",
        "\n",
        "        # Tokenize and encode the Java program\n",
        "        inputs = tokenizer(code, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        program_embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "\n",
        "        embeddings.append(program_embedding)\n",
        "        true_labels.append(pattern)\n",
        "\n",
        "    return np.array(embeddings), np.array(true_labels)\n",
        "\n",
        "# Load the RoBERTa model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"  # Replace with the correct RoBERTa model name\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Get embeddings for each design pattern\n",
        "patterns = [\"Singleton\", \"Prototype\", \"AbstractFactory\", \"Builder\", \"FactoryMethod\"]\n",
        "all_embeddings = []\n",
        "all_labels = []\n",
        "\n",
        "# Custom color palette for each design pattern with higher contrast\n",
        "color_palette = [\"red\", \"green\", \"orange\", \"blue\", \"purple\"]\n",
        "\n",
        "# Custom markers for each design pattern\n",
        "markers = [\"o\", \"s\", \"D\", \"^\", \"P\"]\n",
        "\n",
        "for i, pattern in enumerate(patterns):\n",
        "    pattern_embeddings, pattern_labels = get_embeddings_for_pattern(pattern, model, tokenizer)\n",
        "    all_embeddings.append(pattern_embeddings)\n",
        "    all_labels.append(pattern_labels)\n",
        "\n",
        "# Concatenate the embeddings and labels\n",
        "all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
        "all_labels = np.concatenate(all_labels)\n",
        "\n",
        "# Perform t-SNE\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "tsne_results = tsne.fit_transform(all_embeddings)\n",
        "\n",
        "# Create a scatter plot for t-SNE visualization with custom symbols\n",
        "plt.figure(figsize=(20, 16))\n",
        "\n",
        "for i, pattern in enumerate(patterns):\n",
        "    indices = all_labels == pattern\n",
        "    sns.scatterplot(x=tsne_results[indices, 0], y=tsne_results[indices, 1], marker=markers[i], color=color_palette[i], s=200, label=pattern)\n",
        "\n",
        "# Increase font sizes for better visibility\n",
        "plt.title('t-SNE Visualization for RoBERTa on Different Design Patterns', fontsize=30)\n",
        "plt.xlabel('t-SNE Dimension 1', fontsize=25)\n",
        "plt.ylabel('t-SNE Dimension 2', fontsize=25)\n",
        "plt.legend(title='Design Pattern', loc='upper right', fontsize=22)\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.grid(True)\n",
        "\n",
        "# Save the t-SNE plot as a PDF file\n",
        "plt.savefig('tsne_plot_roberta.pdf', format='pdf')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32a3e7fb-9651-4405-8dd0-bbf03a44dc48",
      "metadata": {
        "id": "32a3e7fb-9651-4405-8dd0-bbf03a44dc48"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd3e2b8d-48b1-4873-a998-f38ce55a6d46",
      "metadata": {
        "id": "fd3e2b8d-48b1-4873-a998-f38ce55a6d46"
      },
      "outputs": [],
      "source": [
        "#Singleton with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9e5b476-be5d-4b0a-b978-a15fab02afd9",
      "metadata": {
        "id": "b9e5b476-be5d-4b0a-b978-a15fab02afd9",
        "outputId": "d324086f-52b5-4ce7-862a-3e7899ac722a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nons (12).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (50).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (25).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (27).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (19).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (24).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (4).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (44).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (38).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.5289256198347108, Recall: 0.7272727272727273, F-score: 0.6124401913875599\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/cephyr/users/sushantk/Alvis/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_distances, euclidean_distances\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize the RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Function to extract embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Function to calculate the distance matrix based on the chosen metric\n",
        "def calculate_distance_matrix(embeddings, metric='cosine'):\n",
        "    if metric == 'cosine':\n",
        "        return cosine_distances(embeddings)\n",
        "    elif metric == 'euclidean':\n",
        "        return euclidean_distances(embeddings)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized metric: {metric}\")\n",
        "\n",
        "# Switch between 'cosine' and 'euclidean'\n",
        "distance_metric = 'euclidean'  # Change to 'euclidean' for Euclidean distance\n",
        "\n",
        "# Initialize lists to store Java programs and their corresponding labels\n",
        "java_programs = []\n",
        "program_labels = []\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_text = f.read()\n",
        "            java_programs.append(program_text)\n",
        "\n",
        "            # Check if the keyword \"singleton\" is present in the filename\n",
        "            if \"singleton\" in program_file:\n",
        "                program_labels.append(1)  # Positive class (implements singleton)\n",
        "            else:\n",
        "                program_labels.append(0)  # Negative class (does not implement singleton)\n",
        "\n",
        "# Calculate embeddings for the Java programs line by line and take the mean\n",
        "program_embeddings = []\n",
        "for program in java_programs:\n",
        "    lines = program.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Apply standard scaling to normalize the embeddings\n",
        "scaler = StandardScaler()\n",
        "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
        "\n",
        "# Calculate the distance matrix based on the chosen metric\n",
        "distance_matrix = calculate_distance_matrix(normalized_embeddings, metric=distance_metric)\n",
        "\n",
        "# Get k-nearest neighbors indices for each program\n",
        "k = 5  # Number of neighbors to consider\n",
        "knn_indices = np.argsort(distance_matrix)[:, 1:k+1]\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program based on the majority label of neighbors\n",
        "for indices in knn_indices:\n",
        "    neighbor_labels = [program_labels[i] for i in indices]\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, predicted_labels, test_size=0.2, random_state=0)\n",
        "\n",
        "# Apply k-nearest neighbor classification\n",
        "n_neighbors = 3  # Number of neighbors to consider\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "predictions = knn.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print the classification results and performance metrics\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4807a0b1-24f5-4205-8cb6-55964e16cc3f",
      "metadata": {
        "id": "4807a0b1-24f5-4205-8cb6-55964e16cc3f"
      },
      "outputs": [],
      "source": [
        "#Singleton with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f35a9f3-1537-4352-bf66-9df8de09a0ed",
      "metadata": {
        "id": "8f35a9f3-1537-4352-bf66-9df8de09a0ed",
        "outputId": "f4a95cf3-89b5-4a8f-c7d8-71b587701294"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nons (12).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (50).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (25).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (27).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (19).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (24).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (4).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (44).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (38).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.7467532467532467, Recall: 0.6363636363636364, F-score: 0.6742424242424243\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize the RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Function to extract embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    if \"singleton\" in file_name:\n",
        "        return 1  # Positive class (implements singleton)\n",
        "    else:\n",
        "        return 0  # Negative class (does not implement singleton)\n",
        "\n",
        "# Initialize lists to store Java programs and their corresponding labels\n",
        "java_programs = []\n",
        "program_labels = []\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_text = f.read()\n",
        "            java_programs.append(program_text)\n",
        "\n",
        "            # Label the program using the provided function\n",
        "            program_labels.append(label_program(program_file))\n",
        "\n",
        "# Calculate embeddings for the Java programs line by line and take the mean\n",
        "program_embeddings = []\n",
        "for program in java_programs:\n",
        "    lines = program.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Apply standard scaling to normalize the embeddings\n",
        "scaler = StandardScaler()\n",
        "normalized_embeddings = scaler.fit_transform(np.vstack(program_embeddings))\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(normalized_embeddings, program_labels, test_size=0.2, random_state=0)\n",
        "\n",
        "# Apply k-nearest neighbor classification\n",
        "n_neighbors = 3  # Number of neighbors to consider\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "predictions = knn.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print the classification results and performance metrics\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"File: {os.listdir(java_programs_folder)[i]}, Predicted Label: {predictions[i]}, True Label: {y_test[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2041ca8b-57df-4cd0-9a97-3e3d6f79ba86",
      "metadata": {
        "id": "2041ca8b-57df-4cd0-9a97-3e3d6f79ba86",
        "outputId": "35279a39-79a4-4663-c278-18f849f6e028"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels and contents saved to singleton/sin.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"singleton\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = 'singleton/sin.csv'  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc24e9e4-ba0c-4f9a-b9f1-4c1ad863cf53",
      "metadata": {
        "id": "fc24e9e4-ba0c-4f9a-b9f1-4c1ad863cf53",
        "outputId": "45527c31-1a76-4e97-ec39-29c8a4166ce7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|| 54/54 [06:34<00:00,  7.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nons (12).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (50).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (25).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (27).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (19).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (24).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (4).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (44).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (38).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.890909090909091, Recall: 0.7272727272727273, F-score: 0.7584415584415585\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = 'singleton/sin.csv'  # Replace with the actual CSV file path\n",
        "\n",
        "# Initialize RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to calculate embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Calculate embeddings for each program by considering embeddings of individual lines\n",
        "program_embeddings = []\n",
        "for content in tqdm(df['Content']):\n",
        "    lines = content.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Convert program_embeddings to NumPy array\n",
        "program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(program_embeddings, df['Label'], test_size=0.2, random_state=0)\n",
        "\n",
        "# Apply k-nearest neighbor classification\n",
        "n_neighbors = 3  # Number of neighbors to consider\n",
        "knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "knn.fit(X_train, y_train)\n",
        "predictions = knn.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and f-score\n",
        "precision = precision_score(y_test, predictions, average='weighted')\n",
        "recall = recall_score(y_test, predictions, average='weighted')\n",
        "f1 = f1_score(y_test, predictions, average='weighted')\n",
        "\n",
        "# Print the classification results and performance metrics\n",
        "for i in range(len(X_test)):\n",
        "    print(f\"File: {df['File Name'].iloc[i]}, Predicted Label: {predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
        "\n",
        "print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dae1008-36fd-49f8-a1ab-506025c896e2",
      "metadata": {
        "id": "9dae1008-36fd-49f8-a1ab-506025c896e2"
      },
      "outputs": [],
      "source": [
        "#k-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8e844af-2aae-4820-bc9d-6d2c99879b77",
      "metadata": {
        "id": "b8e844af-2aae-4820-bc9d-6d2c99879b77",
        "outputId": "ca0f1a51-1321-414c-a47b-17f457fc7667"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|| 54/54 [06:37<00:00,  7.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1: Precision: 0.9242424242424243, Recall: 0.9090909090909091, F-score: 0.9090909090909091\n",
            "Fold 2: Precision: 0.7393939393939394, Recall: 0.7272727272727273, F-score: 0.7272727272727272\n",
            "Fold 3: Precision: 0.8701298701298701, Recall: 0.8181818181818182, F-score: 0.8151515151515152\n",
            "Fold 4: Precision: 0.5303030303030304, Recall: 0.5454545454545454, F-score: 0.4935064935064935\n",
            "Fold 5: Precision: 0.8571428571428571, Recall: 0.8, F-score: 0.7916666666666666\n",
            "Overall Precision: 0.7589506172839506, Recall: 0.7592592592592593, F-score: 0.7588428968574248\n",
            "Fold 1, File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
            "Fold 1, File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "Fold 1, File: nons (44).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1, File: nons (38).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1, File: nons (33).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1, File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
            "Fold 1, File: nons (21).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1, File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
            "Fold 1, File: nons (9).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1, File: singleton (7).java, Predicted Label: 1, True Label: 1\n",
            "Fold 2, File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
            "Fold 2, File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "Fold 2, File: nons (44).java, Predicted Label: 0, True Label: 0\n",
            "Fold 2, File: nons (38).java, Predicted Label: 0, True Label: 0\n",
            "Fold 2, File: nons (33).java, Predicted Label: 0, True Label: 0\n",
            "Fold 2, File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
            "Fold 2, File: nons (21).java, Predicted Label: 0, True Label: 0\n",
            "Fold 2, File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
            "Fold 2, File: nons (9).java, Predicted Label: 0, True Label: 0\n",
            "Fold 2, File: singleton (7).java, Predicted Label: 1, True Label: 1\n",
            "Fold 3, File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
            "Fold 3, File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "Fold 3, File: nons (44).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3, File: nons (38).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3, File: nons (33).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3, File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
            "Fold 3, File: nons (21).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3, File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
            "Fold 3, File: nons (9).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3, File: singleton (7).java, Predicted Label: 1, True Label: 1\n",
            "Fold 4, File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
            "Fold 4, File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "Fold 4, File: nons (44).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4, File: nons (38).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4, File: nons (33).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4, File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
            "Fold 4, File: nons (21).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4, File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
            "Fold 4, File: nons (9).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4, File: singleton (7).java, Predicted Label: 1, True Label: 1\n",
            "Fold 5, File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
            "Fold 5, File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "Fold 5, File: nons (44).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5, File: nons (38).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5, File: nons (33).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5, File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
            "Fold 5, File: nons (21).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5, File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
            "Fold 5, File: nons (9).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5, File: singleton (7).java, Predicted Label: 1, True Label: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = 'singleton/sin.csv'  # Replace with the actual CSV file path\n",
        "\n",
        "# Initialize RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to calculate embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Calculate embeddings for each program by considering embeddings of individual lines\n",
        "program_embeddings = []\n",
        "for content in tqdm(df['Content']):\n",
        "    lines = content.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Convert program_embeddings to NumPy array\n",
        "program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "\n",
        "# Initialize an array to store predicted labels for each program in every fold\n",
        "all_fold_predictions = np.zeros_like(df['Label'])\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
        "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
        "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
        "\n",
        "    # Apply k-nearest neighbor classification\n",
        "    n_neighbors = 3  # Number of neighbors to consider\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "    fold_predictions = knn.predict(X_test)\n",
        "\n",
        "    # Store fold predictions in the array\n",
        "    all_fold_predictions[test_index] = fold_predictions\n",
        "\n",
        "    # Calculate precision, recall, and f-score for the current fold\n",
        "    precision = precision_score(y_test, fold_predictions, average='weighted')\n",
        "    recall = recall_score(y_test, fold_predictions, average='weighted')\n",
        "    f1 = f1_score(y_test, fold_predictions, average='weighted')\n",
        "\n",
        "    print(f\"Fold {fold + 1}: Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
        "\n",
        "# Calculate overall precision, recall, and f-score\n",
        "precision = precision_score(df['Label'], all_fold_predictions, average='weighted')\n",
        "recall = recall_score(df['Label'], all_fold_predictions, average='weighted')\n",
        "f1 = f1_score(df['Label'], all_fold_predictions, average='weighted')\n",
        "\n",
        "print(f\"Overall Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
        "\n",
        "# Print the classification results for each program in every fold\n",
        "for fold in range(n_splits):\n",
        "    fold_predictions = all_fold_predictions[test_index]\n",
        "    true_labels = df['Label'][test_index]\n",
        "\n",
        "    for i in range(len(fold_predictions)):\n",
        "        print(f\"Fold {fold + 1}, File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {fold_predictions[i]}, True Label: {true_labels.iloc[i]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "894036dd-177d-4936-9efe-1eeb05084cac",
      "metadata": {
        "id": "894036dd-177d-4936-9efe-1eeb05084cac",
        "outputId": "3fe14439-698f-4e9e-ce06-3811540d2e3f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|| 54/54 [06:39<00:00,  7.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1: Precision: 0.9242424242424243, Recall: 0.9090909090909091, F-score: 0.9090909090909091\n",
            "Fold 2: Precision: 0.7393939393939394, Recall: 0.7272727272727273, F-score: 0.7272727272727272\n",
            "Fold 3: Precision: 0.8701298701298701, Recall: 0.8181818181818182, F-score: 0.8151515151515152\n",
            "Fold 4: Precision: 0.5303030303030304, Recall: 0.5454545454545454, F-score: 0.4935064935064935\n",
            "Fold 5: Precision: 0.8571428571428571, Recall: 0.8, F-score: 0.7916666666666666\n",
            "Overall Precision: 0.7589506172839506, Recall: 0.7592592592592593, F-score: 0.7588428968574248\n",
            "Fold 1, File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
            "Fold 1, File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "Fold 1, File: nons (44).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1, File: nons (38).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1, File: nons (33).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1, File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
            "Fold 1, File: nons (21).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1, File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
            "Fold 1, File: nons (9).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1, File: singleton (7).java, Predicted Label: 1, True Label: 1\n",
            "Fold 2, File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
            "Fold 2, File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "Fold 2, File: nons (44).java, Predicted Label: 0, True Label: 0\n",
            "Fold 2, File: nons (38).java, Predicted Label: 0, True Label: 0\n",
            "Fold 2, File: nons (33).java, Predicted Label: 0, True Label: 0\n",
            "Fold 2, File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
            "Fold 2, File: nons (21).java, Predicted Label: 0, True Label: 0\n",
            "Fold 2, File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
            "Fold 2, File: nons (9).java, Predicted Label: 0, True Label: 0\n",
            "Fold 2, File: singleton (7).java, Predicted Label: 1, True Label: 1\n",
            "Fold 3, File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
            "Fold 3, File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "Fold 3, File: nons (44).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3, File: nons (38).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3, File: nons (33).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3, File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
            "Fold 3, File: nons (21).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3, File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
            "Fold 3, File: nons (9).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3, File: singleton (7).java, Predicted Label: 1, True Label: 1\n",
            "Fold 4, File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
            "Fold 4, File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "Fold 4, File: nons (44).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4, File: nons (38).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4, File: nons (33).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4, File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
            "Fold 4, File: nons (21).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4, File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
            "Fold 4, File: nons (9).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4, File: singleton (7).java, Predicted Label: 1, True Label: 1\n",
            "Fold 5, File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
            "Fold 5, File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "Fold 5, File: nons (44).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5, File: nons (38).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5, File: nons (33).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5, File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
            "Fold 5, File: nons (21).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5, File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
            "Fold 5, File: nons (9).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5, File: singleton (7).java, Predicted Label: 1, True Label: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = 'singleton/sin.csv'  # Replace with the actual CSV file path\n",
        "\n",
        "# Initialize RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to calculate embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Calculate embeddings for each program by considering embeddings of individual lines\n",
        "program_embeddings = []\n",
        "for content in tqdm(df['Content']):\n",
        "    lines = content.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Convert program_embeddings to NumPy array\n",
        "program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "\n",
        "# Initialize an array to store predicted labels for each program in every fold\n",
        "all_fold_predictions = np.zeros_like(df['Label'])\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
        "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
        "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
        "\n",
        "    # Apply k-nearest neighbor classification\n",
        "    n_neighbors = 3  # Number of neighbors to consider\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "    fold_predictions = knn.predict(X_test)\n",
        "\n",
        "    # Store fold predictions in the array\n",
        "    all_fold_predictions[test_index] = fold_predictions\n",
        "\n",
        "    # Calculate precision, recall, and f-score for the current fold\n",
        "    precision = precision_score(y_test, fold_predictions, average='weighted')\n",
        "    recall = recall_score(y_test, fold_predictions, average='weighted')\n",
        "    f1 = f1_score(y_test, fold_predictions, average='weighted')\n",
        "\n",
        "    print(f\"Fold {fold + 1}: Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
        "\n",
        "# Calculate overall precision, recall, and f-score\n",
        "precision = precision_score(df['Label'], all_fold_predictions, average='weighted')\n",
        "recall = recall_score(df['Label'], all_fold_predictions, average='weighted')\n",
        "f1 = f1_score(df['Label'], all_fold_predictions, average='weighted')\n",
        "\n",
        "print(f\"Overall Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
        "\n",
        "# Print the classification results for each program in every fold\n",
        "for fold in range(n_splits):\n",
        "    fold_predictions = all_fold_predictions[test_index]\n",
        "    true_labels = df['Label'][test_index]\n",
        "\n",
        "    for i in range(len(fold_predictions)):\n",
        "        print(f\"Fold {fold + 1}, File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {fold_predictions[i]}, True Label: {true_labels.iloc[i]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a85509c5-41ad-4370-9fbd-43753e8d37d9",
      "metadata": {
        "id": "a85509c5-41ad-4370-9fbd-43753e8d37d9"
      },
      "outputs": [],
      "source": [
        "#singleton with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "260b4089-249f-430c-85de-56240cc93015",
      "metadata": {
        "id": "260b4089-249f-430c-85de-56240cc93015",
        "outputId": "628bbe21-e35c-4ef5-d5e1-f9653497a0e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels and contents saved to embeddings/sin1.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"singleton\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = 'embeddings/sin1.csv'  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "094f939c-f71a-4bb4-a7a0-6522fcd19ec8",
      "metadata": {
        "id": "094f939c-f71a-4bb4-a7a0-6522fcd19ec8",
        "outputId": "08d84f52-7bae-4ce5-c281-8c9ae2eedda1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|| 52/52 [10:05<00:00, 11.65s/it]   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 (Train), File: nons (29).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1 (Train), File: nons (25).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1 (Train), File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
            "Fold 1 (Train), File: nons (42).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1 (Train), File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
            "Fold 1 (Train), File: nons (34).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1 (Train), File: nons (49).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1 (Train), File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "Fold 1 (Train), File: nons (44).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1 (Train), File: nons (38).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1 (Train), File: singleton (14).java, Predicted Label: 0, True Label: 1\n",
            "Fold 1 (Train), File: nons (33).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1 (Train), File: nons (41).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1 (Train), File: singleton (1).java, Predicted Label: 1, True Label: 1\n",
            "Fold 1 (Train), File: sin.csv, Predicted Label: 0, True Label: 0\n",
            "Fold 1 (Train), File: singleton (3).java, Predicted Label: 0, True Label: 1\n",
            "Fold 1 (Train), File: singleton (23).java, Predicted Label: 1, True Label: 1\n",
            "Fold 1 (Train), File: nons (35).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1 (Train), File: nons (43).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1 (Train), File: singleton (16).java, Predicted Label: 1, True Label: 1\n",
            "Fold 1 (Train), File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
            "Fold 1 (Train), File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
            "Fold 1 (Train), File: nons (48).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1 (Train), File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
            "Fold 1 (Train), File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
            "Fold 1 (Train), File: nons (26).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1 (Train), File: singleton (12).java, Predicted Label: 1, True Label: 1\n",
            "Fold 1 (Train), File: nons (31).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1 (Train), File: nons (37).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1 (Train), File: singleton (22).java, Predicted Label: 1, True Label: 1\n",
            "Fold 1 (Train), File: nons (47).java, Predicted Label: 1, True Label: 0\n",
            "Fold 1 (Train), File: singleton (4).java, Predicted Label: 0, True Label: 1\n",
            "Fold 1 (Train), File: nons (32).java, Predicted Label: 1, True Label: 0\n",
            "Fold 1 (Train), File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
            "Fold 1 (Train), File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
            "Fold 1 (Train), File: singleton (7).java, Predicted Label: 1, True Label: 1\n",
            "Fold 1 (Train), File: nons (45).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1 (Train), File: singleton (19).java, Predicted Label: 1, True Label: 1\n",
            "Fold 1 (Train), File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
            "Fold 1 (Train), File: nons (28).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1 (Train), File: nons (36).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1 (Test), File: nons (50).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1 (Test), File: nons (27).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1 (Test), File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
            "Fold 1 (Test), File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
            "Fold 1 (Test), File: nons (30).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1 (Test), File: nons (40).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1 (Test), File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
            "Fold 1 (Test), File: singleton (6).java, Predicted Label: 0, True Label: 1\n",
            "Fold 1 (Test), File: singleton (21).java, Predicted Label: 0, True Label: 1\n",
            "Fold 1 (Test), File: nons (46).java, Predicted Label: 1, True Label: 0\n",
            "Fold 1 (Test), File: nons (39).java, Predicted Label: 0, True Label: 0\n",
            "Fold 1: Precision: 0.7305194805194805, Recall: 0.7272727272727273, F-score: 0.7226107226107225\n",
            "Fold 2 (Train), File: nons (50).java, Predicted Label: 1, True Label: 0\n",
            "Fold 2 (Train), File: nons (29).java, Predicted Label: 0, True Label: 0\n",
            "Fold 2 (Train), File: nons (25).java, Predicted Label: 0, True Label: 0\n",
            "Fold 2 (Train), File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
            "Fold 2 (Train), File: nons (42).java, Predicted Label: 1, True Label: 0\n",
            "Fold 2 (Train), File: nons (27).java, Predicted Label: 0, True Label: 0\n",
            "Fold 2 (Train), File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
            "Fold 2 (Train), File: nons (49).java, Predicted Label: 0, True Label: 0\n",
            "Fold 2 (Train), File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "Fold 2 (Train), File: nons (44).java, Predicted Label: 0, True Label: 0\n",
            "Fold 2 (Train), File: nons (38).java, Predicted Label: 0, True Label: 0\n",
            "Fold 2 (Train), File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
            "Fold 2 (Train), File: nons (33).java, Predicted Label: 0, True Label: 0\n",
            "Fold 2 (Train), File: nons (41).java, Predicted Label: 0, True Label: 0\n",
            "Fold 2 (Train), File: nons (30).java, Predicted Label: 0, True Label: 0\n",
            "Fold 2 (Train), File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
            "Fold 2 (Train), File: singleton (3).java, Predicted Label: 0, True Label: 1\n",
            "Fold 2 (Train), File: singleton (23).java, Predicted Label: 0, True Label: 1\n",
            "Fold 2 (Train), File: nons (35).java, Predicted Label: 0, True Label: 0\n",
            "Fold 2 (Train), File: nons (43).java, Predicted Label: 0, True Label: 0\n",
            "Fold 2 (Train), File: singleton (16).java, Predicted Label: 1, True Label: 1\n",
            "Fold 2 (Train), File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
            "Fold 2 (Train), File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
            "Fold 2 (Train), File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
            "Fold 2 (Train), File: nons (40).java, Predicted Label: 0, True Label: 0\n",
            "Fold 2 (Train), File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
            "Fold 2 (Train), File: nons (31).java, Predicted Label: 0, True Label: 0\n",
            "Fold 2 (Train), File: singleton (6).java, Predicted Label: 0, True Label: 1\n",
            "Fold 2 (Train), File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
            "Fold 2 (Train), File: singleton (22).java, Predicted Label: 1, True Label: 1\n",
            "Fold 2 (Train), File: singleton (4).java, Predicted Label: 0, True Label: 1\n",
            "Fold 2 (Train), File: nons (32).java, Predicted Label: 1, True Label: 0\n",
            "Fold 2 (Train), File: nons (46).java, Predicted Label: 0, True Label: 0\n",
            "Fold 2 (Train), File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
            "Fold 2 (Train), File: nons (39).java, Predicted Label: 0, True Label: 0\n",
            "Fold 2 (Train), File: singleton (7).java, Predicted Label: 1, True Label: 1\n",
            "Fold 2 (Train), File: nons (45).java, Predicted Label: 0, True Label: 0\n",
            "Fold 2 (Train), File: singleton (19).java, Predicted Label: 0, True Label: 1\n",
            "Fold 2 (Train), File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
            "Fold 2 (Train), File: nons (28).java, Predicted Label: 0, True Label: 0\n",
            "Fold 2 (Train), File: nons (36).java, Predicted Label: 0, True Label: 0\n",
            "Fold 2 (Test), File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
            "Fold 2 (Test), File: nons (34).java, Predicted Label: 1, True Label: 0\n",
            "Fold 2 (Test), File: singleton (14).java, Predicted Label: 0, True Label: 1\n",
            "Fold 2 (Test), File: sin.csv, Predicted Label: 1, True Label: 0\n",
            "Fold 2 (Test), File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
            "Fold 2 (Test), File: nons (48).java, Predicted Label: 1, True Label: 0\n",
            "Fold 2 (Test), File: nons (26).java, Predicted Label: 1, True Label: 0\n",
            "Fold 2 (Test), File: singleton (12).java, Predicted Label: 1, True Label: 1\n",
            "Fold 2 (Test), File: nons (37).java, Predicted Label: 1, True Label: 0\n",
            "Fold 2 (Test), File: nons (47).java, Predicted Label: 1, True Label: 0\n",
            "Fold 2 (Test), File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
            "Fold 2: Precision: 0.1515151515151515, Recall: 0.2727272727272727, F-score: 0.1948051948051948\n",
            "Fold 3 (Train), File: nons (50).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3 (Train), File: nons (29).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3 (Train), File: nons (42).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3 (Train), File: nons (27).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3 (Train), File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
            "Fold 3 (Train), File: nons (34).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3 (Train), File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
            "Fold 3 (Train), File: nons (49).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3 (Train), File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "Fold 3 (Train), File: nons (38).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3 (Train), File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
            "Fold 3 (Train), File: singleton (14).java, Predicted Label: 1, True Label: 1\n",
            "Fold 3 (Train), File: nons (33).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3 (Train), File: nons (30).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3 (Train), File: sin.csv, Predicted Label: 1, True Label: 0\n",
            "Fold 3 (Train), File: singleton (3).java, Predicted Label: 1, True Label: 1\n",
            "Fold 3 (Train), File: nons (35).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3 (Train), File: nons (43).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3 (Train), File: singleton (16).java, Predicted Label: 1, True Label: 1\n",
            "Fold 3 (Train), File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
            "Fold 3 (Train), File: nons (48).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3 (Train), File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
            "Fold 3 (Train), File: nons (26).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3 (Train), File: nons (40).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3 (Train), File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
            "Fold 3 (Train), File: singleton (12).java, Predicted Label: 1, True Label: 1\n",
            "Fold 3 (Train), File: nons (31).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3 (Train), File: singleton (6).java, Predicted Label: 1, True Label: 1\n",
            "Fold 3 (Train), File: nons (37).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3 (Train), File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
            "Fold 3 (Train), File: singleton (22).java, Predicted Label: 1, True Label: 1\n",
            "Fold 3 (Train), File: nons (47).java, Predicted Label: 1, True Label: 0\n",
            "Fold 3 (Train), File: singleton (4).java, Predicted Label: 1, True Label: 1\n",
            "Fold 3 (Train), File: nons (32).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3 (Train), File: nons (46).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3 (Train), File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
            "Fold 3 (Train), File: singleton (17).java, Predicted Label: 0, True Label: 1\n",
            "Fold 3 (Train), File: nons (39).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3 (Train), File: singleton (7).java, Predicted Label: 0, True Label: 1\n",
            "Fold 3 (Train), File: nons (45).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3 (Train), File: singleton (19).java, Predicted Label: 1, True Label: 1\n",
            "Fold 3 (Train), File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
            "Fold 3 (Test), File: nons (25).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3 (Test), File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
            "Fold 3 (Test), File: nons (44).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3 (Test), File: nons (41).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3 (Test), File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
            "Fold 3 (Test), File: singleton (23).java, Predicted Label: 0, True Label: 1\n",
            "Fold 3 (Test), File: singleton (11).java, Predicted Label: 0, True Label: 1\n",
            "Fold 3 (Test), File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
            "Fold 3 (Test), File: nons (28).java, Predicted Label: 1, True Label: 0\n",
            "Fold 3 (Test), File: nons (36).java, Predicted Label: 0, True Label: 0\n",
            "Fold 3: Precision: 0.5, Recall: 0.5, F-score: 0.45054945054945056\n",
            "Fold 4 (Train), File: nons (50).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4 (Train), File: nons (29).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4 (Train), File: nons (25).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4 (Train), File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
            "Fold 4 (Train), File: nons (27).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4 (Train), File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
            "Fold 4 (Train), File: nons (34).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4 (Train), File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
            "Fold 4 (Train), File: nons (49).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4 (Train), File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "Fold 4 (Train), File: nons (44).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4 (Train), File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
            "Fold 4 (Train), File: singleton (14).java, Predicted Label: 1, True Label: 1\n",
            "Fold 4 (Train), File: nons (41).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4 (Train), File: nons (30).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4 (Train), File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
            "Fold 4 (Train), File: sin.csv, Predicted Label: 0, True Label: 0\n",
            "Fold 4 (Train), File: singleton (23).java, Predicted Label: 1, True Label: 1\n",
            "Fold 4 (Train), File: nons (35).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4 (Train), File: nons (43).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4 (Train), File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
            "Fold 4 (Train), File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
            "Fold 4 (Train), File: nons (48).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4 (Train), File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
            "Fold 4 (Train), File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
            "Fold 4 (Train), File: nons (26).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4 (Train), File: nons (40).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4 (Train), File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
            "Fold 4 (Train), File: singleton (12).java, Predicted Label: 1, True Label: 1\n",
            "Fold 4 (Train), File: singleton (6).java, Predicted Label: 1, True Label: 1\n",
            "Fold 4 (Train), File: nons (37).java, Predicted Label: 1, True Label: 0\n",
            "Fold 4 (Train), File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
            "Fold 4 (Train), File: singleton (22).java, Predicted Label: 1, True Label: 1\n",
            "Fold 4 (Train), File: nons (47).java, Predicted Label: 1, True Label: 0\n",
            "Fold 4 (Train), File: nons (32).java, Predicted Label: 1, True Label: 0\n",
            "Fold 4 (Train), File: nons (46).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4 (Train), File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
            "Fold 4 (Train), File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
            "Fold 4 (Train), File: nons (39).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4 (Train), File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
            "Fold 4 (Train), File: nons (28).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4 (Train), File: nons (36).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4 (Test), File: nons (42).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4 (Test), File: nons (38).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4 (Test), File: nons (33).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4 (Test), File: singleton (3).java, Predicted Label: 0, True Label: 1\n",
            "Fold 4 (Test), File: singleton (16).java, Predicted Label: 0, True Label: 1\n",
            "Fold 4 (Test), File: nons (31).java, Predicted Label: 1, True Label: 0\n",
            "Fold 4 (Test), File: singleton (4).java, Predicted Label: 0, True Label: 1\n",
            "Fold 4 (Test), File: singleton (7).java, Predicted Label: 0, True Label: 1\n",
            "Fold 4 (Test), File: nons (45).java, Predicted Label: 0, True Label: 0\n",
            "Fold 4 (Test), File: singleton (19).java, Predicted Label: 0, True Label: 1\n",
            "Fold 4: Precision: 0.22222222222222224, Recall: 0.4, F-score: 0.2857142857142857\n",
            "Fold 5 (Train), File: nons (50).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5 (Train), File: nons (25).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5 (Train), File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
            "Fold 5 (Train), File: nons (42).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5 (Train), File: nons (27).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5 (Train), File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
            "Fold 5 (Train), File: nons (34).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5 (Train), File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
            "Fold 5 (Train), File: nons (44).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5 (Train), File: nons (38).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5 (Train), File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
            "Fold 5 (Train), File: singleton (14).java, Predicted Label: 1, True Label: 1\n",
            "Fold 5 (Train), File: nons (33).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5 (Train), File: nons (41).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5 (Train), File: nons (30).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5 (Train), File: singleton (1).java, Predicted Label: 1, True Label: 1\n",
            "Fold 5 (Train), File: sin.csv, Predicted Label: 0, True Label: 0\n",
            "Fold 5 (Train), File: singleton (3).java, Predicted Label: 0, True Label: 1\n",
            "Fold 5 (Train), File: singleton (23).java, Predicted Label: 1, True Label: 1\n",
            "Fold 5 (Train), File: singleton (16).java, Predicted Label: 1, True Label: 1\n",
            "Fold 5 (Train), File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
            "Fold 5 (Train), File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
            "Fold 5 (Train), File: nons (48).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5 (Train), File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
            "Fold 5 (Train), File: nons (26).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5 (Train), File: nons (40).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5 (Train), File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
            "Fold 5 (Train), File: singleton (12).java, Predicted Label: 1, True Label: 1\n",
            "Fold 5 (Train), File: nons (31).java, Predicted Label: 1, True Label: 0\n",
            "Fold 5 (Train), File: singleton (6).java, Predicted Label: 1, True Label: 1\n",
            "Fold 5 (Train), File: nons (37).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5 (Train), File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
            "Fold 5 (Train), File: nons (47).java, Predicted Label: 1, True Label: 0\n",
            "Fold 5 (Train), File: singleton (4).java, Predicted Label: 0, True Label: 1\n",
            "Fold 5 (Train), File: nons (46).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5 (Train), File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
            "Fold 5 (Train), File: nons (39).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5 (Train), File: singleton (7).java, Predicted Label: 1, True Label: 1\n",
            "Fold 5 (Train), File: nons (45).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5 (Train), File: singleton (19).java, Predicted Label: 1, True Label: 1\n",
            "Fold 5 (Train), File: nons (28).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5 (Train), File: nons (36).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5 (Test), File: nons (29).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5 (Test), File: nons (49).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5 (Test), File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "Fold 5 (Test), File: nons (35).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5 (Test), File: nons (43).java, Predicted Label: 0, True Label: 0\n",
            "Fold 5 (Test), File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
            "Fold 5 (Test), File: singleton (22).java, Predicted Label: 0, True Label: 1\n",
            "Fold 5 (Test), File: nons (32).java, Predicted Label: 1, True Label: 0\n",
            "Fold 5 (Test), File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
            "Fold 5 (Test), File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
            "Fold 5: Precision: 0.8, Recall: 0.8, F-score: 0.8000000000000002\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = 'embeddings/sin1.csv'  # Replace with the actual CSV file path\n",
        "\n",
        "# Initialize RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to calculate embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Calculate embeddings for each program by considering embeddings of individual lines\n",
        "program_embeddings = []\n",
        "for content in tqdm(df['Content']):\n",
        "    lines = content.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Convert program_embeddings to NumPy array\n",
        "program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
        "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
        "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
        "\n",
        "    # Apply k-nearest neighbor classification\n",
        "    n_neighbors = 3  # Number of neighbors to consider\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions on the training set\n",
        "    train_predictions = knn.predict(X_train)\n",
        "    for i in range(len(train_predictions)):\n",
        "        print(f\"Fold {fold + 1} (Train), File: {df['File Name'].iloc[train_index[i]]}, Predicted Label: {train_predictions[i]}, True Label: {y_train.iloc[i]}\")\n",
        "\n",
        "    # Predictions on the test set\n",
        "    test_predictions = knn.predict(X_test)\n",
        "    for i in range(len(test_predictions)):\n",
        "        print(f\"Fold {fold + 1} (Test), File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
        "\n",
        "    # Calculate precision, recall, and f-score for the current fold\n",
        "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
        "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
        "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "    print(f\"Fold {fold + 1}: Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "390576f6-c38f-4dcc-81aa-b6b98fd7e81f",
      "metadata": {
        "id": "390576f6-c38f-4dcc-81aa-b6b98fd7e81f",
        "outputId": "30a40025-7d2b-4325-dc5a-64b3a5f2174e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|| 52/52 [09:51<00:00, 11.38s/it]   \n",
            "/cephyr/users/sushantk/Alvis/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 (Test):\n",
            "File: nons (50).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (30).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (39).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.875, Recall: 0.8333333333333334, F-score: 0.8285714285714286\n",
            "Fold 3 (Test):\n",
            "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (48).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (26).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (47).java, Predicted Label: 1, True Label: 0\n",
            "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
            "Fold 10 (Test):\n",
            "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (35).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (43).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (17).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = 'embeddings/sin1.csv'  # Replace with the actual CSV file path\n",
        "\n",
        "# Initialize RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to calculate embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Calculate embeddings for each program by considering embeddings of individual lines\n",
        "program_embeddings = []\n",
        "for content in tqdm(df['Content']):\n",
        "    lines = content.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Convert program_embeddings to NumPy array\n",
        "program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "n_splits = 10\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
        "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
        "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
        "\n",
        "    # Apply k-nearest neighbor classification\n",
        "    n_neighbors = 3  # Number of neighbors to consider\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions on the test set\n",
        "    test_predictions = knn.predict(X_test)\n",
        "\n",
        "    # Calculate precision, recall, and f-score for the current fold\n",
        "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
        "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
        "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
        "    if precision >= 0.7 and recall >= 0.7 and f1 >= 0.7:\n",
        "        print(f\"Fold {fold + 1} (Test):\")\n",
        "        for i in range(len(test_predictions)):\n",
        "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
        "\n",
        "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22ab1ff5-701c-4518-92b8-25d17322e90e",
      "metadata": {
        "id": "22ab1ff5-701c-4518-92b8-25d17322e90e"
      },
      "outputs": [],
      "source": [
        "#Singleton with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ae2b717-3780-43e1-acd7-6f3579ef705d",
      "metadata": {
        "id": "5ae2b717-3780-43e1-acd7-6f3579ef705d",
        "outputId": "344c3cd1-074b-434e-9fd7-19337853a878"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels and contents saved to embeddings/sin2.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"singleton\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = 'embeddings/sin2.csv'  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9d22662-caca-4847-9901-3d7569ac7b19",
      "metadata": {
        "id": "e9d22662-caca-4847-9901-3d7569ac7b19",
        "outputId": "fde9a42f-b652-46b9-b26b-e11c20e67108"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|| 50/50 [03:10<00:00,  3.82s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 4 (Test):\n",
            "File: nons (55).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (3).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (16).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (6).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n",
            "Fold 8 (Test):\n",
            "File: nons (29).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (6).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (9).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
            "Fold 9 (Test):\n",
            "File: nons (34).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (4).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (7).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (45).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = 'embeddings/sin2.csv'  # Replace with the actual CSV file path\n",
        "\n",
        "# Initialize RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to calculate embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Calculate embeddings for each program by considering embeddings of individual lines\n",
        "program_embeddings = []\n",
        "for content in tqdm(df['Content']):\n",
        "    lines = content.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Convert program_embeddings to NumPy array\n",
        "program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "n_splits = 10\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
        "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
        "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
        "\n",
        "    # Apply k-nearest neighbor classification\n",
        "    n_neighbors = 3  # Number of neighbors to consider\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions on the test set\n",
        "    test_predictions = knn.predict(X_test)\n",
        "\n",
        "    # Calculate precision, recall, and f-score for the current fold\n",
        "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
        "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
        "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
        "    if precision >= 0.7 and recall >= 0.7 and f1 >= 0.7:\n",
        "        print(f\"Fold {fold + 1} (Test):\")\n",
        "        for i in range(len(test_predictions)):\n",
        "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
        "\n",
        "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "757aeffb-81da-4d6c-b8b5-0b67434f733e",
      "metadata": {
        "id": "757aeffb-81da-4d6c-b8b5-0b67434f733e"
      },
      "outputs": [],
      "source": [
        "#Singleton with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a44c1985-0561-4ee2-b9f4-e060c82bf950",
      "metadata": {
        "id": "a44c1985-0561-4ee2-b9f4-e060c82bf950",
        "outputId": "bc8c3159-c390-4e87-99a0-63e4b57cc3dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels and contents saved to embeddings/sin3.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"singleton\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = 'embeddings/sin3.csv'  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a15b2f86-5ca3-439d-bcc1-a3ed2608170c",
      "metadata": {
        "id": "a15b2f86-5ca3-439d-bcc1-a3ed2608170c",
        "outputId": "cbb54d5b-4285-4b6d-c4ce-3a40e2a2824d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|| 52/52 [03:22<00:00,  3.89s/it]\n",
            "/cephyr/users/sushantk/Alvis/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 (Test):\n",
            "File: nons (25).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (53).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (64).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.875, Recall: 0.8333333333333334, F-score: 0.8285714285714286\n",
            "Fold 6 (Test):\n",
            "File: nons (61).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (41).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (28).java, Predicted Label: 1, True Label: 0\n",
            "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
            "Fold 9 (Test):\n",
            "File: nons (42).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (38).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (22).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (19).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n",
            "Fold 10 (Test):\n",
            "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (20).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (14).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = 'embeddings/sin3.csv'  # Replace with the actual CSV file path\n",
        "\n",
        "# Initialize RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to calculate embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Calculate embeddings for each program by considering embeddings of individual lines\n",
        "program_embeddings = []\n",
        "for content in tqdm(df['Content']):\n",
        "    lines = content.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Convert program_embeddings to NumPy array\n",
        "program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "n_splits = 10\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
        "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
        "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
        "\n",
        "    # Apply k-nearest neighbor classification\n",
        "    n_neighbors = 3  # Number of neighbors to consider\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions on the test set\n",
        "    test_predictions = knn.predict(X_test)\n",
        "\n",
        "    # Calculate precision, recall, and f-score for the current fold\n",
        "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
        "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
        "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
        "    if precision >= 0.7 and recall >= 0.7 and f1 >= 0.7:\n",
        "        print(f\"Fold {fold + 1} (Test):\")\n",
        "        for i in range(len(test_predictions)):\n",
        "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
        "\n",
        "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4ee0c32-b38e-495a-909f-96b1c3fb68f0",
      "metadata": {
        "id": "c4ee0c32-b38e-495a-909f-96b1c3fb68f0"
      },
      "outputs": [],
      "source": [
        "#Singleton with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "affc5909-48a0-4bed-86e7-64692d10445e",
      "metadata": {
        "id": "affc5909-48a0-4bed-86e7-64692d10445e",
        "outputId": "14338013-2626-4fd5-9044-6c9e9972655d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels and contents saved to embeddings/sin4.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|| 55/55 [03:27<00:00,  3.76s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 3 (Test):\n",
            "File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (3).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (16).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (51).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (58).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.875, Recall: 0.8333333333333334, F-score: 0.8285714285714286\n",
            "Fold 6 (Test):\n",
            "File: nons (44).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (48).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (52).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 1.0, Recall: 1.0, F-score: 1.0\n",
            "Fold 7 (Test):\n",
            "File: nons (21).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (10).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (4).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (60).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"singleton\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = 'embeddings/sin4.csv'  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = 'embeddings/sin4.csv'  # Replace with the actual CSV file path\n",
        "\n",
        "# Initialize RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to calculate embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Calculate embeddings for each program by considering embeddings of individual lines\n",
        "program_embeddings = []\n",
        "for content in tqdm(df['Content']):\n",
        "    lines = content.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Convert program_embeddings to NumPy array\n",
        "program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "n_splits = 10\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
        "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
        "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
        "\n",
        "    # Apply k-nearest neighbor classification\n",
        "    n_neighbors = 3  # Number of neighbors to consider\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions on the test set\n",
        "    test_predictions = knn.predict(X_test)\n",
        "\n",
        "    # Calculate precision, recall, and f-score for the current fold\n",
        "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
        "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
        "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
        "    if precision >= 0.7 and recall >= 0.7 and f1 >= 0.7:\n",
        "        print(f\"Fold {fold + 1} (Test):\")\n",
        "        for i in range(len(test_predictions)):\n",
        "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
        "\n",
        "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52188409-e3c9-4d8b-841b-1dcd8f33817a",
      "metadata": {
        "id": "52188409-e3c9-4d8b-841b-1dcd8f33817a"
      },
      "outputs": [],
      "source": [
        "#Singleton using different setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19ecbd31-67f3-4bec-bd27-10192606297b",
      "metadata": {
        "id": "19ecbd31-67f3-4bec-bd27-10192606297b",
        "outputId": "34128f12-9e07-48ee-bf73-c177f2f76709"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels and contents saved to embeddings/sin5.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|| 49/49 [03:17<00:00,  4.03s/it]\n",
            "/cephyr/users/sushantk/Alvis/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 2 (Test):\n",
            "File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (63).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (67).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (58).java, Predicted Label: 1, True Label: 0\n",
            "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
            "Fold 3 (Test):\n",
            "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (53).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (14).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (22).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (15).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
            "Fold 6 (Test):\n",
            "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (49).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (14).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (65).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 1.0, Recall: 1.0, F-score: 1.0\n",
            "Fold 7 (Test):\n",
            "File: singleton (25).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (1).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (11).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (4).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
            "Fold 10 (Test):\n",
            "File: nons (19).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (41).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.8333333333333333, Recall: 0.75, F-score: 0.7333333333333334\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"singleton\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = 'embeddings/sin5.csv'  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = 'embeddings/sin5.csv'  # Replace with the actual CSV file path\n",
        "\n",
        "# Initialize RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to calculate embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Calculate embeddings for each program by considering embeddings of individual lines\n",
        "program_embeddings = []\n",
        "for content in tqdm(df['Content']):\n",
        "    lines = content.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Convert program_embeddings to NumPy array\n",
        "program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "n_splits = 10\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
        "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
        "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
        "\n",
        "    # Apply k-nearest neighbor classification\n",
        "    n_neighbors = 3  # Number of neighbors to consider\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions on the test set\n",
        "    test_predictions = knn.predict(X_test)\n",
        "\n",
        "    # Calculate precision, recall, and f-score for the current fold\n",
        "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
        "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
        "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
        "    if precision >= 0.5 and recall >= 0.5 and f1 >= 0.5:\n",
        "        print(f\"Fold {fold + 1} (Test):\")\n",
        "        for i in range(len(test_predictions)):\n",
        "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
        "\n",
        "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22618cc6-c1df-4639-a901-998439321067",
      "metadata": {
        "id": "22618cc6-c1df-4639-a901-998439321067",
        "outputId": "5212ed66-b529-46f7-f0be-06256068ab86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels and contents saved to embeddings/sin6.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|| 51/51 [03:07<00:00,  3.67s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 (Test):\n",
            "File: nons (50).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (63).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (21).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (64).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.875, Recall: 0.8333333333333334, F-score: 0.8285714285714286\n",
            "Fold 2 (Test):\n",
            "File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (61).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (6).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (46).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (45).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
            "Fold 3 (Test):\n",
            "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (47).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (60).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (56).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n",
            "Fold 5 (Test):\n",
            "File: nons (55).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (14).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (59).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (57).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.6, Recall: 0.6, F-score: 0.6\n",
            "Fold 6 (Test):\n",
            "File: singleton (25).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (49).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (48).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (52).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 1.0, Recall: 1.0, F-score: 1.0\n",
            "Fold 7 (Test):\n",
            "File: nons (53).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (23).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (43).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (4).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
            "Fold 9 (Test):\n",
            "File: nons (44).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (22).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (62).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (19).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.8, Recall: 0.6, F-score: 0.5666666666666667\n",
            "Fold 10 (Test):\n",
            "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (67).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (51).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"singleton\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = 'embeddings/sin6.csv'  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = 'embeddings/sin6.csv'  # Replace with the actual CSV file path\n",
        "\n",
        "# Initialize RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to calculate embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Calculate embeddings for each program by considering embeddings of individual lines\n",
        "program_embeddings = []\n",
        "for content in tqdm(df['Content']):\n",
        "    lines = content.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Convert program_embeddings to NumPy array\n",
        "program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "n_splits = 10\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
        "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
        "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
        "\n",
        "    # Apply k-nearest neighbor classification\n",
        "    n_neighbors = 3  # Number of neighbors to consider\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions on the test set\n",
        "    test_predictions = knn.predict(X_test)\n",
        "\n",
        "    # Calculate precision, recall, and f-score for the current fold\n",
        "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
        "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
        "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
        "    if precision >= 0.5 and recall >= 0.5 and f1 >= 0.5:\n",
        "        print(f\"Fold {fold + 1} (Test):\")\n",
        "        for i in range(len(test_predictions)):\n",
        "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
        "\n",
        "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb2e9c8f-c10b-449d-82f8-00be476a65ba",
      "metadata": {
        "id": "eb2e9c8f-c10b-449d-82f8-00be476a65ba"
      },
      "outputs": [],
      "source": [
        "#Singleton with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c23c7525-6b23-49ff-8b4d-3cc30097c97a",
      "metadata": {
        "id": "c23c7525-6b23-49ff-8b4d-3cc30097c97a",
        "outputId": "0a60f1ba-1551-4051-d919-2e5a7d4b0f22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels and contents saved to embeddings/sin7.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|| 53/53 [04:45<00:00,  5.38s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 (Test):\n",
            "File: nons (54).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (17).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (65).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.875, Recall: 0.8333333333333334, F-score: 0.8285714285714286\n",
            "Fold 2 (Test):\n",
            "File: nons (55).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (6).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (6).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (24).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.875, Recall: 0.8333333333333334, F-score: 0.8285714285714286\n",
            "Fold 3 (Test):\n",
            "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (8).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (21).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (46).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.875, Recall: 0.8333333333333334, F-score: 0.8285714285714286\n",
            "Fold 4 (Test):\n",
            "File: nons (34).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (14).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (20).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (60).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n",
            "Fold 5 (Test):\n",
            "File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (27).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (3).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (28).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n",
            "Fold 6 (Test):\n",
            "File: nons (19).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (23).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (35).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (52).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.6, Recall: 0.6, F-score: 0.6\n",
            "Fold 9 (Test):\n",
            "File: nons (33).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (53).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (22).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (19).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
            "Fold 10 (Test):\n",
            "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (14).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (16).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"singleton\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = 'embeddings/sin7.csv'  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = 'embeddings/sin7.csv'  # Replace with the actual CSV file path\n",
        "\n",
        "# Initialize RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to calculate embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Calculate embeddings for each program by considering embeddings of individual lines\n",
        "program_embeddings = []\n",
        "for content in tqdm(df['Content']):\n",
        "    lines = content.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Convert program_embeddings to NumPy array\n",
        "program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "n_splits = 10\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
        "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
        "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
        "\n",
        "    # Apply k-nearest neighbor classification\n",
        "    n_neighbors = 3  # Number of neighbors to consider\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions on the test set\n",
        "    test_predictions = knn.predict(X_test)\n",
        "\n",
        "    # Calculate precision, recall, and f-score for the current fold\n",
        "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
        "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
        "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
        "    if precision >= 0.5 and recall >= 0.5 and f1 >= 0.5:\n",
        "        print(f\"Fold {fold + 1} (Test):\")\n",
        "        for i in range(len(test_predictions)):\n",
        "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
        "\n",
        "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27ebe769-5ac1-4d87-b6b1-4bb41018f92f",
      "metadata": {
        "id": "27ebe769-5ac1-4d87-b6b1-4bb41018f92f"
      },
      "outputs": [],
      "source": [
        "#Singleton with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce01d1b9-eb5c-4776-b458-2c62acd7163a",
      "metadata": {
        "id": "ce01d1b9-eb5c-4776-b458-2c62acd7163a",
        "outputId": "5e6952c4-8d8e-48cb-cadb-1944e0e02ab3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels and contents saved to embeddings/sin8.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|| 51/51 [04:31<00:00,  5.33s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 (Test):\n",
            "File: nons (54).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (17).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (24).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 1.0, Recall: 1.0, F-score: 1.0\n",
            "Fold 2 (Test):\n",
            "File: nons (55).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (6).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (6).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (23).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 1.0, Recall: 1.0, F-score: 1.0\n",
            "Fold 3 (Test):\n",
            "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (8).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (21).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (60).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n",
            "Fold 4 (Test):\n",
            "File: nons (34).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (20).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (15).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n",
            "Fold 5 (Test):\n",
            "File: nons (27).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (14).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (3).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (28).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n",
            "Fold 6 (Test):\n",
            "File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (19).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (35).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (52).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.6, Recall: 0.6, F-score: 0.6\n",
            "Fold 7 (Test):\n",
            "File: nons (30).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (53).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (23).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (4).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.8, Recall: 0.6, F-score: 0.5666666666666667\n",
            "Fold 9 (Test):\n",
            "File: nons (33).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (22).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (46).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (19).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
            "Fold 10 (Test):\n",
            "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (14).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (16).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"singleton\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = 'embeddings/sin8.csv'  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = 'embeddings/sin8.csv'  # Replace with the actual CSV file path\n",
        "\n",
        "# Initialize RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to calculate embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Calculate embeddings for each program by considering embeddings of individual lines\n",
        "program_embeddings = []\n",
        "for content in tqdm(df['Content']):\n",
        "    lines = content.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Convert program_embeddings to NumPy array\n",
        "program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "n_splits = 10\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
        "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
        "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
        "\n",
        "    # Apply k-nearest neighbor classification\n",
        "    n_neighbors = 3  # Number of neighbors to consider\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions on the test set\n",
        "    test_predictions = knn.predict(X_test)\n",
        "\n",
        "    # Calculate precision, recall, and f-score for the current fold\n",
        "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
        "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
        "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
        "    if precision >= 0.4 and recall >= 0.4 and f1 >= 0.4:\n",
        "        print(f\"Fold {fold + 1} (Test):\")\n",
        "        for i in range(len(test_predictions)):\n",
        "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
        "\n",
        "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b6ec30b-4031-4be6-8da1-ca587db5dddb",
      "metadata": {
        "id": "1b6ec30b-4031-4be6-8da1-ca587db5dddb",
        "outputId": "2af0eba5-f891-4353-88a2-c00de443df2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels and contents saved to embeddings/sin9.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|| 51/51 [03:32<00:00,  4.17s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 (Test):\n",
            "File: nons (12).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (1).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (32).java, Predicted Label: 1, True Label: 0\n",
            "Precision: 0.7999999999999999, Recall: 0.6666666666666666, F-score: 0.6249999999999999\n",
            "Fold 2 (Test):\n",
            "File: nons (27).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (40).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (6).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (15).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.6, Recall: 0.6, F-score: 0.6\n",
            "Fold 3 (Test):\n",
            "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (11).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (26).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (21).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n",
            "Fold 4 (Test):\n",
            "File: nons (19).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (22).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (67).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.4333333333333333, Recall: 0.4, F-score: 0.4\n",
            "Fold 5 (Test):\n",
            "File: nons (29).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (38).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (14).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (36).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.3, Recall: 0.4, F-score: 0.34285714285714286\n",
            "Fold 6 (Test):\n",
            "File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (42).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (3).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (24).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n",
            "Fold 7 (Test):\n",
            "File: nons (59).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (33).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (23).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (4).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.6, Recall: 0.6, F-score: 0.6\n",
            "Fold 8 (Test):\n",
            "File: nons (54).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (3).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (16).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (23).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (7).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.8, Recall: 0.6, F-score: 0.5666666666666667\n",
            "Fold 9 (Test):\n",
            "File: nons (61).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (37).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (22).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (19).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.6, Recall: 0.6, F-score: 0.6\n",
            "Fold 10 (Test):\n",
            "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (20).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (2).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"singleton\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = 'embeddings/sin9.csv'  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = 'embeddings/sin9.csv'  # Replace with the actual CSV file path\n",
        "\n",
        "# Initialize RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to calculate embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Calculate embeddings for each program by considering embeddings of individual lines\n",
        "program_embeddings = []\n",
        "for content in tqdm(df['Content']):\n",
        "    lines = content.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Convert program_embeddings to NumPy array\n",
        "program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "n_splits = 10\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
        "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
        "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
        "\n",
        "    # Apply k-nearest neighbor classification\n",
        "    n_neighbors = 3  # Number of neighbors to consider\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions on the test set\n",
        "    test_predictions = knn.predict(X_test)\n",
        "\n",
        "    # Calculate precision, recall, and f-score for the current fold\n",
        "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
        "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
        "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
        "    if precision >= 0.1 and recall >= 0.1 and f1 >= 0.1:\n",
        "        print(f\"Fold {fold + 1} (Test):\")\n",
        "        for i in range(len(test_predictions)):\n",
        "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
        "\n",
        "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c38f346a-4318-4a27-b4e5-73a6647d2cce",
      "metadata": {
        "id": "c38f346a-4318-4a27-b4e5-73a6647d2cce",
        "outputId": "86c3d0e8-7839-4126-f5fc-39c084e057e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels and contents saved to embeddings/sin10.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|| 54/54 [04:37<00:00,  5.14s/it]\n",
            "/cephyr/users/sushantk/Alvis/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 (Test):\n",
            "File: nons (54).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (17).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (23).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 1.0, Recall: 1.0, F-score: 1.0\n",
            "Fold 2 (Test):\n",
            "File: nons (68).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (16).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (26).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (4).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (46).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.5, Recall: 0.5, F-score: 0.48571428571428577\n",
            "Fold 3 (Test):\n",
            "File: singleton (14).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (3).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (16).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (6).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (15).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.875, Recall: 0.8333333333333334, F-score: 0.8285714285714286\n",
            "Fold 4 (Test):\n",
            "File: nons (27).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (20).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (6).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 1.0, Recall: 1.0, F-score: 1.0\n",
            "Fold 5 (Test):\n",
            "File: nons (42).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (33).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (28).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
            "Fold 6 (Test):\n",
            "File: nons (30).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (35).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (19).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (65).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n",
            "Fold 7 (Test):\n",
            "File: nons (25).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (23).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (8).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (21).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (22).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.6, Recall: 0.6, F-score: 0.6\n",
            "Fold 8 (Test):\n",
            "File: nons (18).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (3).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (53).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (24).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.36, Recall: 0.6, F-score: 0.4499999999999999\n",
            "Fold 9 (Test):\n",
            "File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (19).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (34).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (60).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.3, Recall: 0.4, F-score: 0.34285714285714286\n",
            "Fold 10 (Test):\n",
            "File: nons (55).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (14).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (7).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"singleton\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = 'embeddings/sin10.csv'  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = 'embeddings/sin10.csv'  # Replace with the actual CSV file path\n",
        "\n",
        "# Initialize RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to calculate embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Calculate embeddings for each program by considering embeddings of individual lines\n",
        "program_embeddings = []\n",
        "for content in tqdm(df['Content']):\n",
        "    lines = content.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Convert program_embeddings to NumPy array\n",
        "program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "n_splits = 10\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
        "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
        "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
        "\n",
        "    # Apply k-nearest neighbor classification\n",
        "    n_neighbors = 3  # Number of neighbors to consider\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions on the test set\n",
        "    test_predictions = knn.predict(X_test)\n",
        "\n",
        "    # Calculate precision, recall, and f-score for the current fold\n",
        "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
        "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
        "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
        "    if precision >= 0.1 and recall >= 0.1 and f1 >= 0.1:\n",
        "        print(f\"Fold {fold + 1} (Test):\")\n",
        "        for i in range(len(test_predictions)):\n",
        "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
        "\n",
        "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef605068-0d99-4064-b730-8847d11b886f",
      "metadata": {
        "id": "ef605068-0d99-4064-b730-8847d11b886f"
      },
      "outputs": [],
      "source": [
        "#Singleton using different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b235d8bb-bf14-474f-af5f-1c2329dfc296",
      "metadata": {
        "id": "b235d8bb-bf14-474f-af5f-1c2329dfc296",
        "outputId": "45a01a81-6501-4967-befc-7fdc60718a85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels and contents saved to embeddings/sin11.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|| 50/50 [03:23<00:00,  4.07s/it]\n",
            "/cephyr/users/sushantk/Alvis/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 (Test):\n",
            "File: nons (18).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (22).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (39).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.4333333333333333, Recall: 0.4, F-score: 0.4\n",
            "Fold 2 (Test):\n",
            "File: nons (12).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (13).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (23).java, Predicted Label: 1, True Label: 0\n",
            "Precision: 0.16, Recall: 0.4, F-score: 0.2285714285714286\n",
            "Fold 3 (Test):\n",
            "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (63).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (8).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (22).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (60).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
            "Fold 4 (Test):\n",
            "File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (68).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (3).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (35).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (51).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n",
            "Fold 5 (Test):\n",
            "File: nons (30).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (14).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (19).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (36).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.6, Recall: 0.6, F-score: 0.6\n",
            "Fold 6 (Test):\n",
            "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (55).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (14).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (16).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (52).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
            "Fold 7 (Test):\n",
            "File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (7).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (67).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
            "Fold 8 (Test):\n",
            "File: nons (19).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (6).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (46).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.6, Recall: 0.6, F-score: 0.6\n",
            "Fold 9 (Test):\n",
            "File: nons (4).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (4).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (62).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (7).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.8, Recall: 0.6, F-score: 0.5666666666666667\n",
            "Fold 10 (Test):\n",
            "File: nons (59).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (33).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (23).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.4333333333333333, Recall: 0.4, F-score: 0.4\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"singleton\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = 'embeddings/sin11.csv'  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = 'embeddings/sin11.csv'  # Replace with the actual CSV file path\n",
        "\n",
        "# Initialize RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to calculate embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Calculate embeddings for each program by considering embeddings of individual lines\n",
        "program_embeddings = []\n",
        "for content in tqdm(df['Content']):\n",
        "    lines = content.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Convert program_embeddings to NumPy array\n",
        "program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "n_splits = 10\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
        "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
        "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
        "\n",
        "    # Apply k-nearest neighbor classification\n",
        "    n_neighbors = 3  # Number of neighbors to consider\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions on the test set\n",
        "    test_predictions = knn.predict(X_test)\n",
        "\n",
        "    # Calculate precision, recall, and f-score for the current fold\n",
        "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
        "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
        "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
        "    if precision >= 0.1 and recall >= 0.1 and f1 >= 0.1:\n",
        "        print(f\"Fold {fold + 1} (Test):\")\n",
        "        for i in range(len(test_predictions)):\n",
        "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
        "\n",
        "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cd1818e-e930-4a1c-bcfb-ee1c1386494c",
      "metadata": {
        "id": "5cd1818e-e930-4a1c-bcfb-ee1c1386494c"
      },
      "outputs": [],
      "source": [
        "#Singleton with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47391837-18fe-4522-93c2-2337403d2e49",
      "metadata": {
        "id": "47391837-18fe-4522-93c2-2337403d2e49",
        "outputId": "b771080e-43e3-4b56-9bba-e7b5395ba509"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels and contents saved to embeddings/sin12.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|| 51/51 [03:28<00:00,  4.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 (Test):\n",
            "File: nons (12).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (2).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (23).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 1.0, Recall: 1.0, F-score: 1.0\n",
            "Fold 2 (Test):\n",
            "File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (4).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (21).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (6).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (15).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 1.0, Recall: 1.0, F-score: 1.0\n",
            "Fold 3 (Test):\n",
            "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (26).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (8).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (13).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.6, Recall: 0.6, F-score: 0.6\n",
            "Fold 4 (Test):\n",
            "File: nons (7).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (14).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (6).java, Predicted Label: 1, True Label: 0\n",
            "Precision: 0.4333333333333333, Recall: 0.4, F-score: 0.4\n",
            "Fold 5 (Test):\n",
            "File: nons (18).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (14).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (1).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (5).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.85, Recall: 0.8, F-score: 0.7809523809523808\n",
            "Fold 6 (Test):\n",
            "File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (19).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (20).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (11).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (24).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.6, Recall: 0.6, F-score: 0.6\n",
            "Fold 7 (Test):\n",
            "File: nons (22).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (23).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (17).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (4).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.8, Recall: 0.6, F-score: 0.5666666666666667\n",
            "Fold 8 (Test):\n",
            "File: nons (25).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (3).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (16).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (9).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (7).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.1, Recall: 0.2, F-score: 0.13333333333333333\n",
            "Fold 9 (Test):\n",
            "File: nons (3).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (22).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (10).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (19).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
            "Fold 10 (Test):\n",
            "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (16).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (11).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (17).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"singleton\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = 'embeddings/sin12.csv'  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = 'embeddings/sin12.csv'  # Replace with the actual CSV file path\n",
        "\n",
        "# Initialize RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to calculate embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Calculate embeddings for each program by considering embeddings of individual lines\n",
        "program_embeddings = []\n",
        "for content in tqdm(df['Content']):\n",
        "    lines = content.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Convert program_embeddings to NumPy array\n",
        "program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "n_splits = 10\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
        "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
        "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
        "\n",
        "    # Apply k-nearest neighbor classification\n",
        "    n_neighbors = 3  # Number of neighbors to consider\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions on the test set\n",
        "    test_predictions = knn.predict(X_test)\n",
        "\n",
        "    # Calculate precision, recall, and f-score for the current fold\n",
        "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
        "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
        "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
        "    if precision >= 0.1 and recall >= 0.1 and f1 >= 0.1:\n",
        "        print(f\"Fold {fold + 1} (Test):\")\n",
        "        for i in range(len(test_predictions)):\n",
        "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
        "\n",
        "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c2142af-96d7-498d-a518-773271117efb",
      "metadata": {
        "id": "0c2142af-96d7-498d-a518-773271117efb"
      },
      "outputs": [],
      "source": [
        "#Singleton using different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4781086f-4d12-40e8-b0b2-1f91d73711c2",
      "metadata": {
        "id": "4781086f-4d12-40e8-b0b2-1f91d73711c2",
        "outputId": "86be0c59-eaa4-4c8b-e222-e76187b8419e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels and contents saved to embeddings/sin13.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|| 51/51 [03:23<00:00,  4.00s/it]\n",
            "/cephyr/users/sushantk/Alvis/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 (Test):\n",
            "File: nons (54).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (10).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (17).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (8).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (21).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (23).java, Predicted Label: 1, True Label: 0\n",
            "Precision: 0.7999999999999999, Recall: 0.6666666666666666, F-score: 0.6249999999999999\n",
            "Fold 2 (Test):\n",
            "File: singleton (24).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (68).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (67).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (6).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (32).java, Predicted Label: 1, True Label: 0\n",
            "Precision: 0.8666666666666666, Recall: 0.8, F-score: 0.8\n",
            "Fold 3 (Test):\n",
            "File: singleton (18).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (26).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (66).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (51).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (5).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.4333333333333333, Recall: 0.4, F-score: 0.4\n",
            "Fold 4 (Test):\n",
            "File: nons (4).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (43).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (13).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (12).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (31).java, Predicted Label: 1, True Label: 0\n",
            "Precision: 0.4333333333333333, Recall: 0.4, F-score: 0.4\n",
            "Fold 5 (Test):\n",
            "File: nons (42).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (44).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (14).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (1).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (52).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.36, Recall: 0.6, F-score: 0.4499999999999999\n",
            "Fold 6 (Test):\n",
            "File: singleton (25).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (34).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (53).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (11).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (65).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.3, Recall: 0.4, F-score: 0.34285714285714286\n",
            "Fold 7 (Test):\n",
            "File: nons (33).java, Predicted Label: 0, True Label: 0\n",
            "File: nons (41).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (23).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (20).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (4).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.8, Recall: 0.6, F-score: 0.5666666666666667\n",
            "Fold 8 (Test):\n",
            "File: nons (25).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (3).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (16).java, Predicted Label: 0, True Label: 1\n",
            "File: nons (24).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (7).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.1, Recall: 0.2, F-score: 0.13333333333333333\n",
            "Fold 9 (Test):\n",
            "File: nons (7).java, Predicted Label: 1, True Label: 0\n",
            "File: singleton (22).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (15).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (19).java, Predicted Label: 0, True Label: 1\n",
            "File: singleton (2).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.6, Recall: 0.6, F-score: 0.6\n",
            "Fold 10 (Test):\n",
            "File: singleton (9).java, Predicted Label: 1, True Label: 1\n",
            "File: nons (14).java, Predicted Label: 1, True Label: 0\n",
            "File: nons (16).java, Predicted Label: 0, True Label: 0\n",
            "File: singleton (15).java, Predicted Label: 1, True Label: 1\n",
            "File: singleton (17).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.6, Recall: 0.6, F-score: 0.6\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'singleton'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"singleton\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = 'embeddings/sin13.csv'  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = 'embeddings/sin13.csv'  # Replace with the actual CSV file path\n",
        "\n",
        "# Initialize RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to calculate embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Calculate embeddings for each program by considering embeddings of individual lines\n",
        "program_embeddings = []\n",
        "for content in tqdm(df['Content']):\n",
        "    lines = content.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Convert program_embeddings to NumPy array\n",
        "program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "n_splits = 10\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
        "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
        "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
        "\n",
        "    # Apply k-nearest neighbor classification\n",
        "    n_neighbors = 3  # Number of neighbors to consider\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions on the test set\n",
        "    test_predictions = knn.predict(X_test)\n",
        "\n",
        "    # Calculate precision, recall, and f-score for the current fold\n",
        "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
        "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
        "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
        "    if precision >= 0.1 and recall >= 0.1 and f1 >= 0.1:\n",
        "        print(f\"Fold {fold + 1} (Test):\")\n",
        "        for i in range(len(test_predictions)):\n",
        "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
        "\n",
        "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "513ee4a4-4d42-4bcc-b0f5-be95126127e5",
      "metadata": {
        "id": "513ee4a4-4d42-4bcc-b0f5-be95126127e5"
      },
      "outputs": [],
      "source": [
        "#Abstract Factory with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77a73089-0a73-41f6-a06e-c2c1861c11d0",
      "metadata": {
        "id": "77a73089-0a73-41f6-a06e-c2c1861c11d0",
        "outputId": "16e1cc75-82c6-425f-8fea-9716ebc67442"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels and contents saved to embeddings/af1.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|| 33/33 [02:42<00:00,  4.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 (Test):\n",
            "File: nonab (72).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (2).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (16).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (67).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (12).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (6).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.8857142857142858, Recall: 0.8571428571428571, F-score: 0.8507936507936508\n",
            "Fold 2 (Test):\n",
            "File: nonab (11).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (1).java, Predicted Label: 1, True Label: 0\n",
            "File: abstractfactory (4).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (5).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (3).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (74).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (9).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.8928571428571429, Recall: 0.8571428571428571, F-score: 0.8571428571428571\n",
            "Fold 3 (Test):\n",
            "File: nonab (19).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (5).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (13).java, Predicted Label: 0, True Label: 1\n",
            "File: nonab (83).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (11).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (8).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (14).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.8285714285714285, Recall: 0.7142857142857143, F-score: 0.7023809523809523\n",
            "Fold 4 (Test):\n",
            "File: nonab (7).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (9).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (1).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (12).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (85).java, Predicted Label: 1, True Label: 0\n",
            "File: nonab (18).java, Predicted Label: 1, True Label: 0\n",
            "Precision: 0.7999999999999999, Recall: 0.6666666666666666, F-score: 0.6249999999999999\n",
            "Fold 5 (Test):\n",
            "File: abstractfactory (10).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (8).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (15).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (7).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (54).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (49).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 1.0, Recall: 1.0, F-score: 1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'abstractfactory'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"abstractfactory\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = 'embeddings/af1.csv'  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = 'embeddings/af1.csv'  # Replace with the actual CSV file path\n",
        "\n",
        "# Initialize RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to calculate embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Calculate embeddings for each program by considering embeddings of individual lines\n",
        "program_embeddings = []\n",
        "for content in tqdm(df['Content']):\n",
        "    lines = content.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Convert program_embeddings to NumPy array\n",
        "program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
        "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
        "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
        "\n",
        "    # Apply k-nearest neighbor classification\n",
        "    n_neighbors = 3  # Number of neighbors to consider\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions on the test set\n",
        "    test_predictions = knn.predict(X_test)\n",
        "\n",
        "    # Calculate precision, recall, and f-score for the current fold\n",
        "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
        "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
        "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
        "    if precision >= 0.1 and recall >= 0.1 and f1 >= 0.1:\n",
        "        print(f\"Fold {fold + 1} (Test):\")\n",
        "        for i in range(len(test_predictions)):\n",
        "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
        "\n",
        "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e646d60-ed06-40e2-bd41-494dee25b9ea",
      "metadata": {
        "id": "7e646d60-ed06-40e2-bd41-494dee25b9ea"
      },
      "outputs": [],
      "source": [
        "#Abstract Factory using different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4db74ca4-2b59-42f5-aaae-66b2d1ca2040",
      "metadata": {
        "id": "4db74ca4-2b59-42f5-aaae-66b2d1ca2040",
        "outputId": "48769c88-2aec-4137-904b-a3c5309126ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels and contents saved to embeddings/af2.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|| 32/32 [02:20<00:00,  4.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 (Test):\n",
            "File: nonab (11).java, Predicted Label: 1, True Label: 0\n",
            "File: abstractfactory (2).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (2).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (16).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (6).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (16).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (6).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.7142857142857143, Recall: 0.7142857142857143, F-score: 0.7142857142857143\n",
            "Fold 2 (Test):\n",
            "File: nonab (5).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (10).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (4).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (5).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (3).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (12).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (14).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.8928571428571429, Recall: 0.8571428571428571, F-score: 0.8571428571428571\n",
            "Fold 3 (Test):\n",
            "File: nonab (7).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (15).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (13).java, Predicted Label: 0, True Label: 1\n",
            "File: nonab (13).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (11).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (8).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.875, Recall: 0.8333333333333334, F-score: 0.8285714285714286\n",
            "Fold 4 (Test):\n",
            "File: abstractfactory (9).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (3).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (1).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (12).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (4).java, Predicted Label: 1, True Label: 0\n",
            "File: nonab (9).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.875, Recall: 0.8333333333333334, F-score: 0.8285714285714286\n",
            "Fold 5 (Test):\n",
            "File: nonab (1).java, Predicted Label: 1, True Label: 0\n",
            "File: abstractfactory (10).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (8).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (14).java, Predicted Label: 1, True Label: 0\n",
            "File: abstractfactory (15).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (7).java, Predicted Label: 1, True Label: 1\n",
            "Precision: 0.7999999999999999, Recall: 0.6666666666666666, F-score: 0.6249999999999999\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'abstractfactory'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"abstractfactory\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = 'embeddings/af2.csv'  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = 'embeddings/af2.csv'  # Replace with the actual CSV file path\n",
        "\n",
        "# Initialize RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to calculate embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Calculate embeddings for each program by considering embeddings of individual lines\n",
        "program_embeddings = []\n",
        "for content in tqdm(df['Content']):\n",
        "    lines = content.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Convert program_embeddings to NumPy array\n",
        "program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
        "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
        "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
        "\n",
        "    # Apply k-nearest neighbor classification\n",
        "    n_neighbors = 3  # Number of neighbors to consider\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions on the test set\n",
        "    test_predictions = knn.predict(X_test)\n",
        "\n",
        "    # Calculate precision, recall, and f-score for the current fold\n",
        "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
        "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
        "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
        "    if precision >= 0.1 and recall >= 0.1 and f1 >= 0.1:\n",
        "        print(f\"Fold {fold + 1} (Test):\")\n",
        "        for i in range(len(test_predictions)):\n",
        "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
        "\n",
        "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dffd5d6a-fb1a-48e5-93fe-09f8fcbe6b18",
      "metadata": {
        "id": "dffd5d6a-fb1a-48e5-93fe-09f8fcbe6b18"
      },
      "outputs": [],
      "source": [
        "#Abstract Factory using different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe26f1e2-a2ec-41e8-b11f-4a34b7312784",
      "metadata": {
        "id": "fe26f1e2-a2ec-41e8-b11f-4a34b7312784",
        "outputId": "84edca0f-7c45-4228-ea62-7ac24d36b3b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels and contents saved to embeddings/af3.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|| 32/32 [03:27<00:00,  6.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 (Test):\n",
            "File: nonab (11).java, Predicted Label: 1, True Label: 0\n",
            "File: nonab (48).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (2).java, Predicted Label: 0, True Label: 1\n",
            "File: abstractfactory (16).java, Predicted Label: 0, True Label: 1\n",
            "File: nonab (8).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (4).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (5).java, Predicted Label: 0, True Label: 1\n",
            "File: nonab (3).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (3).java, Predicted Label: 0, True Label: 1\n",
            "File: nonab (4).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (8).java, Predicted Label: 0, True Label: 1\n",
            "File: abstractfactory (14).java, Predicted Label: 0, True Label: 1\n",
            "File: nonab (63).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (17).java, Predicted Label: 1, True Label: 0\n",
            "File: nonab (18).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (6).java, Predicted Label: 0, True Label: 1\n",
            "Precision: 0.39743589743589747, Recall: 0.4375, F-score: 0.37662337662337664\n",
            "Fold 2 (Test):\n",
            "File: nonab (5).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (65).java, Predicted Label: 1, True Label: 0\n",
            "File: nonab (7).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (10).java, Predicted Label: 0, True Label: 1\n",
            "File: abstractfactory (9).java, Predicted Label: 0, True Label: 1\n",
            "File: abstractfactory (13).java, Predicted Label: 0, True Label: 1\n",
            "File: abstractfactory (1).java, Predicted Label: 1, True Label: 1\n",
            "File: abstractfactory (12).java, Predicted Label: 0, True Label: 1\n",
            "File: nonab (14).java, Predicted Label: 0, True Label: 0\n",
            "File: nonab (74).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (15).java, Predicted Label: 1, True Label: 1\n",
            "File: nonab (40).java, Predicted Label: 0, True Label: 0\n",
            "File: abstractfactory (11).java, Predicted Label: 0, True Label: 1\n",
            "File: abstractfactory (7).java, Predicted Label: 0, True Label: 1\n",
            "File: nonab (12).java, Predicted Label: 1, True Label: 0\n",
            "File: nonab (47).java, Predicted Label: 0, True Label: 0\n",
            "Precision: 0.5, Recall: 0.5, F-score: 0.4666666666666667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = 'abstractfactory'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"abstractfactory\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = 'embeddings/af3.csv'  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = 'embeddings/af3.csv'  # Replace with the actual CSV file path\n",
        "\n",
        "# Initialize RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to calculate embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Calculate embeddings for each program by considering embeddings of individual lines\n",
        "program_embeddings = []\n",
        "for content in tqdm(df['Content']):\n",
        "    lines = content.split('\\n')\n",
        "    line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "    program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "\n",
        "# Convert program_embeddings to NumPy array\n",
        "program_embeddings = np.vstack(program_embeddings)\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "n_splits = 2\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(program_embeddings, df['Label'])):\n",
        "    X_train, X_test = program_embeddings[train_index], program_embeddings[test_index]\n",
        "    y_train, y_test = df['Label'].iloc[train_index], df['Label'].iloc[test_index]\n",
        "\n",
        "    # Apply k-nearest neighbor classification\n",
        "    n_neighbors = 3  # Number of neighbors to consider\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions on the test set\n",
        "    test_predictions = knn.predict(X_test)\n",
        "\n",
        "    # Calculate precision, recall, and f-score for the current fold\n",
        "    precision = precision_score(y_test, test_predictions, average='weighted')\n",
        "    recall = recall_score(y_test, test_predictions, average='weighted')\n",
        "    f1 = f1_score(y_test, test_predictions, average='weighted')\n",
        "\n",
        "    # Print predictions and performance measures only if precision, recall, and f-score are >= 70%\n",
        "    if precision >= 0.1 and recall >= 0.1 and f1 >= 0.1:\n",
        "        print(f\"Fold {fold + 1} (Test):\")\n",
        "        for i in range(len(test_predictions)):\n",
        "            print(f\"File: {df['File Name'].iloc[test_index[i]]}, Predicted Label: {test_predictions[i]}, True Label: {y_test.iloc[i]}\")\n",
        "\n",
        "        print(f\"Precision: {precision}, Recall: {recall}, F-score: {f1}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Time calculation for abstract factory**"
      ],
      "metadata": {
        "id": "b5S3NgmHrl4e"
      },
      "id": "b5S3NgmHrl4e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3605f92c-a527-4394-9078-e571f961ec69",
      "metadata": {
        "id": "3605f92c-a527-4394-9078-e571f961ec69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 993,
          "referenced_widgets": [
            "a85b7716b66d4a65b86d823e96257fa5",
            "88ea5c3936df4246aa7522d724624c2d",
            "15657c210550401ea93289a6858d7d50",
            "a3863ad6cb3648769b30a476b2b42098",
            "58fa25cf67084e46afb804d08eb828b6",
            "22fa3cbd7ed94791978f61ee89caa413",
            "2d3a29afa01440ba9a4ed69ba1784cf5",
            "4075b3d861e444d1a00b62574ad7b3ac",
            "397c3552e71b47628ff28ca7cd9e690d",
            "33c89bdd0a3542b99ea51e7bcae06e56",
            "9d9b4d7302094f4083ba1ed5b0e7d237",
            "f580602a050b41f98ea604d56790584d",
            "c5f8c596111a401d87fbc934142e7dae",
            "763251a457e44e0eaf033539d64a6da2",
            "75d57b7721cb4fd584bec2509fa66714",
            "d4a1ed7708714d7594b376f20428a861",
            "6841b400af2f4ef281547b1060816087",
            "51f5f873e1da44f29a21387d2d1d992a",
            "850fc7c97eac46e6b3224d0fda01895f",
            "ec2ae4c9f738443ab4838c62e25f2963",
            "500cf334ce8a4eabb66b317be0e397b5",
            "d1990342b2ad4b9c87526d8bff71e5c8",
            "6e0a2dd859c34363b486cfcc494c2bcc",
            "a320118280d6442b9f32c1edb06b0849",
            "1b9a255e89b34ec38f4335158c206063",
            "cde7a03be37e4470b0544d2b5bdec0e9",
            "80b212e293d441a2b1d2f8afefcc14e7",
            "5c7c24cf204a42f9a21eb0ee6754c56a",
            "45d56e2331b64f529870cc9505be108e",
            "22f5b4cbda6049bfb4868b58be78469a",
            "abbb1665b08445e9a0f049442e10eba1",
            "107c51f3cb5f440e96cdb8af45d6c420",
            "ad769370d10f43fab81603faee875dcd",
            "f7266c21ee9e4c6b9fd369b6c1555260",
            "c53095a4c9734d8d9c1c0a7181f24c3c",
            "9b53868e165d4018a582c92c47e8e75e",
            "0a7ea26a59db48818fa9d90b642690ae",
            "c5402d0294d74579a82cb57dc7bc7a19",
            "8ed3ad4e0e124e4080008fc1683ccd95",
            "52f34ebb7ec44fd6a230ea22b34654e7",
            "c73f62744f724ffdbed9e7c7552a5da5",
            "0e75ec5b66f44bf7bd7a073ee177cb03",
            "db6afd6ac9ea4cc6890c95cffd991378",
            "ae5b57e3b91246fab565701d1ffc1295",
            "54748ae79e5243218e2bcd2c8da5a124",
            "91734fe66f1e4c7185b5d74f3111b257",
            "55ed1da451c04c82930492b62329e8f2",
            "f6578d66d83241a3bc755c5f3eb37a07",
            "858d70cb3328472e907370c491ac7aae",
            "42958384a0be4a4582bdbad7ca0ef6e9",
            "5ec9035bbc37424aa74be325533a7d6d",
            "e53d6ee5bae447fc928ce371aa3845d9",
            "d1c74c7b91e6461a91378beefb35b60f",
            "38552133339d4c51b74ef42785c4ae35",
            "5403d9d6accf4398b58bf370e99bfc82",
            "bbaa53a58a6a44bbad5e663504848272",
            "01e899baba324647bc2c415d5f6502b2",
            "a5ec5c41cfc2493ca637a6523504f95e",
            "1a3f5bae1d06428b87497b4b14bca389",
            "d48dc5760cba4851845c243248eb0987",
            "3f6fef2d2a0944b193a16928ea51d17d",
            "29809cea2d69482289f46f05db34716b",
            "857efaa1713d448db7eaabeecc323954",
            "fe1473f11d944ed48bb1cebc9d62f54f",
            "09e171af19574828bf0a0a33d76b01cc",
            "d586aea9022744f7b0547dee768f4ab8"
          ]
        },
        "outputId": "e1a64558-ab7c-47e3-c359-e7fc7b75d432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Labels and contents saved to embeddings/af3.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a85b7716b66d4a65b86d823e96257fa5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f580602a050b41f98ea604d56790584d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e0a2dd859c34363b486cfcc494c2bcc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7266c21ee9e4c6b9fd369b6c1555260"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54748ae79e5243218e2bcd2c8da5a124"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbaa53a58a6a44bbad5e663504848272"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 19/19 [00:50<00:00,  2.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 50180.77802658081, Prediction Time (ms): 49.419403076171875\n",
            "Experiment 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 17/17 [00:44<00:00,  2.61s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 44464.502573013306, Prediction Time (ms): 3.0274391174316406\n",
            "Experiment 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 21/21 [00:55<00:00,  2.62s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 55038.7864112854, Prediction Time (ms): 2.6955604553222656\n",
            "Experiment 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 15/15 [00:41<00:00,  2.75s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 41219.37155723572, Prediction Time (ms): 2.8960704803466797\n",
            "Experiment 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 20/20 [00:52<00:00,  2.63s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 52547.621726989746, Prediction Time (ms): 2.8939247131347656\n",
            "Experiment 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 17/17 [00:46<00:00,  2.73s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 46439.0606880188, Prediction Time (ms): 3.0426979064941406\n",
            "Experiment 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 18/18 [00:48<00:00,  2.70s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 48687.175273895264, Prediction Time (ms): 2.6514530181884766\n",
            "Experiment 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 17/17 [00:40<00:00,  2.35s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 40035.76612472534, Prediction Time (ms): 2.8231143951416016\n",
            "Experiment 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 17/17 [00:43<00:00,  2.58s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 43836.21883392334, Prediction Time (ms): 3.2112598419189453\n",
            "Experiment 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 22/22 [00:50<00:00,  2.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 50130.319356918335, Prediction Time (ms): 4.4116973876953125\n",
            "Mean Training Time (ms): 47257.960057258606\n",
            "Mean Prediction Time (ms): 7.70726203918457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check if CUDA is available and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = '/content/builder'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"builder\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Ensure the directory exists\n",
        "output_dir = 'embeddings'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = os.path.join(output_dir, 'af3.csv')  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = os.path.join(output_dir, 'af3.csv')  # Replace with the actual CSV file path\n",
        "\n",
        "# Initialize RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\").to(device)  # Move model to device\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to calculate embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move back to CPU for NumPy operations\n",
        "\n",
        "# Calculate embeddings for each program by considering embeddings of individual lines\n",
        "def calculate_program_embeddings(df):\n",
        "    program_embeddings = []\n",
        "    for content in tqdm(df['Content']):\n",
        "        lines = content.split('\\n')\n",
        "        line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "        program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "    return np.vstack(program_embeddings)\n",
        "\n",
        "# Function to randomly select negative examples to ensure 40%-60% class balance\n",
        "def balance_classes(df, neg_label=0, pos_label=1, min_ratio=0.4, max_ratio=0.6):\n",
        "    pos_examples = df[df['Label'] == pos_label]\n",
        "    neg_examples = df[df['Label'] == neg_label]\n",
        "\n",
        "    total_pos = len(pos_examples)\n",
        "    available_neg = len(neg_examples)\n",
        "\n",
        "    # Ensure the target_neg_range does not exceed available negative examples\n",
        "    target_neg_min = min(int(total_pos / max_ratio) - total_pos, available_neg)\n",
        "    target_neg_max = min(int(total_pos / min_ratio) - total_pos, available_neg)\n",
        "\n",
        "    # If there are not enough negative examples, we use all of them\n",
        "    if target_neg_max <= 0:\n",
        "        neg_selected = neg_examples\n",
        "    else:\n",
        "        neg_selected = neg_examples.sample(random.randint(target_neg_min, target_neg_max))\n",
        "\n",
        "    return pd.concat([pos_examples, neg_selected])\n",
        "\n",
        "# Perform the experiment 10 times and record training and prediction times\n",
        "n_splits = 2\n",
        "total_training_time = []\n",
        "total_prediction_time = []\n",
        "\n",
        "for experiment in range(10):\n",
        "    print(f\"Experiment {experiment + 1}\")\n",
        "\n",
        "    # Ensure class balance\n",
        "    balanced_df = balance_classes(df)\n",
        "\n",
        "    # Measure training time (includes embedding extraction + KNN fitting)\n",
        "    start_time_train = time.time()\n",
        "\n",
        "    # Get embeddings for balanced data\n",
        "    balanced_embeddings = calculate_program_embeddings(balanced_df)\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "\n",
        "    for fold, (train_index, test_index) in enumerate(skf.split(balanced_embeddings, balanced_df['Label'])):\n",
        "        X_train, X_test = balanced_embeddings[train_index], balanced_embeddings[test_index]\n",
        "        y_train, y_test = balanced_df['Label'].iloc[train_index], balanced_df['Label'].iloc[test_index]\n",
        "\n",
        "        # Apply k-nearest neighbor classification\n",
        "        knn = KNeighborsClassifier(n_neighbors=3)\n",
        "        knn.fit(X_train, y_train)\n",
        "\n",
        "    end_time_train = time.time()\n",
        "    training_time = (end_time_train - start_time_train) * 1000  # Convert to milliseconds\n",
        "    total_training_time.append(training_time)\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time_pred = time.time()\n",
        "\n",
        "    for fold, (train_index, test_index) in enumerate(skf.split(balanced_embeddings, balanced_df['Label'])):\n",
        "        X_test = balanced_embeddings[test_index]\n",
        "        test_predictions = knn.predict(X_test)\n",
        "\n",
        "    end_time_pred = time.time()\n",
        "    prediction_time = (end_time_pred - start_time_pred) * 1000  # Convert to milliseconds\n",
        "    total_prediction_time.append(prediction_time)\n",
        "\n",
        "    # Print the times for the current experiment\n",
        "    print(f\"Training Time (ms): {training_time}, Prediction Time (ms): {prediction_time}\")\n",
        "\n",
        "# Calculate mean times over all 10 experiments\n",
        "mean_training_time = np.mean(total_training_time)\n",
        "mean_prediction_time = np.mean(total_prediction_time)\n",
        "\n",
        "print(f\"Mean Training Time (ms): {mean_training_time}\")\n",
        "print(f\"Mean Prediction Time (ms): {mean_prediction_time}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Builder time calculation**"
      ],
      "metadata": {
        "id": "d0eIiPmwC6rA"
      },
      "id": "d0eIiPmwC6rA"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check if CUDA is available and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = '/content/builder'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"builder\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Ensure the directory exists\n",
        "output_dir = 'embeddings'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = os.path.join(output_dir, 'af3.csv')  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = os.path.join(output_dir, 'af3.csv')  # Replace with the actual CSV file path\n",
        "\n",
        "# Initialize RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\").to(device)  # Move model to device\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to calculate embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move back to CPU for NumPy operations\n",
        "\n",
        "# Calculate embeddings for each program by considering embeddings of individual lines\n",
        "def calculate_program_embeddings(df):\n",
        "    program_embeddings = []\n",
        "    for content in tqdm(df['Content']):\n",
        "        lines = content.split('\\n')\n",
        "        line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "        program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "    return np.vstack(program_embeddings)\n",
        "\n",
        "# Function to randomly select negative examples to ensure 40%-60% class balance\n",
        "def balance_classes(df, neg_label=0, pos_label=1, min_ratio=0.4, max_ratio=0.6):\n",
        "    pos_examples = df[df['Label'] == pos_label]\n",
        "    neg_examples = df[df['Label'] == neg_label]\n",
        "\n",
        "    total_pos = len(pos_examples)\n",
        "    available_neg = len(neg_examples)\n",
        "\n",
        "    # Ensure the target_neg_range does not exceed available negative examples\n",
        "    target_neg_min = min(int(total_pos / max_ratio) - total_pos, available_neg)\n",
        "    target_neg_max = min(int(total_pos / min_ratio) - total_pos, available_neg)\n",
        "\n",
        "    # If there are not enough negative examples, we use all of them\n",
        "    if target_neg_max <= 0:\n",
        "        neg_selected = neg_examples\n",
        "    else:\n",
        "        neg_selected = neg_examples.sample(random.randint(target_neg_min, target_neg_max))\n",
        "\n",
        "    return pd.concat([pos_examples, neg_selected])\n",
        "\n",
        "# Perform the experiment 10 times and record training and prediction times\n",
        "n_splits = 2\n",
        "total_training_time = []\n",
        "total_prediction_time = []\n",
        "\n",
        "for experiment in range(10):\n",
        "    print(f\"Experiment {experiment + 1}\")\n",
        "\n",
        "    # Ensure class balance\n",
        "    balanced_df = balance_classes(df)\n",
        "\n",
        "    # Measure training time (includes embedding extraction + KNN fitting)\n",
        "    start_time_train = time.time()\n",
        "\n",
        "    # Get embeddings for balanced data\n",
        "    balanced_embeddings = calculate_program_embeddings(balanced_df)\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "\n",
        "    for fold, (train_index, test_index) in enumerate(skf.split(balanced_embeddings, balanced_df['Label'])):\n",
        "        X_train, X_test = balanced_embeddings[train_index], balanced_embeddings[test_index]\n",
        "        y_train, y_test = balanced_df['Label'].iloc[train_index], balanced_df['Label'].iloc[test_index]\n",
        "\n",
        "        # Apply k-nearest neighbor classification\n",
        "        knn = KNeighborsClassifier(n_neighbors=3)\n",
        "        knn.fit(X_train, y_train)\n",
        "\n",
        "    end_time_train = time.time()\n",
        "    training_time = (end_time_train - start_time_train) * 1000  # Convert to milliseconds\n",
        "    total_training_time.append(training_time)\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time_pred = time.time()\n",
        "\n",
        "    for fold, (train_index, test_index) in enumerate(skf.split(balanced_embeddings, balanced_df['Label'])):\n",
        "        X_test = balanced_embeddings[test_index]\n",
        "        test_predictions = knn.predict(X_test)\n",
        "\n",
        "    end_time_pred = time.time()\n",
        "    prediction_time = (end_time_pred - start_time_pred) * 1000  # Convert to milliseconds\n",
        "    total_prediction_time.append(prediction_time)\n",
        "\n",
        "    # Print the times for the current experiment\n",
        "    print(f\"Training Time (ms): {training_time}, Prediction Time (ms): {prediction_time}\")\n",
        "\n",
        "# Calculate mean times over all 10 experiments\n",
        "mean_training_time = np.mean(total_training_time)\n",
        "mean_prediction_time = np.mean(total_prediction_time)\n",
        "\n",
        "print(f\"Mean Training Time (ms): {mean_training_time}\")\n",
        "print(f\"Mean Prediction Time (ms): {mean_prediction_time}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtGqxYm0C4hN",
        "outputId": "2cc678d4-15ba-41e3-b691-ea7bf42ddc60"
      },
      "id": "MtGqxYm0C4hN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Labels and contents saved to embeddings/af3.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 17/17 [01:04<00:00,  3.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 64701.75576210022, Prediction Time (ms): 3.0031204223632812\n",
            "Experiment 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 20/20 [00:54<00:00,  2.73s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 54584.04278755188, Prediction Time (ms): 3.2501220703125\n",
            "Experiment 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 20/20 [00:46<00:00,  2.34s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 46840.06667137146, Prediction Time (ms): 2.9244422912597656\n",
            "Experiment 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 18/18 [00:48<00:00,  2.67s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 48072.8554725647, Prediction Time (ms): 2.913236618041992\n",
            "Experiment 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 15/15 [00:40<00:00,  2.71s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 40735.3196144104, Prediction Time (ms): 2.8839111328125\n",
            "Experiment 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 18/18 [00:44<00:00,  2.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 44940.94491004944, Prediction Time (ms): 2.8486251831054688\n",
            "Experiment 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 19/19 [00:49<00:00,  2.61s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 49685.22334098816, Prediction Time (ms): 2.958536148071289\n",
            "Experiment 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 22/22 [00:54<00:00,  2.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 54327.791690826416, Prediction Time (ms): 2.997159957885742\n",
            "Experiment 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 18/18 [00:44<00:00,  2.49s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 44851.84168815613, Prediction Time (ms): 3.690004348754883\n",
            "Experiment 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 22/22 [00:47<00:00,  2.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 47184.78727340698, Prediction Time (ms): 3.6110877990722656\n",
            "Mean Training Time (ms): 49592.46292114258\n",
            "Mean Prediction Time (ms): 3.1080245971679688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GLPUYSFKr7w5"
      },
      "id": "GLPUYSFKr7w5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Singleton time calculation**"
      ],
      "metadata": {
        "id": "ekMXdJoUClo1"
      },
      "id": "ekMXdJoUClo1"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check if CUDA is available and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = '/content/singleton'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"singleton\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Ensure the directory exists\n",
        "output_dir = 'embeddings'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = os.path.join(output_dir, 'af3.csv')  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = os.path.join(output_dir, 'af3.csv')  # Replace with the actual CSV file path\n",
        "\n",
        "# Initialize RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\").to(device)  # Move model to device\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to calculate embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move back to CPU for NumPy operations\n",
        "\n",
        "# Calculate embeddings for each program by considering embeddings of individual lines\n",
        "def calculate_program_embeddings(df):\n",
        "    program_embeddings = []\n",
        "    for content in tqdm(df['Content']):\n",
        "        lines = content.split('\\n')\n",
        "        line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "        program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "    return np.vstack(program_embeddings)\n",
        "\n",
        "# Function to randomly select negative examples to ensure 40%-60% class balance\n",
        "def balance_classes(df, neg_label=0, pos_label=1, min_ratio=0.4, max_ratio=0.6):\n",
        "    pos_examples = df[df['Label'] == pos_label]\n",
        "    neg_examples = df[df['Label'] == neg_label]\n",
        "\n",
        "    total_pos = len(pos_examples)\n",
        "    available_neg = len(neg_examples)\n",
        "\n",
        "    # Ensure the target_neg_range does not exceed available negative examples\n",
        "    target_neg_min = min(int(total_pos / max_ratio) - total_pos, available_neg)\n",
        "    target_neg_max = min(int(total_pos / min_ratio) - total_pos, available_neg)\n",
        "\n",
        "    # If there are not enough negative examples, we use all of them\n",
        "    if target_neg_max <= 0:\n",
        "        neg_selected = neg_examples\n",
        "    else:\n",
        "        neg_selected = neg_examples.sample(random.randint(target_neg_min, target_neg_max))\n",
        "\n",
        "    return pd.concat([pos_examples, neg_selected])\n",
        "\n",
        "# Perform the experiment 10 times and record training and prediction times\n",
        "n_splits = 2\n",
        "total_training_time = []\n",
        "total_prediction_time = []\n",
        "\n",
        "for experiment in range(10):\n",
        "    print(f\"Experiment {experiment + 1}\")\n",
        "\n",
        "    # Ensure class balance\n",
        "    balanced_df = balance_classes(df)\n",
        "\n",
        "    # Measure training time (includes embedding extraction + KNN fitting)\n",
        "    start_time_train = time.time()\n",
        "\n",
        "    # Get embeddings for balanced data\n",
        "    balanced_embeddings = calculate_program_embeddings(balanced_df)\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "\n",
        "    for fold, (train_index, test_index) in enumerate(skf.split(balanced_embeddings, balanced_df['Label'])):\n",
        "        X_train, X_test = balanced_embeddings[train_index], balanced_embeddings[test_index]\n",
        "        y_train, y_test = balanced_df['Label'].iloc[train_index], balanced_df['Label'].iloc[test_index]\n",
        "\n",
        "        # Apply k-nearest neighbor classification\n",
        "        knn = KNeighborsClassifier(n_neighbors=3)\n",
        "        knn.fit(X_train, y_train)\n",
        "\n",
        "    end_time_train = time.time()\n",
        "    training_time = (end_time_train - start_time_train) * 1000  # Convert to milliseconds\n",
        "    total_training_time.append(training_time)\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time_pred = time.time()\n",
        "\n",
        "    for fold, (train_index, test_index) in enumerate(skf.split(balanced_embeddings, balanced_df['Label'])):\n",
        "        X_test = balanced_embeddings[test_index]\n",
        "        test_predictions = knn.predict(X_test)\n",
        "\n",
        "    end_time_pred = time.time()\n",
        "    prediction_time = (end_time_pred - start_time_pred) * 1000  # Convert to milliseconds\n",
        "    total_prediction_time.append(prediction_time)\n",
        "\n",
        "    # Print the times for the current experiment\n",
        "    print(f\"Training Time (ms): {training_time}, Prediction Time (ms): {prediction_time}\")\n",
        "\n",
        "# Calculate mean times over all 10 experiments\n",
        "mean_training_time = np.mean(total_training_time)\n",
        "mean_prediction_time = np.mean(total_prediction_time)\n",
        "\n",
        "print(f\"Mean Training Time (ms): {mean_training_time}\")\n",
        "print(f\"Mean Prediction Time (ms): {mean_prediction_time}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzQz8tOrC1SH",
        "outputId": "0d4eedef-6bc6-4828-c73a-e6c95641c662"
      },
      "id": "JzQz8tOrC1SH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Labels and contents saved to embeddings/af3.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 53/53 [02:22<00:00,  2.69s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 142347.58925437927, Prediction Time (ms): 3.0057430267333984\n",
            "Experiment 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 62/62 [02:15<00:00,  2.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 135824.35989379883, Prediction Time (ms): 3.3414363861083984\n",
            "Experiment 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 51/51 [01:51<00:00,  2.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 111864.23349380493, Prediction Time (ms): 4.061698913574219\n",
            "Experiment 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 43/43 [01:28<00:00,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 88370.54944038391, Prediction Time (ms): 3.7276744842529297\n",
            "Experiment 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 61/61 [02:11<00:00,  2.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 131706.37011528015, Prediction Time (ms): 3.3135414123535156\n",
            "Experiment 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 42/42 [01:31<00:00,  2.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 91576.89547538757, Prediction Time (ms): 3.1740665435791016\n",
            "Experiment 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 47/47 [01:44<00:00,  2.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 104628.97801399231, Prediction Time (ms): 3.9985179901123047\n",
            "Experiment 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 60/60 [02:09<00:00,  2.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 129642.62127876282, Prediction Time (ms): 3.161907196044922\n",
            "Experiment 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 46/46 [01:36<00:00,  2.10s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 96553.04670333862, Prediction Time (ms): 2.9125213623046875\n",
            "Experiment 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 47/47 [01:37<00:00,  2.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 98009.46593284607, Prediction Time (ms): 3.9894580841064453\n",
            "Mean Training Time (ms): 113052.41096019745\n",
            "Mean Prediction Time (ms): 3.468656539916992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prototype time calculation**"
      ],
      "metadata": {
        "id": "IlY9P7PLLG6S"
      },
      "id": "IlY9P7PLLG6S"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check if CUDA is available and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = '/content/singleton'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"singleton\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Ensure the directory exists\n",
        "output_dir = 'embeddings'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = os.path.join(output_dir, 'af3.csv')  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = os.path.join(output_dir, 'af3.csv')  # Replace with the actual CSV file path\n",
        "\n",
        "# Initialize RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\").to(device)  # Move model to device\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to calculate embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move back to CPU for NumPy operations\n",
        "\n",
        "# Calculate embeddings for each program by considering embeddings of individual lines\n",
        "def calculate_program_embeddings(df):\n",
        "    program_embeddings = []\n",
        "    for content in tqdm(df['Content']):\n",
        "        lines = content.split('\\n')\n",
        "        line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "        program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "    return np.vstack(program_embeddings)\n",
        "\n",
        "# Function to randomly select negative examples to ensure 40%-60% class balance\n",
        "def balance_classes(df, neg_label=0, pos_label=1, min_ratio=0.4, max_ratio=0.6):\n",
        "    pos_examples = df[df['Label'] == pos_label]\n",
        "    neg_examples = df[df['Label'] == neg_label]\n",
        "\n",
        "    total_pos = len(pos_examples)\n",
        "    available_neg = len(neg_examples)\n",
        "\n",
        "    # Ensure the target_neg_range does not exceed available negative examples\n",
        "    target_neg_min = min(int(total_pos / max_ratio) - total_pos, available_neg)\n",
        "    target_neg_max = min(int(total_pos / min_ratio) - total_pos, available_neg)\n",
        "\n",
        "    # If there are not enough negative examples, we use all of them\n",
        "    if target_neg_max <= 0:\n",
        "        neg_selected = neg_examples\n",
        "    else:\n",
        "        neg_selected = neg_examples.sample(random.randint(target_neg_min, target_neg_max))\n",
        "\n",
        "    return pd.concat([pos_examples, neg_selected])\n",
        "\n",
        "# Perform the experiment 10 times and record training and prediction times\n",
        "n_splits = 2\n",
        "total_training_time = []\n",
        "total_prediction_time = []\n",
        "\n",
        "for experiment in range(10):\n",
        "    print(f\"Experiment {experiment + 1}\")\n",
        "\n",
        "    # Ensure class balance\n",
        "    balanced_df = balance_classes(df)\n",
        "\n",
        "    # Measure training time (includes embedding extraction + KNN fitting)\n",
        "    start_time_train = time.time()\n",
        "\n",
        "    # Get embeddings for balanced data\n",
        "    balanced_embeddings = calculate_program_embeddings(balanced_df)\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "\n",
        "    for fold, (train_index, test_index) in enumerate(skf.split(balanced_embeddings, balanced_df['Label'])):\n",
        "        X_train, X_test = balanced_embeddings[train_index], balanced_embeddings[test_index]\n",
        "        y_train, y_test = balanced_df['Label'].iloc[train_index], balanced_df['Label'].iloc[test_index]\n",
        "\n",
        "        # Apply k-nearest neighbor classification\n",
        "        knn = KNeighborsClassifier(n_neighbors=3)\n",
        "        knn.fit(X_train, y_train)\n",
        "\n",
        "    end_time_train = time.time()\n",
        "    training_time = (end_time_train - start_time_train) * 1000  # Convert to milliseconds\n",
        "    total_training_time.append(training_time)\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time_pred = time.time()\n",
        "\n",
        "    for fold, (train_index, test_index) in enumerate(skf.split(balanced_embeddings, balanced_df['Label'])):\n",
        "        X_test = balanced_embeddings[test_index]\n",
        "        test_predictions = knn.predict(X_test)\n",
        "\n",
        "    end_time_pred = time.time()\n",
        "    prediction_time = (end_time_pred - start_time_pred) * 1000  # Convert to milliseconds\n",
        "    total_prediction_time.append(prediction_time)\n",
        "\n",
        "    # Print the times for the current experiment\n",
        "    print(f\"Training Time (ms): {training_time}, Prediction Time (ms): {prediction_time}\")\n",
        "\n",
        "# Calculate mean times over all 10 experiments\n",
        "mean_training_time = np.mean(total_training_time)\n",
        "mean_prediction_time = np.mean(total_prediction_time)\n",
        "\n",
        "print(f\"Mean Training Time (ms): {mean_training_time}\")\n",
        "print(f\"Mean Prediction Time (ms): {mean_prediction_time}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNmFFQ0jLKNp",
        "outputId": "2c4a829b-5278-4664-9a9a-11e0a3cefde5"
      },
      "id": "MNmFFQ0jLKNp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Labels and contents saved to embeddings/af3.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 54/54 [01:59<00:00,  2.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 119029.86717224121, Prediction Time (ms): 3.0078887939453125\n",
            "Experiment 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 62/62 [02:03<00:00,  1.99s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 123586.41910552979, Prediction Time (ms): 5.185127258300781\n",
            "Experiment 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 47/47 [01:45<00:00,  2.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 105988.78383636475, Prediction Time (ms): 3.036022186279297\n",
            "Experiment 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 45/45 [01:38<00:00,  2.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 98588.70053291321, Prediction Time (ms): 3.8678646087646484\n",
            "Experiment 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 51/51 [01:42<00:00,  2.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 102734.8051071167, Prediction Time (ms): 2.7723312377929688\n",
            "Experiment 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 47/47 [01:41<00:00,  2.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 101191.24937057495, Prediction Time (ms): 2.7930736541748047\n",
            "Experiment 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 48/48 [01:38<00:00,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 98478.86109352112, Prediction Time (ms): 2.5932788848876953\n",
            "Experiment 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 60/60 [02:01<00:00,  2.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 121365.70239067078, Prediction Time (ms): 2.772808074951172\n",
            "Experiment 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 52/52 [01:44<00:00,  2.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 104584.93423461914, Prediction Time (ms): 2.7954578399658203\n",
            "Experiment 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 44/44 [01:36<00:00,  2.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 96128.29899787903, Prediction Time (ms): 5.895853042602539\n",
            "Mean Training Time (ms): 107167.76218414307\n",
            "Mean Prediction Time (ms): 3.471970558166504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Factory method time calculation**\n",
        "\n"
      ],
      "metadata": {
        "id": "w3NlnIlZJ5DL"
      },
      "id": "w3NlnIlZJ5DL"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check if CUDA is available and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = '/content/factorymethod'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"factorymethod\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Ensure the directory exists\n",
        "output_dir = 'embeddings'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = os.path.join(output_dir, 'af3.csv')  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = os.path.join(output_dir, 'af3.csv')  # Replace with the actual CSV file path\n",
        "\n",
        "# Initialize RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\").to(device)  # Move model to device\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to calculate embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move back to CPU for NumPy operations\n",
        "\n",
        "# Calculate embeddings for each program by considering embeddings of individual lines\n",
        "def calculate_program_embeddings(df):\n",
        "    program_embeddings = []\n",
        "    for content in tqdm(df['Content']):\n",
        "        lines = content.split('\\n')\n",
        "        line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "        program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "    return np.vstack(program_embeddings)\n",
        "\n",
        "# Function to randomly select negative examples to ensure 40%-60% class balance\n",
        "def balance_classes(df, neg_label=0, pos_label=1, min_ratio=0.4, max_ratio=0.6):\n",
        "    pos_examples = df[df['Label'] == pos_label]\n",
        "    neg_examples = df[df['Label'] == neg_label]\n",
        "\n",
        "    total_pos = len(pos_examples)\n",
        "    available_neg = len(neg_examples)\n",
        "\n",
        "    # Ensure the target_neg_range does not exceed available negative examples\n",
        "    target_neg_min = min(int(total_pos / max_ratio) - total_pos, available_neg)\n",
        "    target_neg_max = min(int(total_pos / min_ratio) - total_pos, available_neg)\n",
        "\n",
        "    # If there are not enough negative examples, we use all of them\n",
        "    if target_neg_max <= 0:\n",
        "        neg_selected = neg_examples\n",
        "    else:\n",
        "        neg_selected = neg_examples.sample(random.randint(target_neg_min, target_neg_max))\n",
        "\n",
        "    return pd.concat([pos_examples, neg_selected])\n",
        "\n",
        "# Perform the experiment 10 times and record training and prediction times\n",
        "n_splits = 2\n",
        "total_training_time = []\n",
        "total_prediction_time = []\n",
        "\n",
        "for experiment in range(10):\n",
        "    print(f\"Experiment {experiment + 1}\")\n",
        "\n",
        "    # Ensure class balance\n",
        "    balanced_df = balance_classes(df)\n",
        "\n",
        "    # Measure training time (includes embedding extraction + KNN fitting)\n",
        "    start_time_train = time.time()\n",
        "\n",
        "    # Get embeddings for balanced data\n",
        "    balanced_embeddings = calculate_program_embeddings(balanced_df)\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "\n",
        "    for fold, (train_index, test_index) in enumerate(skf.split(balanced_embeddings, balanced_df['Label'])):\n",
        "        X_train, X_test = balanced_embeddings[train_index], balanced_embeddings[test_index]\n",
        "        y_train, y_test = balanced_df['Label'].iloc[train_index], balanced_df['Label'].iloc[test_index]\n",
        "\n",
        "        # Apply k-nearest neighbor classification\n",
        "        knn = KNeighborsClassifier(n_neighbors=3)\n",
        "        knn.fit(X_train, y_train)\n",
        "\n",
        "    end_time_train = time.time()\n",
        "    training_time = (end_time_train - start_time_train) * 1000  # Convert to milliseconds\n",
        "    total_training_time.append(training_time)\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time_pred = time.time()\n",
        "\n",
        "    for fold, (train_index, test_index) in enumerate(skf.split(balanced_embeddings, balanced_df['Label'])):\n",
        "        X_test = balanced_embeddings[test_index]\n",
        "        test_predictions = knn.predict(X_test)\n",
        "\n",
        "    end_time_pred = time.time()\n",
        "    prediction_time = (end_time_pred - start_time_pred) * 1000  # Convert to milliseconds\n",
        "    total_prediction_time.append(prediction_time)\n",
        "\n",
        "    # Print the times for the current experiment\n",
        "    print(f\"Training Time (ms): {training_time}, Prediction Time (ms): {prediction_time}\")\n",
        "\n",
        "# Calculate mean times over all 10 experiments\n",
        "mean_training_time = np.mean(total_training_time)\n",
        "mean_prediction_time = np.mean(total_prediction_time)\n",
        "\n",
        "print(f\"Mean Training Time (ms): {mean_training_time}\")\n",
        "print(f\"Mean Prediction Time (ms): {mean_prediction_time}\")\n"
      ],
      "metadata": {
        "id": "KXZ0S5e2GIM4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 993,
          "referenced_widgets": [
            "9609b2b9b0ca4800918a4ade70304969",
            "fc5e86b17f08466a815c0139f7345dbc",
            "47349fcb836241f492327b7bab681483",
            "77920beb4cc84236af6a25fa46ee352e",
            "566cd02134a14ea7968f9324afad89aa",
            "5384df90b2e34a55a175fa4507746d13",
            "861bacae6b12433a8497ed7a6242b833",
            "1e1d09770b1347e586f8c16427f1c659",
            "7b2866474cfa4e0faca4c5f302fb796f",
            "f38133e729e34c8e825ac2b868142f8a",
            "23810ddec04942c6ab95715d028050fd",
            "5cc0445716284fe49e04db587dfb4501",
            "f23e8e102ce341a385b06f688a699ba2",
            "d89f64ec82ae4d81ab27bec677e227a9",
            "06a3937dc4464433be2e7051840f73e2",
            "882351e7c8cf419bbf11e9407124f76d",
            "d1c35ab62b474d0694ff33f2c817762a",
            "a99d1f820c2f4c35b067e1b510e900d1",
            "8b27bb4c432346fe88e1404f6c90f913",
            "bfed0126eec942789abbe2f60b31d093",
            "ea8833563fbc4b4193cb31d20763afb5",
            "18fa4ca92deb4435a33561c9a05091ef",
            "43817f19ca384fe79b7d54dfb958444f",
            "39f59c32491047a9805318137e13e570",
            "4a6b5e492bf6457b9e06d8a84e85e9e6",
            "1f6ed3d8931d4666b25db1b7985f351e",
            "0044e7c17ecd4c6f9d2b5e436a00441e",
            "74d543817a2e477eaed95b95c13e52cc",
            "bf9d00d1f9664241b800ed7a9aef8a7b",
            "468d4baed5fd47399829c6c5514b584b",
            "d5802b4b5a174597b8e571f7b5e8929e",
            "e8757b6166a94b53a0c9d65337b6a853",
            "0b0fc5773fab47de93f9a4ea83769bd1",
            "31dfdb4d53e04d8095a7f7f4f960942e",
            "75d90599291f4389b4e366670502ca36",
            "a9f28c3aaaee43c49bf055741844922f",
            "e57424b77c38464dbac0439baac51230",
            "1db3901249c840b09d84e2566a201f38",
            "7cbb2859a0aa4340be21c42bf7a7cae7",
            "05751dc82dfa49cab8713e7fb1fe3da3",
            "cdcd84e81af94363b997e007846f2b38",
            "49135cef2d914e9fb16cccd41c397d74",
            "e24033a4159c42d886ac801ca9329f7c",
            "07dc4bc453cb4faca5b53e7c9d24abd3",
            "ed2e4d7ca46d43c3b6bcae7ec3e22168",
            "30de4a2fee08415eabdfaece97901109",
            "612abc0633004e249f7332e41d13cfe4",
            "2060918d7f964020b663f247017f6c2c",
            "d38c6fa3b47a42fd9cf90476047a49e5",
            "b79cc901b7d143adb1b112e2ec54317d",
            "fef74925a4f74167b495b93620114e0a",
            "b898c4e3404d4ccdb2bf6fa3b6daaea8",
            "5f18f8c5a85e4e3e9483ea46af371a41",
            "effe26a683de41a2bad6d427ee011ec9",
            "f98d25ff23204f99824b2c4e1d95114b",
            "948fcaccf5d3436daedba0c1d8ebc3e7",
            "5679ca49a6704ef5a613247e748b88c5",
            "ed29979a8b494d7d81b8e48e6c869e12",
            "d414e5efa2444edda8d971a95e9ea678",
            "880274dd6d7943edbaf5ffc8315fcd67",
            "b9e5bba6f36440c0a877c6da3dc4176a",
            "05a90fa1b49f4ab3a3580b7620196e56",
            "bb16f519c82543a9a32bb060474613a0",
            "f0adb1fad0a74f3cb94700cc6d78c970",
            "01d51f1be8944fa1a8bb55cb0baead86",
            "fa04f4332ae044f893342237cdd17a5e"
          ]
        },
        "outputId": "bf19de5f-e7d1-4251-e3f7-69b7d82fc471"
      },
      "id": "KXZ0S5e2GIM4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Labels and contents saved to embeddings/af3.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9609b2b9b0ca4800918a4ade70304969"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5cc0445716284fe49e04db587dfb4501"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43817f19ca384fe79b7d54dfb958444f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31dfdb4d53e04d8095a7f7f4f960942e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed2e4d7ca46d43c3b6bcae7ec3e22168"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "948fcaccf5d3436daedba0c1d8ebc3e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 20/20 [00:59<00:00,  2.99s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 59900.19679069519, Prediction Time (ms): 53.635358810424805\n",
            "Experiment 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 21/21 [00:45<00:00,  2.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 45359.7092628479, Prediction Time (ms): 2.72369384765625\n",
            "Experiment 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 20/20 [00:41<00:00,  2.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 41214.684009552, Prediction Time (ms): 2.4390220642089844\n",
            "Experiment 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 24/24 [00:48<00:00,  2.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 48936.90490722656, Prediction Time (ms): 2.44140625\n",
            "Experiment 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 19/19 [00:42<00:00,  2.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 42968.46079826355, Prediction Time (ms): 4.642486572265625\n",
            "Experiment 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 19/19 [00:41<00:00,  2.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 41611.92464828491, Prediction Time (ms): 2.4209022521972656\n",
            "Experiment 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 19/19 [00:38<00:00,  2.01s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 38200.06275177002, Prediction Time (ms): 2.389192581176758\n",
            "Experiment 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 27/27 [00:50<00:00,  1.87s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 50483.14118385315, Prediction Time (ms): 2.547025680541992\n",
            "Experiment 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 20/20 [00:39<00:00,  1.99s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 39801.35083198547, Prediction Time (ms): 2.5534629821777344\n",
            "Experiment 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 22/22 [00:42<00:00,  1.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 42189.897775650024, Prediction Time (ms): 3.662109375\n",
            "Mean Training Time (ms): 45066.63329601288\n",
            "Mean Prediction Time (ms): 7.945466041564941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check if CUDA is available and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = '/content/factorymethod'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"factorymethod\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Ensure the directory exists\n",
        "output_dir = 'embeddings'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = os.path.join(output_dir, 'af3.csv')  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = os.path.join(output_dir, 'af3.csv')  # Replace with the actual CSV file path\n",
        "\n",
        "# Initialize RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\").to(device)  # Move model to device\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to calculate embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move back to CPU for NumPy operations\n",
        "\n",
        "# Calculate embeddings for each program by considering embeddings of individual lines\n",
        "def calculate_program_embeddings(df):\n",
        "    program_embeddings = []\n",
        "    for content in tqdm(df['Content']):\n",
        "        lines = content.split('\\n')\n",
        "        line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "        program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "    return np.vstack(program_embeddings)\n",
        "\n",
        "# Function to randomly select negative examples to ensure 40%-60% class balance\n",
        "def balance_classes(df, neg_label=0, pos_label=1, min_ratio=0.4, max_ratio=0.6):\n",
        "    pos_examples = df[df['Label'] == pos_label]\n",
        "    neg_examples = df[df['Label'] == neg_label]\n",
        "\n",
        "    total_pos = len(pos_examples)\n",
        "    available_neg = len(neg_examples)\n",
        "\n",
        "    # Ensure the target_neg_range does not exceed available negative examples\n",
        "    target_neg_min = min(int(total_pos / max_ratio) - total_pos, available_neg)\n",
        "    target_neg_max = min(int(total_pos / min_ratio) - total_pos, available_neg)\n",
        "\n",
        "    # If there are not enough negative examples, we use all of them\n",
        "    if target_neg_max <= 0:\n",
        "        neg_selected = neg_examples\n",
        "    else:\n",
        "        neg_selected = neg_examples.sample(random.randint(target_neg_min, target_neg_max))\n",
        "\n",
        "    return pd.concat([pos_examples, neg_selected])\n",
        "\n",
        "# Perform the experiment 10 times and record training and prediction times\n",
        "n_splits = 2\n",
        "total_training_time = []\n",
        "total_prediction_time = []\n",
        "\n",
        "for experiment in range(10):\n",
        "    print(f\"Experiment {experiment + 1}\")\n",
        "\n",
        "    # Ensure class balance\n",
        "    balanced_df = balance_classes(df)\n",
        "\n",
        "    # Measure training time (includes embedding extraction + KNN fitting)\n",
        "    start_time_train = time.time()\n",
        "\n",
        "    # Get embeddings for balanced data\n",
        "    balanced_embeddings = calculate_program_embeddings(balanced_df)\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "\n",
        "    for fold, (train_index, test_index) in enumerate(skf.split(balanced_embeddings, balanced_df['Label'])):\n",
        "        X_train, X_test = balanced_embeddings[train_index], balanced_embeddings[test_index]\n",
        "        y_train, y_test = balanced_df['Label'].iloc[train_index], balanced_df['Label'].iloc[test_index]\n",
        "\n",
        "        # Apply k-nearest neighbor classification\n",
        "        knn = KNeighborsClassifier(n_neighbors=3)\n",
        "        knn.fit(X_train, y_train)\n",
        "\n",
        "    end_time_train = time.time()\n",
        "    training_time = (end_time_train - start_time_train) * 1000  # Convert to milliseconds\n",
        "    total_training_time.append(training_time)\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time_pred = time.time()\n",
        "\n",
        "    for fold, (train_index, test_index) in enumerate(skf.split(balanced_embeddings, balanced_df['Label'])):\n",
        "        X_test = balanced_embeddings[test_index]\n",
        "        test_predictions = knn.predict(X_test)\n",
        "\n",
        "    end_time_pred = time.time()\n",
        "    prediction_time = (end_time_pred - start_time_pred) * 1000  # Convert to milliseconds\n",
        "    total_prediction_time.append(prediction_time)\n",
        "\n",
        "    # Print the times for the current experiment\n",
        "    print(f\"Training Time (ms): {training_time}, Prediction Time (ms): {prediction_time}\")\n",
        "\n",
        "# Calculate mean times over all 10 experiments\n",
        "mean_training_time = np.mean(total_training_time)\n",
        "mean_prediction_time = np.mean(total_prediction_time)\n",
        "\n",
        "print(f\"Mean Training Time (ms): {mean_training_time}\")\n",
        "print(f\"Mean Prediction Time (ms): {mean_prediction_time}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0zPl9IRKi4D",
        "outputId": "60e2b855-8019-4ce5-8a12-e596351bb808"
      },
      "id": "X0zPl9IRKi4D",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Labels and contents saved to embeddings/af3.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 18/18 [01:09<00:00,  3.84s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 69096.7800617218, Prediction Time (ms): 3.520488739013672\n",
            "Experiment 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 27/27 [00:54<00:00,  2.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 54662.1150970459, Prediction Time (ms): 3.576040267944336\n",
            "Experiment 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 20/20 [00:39<00:00,  1.97s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 39393.44811439514, Prediction Time (ms): 2.4728775024414062\n",
            "Experiment 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 19/19 [00:39<00:00,  2.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 39731.14824295044, Prediction Time (ms): 2.4645328521728516\n",
            "Experiment 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 24/24 [00:44<00:00,  1.84s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 44150.39658546448, Prediction Time (ms): 2.5043487548828125\n",
            "Experiment 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 22/22 [00:44<00:00,  2.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 44990.877628326416, Prediction Time (ms): 3.30352783203125\n",
            "Experiment 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 21/21 [00:42<00:00,  2.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 42398.306131362915, Prediction Time (ms): 2.562999725341797\n",
            "Experiment 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 19/19 [00:36<00:00,  1.93s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 36648.98586273193, Prediction Time (ms): 7.267951965332031\n",
            "Experiment 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 21/21 [00:41<00:00,  1.97s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 41398.94890785217, Prediction Time (ms): 2.3818016052246094\n",
            "Experiment 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 25/25 [00:45<00:00,  1.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 45648.772954940796, Prediction Time (ms): 2.5293827056884766\n",
            "Mean Training Time (ms): 45811.9779586792\n",
            "Mean Prediction Time (ms): 3.258395195007324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculation of Silhouette Scor Davies-Bouldin Index**"
      ],
      "metadata": {
        "id": "uXmP67j-TcMb"
      },
      "id": "uXmP67j-TcMb"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, silhouette_score, davies_bouldin_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check if CUDA is available and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = '/content/design_patterns'  # Folder containing all design pattern files\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Function to label programs based on the file name for five design patterns\n",
        "def label_program(file_name):\n",
        "    file_name_lower = file_name.lower()\n",
        "    if \"factorymethod\" in file_name_lower:\n",
        "        return 1  # Factory Method\n",
        "    elif \"singleton\" in file_name_lower:\n",
        "        return 2  # Singleton\n",
        "    elif \"builder\" in file_name_lower:\n",
        "        return 3  # Builder\n",
        "    elif \"prototype\" in file_name_lower:\n",
        "        return 4  # Prototype\n",
        "    elif \"abstractfactory\" in file_name_lower:\n",
        "        return 5  # Abstract Factory\n",
        "    else:\n",
        "        return 0  # Negative class (no pattern)\n",
        "\n",
        "# Load Java programs from the folder and classify them based on the pattern\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Ensure the directory exists\n",
        "output_dir = 'embeddings'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = os.path.join(output_dir, 'design_patterns_data.csv')\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "# Initialize RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\").to(device)  # Move model to device\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Function to calculate embeddings from text\n",
        "def get_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()  # Move back to CPU for NumPy operations\n",
        "\n",
        "# Calculate embeddings for each program by considering embeddings of individual lines\n",
        "def calculate_program_embeddings(df):\n",
        "    program_embeddings = []\n",
        "    for content in tqdm(df['Content']):\n",
        "        lines = content.split('\\n')\n",
        "        line_embeddings = [get_embeddings(line) for line in lines if line.strip()]\n",
        "        program_embeddings.append(np.mean(line_embeddings, axis=0))\n",
        "    return np.vstack(program_embeddings)\n",
        "\n",
        "# Function to randomly select negative examples and maintain class balance across all design patterns\n",
        "def balance_classes(df, neg_label=0, pos_labels=[1, 2, 3, 4, 5], min_ratio=0.4, max_ratio=0.6):\n",
        "    pos_examples = df[df['Label'].isin(pos_labels)]\n",
        "    neg_examples = df[df['Label'] == neg_label]\n",
        "\n",
        "    total_pos = len(pos_examples)\n",
        "    available_neg = len(neg_examples)\n",
        "\n",
        "    # Ensure the target_neg_range does not exceed available negative examples\n",
        "    target_neg_min = min(int(total_pos / max_ratio) - total_pos, available_neg)\n",
        "    target_neg_max = min(int(total_pos / min_ratio) - total_pos, available_neg)\n",
        "\n",
        "    # If there are not enough negative examples, use all of them\n",
        "    if target_neg_max <= 0:\n",
        "        neg_selected = neg_examples\n",
        "    else:\n",
        "        neg_selected = neg_examples.sample(random.randint(target_neg_min, target_neg_max))\n",
        "\n",
        "    return pd.concat([pos_examples, neg_selected])\n",
        "\n",
        "# Perform the experiment 10 times and record training and prediction times\n",
        "n_splits = 2\n",
        "total_training_time = []\n",
        "total_prediction_time = []\n",
        "\n",
        "for experiment in range(10):\n",
        "    print(f\"Experiment {experiment + 1}\")\n",
        "\n",
        "    # Ensure class balance across the five design patterns and the negative class\n",
        "    balanced_df = balance_classes(df)\n",
        "\n",
        "    # Measure training time (includes embedding extraction + KNN fitting)\n",
        "    start_time_train = time.time()\n",
        "\n",
        "    # Get embeddings for balanced data\n",
        "    balanced_embeddings = calculate_program_embeddings(balanced_df)\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
        "\n",
        "    for fold, (train_index, test_index) in enumerate(skf.split(balanced_embeddings, balanced_df['Label'])):\n",
        "        X_train, X_test = balanced_embeddings[train_index], balanced_embeddings[test_index]\n",
        "        y_train, y_test = balanced_df['Label'].iloc[train_index], balanced_df['Label'].iloc[test_index]\n",
        "\n",
        "        # Apply k-nearest neighbor classification\n",
        "        knn = KNeighborsClassifier(n_neighbors=3)\n",
        "        knn.fit(X_train, y_train)\n",
        "\n",
        "    end_time_train = time.time()\n",
        "    training_time = (end_time_train - start_time_train) * 1000  # Convert to milliseconds\n",
        "    total_training_time.append(training_time)\n",
        "\n",
        "    # Measure prediction time\n",
        "    start_time_pred = time.time()\n",
        "\n",
        "    for fold, (train_index, test_index) in enumerate(skf.split(balanced_embeddings, balanced_df['Label'])):\n",
        "        X_test = balanced_embeddings[test_index]\n",
        "        test_predictions = knn.predict(X_test)\n",
        "\n",
        "    end_time_pred = time.time()\n",
        "    prediction_time = (end_time_pred - start_time_pred) * 1000  # Convert to milliseconds\n",
        "    total_prediction_time.append(prediction_time)\n",
        "\n",
        "    # Print the times for the current experiment\n",
        "    print(f\"Training Time (ms): {training_time}, Prediction Time (ms): {prediction_time}\")\n",
        "\n",
        "# Calculate mean times over all 10 experiments\n",
        "mean_training_time = np.mean(total_training_time)\n",
        "mean_prediction_time = np.mean(total_prediction_time)\n",
        "\n",
        "print(f\"Mean Training Time (ms): {mean_training_time}\")\n",
        "print(f\"Mean Prediction Time (ms): {mean_prediction_time}\")\n",
        "\n",
        "# Calculate Silhouette Score and Davies-Bouldin Index for clustering quality\n",
        "def calculate_clustering_metrics(embeddings, labels):\n",
        "    silhouette_avg = silhouette_score(embeddings, labels)\n",
        "    davies_bouldin = davies_bouldin_score(embeddings, labels)\n",
        "\n",
        "    print(f\"Silhouette Score: {silhouette_avg:.4f}\")\n",
        "    print(f\"Davies-Bouldin Index: {davies_bouldin:.4f}\")\n",
        "    return silhouette_avg, davies_bouldin\n",
        "\n",
        "# Perform clustering metrics calculations\n",
        "silhouette_avg, davies_bouldin = calculate_clustering_metrics(balanced_embeddings, balanced_df['Label'])\n"
      ],
      "metadata": {
        "id": "Pn6EAJBxMdyX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "15c78eec87a34a1cb3c06bfcfb755e02",
            "387759cea97d43d5bd5529692fe49d88",
            "8abe878b9ff44e879ec5281935eef3e7",
            "403cc3dd74ff4b5bb24ab1024473927a",
            "fba383d6ca2145fda9a7243110b68f07",
            "0017f068077144fb9d1f69cd09a9b98b",
            "0af3104b74274144881eb0251f87e172",
            "42b2907600d643c185dad8d490d95d52",
            "6a5b811ff85141d19fb67366cd1b8219",
            "a6937d2694784d8a89739d8d9edc2852",
            "298e37c42d1545a08ed3f1e1592f309e",
            "254aceeaa3ed40dbac3a5bd4d8412a0c",
            "da327b84daa5498c9f61efb6047cd4ae",
            "cd00e94db6f140c78a24b38b39e861e5",
            "060f3e759c324b8f85ff6b302a8f3fb7",
            "c2e8a4e3c4ae45f99d234d92407f331e",
            "c71eee0cb54b4a439de9ed0294455486",
            "a8a1e005fc2e4150afd87ad5c1c39b6d",
            "2c656a4243a64a5782fd13edc7d0d9bb",
            "e5832f3e24784275a9eb8debed1be72b",
            "981fe0989d884df4819cb5c52857bc20",
            "9ba6432b211c4a17a19372b2161fe653",
            "5672482c45064b3fb324bb129339a180",
            "c09436984cb04e26bcaa9e6cd77d5c00",
            "02e1572dca61425286225c653d4cfb3c",
            "562b23826c49421fbaaf9153dc293209",
            "0545e24b5caf4ef4a901925c27b88359",
            "cdece54bbb8946c8a5e1eed24899bbb6",
            "e916d7dbe1ae461396fc57ab376ba560",
            "3e2190a618794287a6c004b4c723cec9",
            "8e33382ec8a94a6f8f282098f01f41a3",
            "2ce5ca95422741979063ab572fc03b66",
            "f0b7a6e77d31420f86eef8ffb3ede176",
            "fdda8045be3246699ac525ca22a2a38a",
            "08a0dd62b5464943aad8012d68736e69",
            "ef7698c7b1f64d908be8d3716c5fee18",
            "e11031cff8cd480aa13f8d9b36e83ba2",
            "95725bbdb3d54e03ab0d27eae01c6f61",
            "0bd0d6f7032a43889a9b974c4ea833fd",
            "6acc789aa741442a9153e539f6cfc0c1",
            "80e5df3436214910a8db440577a8d92a",
            "e91b4ac9d6c54fe496835359d1a9ab3f",
            "61ff589644b6455cbc54445a6c4d7e11",
            "308745efbfb04b28a95027e3860d250b",
            "6fbffb70f67945d284bc49c3b03a8a1f",
            "62704ad502a740bca4fd8cca07d667f5",
            "5b730bf7f8c845be995c12e134f3c0b9",
            "cc9239924cee44c1bba6edc8c88a1101",
            "3cf6f0de004a404c92cbc41747626e3f",
            "55d111af87a740f98506cb02a030c03d",
            "1849644b3b48450b88a4cf8b4baf9f63",
            "2644e1e2a7134574b4057ec3ffe1d9af",
            "ba5b4a618fef43d4adb0c9144d0fb5cb",
            "5ad03329dfa342b2b079c78b88fd5f07",
            "d1f7b136214a4357ae3b38af5bf37ad8",
            "cd2a0b4a8fbe4363a6df1d06b4182d99",
            "6cece6a126b14946bb79c839d6e21d22",
            "95ed485fdb1f49aa8e37e888d2f87b66",
            "b7ae8fce88c34c5a8be71b8a48556d9c",
            "f156624af620426d92102b5cfb19934f",
            "4ebcd1fba3724fa5b4b18c053fef1ad2",
            "2f189d21a81a4b20999d80e3c5919cb1",
            "5a2d824cf9cd4b04b2db41eb91c6b381",
            "f1ef8cf97bda4a16a7fe49f29d26a745",
            "30bf26fcd91946b582613849d1bbe60b",
            "3b71bc9e22974ec291e716c049227eb7"
          ]
        },
        "outputId": "948d01ce-bbdb-4d8c-a28c-7c64ab3a2919"
      },
      "id": "Pn6EAJBxMdyX",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Labels and contents saved to embeddings/design_patterns_data.csv\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15c78eec87a34a1cb3c06bfcfb755e02",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "254aceeaa3ed40dbac3a5bd4d8412a0c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5672482c45064b3fb324bb129339a180",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fdda8045be3246699ac525ca22a2a38a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fbffb70f67945d284bc49c3b03a8a1f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd2a0b4a8fbe4363a6df1d06b4182d99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 93/93 [03:17<00:00,  2.12s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 197148.0324268341, Prediction Time (ms): 50.83656311035156\n",
            "Experiment 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 93/93 [03:17<00:00,  2.12s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 197164.40987586975, Prediction Time (ms): 3.3011436462402344\n",
            "Experiment 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 93/93 [03:10<00:00,  2.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 190113.5904788971, Prediction Time (ms): 3.7598609924316406\n",
            "Experiment 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 93/93 [03:10<00:00,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 190670.4478263855, Prediction Time (ms): 5.2032470703125\n",
            "Experiment 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 93/93 [03:09<00:00,  2.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 189408.48541259766, Prediction Time (ms): 3.118753433227539\n",
            "Experiment 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 93/93 [03:09<00:00,  2.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 189804.82840538025, Prediction Time (ms): 3.043651580810547\n",
            "Experiment 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 93/93 [03:11<00:00,  2.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 191277.34637260437, Prediction Time (ms): 3.047943115234375\n",
            "Experiment 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 93/93 [03:10<00:00,  2.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 190045.83501815796, Prediction Time (ms): 3.408670425415039\n",
            "Experiment 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 93/93 [03:09<00:00,  2.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 189126.2867450714, Prediction Time (ms): 2.9969215393066406\n",
            "Experiment 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 93/93 [03:08<00:00,  2.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time (ms): 188969.59924697876, Prediction Time (ms): 4.082918167114258\n",
            "Mean Training Time (ms): 191372.8861808777\n",
            "Mean Prediction Time (ms): 8.279967308044434\n",
            "Silhouette Score: 0.0023\n",
            "Davies-Bouldin Index: 3.3818\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check if CUDA is available and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = '/content/factorymethod'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Start timing for loading programs\n",
        "start_time = time.time()\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"factorymethod\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# End timing for loading programs\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to load and label programs: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Start timing for creating DataFrame and saving to CSV\n",
        "start_time = time.time()\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Ensure the directory exists\n",
        "output_dir = 'embeddings'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = os.path.join(output_dir, 'af3.csv')  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to create DataFrame and save to CSV: {end_time - start_time:.2f} seconds\")\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "# Debug: Print column names to verify\n",
        "print(\"Columns in DataFrame after saving:\", df.columns)\n",
        "\n",
        "# Start timing for loading DataFrame from CSV\n",
        "start_time = time.time()\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = os.path.join(output_dir, 'af3.csv')  # Replace with the actual CSV file path\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to load DataFrame from CSV: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Verify if the 'Content' column exists\n",
        "print(\"Columns after loading CSV:\", df.columns)  # Check if 'Content' is present\n",
        "\n",
        "# Check the first few rows of the DataFrame\n",
        "print(\"DataFrame head after loading CSV:\")\n",
        "print(df.head())\n",
        "\n",
        "# Start timing for embedding extraction\n",
        "start_time = time.time()\n",
        "\n",
        "# Embedding Extraction - Example using RoBERTa Model\n",
        "\n",
        "# Load pre-trained RoBERTa model and tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\").to(device)\n",
        "\n",
        "# Tokenize and encode the content using RoBERTa\n",
        "embeddings = []\n",
        "\n",
        "for content in tqdm(df['Content'], desc=\"Processing embeddings\"):\n",
        "    # Tokenize and encode\n",
        "    inputs = tokenizer(content, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512).to(device)\n",
        "\n",
        "    # Get the output embeddings from the model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Extract the [CLS] token embedding\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "\n",
        "    # Store the embedding\n",
        "    embeddings.append(cls_embedding)\n",
        "\n",
        "# End timing for embedding extraction\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to extract embeddings: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Convert the list of embeddings into a numpy array\n",
        "embeddings = np.vstack(embeddings)\n",
        "\n",
        "# Save embeddings to a numpy file\n",
        "start_time = time.time()\n",
        "np.save(os.path.join(output_dir, \"embeddings.npy\"), embeddings)\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to save embeddings: {end_time - start_time:.2f} seconds\")\n",
        "print(f\"Embeddings saved to {os.path.join(output_dir, 'embeddings.npy')}\")\n",
        "\n",
        "# Example: Splitting data into training and testing using StratifiedKFold\n",
        "labels = df['Label'].values\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Train the KNeighborsClassifier model\n",
        "knn_models = []\n",
        "for fold, (train_idx, test_idx) in enumerate(skf.split(embeddings, labels)):\n",
        "    print(f\"Fold {fold + 1}\")\n",
        "\n",
        "    # Split into training and testing sets\n",
        "    X_train, X_test = embeddings[train_idx], embeddings[test_idx]\n",
        "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
        "\n",
        "    # Example classifier: KNeighborsClassifier\n",
        "    knn = KNeighborsClassifier(n_neighbors=3)\n",
        "    knn.fit(X_train, y_train)\n",
        "    knn_models.append(knn)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = knn.predict(X_test)\n",
        "\n",
        "    # Evaluate the classifier\n",
        "    precision = precision_score(y_test, y_pred, average='binary')\n",
        "    recall = recall_score(y_test, y_pred, average='binary')\n",
        "    f1 = f1_score(y_test, y_pred, average='binary')\n",
        "\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n",
        "\n",
        "# --- Prediction Phase ---\n",
        "\n",
        "def predict_program(program_path, knn_model):\n",
        "    # Read and embed the new program\n",
        "    with open(program_path, 'r', encoding='iso-8859-1') as f:\n",
        "        new_program_content = f.read()\n",
        "\n",
        "    # Tokenize and encode the new program content\n",
        "    inputs = tokenizer(new_program_content, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512).to(device)\n",
        "\n",
        "    # Extract embedding\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    new_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "\n",
        "    # Feed the embedding into the KNN model to predict\n",
        "    start_time = time.time()  # Start timing prediction\n",
        "    predicted_label = knn_model.predict(new_embedding)\n",
        "    end_time = time.time()  # End timing prediction\n",
        "\n",
        "    print(f\"Time taken for prediction: {end_time - start_time:.2f} seconds\")\n",
        "    return predicted_label\n",
        "\n",
        "# Example usage:\n",
        "new_program_path = '/content/newexample/builder (4).java'  # Path to the new program file\n",
        "# Use the first KNN model (trained on the first fold) for prediction\n",
        "predicted_value = predict_program(new_program_path, knn_models[0])\n",
        "print(f\"Predicted label for the new program: {predicted_value}\")\n"
      ],
      "metadata": {
        "id": "qMuFx7PfUSn6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30aa9284-faee-4e55-822a-05c6ec3440c7"
      },
      "id": "qMuFx7PfUSn6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Time taken to load and label programs: 0.01 seconds\n",
            "Time taken to create DataFrame and save to CSV: 0.04 seconds\n",
            "Labels and contents saved to embeddings/af3.csv\n",
            "Columns in DataFrame after saving: Index(['File Name', 'Label', 'Content'], dtype='object')\n",
            "Time taken to load DataFrame from CSV: 0.02 seconds\n",
            "Columns after loading CSV: Index(['File Name', 'Label', 'Content'], dtype='object')\n",
            "DataFrame head after loading CSV:\n",
            "         File Name  Label                                            Content\n",
            "0   nonfm (6).java      0  package com.jmonkey.office.lexi.support.editor...\n",
            "1  nonfm (33).java      0  /*\\n * @(#)Figure.java 5.1\\n *\\n */\\n\\npackage...\n",
            "2  nonfm (48).java      0  /*\\n *  Author:  Chris Seguin\\n *\\n *  This so...\n",
            "3  nonfm (35).java      0  /**\\n *\\n    QuickUML; A simple UML tool that ...\n",
            "4  nonfm (76).java      0  /*\\n * @(#)BouncingDrawing.java 5.1\\n *\\n */\\n...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Processing embeddings: 100%|| 93/93 [00:06<00:00, 15.10it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken to extract embeddings: 7.22 seconds\n",
            "Time taken to save embeddings: 0.00 seconds\n",
            "Embeddings saved to embeddings/embeddings.npy\n",
            "Fold 1\n",
            "Precision: 0.0000, Recall: 0.0000, F1-Score: 0.0000\n",
            "Fold 2\n",
            "Precision: 0.0000, Recall: 0.0000, F1-Score: 0.0000\n",
            "Fold 3\n",
            "Precision: 0.6667, Recall: 0.6667, F1-Score: 0.6667\n",
            "Fold 4\n",
            "Precision: 0.3333, Recall: 0.5000, F1-Score: 0.4000\n",
            "Fold 5\n",
            "Precision: 1.0000, Recall: 0.5000, F1-Score: 0.6667\n",
            "Time taken for prediction: 0.00 seconds\n",
            "Predicted label for the new program: [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check if CUDA is available and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = '/content/factorymethod'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Start timing for loading programs\n",
        "start_time = time.time()\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"factorymethod\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# End timing for loading programs\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to load and label programs: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Start timing for creating DataFrame and saving to CSV\n",
        "start_time = time.time()\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Ensure the directory exists\n",
        "output_dir = 'embeddings'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = os.path.join(output_dir, 'af3.csv')  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to create DataFrame and save to CSV: {end_time - start_time:.2f} seconds\")\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "# Debug: Print column names to verify\n",
        "print(\"Columns in DataFrame after saving:\", df.columns)\n",
        "\n",
        "# Start timing for loading DataFrame from CSV\n",
        "start_time = time.time()\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = os.path.join(output_dir, 'af3.csv')  # Replace with the actual CSV file path\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to load DataFrame from CSV: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Verify if the 'Content' column exists\n",
        "print(\"Columns after loading CSV:\", df.columns)  # Check if 'Content' is present\n",
        "\n",
        "# Check the first few rows of the DataFrame\n",
        "print(\"DataFrame head after loading CSV:\")\n",
        "print(df.head())\n",
        "\n",
        "# Start timing for embedding extraction\n",
        "start_time = time.time()\n",
        "\n",
        "# Embedding Extraction - Example using RoBERTa Model\n",
        "\n",
        "# Load pre-trained RoBERTa model and tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\").to(device)\n",
        "\n",
        "# Tokenize and encode the content using RoBERTa\n",
        "embeddings = []\n",
        "\n",
        "for content in tqdm(df['Content'], desc=\"Processing embeddings\"):\n",
        "    # Tokenize and encode\n",
        "    inputs = tokenizer(content, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512).to(device)\n",
        "\n",
        "    # Get the output embeddings from the model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Extract the [CLS] token embedding\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "\n",
        "    # Store the embedding\n",
        "    embeddings.append(cls_embedding)\n",
        "\n",
        "# End timing for embedding extraction\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to extract embeddings: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Convert the list of embeddings into a numpy array\n",
        "embeddings = np.vstack(embeddings)\n",
        "\n",
        "# Save embeddings to a numpy file\n",
        "start_time = time.time()\n",
        "np.save(os.path.join(output_dir, \"embeddings.npy\"), embeddings)\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to save embeddings: {end_time - start_time:.2f} seconds\")\n",
        "print(f\"Embeddings saved to {os.path.join(output_dir, 'embeddings.npy')}\")\n",
        "\n",
        "# Example: Splitting data into training and testing using StratifiedKFold\n",
        "labels = df['Label'].values\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Train the KNeighborsClassifier model\n",
        "knn_models = []\n",
        "for fold, (train_idx, test_idx) in enumerate(skf.split(embeddings, labels)):\n",
        "    print(f\"Fold {fold + 1}\")\n",
        "\n",
        "    # Split into training and testing sets\n",
        "    X_train, X_test = embeddings[train_idx], embeddings[test_idx]\n",
        "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
        "\n",
        "    # Example classifier: KNeighborsClassifier\n",
        "    knn = KNeighborsClassifier(n_neighbors=3)\n",
        "    knn.fit(X_train, y_train)\n",
        "    knn_models.append(knn)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = knn.predict(X_test)\n",
        "\n",
        "    # Evaluate the classifier\n",
        "    precision = precision_score(y_test, y_pred, average='binary')\n",
        "    recall = recall_score(y_test, y_pred, average='binary')\n",
        "    f1 = f1_score(y_test, y_pred, average='binary')\n",
        "\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n",
        "\n",
        "# --- Prediction Phase for Unseen Java Programs ---\n",
        "\n",
        "def predict_directory(unseen_folder, knn_model):\n",
        "    predictions = {}\n",
        "\n",
        "    # Process each unseen Java program in the directory\n",
        "    for program_file in os.listdir(unseen_folder):\n",
        "        file_path = os.path.join(unseen_folder, program_file)\n",
        "\n",
        "        if os.path.isfile(file_path):\n",
        "            with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "                new_program_content = f.read()\n",
        "\n",
        "            # Tokenize and encode the new program content\n",
        "            inputs = tokenizer(new_program_content, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512).to(device)\n",
        "\n",
        "            # Extract embedding\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            new_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "\n",
        "            # Feed the embedding into the KNN model to predict\n",
        "            start_time = time.time()  # Start timing prediction\n",
        "            predicted_label = knn_model.predict(new_embedding)\n",
        "            end_time = time.time()  # End timing prediction\n",
        "\n",
        "            predictions[program_file] = {\n",
        "                \"predicted_label\": predicted_label[0],\n",
        "                \"prediction_time\": f\"{end_time - start_time:.2f} seconds\"\n",
        "            }\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Example usage:\n",
        "unseen_java_folder = '/content/newexample'  # Replace with the folder containing unseen Java programs\n",
        "\n",
        "# Use the first KNN model (trained on the first fold) for prediction\n",
        "predictions = predict_directory(unseen_java_folder, knn_models[0])\n",
        "\n",
        "# Print the predictions and their respective times\n",
        "for program_file, result in predictions.items():\n",
        "    print(f\"Program: {program_file}, Predicted Label: {result['predicted_label']}, Time Taken: {result['prediction_time']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gstD5yLeGMlA",
        "outputId": "612de999-2270-43b6-d4c4-b409e9bc26ca"
      },
      "id": "gstD5yLeGMlA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Time taken to load and label programs: 0.01 seconds\n",
            "Time taken to create DataFrame and save to CSV: 0.02 seconds\n",
            "Labels and contents saved to embeddings/af3.csv\n",
            "Columns in DataFrame after saving: Index(['File Name', 'Label', 'Content'], dtype='object')\n",
            "Time taken to load DataFrame from CSV: 0.01 seconds\n",
            "Columns after loading CSV: Index(['File Name', 'Label', 'Content'], dtype='object')\n",
            "DataFrame head after loading CSV:\n",
            "         File Name  Label                                            Content\n",
            "0   nonfm (6).java      0  package com.jmonkey.office.lexi.support.editor...\n",
            "1  nonfm (33).java      0  /*\\n * @(#)Figure.java 5.1\\n *\\n */\\n\\npackage...\n",
            "2  nonfm (48).java      0  /*\\n *  Author:  Chris Seguin\\n *\\n *  This so...\n",
            "3  nonfm (35).java      0  /**\\n *\\n    QuickUML; A simple UML tool that ...\n",
            "4  nonfm (76).java      0  /*\\n * @(#)BouncingDrawing.java 5.1\\n *\\n */\\n...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Processing embeddings: 100%|| 79/79 [00:03<00:00, 20.89it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken to extract embeddings: 4.58 seconds\n",
            "Time taken to save embeddings: 0.00 seconds\n",
            "Embeddings saved to embeddings/embeddings.npy\n",
            "Fold 1\n",
            "Precision: 0.5000, Recall: 1.0000, F1-Score: 0.6667\n",
            "Fold 2\n",
            "Precision: 0.0000, Recall: 0.0000, F1-Score: 0.0000\n",
            "Fold 3\n",
            "Precision: 1.0000, Recall: 0.5000, F1-Score: 0.6667\n",
            "Fold 4\n",
            "Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000\n",
            "Fold 5\n",
            "Precision: 0.0000, Recall: 0.0000, F1-Score: 0.0000\n",
            "Program: nonfm (16).java, Predicted Label: 0, Time Taken: 0.00 seconds\n",
            "Program: nonfm (15).java, Predicted Label: 0, Time Taken: 0.00 seconds\n",
            "Program: nonfm (19).java, Predicted Label: 0, Time Taken: 0.00 seconds\n",
            "Program: nonfm (17).java, Predicted Label: 0, Time Taken: 0.00 seconds\n",
            "Program: nonfm (18).java, Predicted Label: 0, Time Taken: 0.00 seconds\n",
            "Program: factorymethod (10).java, Predicted Label: 1, Time Taken: 0.00 seconds\n",
            "Program: factorymethod (9).java, Predicted Label: 0, Time Taken: 0.00 seconds\n",
            "Program: nonfm (14).java, Predicted Label: 0, Time Taken: 0.00 seconds\n",
            "Program: nonfm (12).java, Predicted Label: 1, Time Taken: 0.00 seconds\n",
            "Program: nonfm (13).java, Predicted Label: 0, Time Taken: 0.00 seconds\n",
            "Program: nonfm (11).java, Predicted Label: 1, Time Taken: 0.00 seconds\n",
            "Program: factorymethod (11).java, Predicted Label: 1, Time Taken: 0.00 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction time for Singleton**"
      ],
      "metadata": {
        "id": "kmmdt4f_4qUv"
      },
      "id": "kmmdt4f_4qUv"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check if CUDA is available and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = '/content/singleton'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Start timing for loading programs\n",
        "start_time = time.time()\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"singleton\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# End timing for loading programs\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to load and label programs: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Start timing for creating DataFrame and saving to CSV\n",
        "start_time = time.time()\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Ensure the directory exists\n",
        "output_dir = 'embeddings'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = os.path.join(output_dir, 'af3.csv')  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to create DataFrame and save to CSV: {end_time - start_time:.2f} seconds\")\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "# Debug: Print column names to verify\n",
        "print(\"Columns in DataFrame after saving:\", df.columns)\n",
        "\n",
        "# Start timing for loading DataFrame from CSV\n",
        "start_time = time.time()\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = os.path.join(output_dir, 'af3.csv')  # Replace with the actual CSV file path\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to load DataFrame from CSV: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Verify if the 'Content' column exists\n",
        "print(\"Columns after loading CSV:\", df.columns)  # Check if 'Content' is present\n",
        "\n",
        "# Check the first few rows of the DataFrame\n",
        "print(\"DataFrame head after loading CSV:\")\n",
        "print(df.head())\n",
        "\n",
        "# Start timing for embedding extraction\n",
        "start_time = time.time()\n",
        "\n",
        "# Embedding Extraction - Example using RoBERTa Model\n",
        "\n",
        "# Load pre-trained RoBERTa model and tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\").to(device)\n",
        "\n",
        "# Tokenize and encode the content using RoBERTa\n",
        "embeddings = []\n",
        "\n",
        "for content in tqdm(df['Content'], desc=\"Processing embeddings\"):\n",
        "    # Tokenize and encode\n",
        "    inputs = tokenizer(content, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512).to(device)\n",
        "\n",
        "    # Get the output embeddings from the model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Extract the [CLS] token embedding\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "\n",
        "    # Store the embedding\n",
        "    embeddings.append(cls_embedding)\n",
        "\n",
        "# End timing for embedding extraction\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to extract embeddings: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Convert the list of embeddings into a numpy array\n",
        "embeddings = np.vstack(embeddings)\n",
        "\n",
        "# Save embeddings to a numpy file\n",
        "start_time = time.time()\n",
        "np.save(os.path.join(output_dir, \"embeddings.npy\"), embeddings)\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to save embeddings: {end_time - start_time:.2f} seconds\")\n",
        "print(f\"Embeddings saved to {os.path.join(output_dir, 'embeddings.npy')}\")\n",
        "\n",
        "# Example: Splitting data into training and testing using StratifiedKFold\n",
        "labels = df['Label'].values\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Train the KNeighborsClassifier model\n",
        "knn_models = []\n",
        "for fold, (train_idx, test_idx) in enumerate(skf.split(embeddings, labels)):\n",
        "    print(f\"Fold {fold + 1}\")\n",
        "\n",
        "    # Split into training and testing sets\n",
        "    X_train, X_test = embeddings[train_idx], embeddings[test_idx]\n",
        "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
        "\n",
        "    # Example classifier: KNeighborsClassifier\n",
        "    knn = KNeighborsClassifier(n_neighbors=3)\n",
        "    knn.fit(X_train, y_train)\n",
        "    knn_models.append(knn)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = knn.predict(X_test)\n",
        "\n",
        "    # Evaluate the classifier\n",
        "    precision = precision_score(y_test, y_pred, average='binary')\n",
        "    recall = recall_score(y_test, y_pred, average='binary')\n",
        "    f1 = f1_score(y_test, y_pred, average='binary')\n",
        "\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n",
        "\n",
        "# --- Prediction Phase for Unseen Java Programs ---\n",
        "\n",
        "def predict_directory(unseen_folder, knn_model):\n",
        "    predictions = {}\n",
        "\n",
        "    # Process each unseen Java program in the directory\n",
        "    for program_file in os.listdir(unseen_folder):\n",
        "        file_path = os.path.join(unseen_folder, program_file)\n",
        "\n",
        "        if os.path.isfile(file_path):\n",
        "            with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "                new_program_content = f.read()\n",
        "\n",
        "            # Tokenize and encode the new program content\n",
        "            inputs = tokenizer(new_program_content, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512).to(device)\n",
        "\n",
        "            # Extract embedding\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            new_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "\n",
        "            # Feed the embedding into the KNN model to predict\n",
        "            start_time = time.time()  # Start timing prediction\n",
        "            predicted_label = knn_model.predict(new_embedding)\n",
        "            end_time = time.time()  # End timing prediction\n",
        "\n",
        "            predictions[program_file] = {\n",
        "                \"predicted_label\": predicted_label[0],\n",
        "                \"prediction_time\": f\"{end_time - start_time:.2f} seconds\"\n",
        "            }\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Example usage:\n",
        "unseen_java_folder = '/content/newexample'  # Replace with the folder containing unseen Java programs\n",
        "\n",
        "# Use the first KNN model (trained on the first fold) for prediction\n",
        "predictions = predict_directory(unseen_java_folder, knn_models[0])\n",
        "\n",
        "# Print the predictions and their respective times\n",
        "for program_file, result in predictions.items():\n",
        "    print(f\"Program: {program_file}, Predicted Label: {result['predicted_label']}, Time Taken: {result['prediction_time']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHEJSGYyjOCS",
        "outputId": "29a81cf9-cc0f-4de3-c053-dc70c737f9fe"
      },
      "id": "uHEJSGYyjOCS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Time taken to load and label programs: 0.00 seconds\n",
            "Time taken to create DataFrame and save to CSV: 0.02 seconds\n",
            "Labels and contents saved to embeddings/af3.csv\n",
            "Columns in DataFrame after saving: Index(['File Name', 'Label', 'Content'], dtype='object')\n",
            "Time taken to load DataFrame from CSV: 0.01 seconds\n",
            "Columns after loading CSV: Index(['File Name', 'Label', 'Content'], dtype='object')\n",
            "DataFrame head after loading CSV:\n",
            "             File Name  Label  \\\n",
            "0       nons (27).java      0   \n",
            "1  singleton (19).java      1   \n",
            "2       nons (56).java      0   \n",
            "3        nons (2).java      0   \n",
            "4       nons (20).java      0   \n",
            "\n",
            "                                             Content  \n",
            "0  /**\\n * Form -\\n *\\n * Copyright (c) 2002\\n * ...  \n",
            "1  package junit.runner;   \\n    \\n/**   \\n * Thi...  \n",
            "2  /*\\n * @(#)RectangleFigure.java 5.1\\n *\\n */\\n...  \n",
            "3  /*\\n *                 Sun Public License Noti...  \n",
            "4  /*\\n *                 Sun Public License Noti...  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Processing embeddings: 100%|| 85/85 [00:04<00:00, 19.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken to extract embeddings: 5.17 seconds\n",
            "Time taken to save embeddings: 0.00 seconds\n",
            "Embeddings saved to embeddings/embeddings.npy\n",
            "Fold 1\n",
            "Precision: 0.6667, Recall: 0.4000, F1-Score: 0.5000\n",
            "Fold 2\n",
            "Precision: 1.0000, Recall: 0.6000, F1-Score: 0.7500\n",
            "Fold 3\n",
            "Precision: 0.6667, Recall: 0.4000, F1-Score: 0.5000\n",
            "Fold 4\n",
            "Precision: 0.6667, Recall: 0.8000, F1-Score: 0.7273\n",
            "Fold 5\n",
            "Precision: 0.7500, Recall: 0.6000, F1-Score: 0.6667\n",
            "Program: prototype (18).java, Predicted Label: 0, Time Taken: 0.00 seconds\n",
            "Program: prototype (17).java, Predicted Label: 0, Time Taken: 0.00 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LMzXuw545M9H"
      },
      "id": "LMzXuw545M9H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sleton time calculation**"
      ],
      "metadata": {
        "id": "JgR57lXFMGJM"
      },
      "id": "JgR57lXFMGJM"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check if CUDA is available and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = '/content/singleton'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Start timing for loading programs\n",
        "start_time = time.time()\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"singleton\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# End timing for loading programs\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to load and label programs: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Start timing for creating DataFrame and saving to CSV\n",
        "start_time = time.time()\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Ensure the directory exists\n",
        "output_dir = 'embeddings'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = os.path.join(output_dir, 'af3.csv')  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to create DataFrame and save to CSV: {end_time - start_time:.2f} seconds\")\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "# Debug: Print column names to verify\n",
        "print(\"Columns in DataFrame after saving:\", df.columns)\n",
        "\n",
        "# Start timing for loading DataFrame from CSV\n",
        "start_time = time.time()\n",
        "\n",
        "# Define the path to the CSV file containing program names, labels, and content\n",
        "csv_path = os.path.join(output_dir, 'af3.csv')  # Replace with the actual CSV file path\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to load DataFrame from CSV: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Verify if the 'Content' column exists\n",
        "print(\"Columns after loading CSV:\", df.columns)  # Check if 'Content' is present\n",
        "\n",
        "# Check the first few rows of the DataFrame\n",
        "print(\"DataFrame head after loading CSV:\")\n",
        "print(df.head())\n",
        "\n",
        "# Start timing for embedding extraction\n",
        "start_time = time.time()\n",
        "\n",
        "# Embedding Extraction - Example using RoBERTa Model\n",
        "\n",
        "# Load pre-trained RoBERTa model and tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\").to(device)\n",
        "\n",
        "# Tokenize and encode the content using RoBERTa\n",
        "embeddings = []\n",
        "\n",
        "for content in tqdm(df['Content'], desc=\"Processing embeddings\"):\n",
        "    # Tokenize and encode\n",
        "    inputs = tokenizer(content, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512).to(device)\n",
        "\n",
        "    # Get the output embeddings from the model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Extract the [CLS] token embedding\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "\n",
        "    # Store the embedding\n",
        "    embeddings.append(cls_embedding)\n",
        "\n",
        "# End timing for embedding extraction\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to extract embeddings: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Convert the list of embeddings into a numpy array\n",
        "embeddings = np.vstack(embeddings)\n",
        "\n",
        "# Save embeddings to a numpy file\n",
        "start_time = time.time()\n",
        "np.save(os.path.join(output_dir, \"embeddings.npy\"), embeddings)\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to save embeddings: {end_time - start_time:.2f} seconds\")\n",
        "print(f\"Embeddings saved to {os.path.join(output_dir, 'embeddings.npy')}\")\n",
        "\n",
        "# Example: Splitting data into training and testing using StratifiedKFold\n",
        "labels = df['Label'].values\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Train the KNeighborsClassifier model\n",
        "knn_models = []\n",
        "for fold, (train_idx, test_idx) in enumerate(skf.split(embeddings, labels)):\n",
        "    print(f\"Fold {fold + 1}\")\n",
        "\n",
        "    # Split into training and testing sets\n",
        "    X_train, X_test = embeddings[train_idx], embeddings[test_idx]\n",
        "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
        "\n",
        "    # Example classifier: KNeighborsClassifier\n",
        "    knn = KNeighborsClassifier(n_neighbors=3)\n",
        "    knn.fit(X_train, y_train)\n",
        "    knn_models.append(knn)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = knn.predict(X_test)\n",
        "\n",
        "    # Evaluate the classifier\n",
        "    precision = precision_score(y_test, y_pred, average='binary')\n",
        "    recall = recall_score(y_test, y_pred, average='binary')\n",
        "    f1 = f1_score(y_test, y_pred, average='binary')\n",
        "\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n",
        "\n",
        "# --- Prediction Phase for Unseen Java Programs ---\n",
        "\n",
        "def predict_directory(unseen_folder, knn_model):\n",
        "    predictions = {}\n",
        "\n",
        "    # Process each unseen Java program in the directory\n",
        "    for program_file in os.listdir(unseen_folder):\n",
        "        file_path = os.path.join(unseen_folder, program_file)\n",
        "\n",
        "        if os.path.isfile(file_path):\n",
        "            with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "                new_program_content = f.read()\n",
        "\n",
        "            # Tokenize and encode the new program content\n",
        "            inputs = tokenizer(new_program_content, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512).to(device)\n",
        "\n",
        "            # Extract embedding\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            new_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "\n",
        "            # Feed the embedding into the KNN model to predict\n",
        "            start_time = time.time()  # Start timing prediction\n",
        "            predicted_label = knn_model.predict(new_embedding)\n",
        "            end_time = time.time()  # End timing prediction\n",
        "\n",
        "            predictions[program_file] = {\n",
        "                \"predicted_label\": predicted_label[0],\n",
        "                \"prediction_time\": f\"{end_time - start_time:.2f} seconds\"\n",
        "            }\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Example usage:\n",
        "unseen_java_folder = '/content/newexample'  # Replace with the folder containing unseen Java programs\n",
        "\n",
        "# Use the first KNN model (trained on the first fold) for prediction\n",
        "predictions = predict_directory(unseen_java_folder, knn_models[0])\n",
        "\n",
        "# Print the predictions and their respective times\n",
        "for program_file, result in predictions.items():\n",
        "    print(f\"Program: {program_file}, Predicted Label: {result['predicted_label']}, Time Taken: {result['prediction_time']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkcNFDbuNnby",
        "outputId": "1af2abc2-0ee9-41a0-8586-36835e56842f"
      },
      "id": "QkcNFDbuNnby",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Time taken to load and label programs: 0.01 seconds\n",
            "Time taken to create DataFrame and save to CSV: 0.03 seconds\n",
            "Labels and contents saved to embeddings/af3.csv\n",
            "Columns in DataFrame after saving: Index(['File Name', 'Label', 'Content'], dtype='object')\n",
            "Time taken to load DataFrame from CSV: 0.01 seconds\n",
            "Columns after loading CSV: Index(['File Name', 'Label', 'Content'], dtype='object')\n",
            "DataFrame head after loading CSV:\n",
            "             File Name  Label  \\\n",
            "0       nons (68).java      0   \n",
            "1       nons (40).java      0   \n",
            "2        nons (9).java      0   \n",
            "3       nons (27).java      0   \n",
            "4  singleton (13).java      1   \n",
            "\n",
            "                                             Content  \n",
            "0  /*\\n * @(#)ConnectionTool.java 5.1\\n *\\n */\\n\\...  \n",
            "1  /*\\n * @(#)ElbowConnection.java 5.1\\n *\\n */\\n...  \n",
            "2  /*\\n *                 Sun Public License Noti...  \n",
            "3  /**\\n * Form -\\n *\\n * Copyright (c) 2002\\n * ...  \n",
            "4  /*\\n * Author:  Chris Seguin\\n *\\n * This soft...  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Processing embeddings: 100%|| 85/85 [03:09<00:00,  2.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken to extract embeddings: 190.06 seconds\n",
            "Time taken to save embeddings: 0.00 seconds\n",
            "Embeddings saved to embeddings/embeddings.npy\n",
            "Fold 1\n",
            "Precision: 0.7500, Recall: 0.6000, F1-Score: 0.6667\n",
            "Fold 2\n",
            "Precision: 0.0000, Recall: 0.0000, F1-Score: 0.0000\n",
            "Fold 3\n",
            "Precision: 0.7500, Recall: 0.6000, F1-Score: 0.6667\n",
            "Fold 4\n",
            "Precision: 0.8000, Recall: 0.8000, F1-Score: 0.8000\n",
            "Fold 5\n",
            "Precision: 1.0000, Recall: 0.6000, F1-Score: 0.7500\n",
            "Program: 0 (9).java, Predicted Label: 0, Time Taken: 0.00 seconds\n",
            "Program: 0 (6).java, Predicted Label: 0, Time Taken: 0.00 seconds\n",
            "Program: 0 (14).java, Predicted Label: 0, Time Taken: 0.00 seconds\n",
            "Program: 0 (5).java, Predicted Label: 1, Time Taken: 0.00 seconds\n",
            "Program: 0 (10).java, Predicted Label: 0, Time Taken: 0.00 seconds\n",
            "Program: 0 (32).java, Predicted Label: 0, Time Taken: 0.00 seconds\n",
            "Program: 0 (7).java, Predicted Label: 0, Time Taken: 0.00 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eSbqwByrNqTF"
      },
      "id": "eSbqwByrNqTF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prototype, Standard deviation, training and prediction time calculation**"
      ],
      "metadata": {
        "id": "Z6CbyO1bSNwN"
      },
      "id": "Z6CbyO1bSNwN"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check if CUDA is available and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = '/content/prototype'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Start timing for loading programs\n",
        "start_time = time.time()\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"prototype\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# End timing for loading programs\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to load and label programs: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Start timing for creating DataFrame and saving to CSV\n",
        "start_time = time.time()\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Ensure the directory exists\n",
        "output_dir = 'embeddings'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = os.path.join(output_dir, 'af3.csv')  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to create DataFrame and save to CSV: {end_time - start_time:.2f} seconds\")\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "# Start timing for loading DataFrame from CSV\n",
        "start_time = time.time()\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to load DataFrame from CSV: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Start timing for embedding extraction\n",
        "start_time = time.time()\n",
        "\n",
        "# Load pre-trained RoBERTa model and tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\").to(device)\n",
        "\n",
        "# Tokenize and encode the content using RoBERTa\n",
        "embeddings = []\n",
        "\n",
        "for content in tqdm(df['Content'], desc=\"Processing embeddings\"):\n",
        "    # Tokenize and encode\n",
        "    inputs = tokenizer(content, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512).to(device)\n",
        "\n",
        "    # Get the output embeddings from the model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Extract the [CLS] token embedding\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "\n",
        "    # Store the embedding\n",
        "    embeddings.append(cls_embedding)\n",
        "\n",
        "# End timing for embedding extraction\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to extract embeddings: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Convert the list of embeddings into a numpy array\n",
        "embeddings = np.vstack(embeddings)\n",
        "\n",
        "# Save embeddings to a numpy file\n",
        "start_time = time.time()\n",
        "np.save(os.path.join(output_dir, \"embeddings.npy\"), embeddings)\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to save embeddings: {end_time - start_time:.2f} seconds\")\n",
        "print(f\"Embeddings saved to {os.path.join(output_dir, 'embeddings.npy')}\")\n",
        "\n",
        "# Define a constant for the number of runs\n",
        "NUM_RUNS = 10  # Change this value to set the number of runs\n",
        "\n",
        "# Function to run training and evaluation\n",
        "def run_knn_experiment(embeddings, labels, num_runs=NUM_RUNS):\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    f1_scores = []\n",
        "    total_training_time = 0\n",
        "\n",
        "    # Convert labels to a NumPy array for proper indexing\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # Initialize StratifiedKFold\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    for run in range(num_runs):\n",
        "        print(f\"Run {run + 1}\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Train and evaluate on each fold\n",
        "        for fold, (train_idx, test_idx) in enumerate(skf.split(embeddings, labels)):\n",
        "            print(f\"  Fold {fold + 1}\")\n",
        "\n",
        "            # Split into training and testing sets\n",
        "            X_train, X_test = embeddings[train_idx], embeddings[test_idx]\n",
        "            y_train, y_test = labels[train_idx], labels[test_idx]\n",
        "\n",
        "            # Example classifier: KNeighborsClassifier\n",
        "            knn = KNeighborsClassifier(n_neighbors=3)\n",
        "            knn.fit(X_train, y_train)\n",
        "\n",
        "            # Make predictions\n",
        "            y_pred = knn.predict(X_test)\n",
        "\n",
        "            # Evaluate the classifier\n",
        "            precision = precision_score(y_test, y_pred, average='binary')\n",
        "            recall = recall_score(y_test, y_pred, average='binary')\n",
        "            f1 = f1_score(y_test, y_pred, average='binary')\n",
        "\n",
        "            precision_scores.append(precision)\n",
        "            recall_scores.append(recall)\n",
        "            f1_scores.append(f1)\n",
        "\n",
        "        end_time = time.time()\n",
        "        training_time = (end_time - start_time) * 1_000_000  # Convert to microseconds\n",
        "        total_training_time += training_time\n",
        "\n",
        "    mean_precision = np.nanmean(precision_scores)\n",
        "    mean_recall = np.nanmean(recall_scores)\n",
        "    mean_f1 = np.nanmean(f1_scores)\n",
        "\n",
        "    std_precision = np.nanstd(precision_scores)\n",
        "    std_recall = np.nanstd(recall_scores)\n",
        "    std_f1 = np.nanstd(f1_scores)\n",
        "\n",
        "    print(f\"Total Training Time for {num_runs} runs: {total_training_time:.2f} microseconds\")\n",
        "    print(f\"Mean Precision: {mean_precision:.4f}, Standard Deviation: {std_precision:.4f}\")\n",
        "    print(f\"Mean Recall: {mean_recall:.4f}, Standard Deviation: {std_recall:.4f}\")\n",
        "    print(f\"Mean F1-Score: {mean_f1:.4f}, Standard Deviation: {std_f1:.4f}\")\n",
        "\n",
        "    return knn  # Return the last trained KNN model for predictions\n",
        "\n",
        "knn_model = run_knn_experiment(embeddings, labels)\n",
        "\n",
        "# --- Prediction Phase for Unseen Java Programs ---\n",
        "\n",
        "def predict_directory(unseen_folder, knn_model):\n",
        "    predictions = {}\n",
        "\n",
        "    # Process each unseen Java program in the directory\n",
        "    for program_file in os.listdir(unseen_folder):\n",
        "        file_path = os.path.join(unseen_folder, program_file)\n",
        "\n",
        "        if os.path.isfile(file_path):\n",
        "            with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "                new_program_content = f.read()\n",
        "\n",
        "            # Tokenize and encode the new program content\n",
        "            inputs = tokenizer(new_program_content, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512).to(device)\n",
        "\n",
        "            # Extract embedding\n",
        "            start_time = time.time()  # Start timing embedding extraction\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            new_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "            end_time = time.time()  # End timing embedding extraction\n",
        "\n",
        "            # Feed the embedding into the KNN model to predict\n",
        "            start_time = time.time()  # Start timing prediction\n",
        "            predicted_label = knn_model.predict(new_embedding)\n",
        "            end_time = time.time()  # End timing prediction\n",
        "\n",
        "            predictions[program_file] = {\n",
        "                \"predicted_label\": predicted_label[0],\n",
        "                \"embedding_extraction_time\": f\"{(end_time - start_time) * 1_000_000:.2f} microseconds\",\n",
        "                \"prediction_time\": f\"{(end_time - start_time) * 1_000_000:.2f} microseconds\"\n",
        "            }\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Example usage:\n",
        "unseen_java_folder = '/content/newexample'  # Replace with the folder containing unseen Java programs\n",
        "\n",
        "# Use the last KNN model trained for prediction\n",
        "predictions = predict_directory(unseen_java_folder, knn_model)\n",
        "\n",
        "# Print the predictions and their respective times\n",
        "for program_file, result in predictions.items():\n",
        "    print(f\"Program: {program_file}, Predicted Label: {result['predicted_label']}, \"\n",
        "          f\"Embedding Extraction Time: {result['embedding_extraction_time']}, \"\n",
        "          f\"Prediction Time: {result['prediction_time']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQtU58s7STZD",
        "outputId": "46147118-77c7-419b-97ee-de613f2e2687"
      },
      "id": "fQtU58s7STZD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Time taken to load and label programs: 0.00 seconds\n",
            "Time taken to create DataFrame and save to CSV: 0.02 seconds\n",
            "Labels and contents saved to embeddings/af3.csv\n",
            "Time taken to load DataFrame from CSV: 0.01 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Processing embeddings: 100%|| 70/70 [03:14<00:00,  2.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken to extract embeddings: 194.76 seconds\n",
            "Time taken to save embeddings: 0.00 seconds\n",
            "Embeddings saved to embeddings/embeddings.npy\n",
            "Run 1\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 2\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 3\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 4\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 5\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 6\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 7\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 8\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 9\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 10\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Total Training Time for 10 runs: 502141.48 microseconds\n",
            "Mean Precision: 0.9464, Standard Deviation: 0.0659\n",
            "Mean Recall: 0.8048, Standard Deviation: 0.2458\n",
            "Mean F1-Score: 0.8399, Standard Deviation: 0.1761\n",
            "Program: nonp (17).java, Predicted Label: 1, Embedding Extraction Time: 1921.18 microseconds, Prediction Time: 1921.18 microseconds\n",
            "Program: nonp (16).java, Predicted Label: 0, Embedding Extraction Time: 1633.64 microseconds, Prediction Time: 1633.64 microseconds\n",
            "Program: prototype (9).java, Predicted Label: 1, Embedding Extraction Time: 2003.67 microseconds, Prediction Time: 2003.67 microseconds\n",
            "Program: prototype (8).java, Predicted Label: 1, Embedding Extraction Time: 1582.38 microseconds, Prediction Time: 1582.38 microseconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Specify the directory path you want to delete\n",
        "dir_path = '/content/embeddings'\n",
        "\n",
        "# Remove the directory and its contents\n",
        "shutil.rmtree(dir_path)\n",
        "\n",
        "print(f\"Directory '{dir_path}' has been deleted.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpF4ScvfTIem",
        "outputId": "5449f3ec-0dcd-4a5a-9d45-f19949004543"
      },
      "id": "SpF4ScvfTIem",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory '/content/embeddings' has been deleted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Singleton, Standard deviation, training and prediction time calculation**"
      ],
      "metadata": {
        "id": "XqNgvnmeJBYU"
      },
      "id": "XqNgvnmeJBYU"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check if CUDA is available and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = '/content/singleton'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Start timing for loading programs\n",
        "start_time = time.time()\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"singleton\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# End timing for loading programs\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to load and label programs: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Start timing for creating DataFrame and saving to CSV\n",
        "start_time = time.time()\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Ensure the directory exists\n",
        "output_dir = 'embeddings'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = os.path.join(output_dir, 'af3.csv')  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to create DataFrame and save to CSV: {end_time - start_time:.2f} seconds\")\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "# Start timing for loading DataFrame from CSV\n",
        "start_time = time.time()\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to load DataFrame from CSV: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Start timing for embedding extraction\n",
        "start_time = time.time()\n",
        "\n",
        "# Load pre-trained RoBERTa model and tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\").to(device)\n",
        "\n",
        "# Tokenize and encode the content using RoBERTa\n",
        "embeddings = []\n",
        "\n",
        "for content in tqdm(df['Content'], desc=\"Processing embeddings\"):\n",
        "    # Tokenize and encode\n",
        "    inputs = tokenizer(content, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512).to(device)\n",
        "\n",
        "    # Get the output embeddings from the model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Extract the [CLS] token embedding\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "\n",
        "    # Store the embedding\n",
        "    embeddings.append(cls_embedding)\n",
        "\n",
        "# End timing for embedding extraction\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to extract embeddings: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Convert the list of embeddings into a numpy array\n",
        "embeddings = np.vstack(embeddings)\n",
        "\n",
        "# Save embeddings to a numpy file\n",
        "start_time = time.time()\n",
        "np.save(os.path.join(output_dir, \"embeddings.npy\"), embeddings)\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to save embeddings: {end_time - start_time:.2f} seconds\")\n",
        "print(f\"Embeddings saved to {os.path.join(output_dir, 'embeddings.npy')}\")\n",
        "\n",
        "# Define a constant for the number of runs\n",
        "NUM_RUNS = 10  # Change this value to set the number of runs\n",
        "\n",
        "# Function to run training and evaluation\n",
        "def run_knn_experiment(embeddings, labels, num_runs=NUM_RUNS):\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    f1_scores = []\n",
        "    total_training_time = 0\n",
        "\n",
        "    # Convert labels to a NumPy array for proper indexing\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # Initialize StratifiedKFold\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    for run in range(num_runs):\n",
        "        print(f\"Run {run + 1}\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Train and evaluate on each fold\n",
        "        for fold, (train_idx, test_idx) in enumerate(skf.split(embeddings, labels)):\n",
        "            print(f\"  Fold {fold + 1}\")\n",
        "\n",
        "            # Split into training and testing sets\n",
        "            X_train, X_test = embeddings[train_idx], embeddings[test_idx]\n",
        "            y_train, y_test = labels[train_idx], labels[test_idx]\n",
        "\n",
        "            # Example classifier: KNeighborsClassifier\n",
        "            knn = KNeighborsClassifier(n_neighbors=3)\n",
        "            knn.fit(X_train, y_train)\n",
        "\n",
        "            # Make predictions\n",
        "            y_pred = knn.predict(X_test)\n",
        "\n",
        "            # Evaluate the classifier\n",
        "            precision = precision_score(y_test, y_pred, average='binary')\n",
        "            recall = recall_score(y_test, y_pred, average='binary')\n",
        "            f1 = f1_score(y_test, y_pred, average='binary')\n",
        "\n",
        "            precision_scores.append(precision)\n",
        "            recall_scores.append(recall)\n",
        "            f1_scores.append(f1)\n",
        "\n",
        "        end_time = time.time()\n",
        "        training_time = (end_time - start_time) * 1_000_000  # Convert to microseconds\n",
        "        total_training_time += training_time\n",
        "\n",
        "    mean_precision = np.nanmean(precision_scores)\n",
        "    mean_recall = np.nanmean(recall_scores)\n",
        "    mean_f1 = np.nanmean(f1_scores)\n",
        "\n",
        "    std_precision = np.nanstd(precision_scores)\n",
        "    std_recall = np.nanstd(recall_scores)\n",
        "    std_f1 = np.nanstd(f1_scores)\n",
        "\n",
        "    print(f\"Total Training Time for {num_runs} runs: {total_training_time:.2f} microseconds\")\n",
        "    print(f\"Mean Precision: {mean_precision:.4f}, Standard Deviation: {std_precision:.4f}\")\n",
        "    print(f\"Mean Recall: {mean_recall:.4f}, Standard Deviation: {std_recall:.4f}\")\n",
        "    print(f\"Mean F1-Score: {mean_f1:.4f}, Standard Deviation: {std_f1:.4f}\")\n",
        "\n",
        "    return knn  # Return the last trained KNN model for predictions\n",
        "\n",
        "knn_model = run_knn_experiment(embeddings, labels)\n",
        "\n",
        "# --- Prediction Phase for Unseen Java Programs ---\n",
        "\n",
        "def predict_directory(unseen_folder, knn_model):\n",
        "    predictions = {}\n",
        "\n",
        "    # Process each unseen Java program in the directory\n",
        "    for program_file in os.listdir(unseen_folder):\n",
        "        file_path = os.path.join(unseen_folder, program_file)\n",
        "\n",
        "        if os.path.isfile(file_path):\n",
        "            with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "                new_program_content = f.read()\n",
        "\n",
        "            # Tokenize and encode the new program content\n",
        "            inputs = tokenizer(new_program_content, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512).to(device)\n",
        "\n",
        "            # Extract embedding\n",
        "            start_time = time.time()  # Start timing embedding extraction\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            new_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "            end_time = time.time()  # End timing embedding extraction\n",
        "\n",
        "            # Feed the embedding into the KNN model to predict\n",
        "            start_time = time.time()  # Start timing prediction\n",
        "            predicted_label = knn_model.predict(new_embedding)\n",
        "            end_time = time.time()  # End timing prediction\n",
        "\n",
        "            predictions[program_file] = {\n",
        "                \"predicted_label\": predicted_label[0],\n",
        "                \"embedding_extraction_time\": f\"{(end_time - start_time) * 1_000_000:.2f} microseconds\",\n",
        "                \"prediction_time\": f\"{(end_time - start_time) * 1_000_000:.2f} microseconds\"\n",
        "            }\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Example usage:\n",
        "unseen_java_folder = '/content/newexample'  # Replace with the folder containing unseen Java programs\n",
        "\n",
        "# Use the last KNN model trained for prediction\n",
        "predictions = predict_directory(unseen_java_folder, knn_model)\n",
        "\n",
        "# Print the predictions and their respective times\n",
        "for program_file, result in predictions.items():\n",
        "    print(f\"Program: {program_file}, Predicted Label: {result['predicted_label']}, \"\n",
        "          f\"Embedding Extraction Time: {result['embedding_extraction_time']}, \"\n",
        "          f\"Prediction Time: {result['prediction_time']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpnzQ_PPJKPZ",
        "outputId": "c018ae57-e5d9-4eed-f586-51eecdcca53d"
      },
      "id": "rpnzQ_PPJKPZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Time taken to load and label programs: 0.01 seconds\n",
            "Time taken to create DataFrame and save to CSV: 0.05 seconds\n",
            "Labels and contents saved to embeddings/af3.csv\n",
            "Time taken to load DataFrame from CSV: 0.03 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Processing embeddings: 100%|| 79/79 [03:53<00:00,  2.96s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken to extract embeddings: 234.48 seconds\n",
            "Time taken to save embeddings: 0.00 seconds\n",
            "Embeddings saved to embeddings/embeddings.npy\n",
            "Run 1\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 2\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 3\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 4\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 5\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 6\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 7\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 8\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 9\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 10\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Total Training Time for 10 runs: 630822.90 microseconds\n",
            "Mean Precision: 0.7210, Standard Deviation: 0.1686\n",
            "Mean Recall: 0.6400, Standard Deviation: 0.2653\n",
            "Mean F1-Score: 0.6218, Standard Deviation: 0.1837\n",
            "Program: nons (30).java, Predicted Label: 0, Embedding Extraction Time: 1634.60 microseconds, Prediction Time: 1634.60 microseconds\n",
            "Program: singleton (24).java, Predicted Label: 1, Embedding Extraction Time: 1593.11 microseconds, Prediction Time: 1593.11 microseconds\n",
            "Program: nons (23).java, Predicted Label: 0, Embedding Extraction Time: 1590.73 microseconds, Prediction Time: 1590.73 microseconds\n",
            "Program: singleton (1).java, Predicted Label: 0, Embedding Extraction Time: 1622.44 microseconds, Prediction Time: 1622.44 microseconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Specify the directory path you want to delete\n",
        "dir_path = '/content/builder'\n",
        "\n",
        "# Remove the directory and its contents\n",
        "shutil.rmtree(dir_path)\n",
        "\n",
        "print(f\"Directory '{dir_path}' has been deleted.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uP3lPZUmLbwB",
        "outputId": "bc3c8984-32e9-412e-8bda-1385782b2709"
      },
      "id": "uP3lPZUmLbwB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory '/content/builder' has been deleted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check if CUDA is available and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = '/content/builder'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Start timing for loading programs\n",
        "start_time = time.time()\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"builder\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# End timing for loading programs\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to load and label programs: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Start timing for creating DataFrame and saving to CSV\n",
        "start_time = time.time()\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Ensure the directory exists\n",
        "output_dir = 'embeddings'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = os.path.join(output_dir, 'af3.csv')  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to create DataFrame and save to CSV: {end_time - start_time:.2f} seconds\")\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "# Start timing for loading DataFrame from CSV\n",
        "start_time = time.time()\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to load DataFrame from CSV: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Start timing for embedding extraction\n",
        "start_time = time.time()\n",
        "\n",
        "# Load pre-trained RoBERTa model and tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\").to(device)\n",
        "\n",
        "# Tokenize and encode the content using RoBERTa\n",
        "embeddings = []\n",
        "\n",
        "for content in tqdm(df['Content'], desc=\"Processing embeddings\"):\n",
        "    # Tokenize and encode\n",
        "    inputs = tokenizer(content, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512).to(device)\n",
        "\n",
        "    # Get the output embeddings from the model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Extract the [CLS] token embedding\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "\n",
        "    # Store the embedding\n",
        "    embeddings.append(cls_embedding)\n",
        "\n",
        "# End timing for embedding extraction\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to extract embeddings: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Convert the list of embeddings into a numpy array\n",
        "embeddings = np.vstack(embeddings)\n",
        "\n",
        "# Save embeddings to a numpy file\n",
        "start_time = time.time()\n",
        "np.save(os.path.join(output_dir, \"embeddings.npy\"), embeddings)\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to save embeddings: {end_time - start_time:.2f} seconds\")\n",
        "print(f\"Embeddings saved to {os.path.join(output_dir, 'embeddings.npy')}\")\n",
        "\n",
        "# Define a constant for the number of runs\n",
        "NUM_RUNS = 10  # Change this value to set the number of runs\n",
        "\n",
        "# Function to run training and evaluation\n",
        "def run_knn_experiment(embeddings, labels, num_runs=NUM_RUNS):\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    f1_scores = []\n",
        "    total_training_time = 0\n",
        "\n",
        "    # Convert labels to a NumPy array for proper indexing\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # Initialize StratifiedKFold\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    for run in range(num_runs):\n",
        "        print(f\"Run {run + 1}\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Train and evaluate on each fold\n",
        "        for fold, (train_idx, test_idx) in enumerate(skf.split(embeddings, labels)):\n",
        "            print(f\"  Fold {fold + 1}\")\n",
        "\n",
        "            # Split into training and testing sets\n",
        "            X_train, X_test = embeddings[train_idx], embeddings[test_idx]\n",
        "            y_train, y_test = labels[train_idx], labels[test_idx]\n",
        "\n",
        "            # Example classifier: KNeighborsClassifier\n",
        "            knn = KNeighborsClassifier(n_neighbors=3)\n",
        "            knn.fit(X_train, y_train)\n",
        "\n",
        "            # Make predictions\n",
        "            y_pred = knn.predict(X_test)\n",
        "\n",
        "            # Evaluate the classifier\n",
        "            precision = precision_score(y_test, y_pred, average='binary')\n",
        "            recall = recall_score(y_test, y_pred, average='binary')\n",
        "            f1 = f1_score(y_test, y_pred, average='binary')\n",
        "\n",
        "            precision_scores.append(precision)\n",
        "            recall_scores.append(recall)\n",
        "            f1_scores.append(f1)\n",
        "\n",
        "        end_time = time.time()\n",
        "        training_time = (end_time - start_time) * 1_000_000  # Convert to microseconds\n",
        "        total_training_time += training_time\n",
        "\n",
        "    mean_precision = np.nanmean(precision_scores)\n",
        "    mean_recall = np.nanmean(recall_scores)\n",
        "    mean_f1 = np.nanmean(f1_scores)\n",
        "\n",
        "    std_precision = np.nanstd(precision_scores)\n",
        "    std_recall = np.nanstd(recall_scores)\n",
        "    std_f1 = np.nanstd(f1_scores)\n",
        "\n",
        "    print(f\"Total Training Time for {num_runs} runs: {total_training_time:.2f} microseconds\")\n",
        "    print(f\"Mean Precision: {mean_precision:.4f}, Standard Deviation: {std_precision:.4f}\")\n",
        "    print(f\"Mean Recall: {mean_recall:.4f}, Standard Deviation: {std_recall:.4f}\")\n",
        "    print(f\"Mean F1-Score: {mean_f1:.4f}, Standard Deviation: {std_f1:.4f}\")\n",
        "\n",
        "    return knn  # Return the last trained KNN model for predictions\n",
        "\n",
        "knn_model = run_knn_experiment(embeddings, labels)\n",
        "\n",
        "# --- Prediction Phase for Unseen Java Programs ---\n",
        "\n",
        "def predict_directory(unseen_folder, knn_model):\n",
        "    predictions = {}\n",
        "\n",
        "    # Process each unseen Java program in the directory\n",
        "    for program_file in os.listdir(unseen_folder):\n",
        "        file_path = os.path.join(unseen_folder, program_file)\n",
        "\n",
        "        if os.path.isfile(file_path):\n",
        "            with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "                new_program_content = f.read()\n",
        "\n",
        "            # Tokenize and encode the new program content\n",
        "            inputs = tokenizer(new_program_content, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512).to(device)\n",
        "\n",
        "            # Extract embedding\n",
        "            start_time = time.time()  # Start timing embedding extraction\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            new_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "            end_time = time.time()  # End timing embedding extraction\n",
        "\n",
        "            # Feed the embedding into the KNN model to predict\n",
        "            start_time = time.time()  # Start timing prediction\n",
        "            predicted_label = knn_model.predict(new_embedding)\n",
        "            end_time = time.time()  # End timing prediction\n",
        "\n",
        "            predictions[program_file] = {\n",
        "                \"predicted_label\": predicted_label[0],\n",
        "                \"embedding_extraction_time\": f\"{(end_time - start_time) * 1_000_000:.2f} microseconds\",\n",
        "                \"prediction_time\": f\"{(end_time - start_time) * 1_000_000:.2f} microseconds\"\n",
        "            }\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Example usage:\n",
        "unseen_java_folder = '/content/newexample'  # Replace with the folder containing unseen Java programs\n",
        "\n",
        "# Use the last KNN model trained for prediction\n",
        "predictions = predict_directory(unseen_java_folder, knn_model)\n",
        "\n",
        "# Print the predictions and their respective times\n",
        "for program_file, result in predictions.items():\n",
        "    print(f\"Program: {program_file}, Predicted Label: {result['predicted_label']}, \"\n",
        "          f\"Embedding Extraction Time: {result['embedding_extraction_time']}, \"\n",
        "          f\"Prediction Time: {result['prediction_time']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zk-wEg3Lb9u",
        "outputId": "c6420142-c2f9-46f7-d580-35f6d547b0f5"
      },
      "id": "6zk-wEg3Lb9u",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Time taken to load and label programs: 0.01 seconds\n",
            "Time taken to create DataFrame and save to CSV: 0.03 seconds\n",
            "Labels and contents saved to embeddings/af3.csv\n",
            "Time taken to load DataFrame from CSV: 0.02 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Processing embeddings: 100%|| 105/105 [04:17<00:00,  2.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken to extract embeddings: 257.76 seconds\n",
            "Time taken to save embeddings: 0.00 seconds\n",
            "Embeddings saved to embeddings/embeddings.npy\n",
            "Run 1\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 2\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 3\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 4\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 5\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 6\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 7\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 8\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 9\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 10\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Total Training Time for 10 runs: 648471.59 microseconds\n",
            "Mean Precision: 0.8667, Standard Deviation: 0.2667\n",
            "Mean Recall: 0.6000, Standard Deviation: 0.2000\n",
            "Mean F1-Score: 0.6800, Standard Deviation: 0.1904\n",
            "Program: builder (5).java, Predicted Label: 1, Embedding Extraction Time: 2240.66 microseconds, Prediction Time: 2240.66 microseconds\n",
            "Program: builder (3).java, Predicted Label: 1, Embedding Extraction Time: 1868.01 microseconds, Prediction Time: 1868.01 microseconds\n",
            "Program: nonb (119).java, Predicted Label: 0, Embedding Extraction Time: 1942.63 microseconds, Prediction Time: 1942.63 microseconds\n",
            "Program: nonb (108).java, Predicted Label: 1, Embedding Extraction Time: 1706.36 microseconds, Prediction Time: 1706.36 microseconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Abstract factory, standard deviation, training time, prediction time.**"
      ],
      "metadata": {
        "id": "MLLEUJWkOFNH"
      },
      "id": "MLLEUJWkOFNH"
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Specify the directory path you want to delete\n",
        "dir_path = '/content/embeddings'\n",
        "\n",
        "# Remove the directory and its contents\n",
        "shutil.rmtree(dir_path)\n",
        "\n",
        "print(f\"Directory '{dir_path}' has been deleted.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPiv0D36KDUp",
        "outputId": "71c76988-9664-484a-ea58-b9b4d0139258"
      },
      "id": "PPiv0D36KDUp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory '/content/embeddings' has been deleted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check if CUDA is available and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = '/content/abstractfactory'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Start timing for loading programs\n",
        "start_time = time.time()\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"abstractfactory\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# End timing for loading programs\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to load and label programs: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Start timing for creating DataFrame and saving to CSV\n",
        "start_time = time.time()\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Ensure the directory exists\n",
        "output_dir = 'embeddings'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = os.path.join(output_dir, 'af3.csv')  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to create DataFrame and save to CSV: {end_time - start_time:.2f} seconds\")\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "# Start timing for loading DataFrame from CSV\n",
        "start_time = time.time()\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to load DataFrame from CSV: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Start timing for embedding extraction\n",
        "start_time = time.time()\n",
        "\n",
        "# Load pre-trained RoBERTa model and tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\").to(device)\n",
        "\n",
        "# Tokenize and encode the content using RoBERTa\n",
        "embeddings = []\n",
        "\n",
        "for content in tqdm(df['Content'], desc=\"Processing embeddings\"):\n",
        "    # Tokenize and encode\n",
        "    inputs = tokenizer(content, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512).to(device)\n",
        "\n",
        "    # Get the output embeddings from the model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Extract the [CLS] token embedding\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "\n",
        "    # Store the embedding\n",
        "    embeddings.append(cls_embedding)\n",
        "\n",
        "# End timing for embedding extraction\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to extract embeddings: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Convert the list of embeddings into a numpy array\n",
        "embeddings = np.vstack(embeddings)\n",
        "\n",
        "# Save embeddings to a numpy file\n",
        "start_time = time.time()\n",
        "np.save(os.path.join(output_dir, \"embeddings.npy\"), embeddings)\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to save embeddings: {end_time - start_time:.2f} seconds\")\n",
        "print(f\"Embeddings saved to {os.path.join(output_dir, 'embeddings.npy')}\")\n",
        "\n",
        "# Define a constant for the number of runs\n",
        "NUM_RUNS = 10  # Change this value to set the number of runs\n",
        "\n",
        "# Function to run training and evaluation\n",
        "def run_knn_experiment(embeddings, labels, num_runs=NUM_RUNS):\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    f1_scores = []\n",
        "    total_training_time = 0\n",
        "\n",
        "    # Convert labels to a NumPy array for proper indexing\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # Initialize StratifiedKFold\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    for run in range(num_runs):\n",
        "        print(f\"Run {run + 1}\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Train and evaluate on each fold\n",
        "        for fold, (train_idx, test_idx) in enumerate(skf.split(embeddings, labels)):\n",
        "            print(f\"  Fold {fold + 1}\")\n",
        "\n",
        "            # Split into training and testing sets\n",
        "            X_train, X_test = embeddings[train_idx], embeddings[test_idx]\n",
        "            y_train, y_test = labels[train_idx], labels[test_idx]\n",
        "\n",
        "            # Example classifier: KNeighborsClassifier\n",
        "            knn = KNeighborsClassifier(n_neighbors=3)\n",
        "            knn.fit(X_train, y_train)\n",
        "\n",
        "            # Make predictions\n",
        "            y_pred = knn.predict(X_test)\n",
        "\n",
        "            # Evaluate the classifier\n",
        "            precision = precision_score(y_test, y_pred, average='binary')\n",
        "            recall = recall_score(y_test, y_pred, average='binary')\n",
        "            f1 = f1_score(y_test, y_pred, average='binary')\n",
        "\n",
        "            precision_scores.append(precision)\n",
        "            recall_scores.append(recall)\n",
        "            f1_scores.append(f1)\n",
        "\n",
        "        end_time = time.time()\n",
        "        training_time = (end_time - start_time) * 1_000_000  # Convert to microseconds\n",
        "        total_training_time += training_time\n",
        "\n",
        "    mean_precision = np.nanmean(precision_scores)\n",
        "    mean_recall = np.nanmean(recall_scores)\n",
        "    mean_f1 = np.nanmean(f1_scores)\n",
        "\n",
        "    std_precision = np.nanstd(precision_scores)\n",
        "    std_recall = np.nanstd(recall_scores)\n",
        "    std_f1 = np.nanstd(f1_scores)\n",
        "\n",
        "    print(f\"Total Training Time for {num_runs} runs: {total_training_time:.2f} microseconds\")\n",
        "    print(f\"Mean Precision: {mean_precision:.4f}, Standard Deviation: {std_precision:.4f}\")\n",
        "    print(f\"Mean Recall: {mean_recall:.4f}, Standard Deviation: {std_recall:.4f}\")\n",
        "    print(f\"Mean F1-Score: {mean_f1:.4f}, Standard Deviation: {std_f1:.4f}\")\n",
        "\n",
        "    return knn  # Return the last trained KNN model for predictions\n",
        "\n",
        "knn_model = run_knn_experiment(embeddings, labels)\n",
        "\n",
        "# --- Prediction Phase for Unseen Java Programs ---\n",
        "\n",
        "def predict_directory(unseen_folder, knn_model):\n",
        "    predictions = {}\n",
        "\n",
        "    # Process each unseen Java program in the directory\n",
        "    for program_file in os.listdir(unseen_folder):\n",
        "        file_path = os.path.join(unseen_folder, program_file)\n",
        "\n",
        "        if os.path.isfile(file_path):\n",
        "            with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "                new_program_content = f.read()\n",
        "\n",
        "            # Tokenize and encode the new program content\n",
        "            inputs = tokenizer(new_program_content, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512).to(device)\n",
        "\n",
        "            # Extract embedding\n",
        "            start_time = time.time()  # Start timing embedding extraction\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            new_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "            end_time = time.time()  # End timing embedding extraction\n",
        "\n",
        "            # Feed the embedding into the KNN model to predict\n",
        "            start_time = time.time()  # Start timing prediction\n",
        "            predicted_label = knn_model.predict(new_embedding)\n",
        "            end_time = time.time()  # End timing prediction\n",
        "\n",
        "            predictions[program_file] = {\n",
        "                \"predicted_label\": predicted_label[0],\n",
        "                \"embedding_extraction_time\": f\"{(end_time - start_time) * 1_000_000:.2f} microseconds\",\n",
        "                \"prediction_time\": f\"{(end_time - start_time) * 1_000_000:.2f} microseconds\"\n",
        "            }\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Example usage:\n",
        "unseen_java_folder = '/content/newexample'  # Replace with the folder containing unseen Java programs\n",
        "\n",
        "# Use the last KNN model trained for prediction\n",
        "predictions = predict_directory(unseen_java_folder, knn_model)\n",
        "\n",
        "# Print the predictions and their respective times\n",
        "for program_file, result in predictions.items():\n",
        "    print(f\"Program: {program_file}, Predicted Label: {result['predicted_label']}, \"\n",
        "          f\"Embedding Extraction Time: {result['embedding_extraction_time']}, \"\n",
        "          f\"Prediction Time: {result['prediction_time']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44ikhmHQOZ4V",
        "outputId": "db694169-e850-4ef4-f94e-dbb9145f9d8f"
      },
      "id": "44ikhmHQOZ4V",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Time taken to load and label programs: 0.01 seconds\n",
            "Time taken to create DataFrame and save to CSV: 0.02 seconds\n",
            "Labels and contents saved to embeddings/af3.csv\n",
            "Time taken to load DataFrame from CSV: 0.01 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Processing embeddings: 100%|| 90/90 [03:55<00:00,  2.62s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken to extract embeddings: 236.38 seconds\n",
            "Time taken to save embeddings: 0.00 seconds\n",
            "Embeddings saved to embeddings/embeddings.npy\n",
            "Run 1\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 2\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 3\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 4\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 5\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 6\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 7\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 8\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 9\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 10\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Total Training Time for 10 runs: 499723.67 microseconds\n",
            "Mean Precision: 0.7976, Standard Deviation: 0.1746\n",
            "Mean Recall: 0.8667, Standard Deviation: 0.1633\n",
            "Mean F1-Score: 0.8102, Standard Deviation: 0.1147\n",
            "Program: abstractfactory (3).java, Predicted Label: 1, Embedding Extraction Time: 1977.44 microseconds, Prediction Time: 1977.44 microseconds\n",
            "Program: nonab (63).java, Predicted Label: 0, Embedding Extraction Time: 2074.48 microseconds, Prediction Time: 2074.48 microseconds\n",
            "Program: nonab (74).java, Predicted Label: 0, Embedding Extraction Time: 1671.55 microseconds, Prediction Time: 1671.55 microseconds\n",
            "Program: abstractfactory (6).java, Predicted Label: 1, Embedding Extraction Time: 1679.18 microseconds, Prediction Time: 1679.18 microseconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Specify the directory path you want to delete\n",
        "dir_path = '/content/embeddings'\n",
        "\n",
        "# Remove the directory and its contents\n",
        "shutil.rmtree(dir_path)\n",
        "\n",
        "print(f\"Directory '{dir_path}' has been deleted.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfcoTzjHP7Vo",
        "outputId": "754e7ab2-42f9-4c2f-9ecf-eb0121f4930a"
      },
      "id": "lfcoTzjHP7Vo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory '/content/embeddings' has been deleted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Factory method, standard deviation, training time, prediction time calculation**"
      ],
      "metadata": {
        "id": "A-vAdJwAQS2y"
      },
      "id": "A-vAdJwAQS2y"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check if CUDA is available and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the path to the folder containing your Java programs\n",
        "java_programs_folder = '/content/factorymethod'  # Replace with the actual folder path\n",
        "\n",
        "# Initialize lists to store program names, labels, and contents\n",
        "program_names = []\n",
        "labels = []\n",
        "contents = []\n",
        "\n",
        "# Start timing for loading programs\n",
        "start_time = time.time()\n",
        "\n",
        "# Function to label programs as positive (1) or negative (0) based on the file name\n",
        "def label_program(file_name):\n",
        "    return 1 if \"factorymethod\" in file_name.lower() else 0\n",
        "\n",
        "# Load Java programs from the folder and classify them as positive or negative\n",
        "for program_file in os.listdir(java_programs_folder):\n",
        "    file_path = os.path.join(java_programs_folder, program_file)\n",
        "\n",
        "    # Check if the item is a file, not a directory\n",
        "    if os.path.isfile(file_path):\n",
        "        with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "            program_content = f.read()\n",
        "            program_names.append(program_file)\n",
        "            labels.append(label_program(program_file))\n",
        "            contents.append(program_content)\n",
        "\n",
        "# End timing for loading programs\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to load and label programs: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Start timing for creating DataFrame and saving to CSV\n",
        "start_time = time.time()\n",
        "\n",
        "# Create a DataFrame to store the data\n",
        "data = {'File Name': program_names, 'Label': labels, 'Content': contents}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Ensure the directory exists\n",
        "output_dir = 'embeddings'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_path = os.path.join(output_dir, 'af3.csv')  # Replace with the desired CSV file path\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to create DataFrame and save to CSV: {end_time - start_time:.2f} seconds\")\n",
        "print(f\"Labels and contents saved to {csv_path}\")\n",
        "\n",
        "# Start timing for loading DataFrame from CSV\n",
        "start_time = time.time()\n",
        "\n",
        "# Load the DataFrame from the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to load DataFrame from CSV: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Start timing for embedding extraction\n",
        "start_time = time.time()\n",
        "\n",
        "# Load pre-trained RoBERTa model and tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "model = RobertaModel.from_pretrained(\"roberta-base\").to(device)\n",
        "\n",
        "# Tokenize and encode the content using RoBERTa\n",
        "embeddings = []\n",
        "\n",
        "for content in tqdm(df['Content'], desc=\"Processing embeddings\"):\n",
        "    # Tokenize and encode\n",
        "    inputs = tokenizer(content, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512).to(device)\n",
        "\n",
        "    # Get the output embeddings from the model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Extract the [CLS] token embedding\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "\n",
        "    # Store the embedding\n",
        "    embeddings.append(cls_embedding)\n",
        "\n",
        "# End timing for embedding extraction\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to extract embeddings: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Convert the list of embeddings into a numpy array\n",
        "embeddings = np.vstack(embeddings)\n",
        "\n",
        "# Save embeddings to a numpy file\n",
        "start_time = time.time()\n",
        "np.save(os.path.join(output_dir, \"embeddings.npy\"), embeddings)\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to save embeddings: {end_time - start_time:.2f} seconds\")\n",
        "print(f\"Embeddings saved to {os.path.join(output_dir, 'embeddings.npy')}\")\n",
        "\n",
        "# Define a constant for the number of runs\n",
        "NUM_RUNS = 10  # Change this value to set the number of runs\n",
        "\n",
        "# Function to run training and evaluation\n",
        "def run_knn_experiment(embeddings, labels, num_runs=NUM_RUNS):\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "    f1_scores = []\n",
        "    total_training_time = 0\n",
        "\n",
        "    # Convert labels to a NumPy array for proper indexing\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # Initialize StratifiedKFold\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    for run in range(num_runs):\n",
        "        print(f\"Run {run + 1}\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Train and evaluate on each fold\n",
        "        for fold, (train_idx, test_idx) in enumerate(skf.split(embeddings, labels)):\n",
        "            print(f\"  Fold {fold + 1}\")\n",
        "\n",
        "            # Split into training and testing sets\n",
        "            X_train, X_test = embeddings[train_idx], embeddings[test_idx]\n",
        "            y_train, y_test = labels[train_idx], labels[test_idx]\n",
        "\n",
        "            # Example classifier: KNeighborsClassifier\n",
        "            knn = KNeighborsClassifier(n_neighbors=3)\n",
        "            knn.fit(X_train, y_train)\n",
        "\n",
        "            # Make predictions\n",
        "            y_pred = knn.predict(X_test)\n",
        "\n",
        "            # Evaluate the classifier\n",
        "            precision = precision_score(y_test, y_pred, average='binary')\n",
        "            recall = recall_score(y_test, y_pred, average='binary')\n",
        "            f1 = f1_score(y_test, y_pred, average='binary')\n",
        "\n",
        "            precision_scores.append(precision)\n",
        "            recall_scores.append(recall)\n",
        "            f1_scores.append(f1)\n",
        "\n",
        "        end_time = time.time()\n",
        "        training_time = (end_time - start_time) * 1_000_000  # Convert to microseconds\n",
        "        total_training_time += training_time\n",
        "\n",
        "    mean_precision = np.nanmean(precision_scores)\n",
        "    mean_recall = np.nanmean(recall_scores)\n",
        "    mean_f1 = np.nanmean(f1_scores)\n",
        "\n",
        "    std_precision = np.nanstd(precision_scores)\n",
        "    std_recall = np.nanstd(recall_scores)\n",
        "    std_f1 = np.nanstd(f1_scores)\n",
        "\n",
        "    print(f\"Total Training Time for {num_runs} runs: {total_training_time:.2f} microseconds\")\n",
        "    print(f\"Mean Precision: {mean_precision:.4f}, Standard Deviation: {std_precision:.4f}\")\n",
        "    print(f\"Mean Recall: {mean_recall:.4f}, Standard Deviation: {std_recall:.4f}\")\n",
        "    print(f\"Mean F1-Score: {mean_f1:.4f}, Standard Deviation: {std_f1:.4f}\")\n",
        "\n",
        "    return knn  # Return the last trained KNN model for predictions\n",
        "\n",
        "knn_model = run_knn_experiment(embeddings, labels)\n",
        "\n",
        "# --- Prediction Phase for Unseen Java Programs ---\n",
        "\n",
        "def predict_directory(unseen_folder, knn_model):\n",
        "    predictions = {}\n",
        "\n",
        "    # Process each unseen Java program in the directory\n",
        "    for program_file in os.listdir(unseen_folder):\n",
        "        file_path = os.path.join(unseen_folder, program_file)\n",
        "\n",
        "        if os.path.isfile(file_path):\n",
        "            with open(file_path, 'r', encoding='iso-8859-1') as f:\n",
        "                new_program_content = f.read()\n",
        "\n",
        "            # Tokenize and encode the new program content\n",
        "            inputs = tokenizer(new_program_content, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512).to(device)\n",
        "\n",
        "            # Extract embedding\n",
        "            start_time = time.time()  # Start timing embedding extraction\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            new_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "            end_time = time.time()  # End timing embedding extraction\n",
        "\n",
        "            # Feed the embedding into the KNN model to predict\n",
        "            start_time = time.time()  # Start timing prediction\n",
        "            predicted_label = knn_model.predict(new_embedding)\n",
        "            end_time = time.time()  # End timing prediction\n",
        "\n",
        "            predictions[program_file] = {\n",
        "                \"predicted_label\": predicted_label[0],\n",
        "                \"embedding_extraction_time\": f\"{(end_time - start_time) * 1_000_000:.2f} microseconds\",\n",
        "                \"prediction_time\": f\"{(end_time - start_time) * 1_000_000:.2f} microseconds\"\n",
        "            }\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Example usage:\n",
        "unseen_java_folder = '/content/newexample'  # Replace with the folder containing unseen Java programs\n",
        "\n",
        "# Use the last KNN model trained for prediction\n",
        "predictions = predict_directory(unseen_java_folder, knn_model)\n",
        "\n",
        "# Print the predictions and their respective times\n",
        "for program_file, result in predictions.items():\n",
        "    print(f\"Program: {program_file}, Predicted Label: {result['predicted_label']}, \"\n",
        "          f\"Embedding Extraction Time: {result['embedding_extraction_time']}, \"\n",
        "          f\"Prediction Time: {result['prediction_time']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpTgw5bCO6xJ",
        "outputId": "c3340901-de04-41f3-87a9-26d8214dd9ae"
      },
      "id": "JpTgw5bCO6xJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Time taken to load and label programs: 0.01 seconds\n",
            "Time taken to create DataFrame and save to CSV: 0.03 seconds\n",
            "Labels and contents saved to embeddings/af3.csv\n",
            "Time taken to load DataFrame from CSV: 0.03 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Processing embeddings: 100%|| 78/78 [03:40<00:00,  2.82s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken to extract embeddings: 221.08 seconds\n",
            "Time taken to save embeddings: 0.00 seconds\n",
            "Embeddings saved to embeddings/embeddings.npy\n",
            "Run 1\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 2\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 3\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 4\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 5\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 6\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 7\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 8\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 9\n",
            "  Fold 1\n",
            "  Fold 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Run 10\n",
            "  Fold 1\n",
            "  Fold 2\n",
            "  Fold 3\n",
            "  Fold 4\n",
            "  Fold 5\n",
            "Total Training Time for 10 runs: 505620.48 microseconds\n",
            "Mean Precision: 0.5667, Standard Deviation: 0.3266\n",
            "Mean Recall: 0.6333, Standard Deviation: 0.3712\n",
            "Mean F1-Score: 0.5800, Standard Deviation: 0.3124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Program: factorymethod (8).java, Predicted Label: 1, Embedding Extraction Time: 2053.26 microseconds, Prediction Time: 2053.26 microseconds\n",
            "Program: factorymethod (5).java, Predicted Label: 1, Embedding Extraction Time: 1656.06 microseconds, Prediction Time: 1656.06 microseconds\n",
            "Program: nonfm (2).java, Predicted Label: 0, Embedding Extraction Time: 1658.68 microseconds, Prediction Time: 1658.68 microseconds\n",
            "Program: nonfm (1).java, Predicted Label: 0, Embedding Extraction Time: 1659.39 microseconds, Prediction Time: 1659.39 microseconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RC2ZL-WTQsVm"
      },
      "id": "RC2ZL-WTQsVm",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a85b7716b66d4a65b86d823e96257fa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88ea5c3936df4246aa7522d724624c2d",
              "IPY_MODEL_15657c210550401ea93289a6858d7d50",
              "IPY_MODEL_a3863ad6cb3648769b30a476b2b42098"
            ],
            "layout": "IPY_MODEL_58fa25cf67084e46afb804d08eb828b6"
          }
        },
        "88ea5c3936df4246aa7522d724624c2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22fa3cbd7ed94791978f61ee89caa413",
            "placeholder": "",
            "style": "IPY_MODEL_2d3a29afa01440ba9a4ed69ba1784cf5",
            "value": "tokenizer_config.json:100%"
          }
        },
        "15657c210550401ea93289a6858d7d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4075b3d861e444d1a00b62574ad7b3ac",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_397c3552e71b47628ff28ca7cd9e690d",
            "value": 25
          }
        },
        "a3863ad6cb3648769b30a476b2b42098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33c89bdd0a3542b99ea51e7bcae06e56",
            "placeholder": "",
            "style": "IPY_MODEL_9d9b4d7302094f4083ba1ed5b0e7d237",
            "value": "25.0/25.0[00:00&lt;00:00,386B/s]"
          }
        },
        "58fa25cf67084e46afb804d08eb828b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22fa3cbd7ed94791978f61ee89caa413": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d3a29afa01440ba9a4ed69ba1784cf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4075b3d861e444d1a00b62574ad7b3ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "397c3552e71b47628ff28ca7cd9e690d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33c89bdd0a3542b99ea51e7bcae06e56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d9b4d7302094f4083ba1ed5b0e7d237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f580602a050b41f98ea604d56790584d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5f8c596111a401d87fbc934142e7dae",
              "IPY_MODEL_763251a457e44e0eaf033539d64a6da2",
              "IPY_MODEL_75d57b7721cb4fd584bec2509fa66714"
            ],
            "layout": "IPY_MODEL_d4a1ed7708714d7594b376f20428a861"
          }
        },
        "c5f8c596111a401d87fbc934142e7dae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6841b400af2f4ef281547b1060816087",
            "placeholder": "",
            "style": "IPY_MODEL_51f5f873e1da44f29a21387d2d1d992a",
            "value": "vocab.json:100%"
          }
        },
        "763251a457e44e0eaf033539d64a6da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_850fc7c97eac46e6b3224d0fda01895f",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec2ae4c9f738443ab4838c62e25f2963",
            "value": 898823
          }
        },
        "75d57b7721cb4fd584bec2509fa66714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_500cf334ce8a4eabb66b317be0e397b5",
            "placeholder": "",
            "style": "IPY_MODEL_d1990342b2ad4b9c87526d8bff71e5c8",
            "value": "899k/899k[00:00&lt;00:00,3.18MB/s]"
          }
        },
        "d4a1ed7708714d7594b376f20428a861": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6841b400af2f4ef281547b1060816087": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51f5f873e1da44f29a21387d2d1d992a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "850fc7c97eac46e6b3224d0fda01895f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec2ae4c9f738443ab4838c62e25f2963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "500cf334ce8a4eabb66b317be0e397b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1990342b2ad4b9c87526d8bff71e5c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e0a2dd859c34363b486cfcc494c2bcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a320118280d6442b9f32c1edb06b0849",
              "IPY_MODEL_1b9a255e89b34ec38f4335158c206063",
              "IPY_MODEL_cde7a03be37e4470b0544d2b5bdec0e9"
            ],
            "layout": "IPY_MODEL_80b212e293d441a2b1d2f8afefcc14e7"
          }
        },
        "a320118280d6442b9f32c1edb06b0849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c7c24cf204a42f9a21eb0ee6754c56a",
            "placeholder": "",
            "style": "IPY_MODEL_45d56e2331b64f529870cc9505be108e",
            "value": "merges.txt:100%"
          }
        },
        "1b9a255e89b34ec38f4335158c206063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22f5b4cbda6049bfb4868b58be78469a",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_abbb1665b08445e9a0f049442e10eba1",
            "value": 456318
          }
        },
        "cde7a03be37e4470b0544d2b5bdec0e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_107c51f3cb5f440e96cdb8af45d6c420",
            "placeholder": "",
            "style": "IPY_MODEL_ad769370d10f43fab81603faee875dcd",
            "value": "456k/456k[00:00&lt;00:00,3.82MB/s]"
          }
        },
        "80b212e293d441a2b1d2f8afefcc14e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c7c24cf204a42f9a21eb0ee6754c56a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45d56e2331b64f529870cc9505be108e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22f5b4cbda6049bfb4868b58be78469a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abbb1665b08445e9a0f049442e10eba1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "107c51f3cb5f440e96cdb8af45d6c420": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad769370d10f43fab81603faee875dcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7266c21ee9e4c6b9fd369b6c1555260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c53095a4c9734d8d9c1c0a7181f24c3c",
              "IPY_MODEL_9b53868e165d4018a582c92c47e8e75e",
              "IPY_MODEL_0a7ea26a59db48818fa9d90b642690ae"
            ],
            "layout": "IPY_MODEL_c5402d0294d74579a82cb57dc7bc7a19"
          }
        },
        "c53095a4c9734d8d9c1c0a7181f24c3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ed3ad4e0e124e4080008fc1683ccd95",
            "placeholder": "",
            "style": "IPY_MODEL_52f34ebb7ec44fd6a230ea22b34654e7",
            "value": "tokenizer.json:100%"
          }
        },
        "9b53868e165d4018a582c92c47e8e75e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c73f62744f724ffdbed9e7c7552a5da5",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e75ec5b66f44bf7bd7a073ee177cb03",
            "value": 1355863
          }
        },
        "0a7ea26a59db48818fa9d90b642690ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db6afd6ac9ea4cc6890c95cffd991378",
            "placeholder": "",
            "style": "IPY_MODEL_ae5b57e3b91246fab565701d1ffc1295",
            "value": "1.36M/1.36M[00:00&lt;00:00,5.72MB/s]"
          }
        },
        "c5402d0294d74579a82cb57dc7bc7a19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ed3ad4e0e124e4080008fc1683ccd95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52f34ebb7ec44fd6a230ea22b34654e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c73f62744f724ffdbed9e7c7552a5da5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e75ec5b66f44bf7bd7a073ee177cb03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db6afd6ac9ea4cc6890c95cffd991378": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae5b57e3b91246fab565701d1ffc1295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54748ae79e5243218e2bcd2c8da5a124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91734fe66f1e4c7185b5d74f3111b257",
              "IPY_MODEL_55ed1da451c04c82930492b62329e8f2",
              "IPY_MODEL_f6578d66d83241a3bc755c5f3eb37a07"
            ],
            "layout": "IPY_MODEL_858d70cb3328472e907370c491ac7aae"
          }
        },
        "91734fe66f1e4c7185b5d74f3111b257": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42958384a0be4a4582bdbad7ca0ef6e9",
            "placeholder": "",
            "style": "IPY_MODEL_5ec9035bbc37424aa74be325533a7d6d",
            "value": "config.json:100%"
          }
        },
        "55ed1da451c04c82930492b62329e8f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e53d6ee5bae447fc928ce371aa3845d9",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1c74c7b91e6461a91378beefb35b60f",
            "value": 481
          }
        },
        "f6578d66d83241a3bc755c5f3eb37a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38552133339d4c51b74ef42785c4ae35",
            "placeholder": "",
            "style": "IPY_MODEL_5403d9d6accf4398b58bf370e99bfc82",
            "value": "481/481[00:00&lt;00:00,12.3kB/s]"
          }
        },
        "858d70cb3328472e907370c491ac7aae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42958384a0be4a4582bdbad7ca0ef6e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ec9035bbc37424aa74be325533a7d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e53d6ee5bae447fc928ce371aa3845d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1c74c7b91e6461a91378beefb35b60f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38552133339d4c51b74ef42785c4ae35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5403d9d6accf4398b58bf370e99bfc82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bbaa53a58a6a44bbad5e663504848272": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01e899baba324647bc2c415d5f6502b2",
              "IPY_MODEL_a5ec5c41cfc2493ca637a6523504f95e",
              "IPY_MODEL_1a3f5bae1d06428b87497b4b14bca389"
            ],
            "layout": "IPY_MODEL_d48dc5760cba4851845c243248eb0987"
          }
        },
        "01e899baba324647bc2c415d5f6502b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f6fef2d2a0944b193a16928ea51d17d",
            "placeholder": "",
            "style": "IPY_MODEL_29809cea2d69482289f46f05db34716b",
            "value": "model.safetensors:100%"
          }
        },
        "a5ec5c41cfc2493ca637a6523504f95e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_857efaa1713d448db7eaabeecc323954",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe1473f11d944ed48bb1cebc9d62f54f",
            "value": 498818054
          }
        },
        "1a3f5bae1d06428b87497b4b14bca389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09e171af19574828bf0a0a33d76b01cc",
            "placeholder": "",
            "style": "IPY_MODEL_d586aea9022744f7b0547dee768f4ab8",
            "value": "499M/499M[00:07&lt;00:00,98.9MB/s]"
          }
        },
        "d48dc5760cba4851845c243248eb0987": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f6fef2d2a0944b193a16928ea51d17d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29809cea2d69482289f46f05db34716b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "857efaa1713d448db7eaabeecc323954": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe1473f11d944ed48bb1cebc9d62f54f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09e171af19574828bf0a0a33d76b01cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d586aea9022744f7b0547dee768f4ab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9609b2b9b0ca4800918a4ade70304969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc5e86b17f08466a815c0139f7345dbc",
              "IPY_MODEL_47349fcb836241f492327b7bab681483",
              "IPY_MODEL_77920beb4cc84236af6a25fa46ee352e"
            ],
            "layout": "IPY_MODEL_566cd02134a14ea7968f9324afad89aa"
          }
        },
        "fc5e86b17f08466a815c0139f7345dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5384df90b2e34a55a175fa4507746d13",
            "placeholder": "",
            "style": "IPY_MODEL_861bacae6b12433a8497ed7a6242b833",
            "value": "tokenizer_config.json:100%"
          }
        },
        "47349fcb836241f492327b7bab681483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e1d09770b1347e586f8c16427f1c659",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b2866474cfa4e0faca4c5f302fb796f",
            "value": 25
          }
        },
        "77920beb4cc84236af6a25fa46ee352e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f38133e729e34c8e825ac2b868142f8a",
            "placeholder": "",
            "style": "IPY_MODEL_23810ddec04942c6ab95715d028050fd",
            "value": "25.0/25.0[00:00&lt;00:00,588B/s]"
          }
        },
        "566cd02134a14ea7968f9324afad89aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5384df90b2e34a55a175fa4507746d13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "861bacae6b12433a8497ed7a6242b833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e1d09770b1347e586f8c16427f1c659": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b2866474cfa4e0faca4c5f302fb796f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f38133e729e34c8e825ac2b868142f8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23810ddec04942c6ab95715d028050fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cc0445716284fe49e04db587dfb4501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f23e8e102ce341a385b06f688a699ba2",
              "IPY_MODEL_d89f64ec82ae4d81ab27bec677e227a9",
              "IPY_MODEL_06a3937dc4464433be2e7051840f73e2"
            ],
            "layout": "IPY_MODEL_882351e7c8cf419bbf11e9407124f76d"
          }
        },
        "f23e8e102ce341a385b06f688a699ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1c35ab62b474d0694ff33f2c817762a",
            "placeholder": "",
            "style": "IPY_MODEL_a99d1f820c2f4c35b067e1b510e900d1",
            "value": "vocab.json:100%"
          }
        },
        "d89f64ec82ae4d81ab27bec677e227a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b27bb4c432346fe88e1404f6c90f913",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bfed0126eec942789abbe2f60b31d093",
            "value": 898823
          }
        },
        "06a3937dc4464433be2e7051840f73e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea8833563fbc4b4193cb31d20763afb5",
            "placeholder": "",
            "style": "IPY_MODEL_18fa4ca92deb4435a33561c9a05091ef",
            "value": "899k/899k[00:00&lt;00:00,9.24MB/s]"
          }
        },
        "882351e7c8cf419bbf11e9407124f76d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1c35ab62b474d0694ff33f2c817762a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a99d1f820c2f4c35b067e1b510e900d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b27bb4c432346fe88e1404f6c90f913": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfed0126eec942789abbe2f60b31d093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea8833563fbc4b4193cb31d20763afb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18fa4ca92deb4435a33561c9a05091ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43817f19ca384fe79b7d54dfb958444f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39f59c32491047a9805318137e13e570",
              "IPY_MODEL_4a6b5e492bf6457b9e06d8a84e85e9e6",
              "IPY_MODEL_1f6ed3d8931d4666b25db1b7985f351e"
            ],
            "layout": "IPY_MODEL_0044e7c17ecd4c6f9d2b5e436a00441e"
          }
        },
        "39f59c32491047a9805318137e13e570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74d543817a2e477eaed95b95c13e52cc",
            "placeholder": "",
            "style": "IPY_MODEL_bf9d00d1f9664241b800ed7a9aef8a7b",
            "value": "merges.txt:100%"
          }
        },
        "4a6b5e492bf6457b9e06d8a84e85e9e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_468d4baed5fd47399829c6c5514b584b",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5802b4b5a174597b8e571f7b5e8929e",
            "value": 456318
          }
        },
        "1f6ed3d8931d4666b25db1b7985f351e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8757b6166a94b53a0c9d65337b6a853",
            "placeholder": "",
            "style": "IPY_MODEL_0b0fc5773fab47de93f9a4ea83769bd1",
            "value": "456k/456k[00:00&lt;00:00,17.8MB/s]"
          }
        },
        "0044e7c17ecd4c6f9d2b5e436a00441e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74d543817a2e477eaed95b95c13e52cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf9d00d1f9664241b800ed7a9aef8a7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "468d4baed5fd47399829c6c5514b584b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5802b4b5a174597b8e571f7b5e8929e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8757b6166a94b53a0c9d65337b6a853": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b0fc5773fab47de93f9a4ea83769bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31dfdb4d53e04d8095a7f7f4f960942e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75d90599291f4389b4e366670502ca36",
              "IPY_MODEL_a9f28c3aaaee43c49bf055741844922f",
              "IPY_MODEL_e57424b77c38464dbac0439baac51230"
            ],
            "layout": "IPY_MODEL_1db3901249c840b09d84e2566a201f38"
          }
        },
        "75d90599291f4389b4e366670502ca36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cbb2859a0aa4340be21c42bf7a7cae7",
            "placeholder": "",
            "style": "IPY_MODEL_05751dc82dfa49cab8713e7fb1fe3da3",
            "value": "tokenizer.json:100%"
          }
        },
        "a9f28c3aaaee43c49bf055741844922f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdcd84e81af94363b997e007846f2b38",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49135cef2d914e9fb16cccd41c397d74",
            "value": 1355863
          }
        },
        "e57424b77c38464dbac0439baac51230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e24033a4159c42d886ac801ca9329f7c",
            "placeholder": "",
            "style": "IPY_MODEL_07dc4bc453cb4faca5b53e7c9d24abd3",
            "value": "1.36M/1.36M[00:00&lt;00:00,16.6MB/s]"
          }
        },
        "1db3901249c840b09d84e2566a201f38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cbb2859a0aa4340be21c42bf7a7cae7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05751dc82dfa49cab8713e7fb1fe3da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdcd84e81af94363b997e007846f2b38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49135cef2d914e9fb16cccd41c397d74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e24033a4159c42d886ac801ca9329f7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07dc4bc453cb4faca5b53e7c9d24abd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed2e4d7ca46d43c3b6bcae7ec3e22168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30de4a2fee08415eabdfaece97901109",
              "IPY_MODEL_612abc0633004e249f7332e41d13cfe4",
              "IPY_MODEL_2060918d7f964020b663f247017f6c2c"
            ],
            "layout": "IPY_MODEL_d38c6fa3b47a42fd9cf90476047a49e5"
          }
        },
        "30de4a2fee08415eabdfaece97901109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b79cc901b7d143adb1b112e2ec54317d",
            "placeholder": "",
            "style": "IPY_MODEL_fef74925a4f74167b495b93620114e0a",
            "value": "config.json:100%"
          }
        },
        "612abc0633004e249f7332e41d13cfe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b898c4e3404d4ccdb2bf6fa3b6daaea8",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f18f8c5a85e4e3e9483ea46af371a41",
            "value": 481
          }
        },
        "2060918d7f964020b663f247017f6c2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_effe26a683de41a2bad6d427ee011ec9",
            "placeholder": "",
            "style": "IPY_MODEL_f98d25ff23204f99824b2c4e1d95114b",
            "value": "481/481[00:00&lt;00:00,14.0kB/s]"
          }
        },
        "d38c6fa3b47a42fd9cf90476047a49e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b79cc901b7d143adb1b112e2ec54317d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fef74925a4f74167b495b93620114e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b898c4e3404d4ccdb2bf6fa3b6daaea8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f18f8c5a85e4e3e9483ea46af371a41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "effe26a683de41a2bad6d427ee011ec9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f98d25ff23204f99824b2c4e1d95114b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "948fcaccf5d3436daedba0c1d8ebc3e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5679ca49a6704ef5a613247e748b88c5",
              "IPY_MODEL_ed29979a8b494d7d81b8e48e6c869e12",
              "IPY_MODEL_d414e5efa2444edda8d971a95e9ea678"
            ],
            "layout": "IPY_MODEL_880274dd6d7943edbaf5ffc8315fcd67"
          }
        },
        "5679ca49a6704ef5a613247e748b88c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9e5bba6f36440c0a877c6da3dc4176a",
            "placeholder": "",
            "style": "IPY_MODEL_05a90fa1b49f4ab3a3580b7620196e56",
            "value": "model.safetensors:100%"
          }
        },
        "ed29979a8b494d7d81b8e48e6c869e12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb16f519c82543a9a32bb060474613a0",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0adb1fad0a74f3cb94700cc6d78c970",
            "value": 498818054
          }
        },
        "d414e5efa2444edda8d971a95e9ea678": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01d51f1be8944fa1a8bb55cb0baead86",
            "placeholder": "",
            "style": "IPY_MODEL_fa04f4332ae044f893342237cdd17a5e",
            "value": "499M/499M[00:05&lt;00:00,127MB/s]"
          }
        },
        "880274dd6d7943edbaf5ffc8315fcd67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9e5bba6f36440c0a877c6da3dc4176a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05a90fa1b49f4ab3a3580b7620196e56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb16f519c82543a9a32bb060474613a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0adb1fad0a74f3cb94700cc6d78c970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "01d51f1be8944fa1a8bb55cb0baead86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa04f4332ae044f893342237cdd17a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15c78eec87a34a1cb3c06bfcfb755e02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_387759cea97d43d5bd5529692fe49d88",
              "IPY_MODEL_8abe878b9ff44e879ec5281935eef3e7",
              "IPY_MODEL_403cc3dd74ff4b5bb24ab1024473927a"
            ],
            "layout": "IPY_MODEL_fba383d6ca2145fda9a7243110b68f07"
          }
        },
        "387759cea97d43d5bd5529692fe49d88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0017f068077144fb9d1f69cd09a9b98b",
            "placeholder": "",
            "style": "IPY_MODEL_0af3104b74274144881eb0251f87e172",
            "value": "tokenizer_config.json:100%"
          }
        },
        "8abe878b9ff44e879ec5281935eef3e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42b2907600d643c185dad8d490d95d52",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a5b811ff85141d19fb67366cd1b8219",
            "value": 25
          }
        },
        "403cc3dd74ff4b5bb24ab1024473927a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6937d2694784d8a89739d8d9edc2852",
            "placeholder": "",
            "style": "IPY_MODEL_298e37c42d1545a08ed3f1e1592f309e",
            "value": "25.0/25.0[00:00&lt;00:00,1.75kB/s]"
          }
        },
        "fba383d6ca2145fda9a7243110b68f07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0017f068077144fb9d1f69cd09a9b98b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0af3104b74274144881eb0251f87e172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42b2907600d643c185dad8d490d95d52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a5b811ff85141d19fb67366cd1b8219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6937d2694784d8a89739d8d9edc2852": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "298e37c42d1545a08ed3f1e1592f309e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "254aceeaa3ed40dbac3a5bd4d8412a0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da327b84daa5498c9f61efb6047cd4ae",
              "IPY_MODEL_cd00e94db6f140c78a24b38b39e861e5",
              "IPY_MODEL_060f3e759c324b8f85ff6b302a8f3fb7"
            ],
            "layout": "IPY_MODEL_c2e8a4e3c4ae45f99d234d92407f331e"
          }
        },
        "da327b84daa5498c9f61efb6047cd4ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c71eee0cb54b4a439de9ed0294455486",
            "placeholder": "",
            "style": "IPY_MODEL_a8a1e005fc2e4150afd87ad5c1c39b6d",
            "value": "vocab.json:100%"
          }
        },
        "cd00e94db6f140c78a24b38b39e861e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c656a4243a64a5782fd13edc7d0d9bb",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5832f3e24784275a9eb8debed1be72b",
            "value": 898823
          }
        },
        "060f3e759c324b8f85ff6b302a8f3fb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_981fe0989d884df4819cb5c52857bc20",
            "placeholder": "",
            "style": "IPY_MODEL_9ba6432b211c4a17a19372b2161fe653",
            "value": "899k/899k[00:00&lt;00:00,3.52MB/s]"
          }
        },
        "c2e8a4e3c4ae45f99d234d92407f331e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c71eee0cb54b4a439de9ed0294455486": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8a1e005fc2e4150afd87ad5c1c39b6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c656a4243a64a5782fd13edc7d0d9bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5832f3e24784275a9eb8debed1be72b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "981fe0989d884df4819cb5c52857bc20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ba6432b211c4a17a19372b2161fe653": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5672482c45064b3fb324bb129339a180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c09436984cb04e26bcaa9e6cd77d5c00",
              "IPY_MODEL_02e1572dca61425286225c653d4cfb3c",
              "IPY_MODEL_562b23826c49421fbaaf9153dc293209"
            ],
            "layout": "IPY_MODEL_0545e24b5caf4ef4a901925c27b88359"
          }
        },
        "c09436984cb04e26bcaa9e6cd77d5c00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdece54bbb8946c8a5e1eed24899bbb6",
            "placeholder": "",
            "style": "IPY_MODEL_e916d7dbe1ae461396fc57ab376ba560",
            "value": "merges.txt:100%"
          }
        },
        "02e1572dca61425286225c653d4cfb3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e2190a618794287a6c004b4c723cec9",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e33382ec8a94a6f8f282098f01f41a3",
            "value": 456318
          }
        },
        "562b23826c49421fbaaf9153dc293209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ce5ca95422741979063ab572fc03b66",
            "placeholder": "",
            "style": "IPY_MODEL_f0b7a6e77d31420f86eef8ffb3ede176",
            "value": "456k/456k[00:00&lt;00:00,2.53MB/s]"
          }
        },
        "0545e24b5caf4ef4a901925c27b88359": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdece54bbb8946c8a5e1eed24899bbb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e916d7dbe1ae461396fc57ab376ba560": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e2190a618794287a6c004b4c723cec9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e33382ec8a94a6f8f282098f01f41a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ce5ca95422741979063ab572fc03b66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0b7a6e77d31420f86eef8ffb3ede176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdda8045be3246699ac525ca22a2a38a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08a0dd62b5464943aad8012d68736e69",
              "IPY_MODEL_ef7698c7b1f64d908be8d3716c5fee18",
              "IPY_MODEL_e11031cff8cd480aa13f8d9b36e83ba2"
            ],
            "layout": "IPY_MODEL_95725bbdb3d54e03ab0d27eae01c6f61"
          }
        },
        "08a0dd62b5464943aad8012d68736e69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bd0d6f7032a43889a9b974c4ea833fd",
            "placeholder": "",
            "style": "IPY_MODEL_6acc789aa741442a9153e539f6cfc0c1",
            "value": "tokenizer.json:100%"
          }
        },
        "ef7698c7b1f64d908be8d3716c5fee18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80e5df3436214910a8db440577a8d92a",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e91b4ac9d6c54fe496835359d1a9ab3f",
            "value": 1355863
          }
        },
        "e11031cff8cd480aa13f8d9b36e83ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61ff589644b6455cbc54445a6c4d7e11",
            "placeholder": "",
            "style": "IPY_MODEL_308745efbfb04b28a95027e3860d250b",
            "value": "1.36M/1.36M[00:00&lt;00:00,5.44MB/s]"
          }
        },
        "95725bbdb3d54e03ab0d27eae01c6f61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bd0d6f7032a43889a9b974c4ea833fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6acc789aa741442a9153e539f6cfc0c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80e5df3436214910a8db440577a8d92a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e91b4ac9d6c54fe496835359d1a9ab3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "61ff589644b6455cbc54445a6c4d7e11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "308745efbfb04b28a95027e3860d250b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fbffb70f67945d284bc49c3b03a8a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62704ad502a740bca4fd8cca07d667f5",
              "IPY_MODEL_5b730bf7f8c845be995c12e134f3c0b9",
              "IPY_MODEL_cc9239924cee44c1bba6edc8c88a1101"
            ],
            "layout": "IPY_MODEL_3cf6f0de004a404c92cbc41747626e3f"
          }
        },
        "62704ad502a740bca4fd8cca07d667f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55d111af87a740f98506cb02a030c03d",
            "placeholder": "",
            "style": "IPY_MODEL_1849644b3b48450b88a4cf8b4baf9f63",
            "value": "config.json:100%"
          }
        },
        "5b730bf7f8c845be995c12e134f3c0b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2644e1e2a7134574b4057ec3ffe1d9af",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba5b4a618fef43d4adb0c9144d0fb5cb",
            "value": 481
          }
        },
        "cc9239924cee44c1bba6edc8c88a1101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ad03329dfa342b2b079c78b88fd5f07",
            "placeholder": "",
            "style": "IPY_MODEL_d1f7b136214a4357ae3b38af5bf37ad8",
            "value": "481/481[00:00&lt;00:00,23.0kB/s]"
          }
        },
        "3cf6f0de004a404c92cbc41747626e3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55d111af87a740f98506cb02a030c03d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1849644b3b48450b88a4cf8b4baf9f63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2644e1e2a7134574b4057ec3ffe1d9af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba5b4a618fef43d4adb0c9144d0fb5cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ad03329dfa342b2b079c78b88fd5f07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1f7b136214a4357ae3b38af5bf37ad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd2a0b4a8fbe4363a6df1d06b4182d99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6cece6a126b14946bb79c839d6e21d22",
              "IPY_MODEL_95ed485fdb1f49aa8e37e888d2f87b66",
              "IPY_MODEL_b7ae8fce88c34c5a8be71b8a48556d9c"
            ],
            "layout": "IPY_MODEL_f156624af620426d92102b5cfb19934f"
          }
        },
        "6cece6a126b14946bb79c839d6e21d22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ebcd1fba3724fa5b4b18c053fef1ad2",
            "placeholder": "",
            "style": "IPY_MODEL_2f189d21a81a4b20999d80e3c5919cb1",
            "value": "model.safetensors:100%"
          }
        },
        "95ed485fdb1f49aa8e37e888d2f87b66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a2d824cf9cd4b04b2db41eb91c6b381",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1ef8cf97bda4a16a7fe49f29d26a745",
            "value": 498818054
          }
        },
        "b7ae8fce88c34c5a8be71b8a48556d9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30bf26fcd91946b582613849d1bbe60b",
            "placeholder": "",
            "style": "IPY_MODEL_3b71bc9e22974ec291e716c049227eb7",
            "value": "499M/499M[00:06&lt;00:00,153MB/s]"
          }
        },
        "f156624af620426d92102b5cfb19934f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ebcd1fba3724fa5b4b18c053fef1ad2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f189d21a81a4b20999d80e3c5919cb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a2d824cf9cd4b04b2db41eb91c6b381": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1ef8cf97bda4a16a7fe49f29d26a745": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30bf26fcd91946b582613849d1bbe60b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b71bc9e22974ec291e716c049227eb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}