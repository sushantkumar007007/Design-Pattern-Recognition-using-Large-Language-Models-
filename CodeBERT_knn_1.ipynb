{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "904b50dd-9152-4385-9f91-832a1a65be0e",
      "metadata": {
        "id": "904b50dd-9152-4385-9f91-832a1a65be0e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"singleton\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"singleton\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize an array to store predicted labels\n",
        "predicted_labels = []\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels.append(predicted_label)\n",
        "\n",
        "# Convert predicted_labels to NumPy array for further analysis\n",
        "predicted_labels = np.array(predicted_labels)\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3daf9e57-7d27-4171-a637-4e43f44d85e1",
      "metadata": {
        "id": "3daf9e57-7d27-4171-a637-4e43f44d85e1",
        "outputId": "468a8d7c-159a-4a71-b14b-d92cd0034138"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nons (54).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (25).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (25).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (18).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (19).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (55).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (34).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (24).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (68).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (9).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (33).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (53).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (35).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (16).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (22).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (47).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (60).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (46).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (5).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (19).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (65).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (52).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (28).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.78\n",
            "Recall: 0.75\n",
            "F1 Score: 0.73\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"singleton\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"singleton\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e0f7908-0eee-4b84-9fc1-5b42710c547e",
      "metadata": {
        "id": "5e0f7908-0eee-4b84-9fc1-5b42710c547e"
      },
      "outputs": [],
      "source": [
        "Singleton with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "407b036b-84f6-49ea-a291-6dddac6b9bd4",
      "metadata": {
        "id": "407b036b-84f6-49ea-a291-6dddac6b9bd4",
        "outputId": "1be2eb22-161b-423f-e0b6-8b47ee021eb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nons (54).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (25).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (25).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (18).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (19).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (55).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (34).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (24).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (68).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (9).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (33).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (53).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (35).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (16).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (22).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (47).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (60).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (46).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (5).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (19).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (65).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (52).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (28).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.78\n",
            "Recall: 0.75\n",
            "F1 Score: 0.73\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"singleton\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"singleton\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7df516d-6a9a-4043-a1f1-3607601969e9",
      "metadata": {
        "id": "b7df516d-6a9a-4043-a1f1-3607601969e9"
      },
      "outputs": [],
      "source": [
        "Singleton with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdbd23bd-c00c-4152-b3f3-a1e0b9dfe0af",
      "metadata": {
        "id": "bdbd23bd-c00c-4152-b3f3-a1e0b9dfe0af",
        "outputId": "8ecf87ae-d0ec-4307-bd12-37c2df8e70ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nons (50).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (25).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (18).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (4).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (44).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (38).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (41).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (23).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (11).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (2).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (48).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (63).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (40).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (37).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (22).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (51).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (32).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (56).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (62).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (64).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (19).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (2).java, Actual Label: 1, Predicted Label: 1\n",
            "\n",
            "Precision: 0.75\n",
            "Recall: 0.74\n",
            "F1 Score: 0.75\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"singleton\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"singleton\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd90482f-d0ce-4c18-a515-c3e972078c3d",
      "metadata": {
        "id": "dd90482f-d0ce-4c18-a515-c3e972078c3d"
      },
      "outputs": [],
      "source": [
        "Singleton with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e077534-f98e-4869-9d70-88ded1e88973",
      "metadata": {
        "id": "3e077534-f98e-4869-9d70-88ded1e88973",
        "outputId": "7626c7f9-b55a-4e86-fe0e-509fedd4641b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nons (54).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (25).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (18).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (19).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (34).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (9).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (33).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (53).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (16).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (22).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (60).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (46).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (5).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (19).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (28).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.76\n",
            "Recall: 0.71\n",
            "F1 Score: 0.71\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"singleton\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"singleton\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7615078-d8c4-48af-9934-0af845efca16",
      "metadata": {
        "id": "f7615078-d8c4-48af-9934-0af845efca16",
        "outputId": "d37c1826-f769-4a44-9dfd-09ea1742bd44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nons (54).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (25).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (27).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (18).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (19).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (34).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (9).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (53).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (16).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (22).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (60).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (46).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (5).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (19).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (28).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.69\n",
            "Recall: 0.65\n",
            "F1 Score: 0.65\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"singleton\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"singleton\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3fd05c9-dc1c-41c7-aad9-432fcd9bbca1",
      "metadata": {
        "id": "c3fd05c9-dc1c-41c7-aad9-432fcd9bbca1"
      },
      "outputs": [],
      "source": [
        "Builder with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37d5eb4d-3dd8-496b-afa1-7dceec1acdc6",
      "metadata": {
        "id": "37d5eb4d-3dd8-496b-afa1-7dceec1acdc6",
        "outputId": "107184cd-3023-4047-eb89-484d2fa14e1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonb (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (41).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (110).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (85).java, Actual Label: 0, Predicted Label: 1\n",
            "File: builder (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (92).java, Actual Label: 0, Predicted Label: 1\n",
            "File: builder (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (93).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (108).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonb (131).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonb (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (24).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.79\n",
            "Recall: 0.77\n",
            "F1 Score: 0.77\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"builder\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"builder\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb9f2d28-d993-4409-ae7b-f097d6688457",
      "metadata": {
        "id": "cb9f2d28-d993-4409-ae7b-f097d6688457"
      },
      "outputs": [],
      "source": [
        "#Builder with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d9dea7c-1570-48c1-8575-28c11a4da1c2",
      "metadata": {
        "id": "9d9dea7c-1570-48c1-8575-28c11a4da1c2",
        "outputId": "42fe9cc2-022c-4317-e077-e7bd28f27bb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonb (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (5).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (110).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (119).java, Actual Label: 0, Predicted Label: 1\n",
            "File: builder (8).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (93).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (108).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonb (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (7).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.67\n",
            "Recall: 0.67\n",
            "F1 Score: 0.65\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"builder\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"builder\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae3fff63-6ba6-4da4-b17f-13aac52d8d5c",
      "metadata": {
        "id": "ae3fff63-6ba6-4da4-b17f-13aac52d8d5c"
      },
      "outputs": [],
      "source": [
        "#Builder with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f54fb60-8f59-4d97-b879-3d26b6b49bb1",
      "metadata": {
        "id": "4f54fb60-8f59-4d97-b879-3d26b6b49bb1",
        "outputId": "822e473f-d2f6-4033-d519-469c0ef95e93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: builder (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (89).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (49).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (36).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (126).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (44).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (120).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (69).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (129).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (114).java, Actual Label: 0, Predicted Label: 1\n",
            "File: builder (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (33).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.90\n",
            "Recall: 0.90\n",
            "F1 Score: 0.90\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"builder\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"builder\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a351f8ed-ef7f-4345-98eb-7fb254c86c1a",
      "metadata": {
        "id": "a351f8ed-ef7f-4345-98eb-7fb254c86c1a"
      },
      "outputs": [],
      "source": [
        "#Builder with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d17ee28d-d16b-4533-b912-b568933fb86c",
      "metadata": {
        "id": "d17ee28d-d16b-4533-b912-b568933fb86c",
        "outputId": "e3a3d560-14cb-405b-e7ce-5e315b6cc6a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonb (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (5).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (110).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (92).java, Actual Label: 0, Predicted Label: 1\n",
            "File: builder (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (119).java, Actual Label: 0, Predicted Label: 1\n",
            "File: builder (8).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (93).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (108).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonb (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (7).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.63\n",
            "Recall: 0.64\n",
            "F1 Score: 0.63\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"builder\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"builder\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dacb2a99-27d0-40aa-a8f6-3b442b3fb092",
      "metadata": {
        "id": "dacb2a99-27d0-40aa-a8f6-3b442b3fb092"
      },
      "outputs": [],
      "source": [
        "#Builder with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75a20231-7226-4078-bb90-a80384fd282f",
      "metadata": {
        "id": "75a20231-7226-4078-bb90-a80384fd282f",
        "outputId": "371fec3a-e482-4503-c5a4-026e10242d0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: builder (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (50).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (36).java, Actual Label: 0, Predicted Label: 1\n",
            "File: builder (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (87).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (29).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (123).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (129).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (114).java, Actual Label: 0, Predicted Label: 1\n",
            "File: builder (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (62).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.79\n",
            "Recall: 0.79\n",
            "F1 Score: 0.79\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"builder\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"builder\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c06d5cc9-8d88-462d-8203-7d21f6ace3f7",
      "metadata": {
        "id": "c06d5cc9-8d88-462d-8203-7d21f6ace3f7"
      },
      "outputs": [],
      "source": [
        "#abstract factory with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0b5c718-ba8b-4532-bb58-393d619e79fe",
      "metadata": {
        "id": "d0b5c718-ba8b-4532-bb58-393d619e79fe",
        "outputId": "7f0eb9dc-3a0d-4b17-da75-0d4d5a193170"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonfm (34).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (37).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (13).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonfm (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (16).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (49).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (5).java, Actual Label: 1, Predicted Label: 0\n",
            "File: abstractfactory (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: abstractfactory (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (15).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (52).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (6).java, Actual Label: 1, Predicted Label: 1\n",
            "\n",
            "Precision: 0.70\n",
            "Recall: 0.70\n",
            "F1 Score: 0.70\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"abstractfactory\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"abstractfactory\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db7804ed-0c50-4fff-adc1-169cb11817b1",
      "metadata": {
        "id": "db7804ed-0c50-4fff-adc1-169cb11817b1"
      },
      "outputs": [],
      "source": [
        "#abstract factory with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f76c954-e0f0-4ece-8152-37a4a7d666b9",
      "metadata": {
        "id": "1f76c954-e0f0-4ece-8152-37a4a7d666b9",
        "outputId": "59f23179-75db-4ec1-cdef-65782bdea7b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonab (22).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (19).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (70).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: abstractfactory (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (14).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (36).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (42).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (32).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (38).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (4).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (73).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (43).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (54).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonab (64).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (84).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (47).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (6).java, Actual Label: 1, Predicted Label: 1\n",
            "\n",
            "Precision: 0.83\n",
            "Recall: 0.83\n",
            "F1 Score: 0.83\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"abstractfactory\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"abstractfactory\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0114a3a-3add-454b-a978-2c9ea8972070",
      "metadata": {
        "id": "d0114a3a-3add-454b-a978-2c9ea8972070"
      },
      "outputs": [],
      "source": [
        "#abstract factory with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0f29081-8a4d-443a-ab86-021a92e1c0bd",
      "metadata": {
        "id": "f0f29081-8a4d-443a-ab86-021a92e1c0bd",
        "outputId": "4ca6b7cb-c045-4826-fb3b-16fa86c85010"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: abstractfactory (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (65).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: abstractfactory (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (33).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (86).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (29).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (62).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonab (17).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (6).java, Actual Label: 1, Predicted Label: 0\n",
            "\n",
            "Precision: 0.86\n",
            "Recall: 0.85\n",
            "F1 Score: 0.85\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"abstractfactory\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"abstractfactory\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7334bc2-9afb-4eec-9673-6c5fe7b33a56",
      "metadata": {
        "id": "e7334bc2-9afb-4eec-9673-6c5fe7b33a56"
      },
      "outputs": [],
      "source": [
        "#abstract factory with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b733d87-c74c-46ac-a53b-0187b7490a28",
      "metadata": {
        "id": "4b733d87-c74c-46ac-a53b-0187b7490a28",
        "outputId": "96326353-a68a-407b-95e9-fa07a3e1669b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonab (11).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (1).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (4).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: abstractfactory (6).java, Actual Label: 1, Predicted Label: 0\n",
            "\n",
            "Precision: 0.87\n",
            "Recall: 0.87\n",
            "F1 Score: 0.87\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"abstractfactory\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"abstractfactory\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "273845d2-4392-4bfb-9567-1188258cb5f8",
      "metadata": {
        "id": "273845d2-4392-4bfb-9567-1188258cb5f8"
      },
      "outputs": [],
      "source": [
        "#abstract factory with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f2ce492-fcbb-4660-8038-dd46a98bed01",
      "metadata": {
        "id": "4f2ce492-fcbb-4660-8038-dd46a98bed01",
        "outputId": "84f215db-526b-4ade-ed3f-55550118cb6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonab (11).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (22).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (65).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (13).java, Actual Label: 1, Predicted Label: 0\n",
            "File: abstractfactory (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: abstractfactory (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (32).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (38).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (57).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (50).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (45).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (43).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (61).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (54).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (63).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (68).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (20).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (6).java, Actual Label: 1, Predicted Label: 1\n",
            "\n",
            "Precision: 0.82\n",
            "Recall: 0.82\n",
            "F1 Score: 0.82\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"abstractfactory\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"abstractfactory\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6f493c0-ac4f-455d-8b2b-35b2237b7b2a",
      "metadata": {
        "id": "e6f493c0-ac4f-455d-8b2b-35b2237b7b2a"
      },
      "outputs": [],
      "source": [
        "#Prototype with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6dcad75-7269-4818-831e-0c0ebfbaeec3",
      "metadata": {
        "id": "f6dcad75-7269-4818-831e-0c0ebfbaeec3",
        "outputId": "4a991671-f918-448f-ce11-8bbe3104f7d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: prototype (27).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (43).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (35).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (51).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (22).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (29).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (37).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (18).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (22).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (32).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (19).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (32).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (26).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (48).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (45).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (25).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (50).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (29).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (31).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (52).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (10).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (41).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (47).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (23).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (1).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (28).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (30).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (18).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (34).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (26).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (9).java, Actual Label: 1, Predicted Label: 1\n",
            "\n",
            "Precision: 0.81\n",
            "Recall: 0.80\n",
            "F1 Score: 0.79\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"prototype\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"prototype\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33b2dbf7-ff9d-448d-83c7-b702ebf9eb8f",
      "metadata": {
        "id": "33b2dbf7-ff9d-448d-83c7-b702ebf9eb8f"
      },
      "outputs": [],
      "source": [
        "#Prototype with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94771738-fba3-4bbf-a2d7-7edee410909c",
      "metadata": {
        "id": "94771738-fba3-4bbf-a2d7-7edee410909c",
        "outputId": "2078bde5-dfde-4262-a79e-4c8c62e27748"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: prototype (27).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (59).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (22).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (21).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (58).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (18).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (22).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (32).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (19).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (26).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (25).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (4).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (29).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (31).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (19).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (10).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (60).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (56).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (23).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (1).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (28).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (30).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (18).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (57).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (11).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (61).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.77\n",
            "Recall: 0.77\n",
            "F1 Score: 0.77\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"prototype\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"prototype\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ef9daf9-ffd1-4411-9c55-05ea1544128d",
      "metadata": {
        "id": "2ef9daf9-ffd1-4411-9c55-05ea1544128d"
      },
      "outputs": [],
      "source": [
        "#Prototype with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fbf562a-e2de-4f90-87ef-ee892a0ff730",
      "metadata": {
        "id": "5fbf562a-e2de-4f90-87ef-ee892a0ff730",
        "outputId": "2f702629-824b-45e2-826a-21d3fdd0d37f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: prototype (27).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (59).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (22).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (21).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (58).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (18).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (22).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (32).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (19).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (26).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (25).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (4).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (29).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (31).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (19).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (10).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (60).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (56).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (23).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (1).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (28).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (30).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (18).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (57).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (11).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (61).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.77\n",
            "Recall: 0.77\n",
            "F1 Score: 0.77\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"prototype\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"prototype\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b4970f3-70ae-420e-800a-5f5e3b7394fb",
      "metadata": {
        "id": "8b4970f3-70ae-420e-800a-5f5e3b7394fb"
      },
      "outputs": [],
      "source": [
        "#Prototype with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f4b21fb-6d6f-4339-b0c0-f4244eda2456",
      "metadata": {
        "id": "0f4b21fb-6d6f-4339-b0c0-f4244eda2456",
        "outputId": "7d56ec2f-e885-41c3-b4dc-e529ad1fb2fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: prototype (27).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (43).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (59).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (31).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (22).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (44).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (37).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (36).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (58).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (18).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (32).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (19).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (38).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (26).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (48).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (45).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (25).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (33).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (50).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (29).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (31).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (19).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (52).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (10).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (41).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (55).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (56).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (47).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (1).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (28).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (30).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (57).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (34).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (26).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (40).java, Actual Label: 0, Predicted Label: 1\n",
            "\n",
            "Precision: 0.84\n",
            "Recall: 0.81\n",
            "F1 Score: 0.81\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"prototype\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"prototype\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d36871e-385a-467e-909f-c7e9e30ff9ac",
      "metadata": {
        "id": "0d36871e-385a-467e-909f-c7e9e30ff9ac"
      },
      "outputs": [],
      "source": [
        "#Prototype with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea8ecb4a-f14e-41c6-844f-2d556a67a954",
      "metadata": {
        "id": "ea8ecb4a-f14e-41c6-844f-2d556a67a954",
        "outputId": "18f48868-7bb5-4313-c475-0ee25d367f94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: prototype (27).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (43).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (35).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (51).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (22).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (44).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (36).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (58).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (49).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (18).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (22).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (32).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (19).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (38).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (26).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (46).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (42).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (45).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (25).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (4).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (29).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (31).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (19).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (52).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (10).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (55).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (60).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (56).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (47).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (28).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (30).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (34).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (26).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (40).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (61).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.83\n",
            "Recall: 0.82\n",
            "F1 Score: 0.81\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"prototype\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"prototype\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16606c28-cdc0-4a5c-a2a8-2bde64c9eeb9",
      "metadata": {
        "id": "16606c28-cdc0-4a5c-a2a8-2bde64c9eeb9",
        "outputId": "aad26b99-ee04-43df-97ee-bcd7314118d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: prototype (27).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (43).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (35).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (51).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (22).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (44).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (36).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (58).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (49).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (18).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (22).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (32).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (19).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (38).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (26).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (46).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (42).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (45).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (25).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (4).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (29).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (31).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (19).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (52).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (10).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (55).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (60).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (56).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (47).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (28).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (30).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (34).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (26).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (40).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (61).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.83\n",
            "Recall: 0.82\n",
            "F1 Score: 0.81\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"prototype\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"prototype\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4083233-4c47-46be-8655-00a445b80d15",
      "metadata": {
        "id": "e4083233-4c47-46be-8655-00a445b80d15"
      },
      "outputs": [],
      "source": [
        "#Factory Method with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48298074-a16c-4848-8eac-96550f0bfe6b",
      "metadata": {
        "id": "48298074-a16c-4848-8eac-96550f0bfe6b",
        "outputId": "732cf8a9-a028-4548-eadd-16099a848305"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonfm (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (9).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (11).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (17).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (9).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (15).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.71\n",
            "Recall: 0.70\n",
            "F1 Score: 0.69\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"factorymethod\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cccc939-90de-4db6-980f-097fd3227083",
      "metadata": {
        "id": "2cccc939-90de-4db6-980f-097fd3227083"
      },
      "outputs": [],
      "source": [
        "#Factory method with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4c80dfa-e9be-4b31-bb43-d675659301af",
      "metadata": {
        "id": "c4c80dfa-e9be-4b31-bb43-d675659301af",
        "outputId": "2e0e030a-1ff9-4eea-fa1f-9f58ccbd3d30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonfm (77).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (80).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (79).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (75).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (78).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (82).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonfm (74).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (81).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (76).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (73).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.77\n",
            "Recall: 0.76\n",
            "F1 Score: 0.76\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"factorymethod\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eabebac7-6217-4ecb-9b15-f8b6b9593e68",
      "metadata": {
        "id": "eabebac7-6217-4ecb-9b15-f8b6b9593e68"
      },
      "outputs": [],
      "source": [
        "#Factory Method with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e877816-f680-46e2-89b3-8fa3a21bb10b",
      "metadata": {
        "id": "9e877816-f680-46e2-89b3-8fa3a21bb10b",
        "outputId": "9c809e54-46d8-4195-d66c-a1631d8764b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonfm (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (4).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (1).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (8).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (7).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.84\n",
            "Recall: 0.84\n",
            "F1 Score: 0.84\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"factorymethod\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d10a31c1-9028-4d89-90f3-22dbb8a52270",
      "metadata": {
        "id": "d10a31c1-9028-4d89-90f3-22dbb8a52270"
      },
      "outputs": [],
      "source": [
        "#Factory method with different settingsactual_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b130c18a-d8cb-4919-9a20-55f940ddcf5f",
      "metadata": {
        "id": "b130c18a-d8cb-4919-9a20-55f940ddcf5f",
        "outputId": "3707fe5c-3d35-4f67-98f6-1199e02b42a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonfm (77).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (80).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (79).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (75).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (72).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (78).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (74).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (76).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (71).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonfm (73).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.82\n",
            "Recall: 0.81\n",
            "F1 Score: 0.81\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"factorymethod\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fa7d264-22bc-4a2d-8188-b66996258b62",
      "metadata": {
        "id": "4fa7d264-22bc-4a2d-8188-b66996258b62"
      },
      "outputs": [],
      "source": [
        "#Factory method with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b465b38-9d7b-44c4-8e93-7aac5f8a17b1",
      "metadata": {
        "id": "3b465b38-9d7b-44c4-8e93-7aac5f8a17b1",
        "outputId": "6dd18358-0e4e-4813-93d0-f9e53bf7e568"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonfm (77).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (68).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (79).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (75).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (72).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (70).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (82).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (81).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (6).java, Actual Label: 1, Predicted Label: 0\n",
            "\n",
            "Precision: 0.68\n",
            "Recall: 0.68\n",
            "F1 Score: 0.68\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"factorymethod\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ae5e35d-6710-4c5b-85bb-831b48e6e753",
      "metadata": {
        "id": "7ae5e35d-6710-4c5b-85bb-831b48e6e753"
      },
      "outputs": [],
      "source": [
        "#Factory Method with different settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e133b575-a751-49e2-b2f2-a53aa6cda61e",
      "metadata": {
        "id": "e133b575-a751-49e2-b2f2-a53aa6cda61e",
        "outputId": "f3fac23c-58dd-4e9f-fdad-c0d656b32343"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File: nonfm (77).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (80).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (79).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (75).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (72).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (78).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (82).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonfm (74).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (81).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (76).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (71).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonfm (73).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.74\n",
            "Recall: 0.74\n",
            "F1 Score: 0.74\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"factorymethod\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db1ebd82-b5b1-48e4-a342-14b5c40b61f6",
      "metadata": {
        "id": "db1ebd82-b5b1-48e4-a342-14b5c40b61f6"
      },
      "outputs": [],
      "source": [
        "#To plot t-SNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18bdadc2-36dd-41d1-8a3d-781db4e17998",
      "metadata": {
        "id": "18bdadc2-36dd-41d1-8a3d-781db4e17998",
        "outputId": "e5bcffe9-7a70-4527-fb6a-eee73b6b8149"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting seaborn\n",
            "  Downloading seaborn-0.13.0-py3-none-any.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m294.6/294.6 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy!=1.24.0,>=1.20 in /apps/Arch/software/SciPy-bundle/2022.05-foss-2022a/lib/python3.10/site-packages (from seaborn) (1.22.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in /apps/Arch/software/matplotlib/3.5.2-foss-2022a/lib/python3.10/site-packages (from seaborn) (3.5.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /apps/Arch/software/SciPy-bundle/2022.05-foss-2022a/lib/python3.10/site-packages (from seaborn) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /apps/Arch/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /apps/Arch/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (20.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /apps/Arch/software/matplotlib/3.5.2-foss-2022a/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /apps/Arch/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (3.0.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /apps/Arch/software/matplotlib/3.5.2-foss-2022a/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.4.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /apps/Arch/software/Pillow/9.1.1-GCCcore-11.3.0/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (9.1.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /apps/Arch/software/matplotlib/3.5.2-foss-2022a/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (4.34.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /apps/Arch/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /apps/Arch/software/Python/3.10.4-GCCcore-11.3.0/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.3->seaborn) (1.16.0)\n",
            "Installing collected packages: seaborn\n",
            "Successfully installed seaborn-0.13.0\n",
            "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
            "You should consider upgrading via the '/apps/Arch/software/Python/3.10.4-GCCcore-11.3.0/bin/python3.10 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "100308e0-b77a-4221-8acc-fd7f82d441cc",
      "metadata": {
        "id": "100308e0-b77a-4221-8acc-fd7f82d441cc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Function to get embeddings for a given design pattern\n",
        "def get_embeddings_for_pattern(pattern, model, tokenizer):\n",
        "    directory = os.path.join(\"all_design_patterns\", pattern.lower())\n",
        "    files = [file for file in os.listdir(directory) if os.path.isfile(os.path.join(directory, file))]\n",
        "\n",
        "    embeddings = []\n",
        "    true_labels = []\n",
        "\n",
        "    for file in files:\n",
        "        with open(os.path.join(directory, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "            code = f.read()\n",
        "\n",
        "        # Tokenize and encode the Java program\n",
        "        inputs = tokenizer(code, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        program_embedding = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "\n",
        "        embeddings.append(program_embedding)\n",
        "        true_labels.append(pattern)\n",
        "\n",
        "    return np.array(embeddings), np.array(true_labels)\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Get embeddings for each design pattern\n",
        "patterns = [\"Singleton\", \"Prototype\", \"AbstractFactory\", \"Builder\", \"FactoryMethod\"]\n",
        "all_embeddings = []\n",
        "all_labels = []\n",
        "\n",
        "# Custom color palette for each design pattern with higher contrast\n",
        "color_palette = [\"red\", \"green\", \"orange\", \"blue\", \"purple\"]\n",
        "\n",
        "# Custom markers for each design pattern\n",
        "markers = [\"o\", \"s\", \"D\", \"^\", \"P\"]\n",
        "\n",
        "for i, pattern in enumerate(patterns):\n",
        "    pattern_embeddings, pattern_labels = get_embeddings_for_pattern(pattern, model, tokenizer)\n",
        "    all_embeddings.append(pattern_embeddings)\n",
        "    all_labels.append(pattern_labels)\n",
        "\n",
        "# Concatenate the embeddings and labels\n",
        "all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
        "all_labels = np.concatenate(all_labels)\n",
        "\n",
        "# Perform t-SNE\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "tsne_results = tsne.fit_transform(all_embeddings)\n",
        "\n",
        "# Create a scatter plot for t-SNE visualization with custom symbols\n",
        "plt.figure(figsize=(20, 16))\n",
        "\n",
        "for i, pattern in enumerate(patterns):\n",
        "    indices = all_labels == pattern\n",
        "    sns.scatterplot(x=tsne_results[indices, 0], y=tsne_results[indices, 1], marker=markers[i], color=color_palette[i], s=200, label=pattern)\n",
        "\n",
        "# Increase font sizes for better visibility\n",
        "plt.title('t-SNE Visualization for CodeBERT on Different Design Patterns', fontsize=30)\n",
        "plt.xlabel('t-SNE Dimension 1', fontsize=25)\n",
        "plt.ylabel('t-SNE Dimension 2', fontsize=25)\n",
        "plt.legend(title='Design Pattern', loc='upper right', fontsize=22)\n",
        "plt.xticks(fontsize=20)\n",
        "plt.yticks(fontsize=20)\n",
        "plt.grid(True)\n",
        "\n",
        "# Save the t-SNE plot as a PDF file\n",
        "plt.savefig('tsne_plot_updated_symbols_colors.pdf', format='pdf')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "p88WzSc6ogZA",
      "metadata": {
        "id": "p88WzSc6ogZA"
      },
      "source": [
        "testing the time module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c729eb2-a50f-4d0f-a4ff-b714296fd93c",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 368,
          "referenced_widgets": [
            "fbb3a7d54d3f4b979da8a0fb599a5de7",
            "db6e83e495d748f3832fe4f6842abeb4",
            "770ce23b84fe4e419b2fbb19d2ed2d13",
            "9497be65739b4919abea118d344bd4f6",
            "e667eb72729f4cfbbfac941cd3ecb21f",
            "a3f6c7e8f4fa41a2b209b80a85456158",
            "288553384e4541abbdcf55e1003c8cf5",
            "7c7b1e1fc23b4643b0346651b247438d",
            "cc4f1a5759e54b1ca200d354d37b99c7",
            "8c83c857ea7c49289ab85ed3736d2558",
            "0f5f1c475bc4483e9be3e6d5e00d491b",
            "8d17f81b4b884012bdcc8c53e6cc7d74",
            "ba13e71bca71463b9bc1548aaf49e352",
            "f8a346924c644c8f9631b9f86daaf73e",
            "d728658f24914208a3e107b8d6d0973f",
            "af8e45438afd4672967c9817435a0ed4",
            "f3b552e728ce41f7a555e650269d736b",
            "542d184132e546d8a005d7a11a1045d5",
            "3512aab0fc6f4e3db3e9847684ea6639",
            "69fb4505d7464d4092c8d543ee596c61",
            "64e57361b5944b2a91112225696c0490",
            "069364f5a1be40ae978ba2c9b7a95291",
            "81356b11043c4ef081fb196bc00db57b",
            "c187cb5e29224545bacbb57f89078dfb",
            "a41e6faf3bf94cfdb875dd2575d61720",
            "a51ecdec6d384172bbb9627a4c8f85fa",
            "cdc7ca4fa7e44c42acd49042505133ca",
            "784bdcecc2304b3ea0d049ab9b4636da",
            "66eb1acdc50040d6b5a098ae00035610",
            "02b627e68f4a421ba09ba15b9ab08dca",
            "53314f68b919408eb7bd21d31241a7b6",
            "c3dfd3d0b5444676b863f4d174018255",
            "8b628394476340688c29a9a5f42e825f",
            "e71aacc132b44a2b9537042d2acee67d",
            "fa833aef462f49ac9f5de3d43d60432d",
            "75a52a6867754aa790c4fa0011a4d86b",
            "8596e8a719f6402199e14d5c78127405",
            "37f1382bde094b37bfd597ac8be0c4f7",
            "4f78fc52fb2a418c87770ba3fb041990",
            "b2b134a3cdfd4176afb896313ec427a8",
            "43a9d3c5cde042af84ecb5c5dbf94065",
            "dbd1eae035b44e758f3033ffeef65847",
            "069cfab2125844a58cbcc8c5164bb2ca",
            "97e9c9d72f184fc39d0b8dd121f7e351",
            "f66d5e14400a4b22862fdfe1d821305d",
            "990c38df28e443dd94ab0b9f8ac7d36e",
            "d0c2dd25680d4139b5581c6da5f06049",
            "eed0003fa6ca4a5085def1f17daa547f",
            "f0a7f19611d54ebfa4ffacccd79c91ec",
            "0e706a81e337422fbc7fba5096679a2c",
            "4dfe97c2b40a449ebcbb0b35cd84f7af",
            "183973f08d6f41b5bc97cc594ef6d5dc",
            "6b82c85c2b3b4ba3b2c82540f1dac4db",
            "df56c6c33fe4465d9e7ceec2f78eb045",
            "1091411f109f4a168a27a1ce4011d1ff",
            "f66166883b294dddbf0125787eec3866",
            "62a4ac8655de4477839e5e121b225b1a",
            "8327eb9accd443b5aa9dbff743e0065d",
            "7328e328f2eb4fd68619159748eb3540",
            "ffaabcb4e78043a19a630270d709447a",
            "34dc93f2356b4b0d80c9621dea9f24f0",
            "f306098093cf4f54bb99a66e43699a69",
            "3e0dfff6c8c44447b9182344c7cac666",
            "083fe7730cb740c7b50dfeddede172d6",
            "d500e7de70e34c67af5a3aac614b2622",
            "dbb19fbfaa8e40cfa1523f3210144828"
          ]
        },
        "id": "0c729eb2-a50f-4d0f-a4ff-b714296fd93c",
        "outputId": "8c7b07a6-8beb-49cf-909b-9bb1de014480"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbb3a7d54d3f4b979da8a0fb599a5de7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d17f81b4b884012bdcc8c53e6cc7d74",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81356b11043c4ef081fb196bc00db57b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e71aacc132b44a2b9537042d2acee67d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f66d5e14400a4b22862fdfe1d821305d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f66166883b294dddbf0125787eec3866",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 1280426.65 ms\n",
            "Prediction Time: 187.51 ms\n",
            "File: nonfm (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (4).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (11).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (1).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (9).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (2).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.88\n",
            "Recall: 0.85\n",
            "F1 Score: 0.84\n",
            "Total Execution Time: 1280664.10 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"factorymethod\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure overall execution time\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time: {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Tvn3xc_EPIKR",
      "metadata": {
        "id": "Tvn3xc_EPIKR"
      },
      "source": [
        "**Factory method time calcution with different settings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tF3GJteUo0o3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888,
          "referenced_widgets": [
            "5907ebb8962d41269e8b790132be3200",
            "b4a0917627e146cb920637a654862c89",
            "5df0656f326d4adeaca6dbf477f6c5f0",
            "b70ea907b945487699a1136c23f18150",
            "a532e7986bbd42328ec25474fab7654b",
            "390e89587a10429fb923114e9246fce6",
            "067dcdd227b74c0b90042e9536cf87ac",
            "35689df6cbaa415e8339a85527800bf1",
            "2a6d2ba3a56c43fa83f3957e451bd3a9",
            "8a11a4f5e04443ca94769314d5ca58bb",
            "3d01efc07acb4f1da8b0eadc4781638c",
            "0ee01b02d6c64eec998940f865277aa6",
            "25102ffcf8b54de2849628f1b25e3ec7",
            "b84c022598c24735a9eeb1e4ad7fab77",
            "dae344eee7424907aa02b0c729b2887f",
            "7744fe4224fa4757bdae65ac3704f249",
            "a92e02484c8c42dc9c2efa4b38be1163",
            "c647c9d66a2f46c69d5e0ca332496f68",
            "248c8fd066f249829e8ff741b44b9b92",
            "a4fca2b9be304de984d5460b8fc72367",
            "7ff94a11c31a47a09228f2f9b662318a",
            "49fd5d28bad14dafb77a25ce5badc759",
            "9c5732a354ec40ae919d917b98314f2b",
            "c87e1e31a2b84a9dac6a54eba85413d7",
            "25a4d8b8319e4ce8a9faa8541b1946eb",
            "3d4ca38f1a6a4473a589188fa038dd10",
            "3e0d4b26ccd7424cb3abaf96cf80bdf2",
            "72cd107feb67478e90d92162add6c261",
            "7060a98ce8e24e988e78dd87906bade5",
            "bf500391e9dc4b8399796cfa9bcb758c",
            "adc080130c554507b21c1efe26ee93a7",
            "a2ad85ad1a0e4cc5ab055f123c4339f9",
            "06d0475cb393469781586318d84b4df6",
            "efdbde77bb3e4dee8c997bcf39ffae98",
            "cb3ac662a20740bc890b7a15dd35ae3b",
            "d7eebb5c6cd74a9d9901d9eab71a6a39",
            "4dff183204c541d3989f22e7e0b03dd8",
            "c6070bea59504e2ea266d52ac85f0f20",
            "08d7dfaa2b71403a9c8117d46396869b",
            "86ffef4a494d4a2ba427ce3622399b5a",
            "9123abd540ca44509adc6e189a6fe14f",
            "4f0a5d8a186744b8914ae9978726e2e2",
            "812f69994d4f4b09beef13af48108d68",
            "d0ec6e98a08b483f88fc3a13a666af91",
            "74d65ad56aba4db28066ed3c5a8fb048",
            "4dfad4af40354dfcb41567e32f527fb2",
            "1333d801046f4f1d997e2f1088b1580d",
            "80946a3b82f648c3827bfba6702fff02",
            "e6626ebeab394b35ab4c715961959eef",
            "5e27634be5cf4e59b42b086b14160f79",
            "c304ffe74f92430394d29e61b59bed7d",
            "fb9a0aa90c8e4cfeb5d754964d35333d",
            "6456c11a56174f23a4a205a16bf0b44a",
            "bc2a5116e0fd43ae8cf6d0fce3d5c651",
            "4043a7a7182b451b987566dca1af8e67",
            "8dca732697b543f4853b4a3371aa3c26",
            "093579bea7a64e26a3fc145ffcbff278",
            "c5a037ffd0424927936caa0711379c1b",
            "4a19bc50728340f9a4c7b23f8ff18294",
            "af8fc74b36ef4db38466f59575ba2988",
            "869934883ee34d3eb7724e99708766cc",
            "a8a64b6cc4e54bee8192f734e0765727",
            "45d1fabc784c4ac0a0dd507af3f58fe2",
            "5dcfcd189dda4f69922c16c20c68c69a",
            "deddf28b7f834d09aedcd06a964ce5c1",
            "176527e43438462b9646c74138242339"
          ]
        },
        "id": "tF3GJteUo0o3",
        "outputId": "c2416e66-d148-44a3-c5fb-cd93c2f204bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5907ebb8962d41269e8b790132be3200",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ee01b02d6c64eec998940f865277aa6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c5732a354ec40ae919d917b98314f2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "efdbde77bb3e4dee8c997bcf39ffae98",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74d65ad56aba4db28066ed3c5a8fb048",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8dca732697b543f4853b4a3371aa3c26",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 364704.67 ms\n",
            "Prediction Time: 101.21 ms\n",
            "File: factorymethod (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (77).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (82).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonfm (81).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (72).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (74).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (73).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (79).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (76).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (80).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (71).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonfm (78).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (75).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.79\n",
            "Recall: 0.78\n",
            "F1 Score: 0.78\n",
            "Total Execution Time: 364848.23 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"factorymethod\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure overall execution time\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time: {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fpAx7PR6GZfn",
      "metadata": {
        "id": "fpAx7PR6GZfn"
      },
      "source": [
        "**Time for singleton**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EGM46481DLQ2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGM46481DLQ2",
        "outputId": "7bdec21a-13cc-4394-94e2-74e27f93101c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 376635.22 ms\n",
            "Prediction Time: 3.27 ms\n",
            "File: factorymethod (4).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (77).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (82).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (81).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (1).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (72).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (74).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (73).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (79).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (76).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (11).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (80).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (71).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (78).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (75).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 1.00\n",
            "Recall: 1.00\n",
            "F1 Score: 1.00\n",
            "Total Execution Time: 376647.07 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"singleton\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure overall execution time\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time: {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qIEmYxoOOvI9",
      "metadata": {
        "id": "qIEmYxoOOvI9"
      },
      "source": [
        "**Singleton time calculation with different settings**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8uKKfSeIRX2i",
      "metadata": {
        "id": "8uKKfSeIRX2i"
      },
      "source": [
        "**Singleton with different settings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "z2DVpOSBO_or",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2DVpOSBO_or",
        "outputId": "fedeb5ee-c285-41fc-84b8-1b951cb55cc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 122461.56 ms\n",
            "Prediction Time: 8.67 ms\n",
            "File: singleton (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (45).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (24).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (64).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (16).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (18).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (37).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (62).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (33).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (4).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (19).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (52).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (42).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (56).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (19).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (22).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (49).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (5).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (65).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (61).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (29).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (25).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (7).java, Actual Label: 1, Predicted Label: 0\n",
            "\n",
            "Precision: 0.68\n",
            "Recall: 0.67\n",
            "F1 Score: 0.66\n",
            "Total Execution Time (Training + Prediction + Misc.): 122478.56 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/singleton\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"singleton\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HzWiSDosVCGC",
      "metadata": {
        "id": "HzWiSDosVCGC"
      },
      "source": [
        "**Singleton time calculation with different settings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1Xo7SFJZRjiN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Xo7SFJZRjiN",
        "outputId": "542881b7-65d6-43ca-a6db-968a161ff42e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 97906.88 ms\n",
            "Prediction Time: 3.52 ms\n",
            "File: singleton (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (45).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (53).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (16).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (18).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (37).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (54).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (48).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (34).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (33).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (19).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (52).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (42).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (38).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (51).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (22).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (35).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (50).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (49).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (5).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (47).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (43).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (41).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (44).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (36).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (25).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (40).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (46).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (7).java, Actual Label: 1, Predicted Label: 0\n",
            "\n",
            "Precision: 0.67\n",
            "Recall: 0.66\n",
            "F1 Score: 0.66\n",
            "Total Execution Time (Training + Prediction + Misc.): 97930.34 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/singleton\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"singleton\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gMVxti_-Z4h3",
      "metadata": {
        "id": "gMVxti_-Z4h3"
      },
      "source": [
        "**Singleton time calculation with different settings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AaMSS9BIVlvh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaMSS9BIVlvh",
        "outputId": "021c2da5-4541-4f05-94b4-d6c4713fd7bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 107471.01 ms\n",
            "Prediction Time: 3.39 ms\n",
            "File: singleton (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (53).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (60).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (16).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (18).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (63).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (55).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (37).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (62).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (19).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (57).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (11).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (51).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (22).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (35).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (5).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (1).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (9).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (66).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (41).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (44).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (25).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (25).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (46).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (7).java, Actual Label: 1, Predicted Label: 0\n",
            "\n",
            "Precision: 0.74\n",
            "Recall: 0.71\n",
            "F1 Score: 0.71\n",
            "Total Execution Time (Training + Prediction + Misc.): 107483.17 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/singleton\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"singleton\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aKOQkmDHa1O5",
      "metadata": {
        "id": "aKOQkmDHa1O5"
      },
      "source": [
        "**Factory method time calculation using different settings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uB7V3MeuZ_JX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uB7V3MeuZ_JX",
        "outputId": "d6f8b9c0-94c8-43f6-fee3-667c1db7cb0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Training (Embedding Generation) Time: 84570.35 ms\n",
            "Prediction Time: 2.57 ms\n",
            "File: factorymethod (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (20).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (16).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonfm (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (4).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (25).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (8).java, Actual Label: 1, Predicted Label: 1\n",
            "\n",
            "Precision: 0.84\n",
            "Recall: 0.84\n",
            "F1 Score: 0.84\n",
            "Total Execution Time (Training + Prediction + Misc.): 84587.95 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"factorymethod\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zeQgcZr-cPoT",
      "metadata": {
        "id": "zeQgcZr-cPoT"
      },
      "source": [
        "**Factory method with different settings **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1U42-4oncLpO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U42-4oncLpO",
        "outputId": "50792abb-6da5-4970-c3ff-b3e360a15024"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 46214.70 ms\n",
            "Prediction Time: 3.54 ms\n",
            "File: factorymethod (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (77).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (68).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (42).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (49).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (76).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (32).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (67).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (70).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (71).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (78).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (26).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (69).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (38).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (51).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (47).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (8).java, Actual Label: 1, Predicted Label: 1\n",
            "\n",
            "Precision: 0.85\n",
            "Recall: 0.85\n",
            "F1 Score: 0.85\n",
            "Total Execution Time (Training + Prediction + Misc.): 46234.43 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"factorymethod\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KJUnYLMCdK_y",
      "metadata": {
        "id": "KJUnYLMCdK_y"
      },
      "source": [
        "**Factory method with different settings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XGD8jtIibXQy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGD8jtIibXQy",
        "outputId": "40215059-aa0f-463f-cc0d-2adb969f334b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 78577.67 ms\n",
            "Prediction Time: 2.81 ms\n",
            "File: factorymethod (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (35).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonfm (34).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (29).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (32).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (11).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (33).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonfm (25).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (26).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (31).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (8).java, Actual Label: 1, Predicted Label: 1\n",
            "\n",
            "Precision: 0.63\n",
            "Recall: 0.62\n",
            "F1 Score: 0.63\n",
            "Total Execution Time (Training + Prediction + Misc.): 78591.68 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"factorymethod\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DFDSlImNmUcY",
      "metadata": {
        "id": "DFDSlImNmUcY"
      },
      "source": [
        "**Factory method with different settings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aEcVUvR9fX6d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEcVUvR9fX6d",
        "outputId": "7385fca0-4873-4153-e9b3-147ebeb89e60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 79601.84 ms\n",
            "Prediction Time: 3.21 ms\n",
            "File: factorymethod (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (20).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (22).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (29).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (16).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonfm (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (19).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (25).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (26).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (8).java, Actual Label: 1, Predicted Label: 1\n",
            "\n",
            "Precision: 0.83\n",
            "Recall: 0.82\n",
            "F1 Score: 0.82\n",
            "Total Execution Time (Training + Prediction + Misc.): 79613.18 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"factorymethod\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NjvqzO5_mM8H",
      "metadata": {
        "id": "NjvqzO5_mM8H"
      },
      "source": [
        "**Singleton with different settings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T2AEUllOoxDT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2AEUllOoxDT",
        "outputId": "bf7f1142-5729-4fd0-ca46-74755f74efbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 195491.85 ms\n",
            "Prediction Time: 4.71 ms\n",
            "File: singleton (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (45).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (64).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (16).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (18).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (63).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (62).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (34).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (33).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (19).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (42).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (32).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (19).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (22).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (67).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (22).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (5).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (65).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (9).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (66).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (43).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (44).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (25).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (46).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (31).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (7).java, Actual Label: 1, Predicted Label: 0\n",
            "\n",
            "Precision: 0.66\n",
            "Recall: 0.64\n",
            "F1 Score: 0.63\n",
            "Total Execution Time (Training + Prediction + Misc.): 195511.11 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/singleton\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"singleton\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8T7sK6OwqLc7",
      "metadata": {
        "id": "8T7sK6OwqLc7"
      },
      "source": [
        "**Singleton time calcultion with different settings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eISBall3oyB1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eISBall3oyB1",
        "outputId": "fdbd9d84-a888-49c7-8a6a-ee989acf460d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 98509.27 ms\n",
            "Prediction Time: 5.50 ms\n",
            "File: factorymethod (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (20).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (22).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (29).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (16).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonfm (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (19).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (25).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (26).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (8).java, Actual Label: 1, Predicted Label: 1\n",
            "\n",
            "Precision: 0.83\n",
            "Recall: 0.82\n",
            "F1 Score: 0.82\n",
            "Total Execution Time (Training + Prediction + Misc.): 98531.75 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"factorymethod\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_QZZr4CUrrFa",
      "metadata": {
        "id": "_QZZr4CUrrFa"
      },
      "source": [
        "**Factory method time calculation with different settings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Q4JWV8KmqQUb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4JWV8KmqQUb",
        "outputId": "7ef0ded7-d98c-47f4-a788-16df241770fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 95059.75 ms\n",
            "Prediction Time: 2.87 ms\n",
            "File: factorymethod (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (20).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonfm (22).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (29).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (16).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonfm (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (19).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (25).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (26).java, Actual Label: 0, Predicted Label: 1\n",
            "File: factorymethod (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: factorymethod (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: factorymethod (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonfm (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonfm (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: factorymethod (8).java, Actual Label: 1, Predicted Label: 1\n",
            "\n",
            "Precision: 0.83\n",
            "Recall: 0.82\n",
            "F1 Score: 0.82\n",
            "Total Execution Time (Training + Prediction + Misc.): 95069.99 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/factorymethod\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"factorymethod\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oNJnXRKVs9YH",
      "metadata": {
        "id": "oNJnXRKVs9YH"
      },
      "source": [
        "**Singleton with different settings**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A3E-5iYbrx1_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3E-5iYbrx1_",
        "outputId": "62a72d44-d66a-4e45-f194-f11b473a68f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 133244.40 ms\n",
            "Prediction Time: 3.41 ms\n",
            "File: singleton (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (68).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (24).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (64).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (16).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (18).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (26).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (48).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (19).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (42).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (38).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (51).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (19).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (22).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (50).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nons (67).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (49).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (5).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (65).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (9).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (47).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (66).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (41).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nons (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (25).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (25).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (40).java, Actual Label: 0, Predicted Label: 0\n",
            "File: singleton (24).java, Actual Label: 1, Predicted Label: 0\n",
            "File: singleton (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: singleton (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nons (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nons (27).java, Actual Label: 0, Predicted Label: 1\n",
            "File: singleton (7).java, Actual Label: 1, Predicted Label: 0\n",
            "\n",
            "Precision: 0.60\n",
            "Recall: 0.58\n",
            "F1 Score: 0.57\n",
            "Total Execution Time (Training + Prediction + Misc.): 133256.73 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/singleton\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"singleton\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XiZOpjuNxA6c",
      "metadata": {
        "id": "XiZOpjuNxA6c"
      },
      "source": [
        "**Builder with settings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9WkeU7q_xEv3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WkeU7q_xEv3",
        "outputId": "cc4e1127-d258-43a9-dd35-d08c77095a97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 75283.62 ms\n",
            "Prediction Time: 2.94 ms\n",
            "File: nonb (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (11).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (16).java, Actual Label: 0, Predicted Label: 1\n",
            "File: builder (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (12).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.84\n",
            "Recall: 0.83\n",
            "F1 Score: 0.83\n",
            "Total Execution Time (Training + Prediction + Misc.): 75293.55 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/builder\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"builder\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kaGVyNzbx1d8",
      "metadata": {
        "id": "kaGVyNzbx1d8"
      },
      "source": [
        "**Builder time calculation with different settings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_EAdDekZxPCc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819,
          "referenced_widgets": [
            "727b8510d4ab460fa6061119ae7636f2",
            "8102aa727066499e90e4afa59ed88f99",
            "26652166ee2e4c289bf4f47c1eb2f57f",
            "38b9e17c1eb64cc6954d9286a9d8b916",
            "88d598437ce74979aa7383ccbcfd4d86",
            "3d2c725bbb9c40f9a256303467eefd87",
            "4ac8dc3f637144088040304f53d17604",
            "5766d5fc03064de69cacabcef689336c",
            "b4e67002c7494fe48c3663e075f024ff",
            "3039a34550ae4ac690b7019d3d03a80d",
            "352d2ce09dce4eb68f7c8af13db4791b",
            "9ed22cb538594777a328111f6a14b84b",
            "a422160c58ff47c0bd3a599511599076",
            "1252b99ee1b14f6ebec527c36c673044",
            "ddd84975ba3743b4b1d68dc88e9bbca5",
            "3d123770cc92497d851afdfe0b46a80e",
            "752b1d31e3324aa0a8c00e1856aa78e2",
            "e577e207cda54e939d20a8ca7e86d721",
            "94ba75acd1434ed4b791aa83a91bdfeb",
            "2205c44b144e45cba30f3bde7caa0f3e",
            "a8dfac5df8ef4315a37e4bcefc25902e",
            "750225f407e640808ccabe29221e4b2d",
            "1d0a035aa95e4d17893f2fc8123f2e84",
            "e69f775a51134f8db786cfa83ab7d557",
            "ba4bd4494eb34c8999fb6e9c27dde41e",
            "fb4e9bdefed143e0a7cf54b5957bec4f",
            "527bcbc98e4d492d87c2edecfeed7979",
            "514a89e105f64ce7ad4e3d63e8768259",
            "e0e038ec9ab94480bdf722160c35ddad",
            "fb90e164238c495d80f85df3d3486407",
            "55b553fecf3943d48474d1c5dbc608fa",
            "cb471ac99b1d4f288fba0e997493e82c",
            "951655ab30284914acbb21393ed98655",
            "6a13f5d9e3034c60b8db1d512d507971",
            "27459b775c0f4c2788325c1b6b7267a2",
            "407aeeb0f0034feaacdae64f186c8045",
            "e4d70e9bdeef43edb4bffae6c7b06cf4",
            "3b5aea119777494f995f99ca3e44e3ac",
            "2ed29106065e4f909e63daf380c783ab",
            "a6f508988bfb4871b543c78f25c38b8b",
            "db0b368c1a2942fca050b477b18e6feb",
            "faa3279aaf4b46e7b7de865b12730f1d",
            "14792133286a4a4d8dc1d3f2bd589ead",
            "72291a608b8443c8acf6abf06c8753e8",
            "6cc85f34154a43d3965e3f2b0166a936",
            "effd9f74cf9141e38aceac60efdc3742",
            "7a8b6bfe90ed4c14adce23d5e0631711",
            "29ec4a59b1c843c687fb12ea29c3878e",
            "15bd8236e608410b88cb38d6710d8962",
            "c2f9b055f60c4596bfb958998443d5ce",
            "bd5d543825ce4d318d4e586ef1b9266e",
            "55cf4187a01344dbbf4af4d16a148a82",
            "c7c7f79570d84667b72913f79d0def6f",
            "b2f024ad905c4f68a272ba9a89d8ee19",
            "8868c9d1e2ee4078a0387a8e1c26e8d7",
            "4609b2d80963451db2bfb61687830391",
            "51074d03825c4a608109357d88c33e7e",
            "c350a42f47b64f74a18fbe971c1f5ad8",
            "d264453bb3864d26a8615fb05cf718f6",
            "e804483d6fa04040a4d04f518c422ecc",
            "3138a201a11a4c9c8e00cacdfd0cd4f0",
            "47b7ee25a40647139540842772a670aa",
            "bd9466475a2046d79f8b010c6acef4b2",
            "b3fc0f4e42504654b315ca9d5ed75258",
            "cda51966c77f45e396647ce7e587712e",
            "048224c2fc4d4442ab4ac789c3abe4b6"
          ]
        },
        "id": "_EAdDekZxPCc",
        "outputId": "1f71c6df-a0d7-49e3-f26f-5dcbeb126570"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "727b8510d4ab460fa6061119ae7636f2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ed22cb538594777a328111f6a14b84b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d0a035aa95e4d17893f2fc8123f2e84",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a13f5d9e3034c60b8db1d512d507971",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6cc85f34154a43d3965e3f2b0166a936",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4609b2d80963451db2bfb61687830391",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 45103.20 ms\n",
            "Prediction Time: 49.39 ms\n",
            "File: builder (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (1).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonb (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (4).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (8).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.84\n",
            "Recall: 0.83\n",
            "F1 Score: 0.83\n",
            "Total Execution Time (Training + Prediction + Misc.): 45160.55 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/builder\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"builder\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "C0y0hvSSwWYX",
      "metadata": {
        "id": "C0y0hvSSwWYX"
      },
      "source": [
        "**Builder with different seetings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YqNuhpE4yGy9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqNuhpE4yGy9",
        "outputId": "3b42153e-cad1-416e-dbc8-6a7854fe3d0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 80378.07 ms\n",
            "Prediction Time: 3.09 ms\n",
            "File: builder (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (1).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonb (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (4).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (8).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.84\n",
            "Recall: 0.83\n",
            "F1 Score: 0.83\n",
            "Total Execution Time (Training + Prediction + Misc.): 80390.35 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/builder\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"builder\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AACqRSdhGyHt",
      "metadata": {
        "id": "AACqRSdhGyHt"
      },
      "source": [
        "**Builder with different settings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nqhT4rOzHBKL",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqhT4rOzHBKL",
        "outputId": "365b9249-55d9-4014-926e-2b37bb749388"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 69154.35 ms\n",
            "Prediction Time: 2.89 ms\n",
            "File: nonb (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (9).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (27).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonb (34).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonb (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (26).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (35).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (8).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (5).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (32).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (29).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (31).java, Actual Label: 0, Predicted Label: 1\n",
            "\n",
            "Precision: 0.20\n",
            "Recall: 0.33\n",
            "F1 Score: 0.25\n",
            "Total Execution Time (Training + Prediction + Misc.): 69172.41 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/builder\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"builder\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WuzLlOmaIBQH",
      "metadata": {
        "id": "WuzLlOmaIBQH"
      },
      "source": [
        "**Builder with different settings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fSQvce-Hjz4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fSQvce-Hjz4",
        "outputId": "39994c7b-e8d8-4b7e-e092-0db2b89fc091"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 67862.53 ms\n",
            "Prediction Time: 3.15 ms\n",
            "File: nonb (128).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (129).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (131).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (130).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (125).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (132).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: builder (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (133).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (134).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (127).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.88\n",
            "Recall: 0.83\n",
            "F1 Score: 0.83\n",
            "Total Execution Time (Training + Prediction + Misc.): 67876.22 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/builder\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"builder\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0uvj3KrfJhVl",
      "metadata": {
        "id": "0uvj3KrfJhVl"
      },
      "source": [
        "**Builder with different settings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c-eDPk8nILun",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-eDPk8nILun",
        "outputId": "276b80bd-e7f7-478a-a29b-18b9761b79e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 127342.93 ms\n",
            "Prediction Time: 3.13 ms\n",
            "File: nonb (92).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (93).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (108).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonb (131).java, Actual Label: 0, Predicted Label: 1\n",
            "File: builder (8).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (3).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (5).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: builder (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (116).java, Actual Label: 0, Predicted Label: 1\n",
            "File: builder (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonb (119).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonb (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonb (99).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonb (81).java, Actual Label: 0, Predicted Label: 0\n",
            "File: builder (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonb (41).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.44\n",
            "Recall: 0.45\n",
            "F1 Score: 0.45\n",
            "Total Execution Time (Training + Prediction + Misc.): 127355.14 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/builder\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"builder\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PnlP4XD0KuI9",
      "metadata": {
        "id": "PnlP4XD0KuI9"
      },
      "source": [
        "**Prototyope with different settings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5lxAWoanJkP2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lxAWoanJkP2",
        "outputId": "1221f1fb-7f4a-4589-dd6b-32cdf1622468"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 152617.35 ms\n",
            "Prediction Time: 10.73 ms\n",
            "File: prototype (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (22).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (27).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (31).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (19).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (29).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (4).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (29).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (25).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (18).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (33).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (32).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (28).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (26).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (19).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (32).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (31).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (23).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (11).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (30).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (10).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (22).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (26).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (25).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.90\n",
            "Recall: 0.89\n",
            "F1 Score: 0.89\n",
            "Total Execution Time (Training + Prediction + Misc.): 152636.11 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/prototype\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"prototype\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VSEH0b6zL4O_",
      "metadata": {
        "id": "VSEH0b6zL4O_"
      },
      "source": [
        "**Prototype with different settings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8SUMos7tK8nf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SUMos7tK8nf",
        "outputId": "686cbac1-a7fd-4de2-b94c-16d2865bbf85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 153786.84 ms\n",
            "Prediction Time: 3.82 ms\n",
            "File: prototype (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (22).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (27).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (31).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (19).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (42).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (29).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (48).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (35).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (36).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (29).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (45).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (52).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (34).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (60).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (55).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (25).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (18).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (37).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (44).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (33).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (49).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (32).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (58).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (47).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (28).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (26).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (41).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (32).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (57).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (59).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (31).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (46).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (56).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (43).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (30).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (53).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (10).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (54).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (50).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (51).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (40).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (38).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (61).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.79\n",
            "Recall: 0.77\n",
            "F1 Score: 0.76\n",
            "Total Execution Time (Training + Prediction + Misc.): 153811.65 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/prototype\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"prototype\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cWHZS9ViOIlO",
      "metadata": {
        "id": "cWHZS9ViOIlO"
      },
      "source": [
        "**Prototype with different settings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tD581WRFMJgy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD581WRFMJgy",
        "outputId": "8239f7ef-22ec-4284-e773-cfb6d44c1401"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 164954.88 ms\n",
            "Prediction Time: 3.67 ms\n",
            "File: prototype (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (22).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (27).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (31).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (19).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (29).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (35).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (36).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (29).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (34).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (25).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (18).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (37).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (24).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (33).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (32).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (28).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (26).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (19).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (21).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (41).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (32).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (31).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (23).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (30).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (10).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (40).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (38).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (22).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (26).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (25).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.82\n",
            "Recall: 0.81\n",
            "F1 Score: 0.81\n",
            "Total Execution Time (Training + Prediction + Misc.): 164968.45 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/prototype\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"prototype\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ySsPJliZPTKS",
      "metadata": {
        "id": "ySsPJliZPTKS"
      },
      "source": [
        "**Prototype with different settings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Wa4mnC3mOZBy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wa4mnC3mOZBy",
        "outputId": "6f2d9ba2-d13f-42a0-a351-68e3ddd227c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 175072.66 ms\n",
            "Prediction Time: 4.65 ms\n",
            "File: prototype (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (22).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (27).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (31).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (19).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (29).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (35).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (18).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (36).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (29).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (25).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (18).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (37).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (44).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (32).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (28).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (26).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (19).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (21).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (32).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (31).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (23).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (43).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (11).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (30).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (10).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (38).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (26).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (20).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (25).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.84\n",
            "Recall: 0.83\n",
            "F1 Score: 0.83\n",
            "Total Execution Time (Training + Prediction + Misc.): 175094.36 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/prototype\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"prototype\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TiLJv3gbRszG",
      "metadata": {
        "id": "TiLJv3gbRszG"
      },
      "source": [
        "**Prototype with different settings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b_7idRQBPoPo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_7idRQBPoPo",
        "outputId": "c99a55b0-0c11-4dcc-bdad-92ef1f52a4b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 134111.86 ms\n",
            "Prediction Time: 3.49 ms\n",
            "File: prototype (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (28).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (22).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (27).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (31).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (19).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (42).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (29).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (20).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (17).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (12).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (29).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (45).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (52).java, Actual Label: 0, Predicted Label: 1\n",
            "File: prototype (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (55).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (1).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (25).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (27).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (18).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (24).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (44).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (2).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (32).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (58).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (28).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (26).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (41).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (57).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (31).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (7).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (21).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (46).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (23).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (23).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (56).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (43).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (11).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (30).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (53).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (10).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonp (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (54).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (51).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (40).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonp (38).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (22).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonp (26).java, Actual Label: 0, Predicted Label: 0\n",
            "File: prototype (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (24).java, Actual Label: 1, Predicted Label: 1\n",
            "File: prototype (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: prototype (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonp (25).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.77\n",
            "Recall: 0.75\n",
            "F1 Score: 0.75\n",
            "Total Execution Time (Training + Prediction + Misc.): 134129.34 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/prototype\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"prototype\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "H-3J1PXwTtDs",
      "metadata": {
        "id": "H-3J1PXwTtDs"
      },
      "source": [
        "**Abstract Factory with different settings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MobeEixhSBSO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MobeEixhSBSO",
        "outputId": "d7486839-1f12-4a26-af94-e61faa91d18a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 133009.30 ms\n",
            "Prediction Time: 3.20 ms\n",
            "File: nonab (10).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (14).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (15).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (4).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (9).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (6).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (13).java, Actual Label: 1, Predicted Label: 0\n",
            "File: abstractfactory (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (17).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (16).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (13).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (1).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (7).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (3).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonab (12).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (11).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (6).java, Actual Label: 1, Predicted Label: 0\n",
            "File: abstractfactory (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (5).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (8).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (5).java, Actual Label: 1, Predicted Label: 1\n",
            "\n",
            "Precision: 0.85\n",
            "Recall: 0.85\n",
            "F1 Score: 0.85\n",
            "Total Execution Time (Training + Prediction + Misc.): 133022.20 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/abstractfactory\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"abstractfactory\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rgkRDqMCVLf_",
      "metadata": {
        "id": "rgkRDqMCVLf_"
      },
      "source": [
        "**Abstract Factory with different settings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nZReovEhVQy4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZReovEhVQy4",
        "outputId": "499ceaf5-4c06-485e-bdaa-64e94f7a2039"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 85384.84 ms\n",
            "Prediction Time: 3.83 ms\n",
            "File: nonab (76).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (73).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (71).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (70).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (74).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (69).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (67).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (75).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (72).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonab (77).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (64).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (68).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (65).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (66).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.93\n",
            "Recall: 0.93\n",
            "F1 Score: 0.93\n",
            "Total Execution Time (Training + Prediction + Misc.): 85403.24 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/abstractfactory\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"abstractfactory\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QYDVQNE6jLr3",
      "metadata": {
        "id": "QYDVQNE6jLr3"
      },
      "source": [
        "**Abstract factory with different settings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZW2TJPXUjpZc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW2TJPXUjpZc",
        "outputId": "284381b4-8cc8-494f-ca00-e13404ae45c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 95415.50 ms\n",
            "Prediction Time: 3.61 ms\n",
            "File: nonab (83).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (76).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (80).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (81).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (86).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (74).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (87).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (75).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (1).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (78).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (82).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (77).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (79).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (84).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (85).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (2).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (5).java, Actual Label: 1, Predicted Label: 1\n",
            "\n",
            "Precision: 0.88\n",
            "Recall: 0.84\n",
            "F1 Score: 0.84\n",
            "Total Execution Time (Training + Prediction + Misc.): 95431.30 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/abstractfactory\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"abstractfactory\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wCgZFj2QlOVj",
      "metadata": {
        "id": "wCgZFj2QlOVj"
      },
      "source": [
        "**Abstract Factory using different settings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4gkqcjdLkh_s",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gkqcjdLkh_s",
        "outputId": "06084ad5-d3c3-4e44-db1f-a245d34e67b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 98124.97 ms\n",
            "Prediction Time: 2.91 ms\n",
            "File: nonab (76).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (63).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (81).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (34).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (74).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (69).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (52).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (57).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (72).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (79).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (84).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (37).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (44).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (5).java, Actual Label: 1, Predicted Label: 1\n",
            "\n",
            "Precision: 0.92\n",
            "Recall: 0.90\n",
            "F1 Score: 0.90\n",
            "Total Execution Time (Training + Prediction + Misc.): 98155.65 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/abstractfactory\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"abstractfactory\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tyjUM5ksmFdP",
      "metadata": {
        "id": "tyjUM5ksmFdP"
      },
      "source": [
        "**abstract factory with different settings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Uu6IXZb7lcvU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uu6IXZb7lcvU",
        "outputId": "ec8a25d1-83ed-4149-bcf0-37a9386c8e87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 50682.77 ms\n",
            "Prediction Time: 3.28 ms\n",
            "File: nonab (50).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (33).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (51).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (34).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (52).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (49).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (36).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (31).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (14).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (40).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (54).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (35).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (4).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonab (37).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (39).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (32).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (38).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (30).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (29).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (53).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.89\n",
            "Recall: 0.88\n",
            "F1 Score: 0.88\n",
            "Total Execution Time (Training + Prediction + Misc.): 50695.22 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/abstractfactory\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"abstractfactory\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "o4DRpNQFmmw1",
      "metadata": {
        "id": "o4DRpNQFmmw1"
      },
      "source": [
        "**Abstract Factory with different settiings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bkm2Om29mSGc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkm2Om29mSGc",
        "outputId": "5d9e8ec8-cec2-4326-8ade-e81e3808aed6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training (Embedding Generation) Time: 96412.41 ms\n",
            "Prediction Time: 3.07 ms\n",
            "File: nonab (83).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (8).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (80).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (73).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (71).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (1).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (70).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (81).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (86).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (13).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (74).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (16).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (9).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (3).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (69).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (67).java, Actual Label: 0, Predicted Label: 1\n",
            "File: abstractfactory (11).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (2).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (15).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (10).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (78).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (82).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (72).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (14).java, Actual Label: 1, Predicted Label: 0\n",
            "File: nonab (79).java, Actual Label: 0, Predicted Label: 0\n",
            "File: nonab (84).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (6).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (4).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (85).java, Actual Label: 0, Predicted Label: 1\n",
            "File: nonab (68).java, Actual Label: 0, Predicted Label: 0\n",
            "File: abstractfactory (12).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (7).java, Actual Label: 1, Predicted Label: 1\n",
            "File: abstractfactory (5).java, Actual Label: 1, Predicted Label: 1\n",
            "File: nonab (66).java, Actual Label: 0, Predicted Label: 0\n",
            "\n",
            "Precision: 0.87\n",
            "Recall: 0.85\n",
            "F1 Score: 0.85\n",
            "Total Execution Time (Training + Prediction + Misc.): 96431.34 ms\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/abstractfactory\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "program_embeddings = []\n",
        "true_labels = []\n",
        "\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Measure the total execution time\n",
        "start_time = time.time()\n",
        "\n",
        "# Measure the training time (embedding generation)\n",
        "start_training_time = time.time()\n",
        "\n",
        "for file in java_files:\n",
        "    with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "        java_code = f.read()\n",
        "\n",
        "        # Get the embedding of the program by taking the mean of line embeddings\n",
        "        program_embedding = get_line_embeddings(java_code)\n",
        "        program_embeddings.append(program_embedding)\n",
        "\n",
        "        # Define true labels based on the file names\n",
        "        true_labels.append(1 if \"abstractfactory\" in file else 0)\n",
        "\n",
        "# Convert program_embeddings to a NumPy array\n",
        "program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "# Measure the end of training time\n",
        "end_training_time = time.time()\n",
        "training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "# Measure the prediction time\n",
        "prediction_start_time = time.time()\n",
        "\n",
        "# Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "k = 5  # Adjust this value as needed\n",
        "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "neighbors.fit(program_embeddings)\n",
        "_, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "# Initialize arrays to store actual and predicted labels\n",
        "actual_labels = np.array(true_labels)\n",
        "predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "# Predict labels for each program\n",
        "for i in range(len(java_files)):\n",
        "    # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "    neighbor_indices = indices[i, 1:]\n",
        "\n",
        "    # Get the labels of the neighbors\n",
        "    neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "    # Assign the majority label to the program\n",
        "    predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "    predicted_labels[i] = predicted_label\n",
        "\n",
        "# Measure the end of prediction time\n",
        "prediction_end_time = time.time()\n",
        "prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "# Print actual and predicted labels for each program\n",
        "for i, file in enumerate(java_files):\n",
        "    print(f\"File: {file}, Actual Label: {actual_labels[i]}, Predicted Label: {predicted_labels[i]}\")\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Measure total execution time (from the start of the script to the end of prediction)\n",
        "overall_end_time = time.time()\n",
        "execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wscEm99Cn6hb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wscEm99Cn6hb",
        "outputId": "d05f028d-e1d7-45a2-8445-a9ffa7886676"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run 1 of 10\n",
            "Run 2 of 10\n",
            "Run 3 of 10\n",
            "Run 4 of 10\n",
            "Run 5 of 10\n",
            "Run 6 of 10\n",
            "Run 7 of 10\n",
            "Run 8 of 10\n",
            "Run 9 of 10\n",
            "Run 10 of 10\n",
            "\n",
            "Mean Precision: 0.87 (0.00)\n",
            "Mean Recall: 0.85 (0.00)\n",
            "Mean F1 Score: 0.85 (0.00)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Function to calculate standard deviation\n",
        "def calculate_std(values):\n",
        "    return np.std(values)\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"abstractfactory\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Running the experiment multiple times to calculate mean and standard deviation\n",
        "n_runs = 10  # Change this value to 10-30 based on reviewer comment\n",
        "precision_values = []\n",
        "recall_values = []\n",
        "f1_values = []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1} of {n_runs}\")\n",
        "\n",
        "    program_embeddings = []\n",
        "    true_labels = []\n",
        "\n",
        "    # Measure training time for each run\n",
        "    start_training_time = time.time()\n",
        "\n",
        "    for file in java_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "            java_code = f.read()\n",
        "\n",
        "            # Get the embedding of the program by taking the mean of line embeddings\n",
        "            program_embedding = get_line_embeddings(java_code)\n",
        "            program_embeddings.append(program_embedding)\n",
        "\n",
        "            # Define true labels based on the file names\n",
        "            true_labels.append(1 if \"abstractfactory\" in file else 0)\n",
        "\n",
        "    # Convert program_embeddings to a NumPy array\n",
        "    program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "    # Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "    k = 5  # Adjust this value as needed\n",
        "    neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "    neighbors.fit(program_embeddings)\n",
        "    _, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "    # Initialize arrays to store actual and predicted labels\n",
        "    actual_labels = np.array(true_labels)\n",
        "    predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "    # Predict labels for each program\n",
        "    for i in range(len(java_files)):\n",
        "        # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "        neighbor_indices = indices[i, 1:]\n",
        "\n",
        "        # Get the labels of the neighbors\n",
        "        neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "        # Assign the majority label to the program\n",
        "        predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "        predicted_labels[i] = predicted_label\n",
        "\n",
        "    # Calculate precision, recall, and F1 score for this run\n",
        "    precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "    recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "    f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "    precision_values.append(precision)\n",
        "    recall_values.append(recall)\n",
        "    f1_values.append(f1)\n",
        "\n",
        "# Calculate mean and standard deviation for precision, recall, and F1 score\n",
        "precision_mean = np.mean(precision_values)\n",
        "recall_mean = np.mean(recall_values)\n",
        "f1_mean = np.mean(f1_values)\n",
        "\n",
        "precision_std = calculate_std(precision_values)\n",
        "recall_std = calculate_std(recall_values)\n",
        "f1_std = calculate_std(f1_values)\n",
        "\n",
        "# Print results\n",
        "print(f\"\\nMean Precision: {precision_mean:.2f} ({precision_std:.2f})\")\n",
        "print(f\"Mean Recall: {recall_mean:.2f} ({recall_std:.2f})\")\n",
        "print(f\"Mean F1 Score: {f1_mean:.2f} ({f1_std:.2f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KTiRxfcXqOe8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTiRxfcXqOe8",
        "outputId": "085fe9a9-b18d-44e1-9e0c-57c1e46bb30b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run 1 of 10\n",
            "Training (Embedding Generation) Time: 44903.97 ms\n",
            "Prediction Time: 1.49 ms\n",
            "Total Execution Time (Training + Prediction + Misc.): 44913.16 ms\n",
            "Run 2 of 10\n",
            "Training (Embedding Generation) Time: 40218.23 ms\n",
            "Prediction Time: 2.11 ms\n",
            "Total Execution Time (Training + Prediction + Misc.): 40226.85 ms\n",
            "Run 3 of 10\n",
            "Training (Embedding Generation) Time: 42333.74 ms\n",
            "Prediction Time: 2.63 ms\n",
            "Total Execution Time (Training + Prediction + Misc.): 42342.60 ms\n",
            "Run 4 of 10\n",
            "Training (Embedding Generation) Time: 39591.39 ms\n",
            "Prediction Time: 1.60 ms\n",
            "Total Execution Time (Training + Prediction + Misc.): 39601.08 ms\n",
            "Run 5 of 10\n",
            "Training (Embedding Generation) Time: 40380.98 ms\n",
            "Prediction Time: 2.48 ms\n",
            "Total Execution Time (Training + Prediction + Misc.): 40390.18 ms\n",
            "Run 6 of 10\n",
            "Training (Embedding Generation) Time: 39603.42 ms\n",
            "Prediction Time: 2.06 ms\n",
            "Total Execution Time (Training + Prediction + Misc.): 39614.12 ms\n",
            "Run 7 of 10\n",
            "Training (Embedding Generation) Time: 38297.19 ms\n",
            "Prediction Time: 2.64 ms\n",
            "Total Execution Time (Training + Prediction + Misc.): 38306.09 ms\n",
            "Run 8 of 10\n",
            "Training (Embedding Generation) Time: 40640.58 ms\n",
            "Prediction Time: 2.77 ms\n",
            "Total Execution Time (Training + Prediction + Misc.): 40648.74 ms\n",
            "Run 9 of 10\n",
            "Training (Embedding Generation) Time: 41107.14 ms\n",
            "Prediction Time: 2.00 ms\n",
            "Total Execution Time (Training + Prediction + Misc.): 41117.02 ms\n",
            "Run 10 of 10\n",
            "Training (Embedding Generation) Time: 43048.64 ms\n",
            "Prediction Time: 2.28 ms\n",
            "Total Execution Time (Training + Prediction + Misc.): 43057.81 ms\n",
            "\n",
            "Mean Precision: 0.69 (0.16)\n",
            "Mean Recall: 0.68 (0.15)\n",
            "Mean F1 Score: 0.67 (0.17)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time  # Import time for measuring execution time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import random\n",
        "\n",
        "# Function to calculate standard deviation\n",
        "def calculate_std(values):\n",
        "    return np.std(values)\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/builder\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Separate positive and negative class files\n",
        "positive_files = [file for file in java_files if \"builder\" in file.lower()]  # Positive class contains 'builder'\n",
        "negative_files = [file for file in java_files if \"builder\" not in file.lower()]  # Negative class\n",
        "\n",
        "# Running the experiment multiple times to calculate mean and standard deviation\n",
        "n_runs = 10  # Number of iterations (adjust as needed)\n",
        "precision_values = []\n",
        "recall_values = []\n",
        "f1_values = []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1} of {n_runs}\")\n",
        "\n",
        "    # Randomly sample the same number of positive and negative examples\n",
        "    num_positive = len(positive_files)\n",
        "    sampled_negative_files = random.sample(negative_files, num_positive)\n",
        "\n",
        "    sampled_files = positive_files + sampled_negative_files\n",
        "    random.shuffle(sampled_files)  # Shuffle to avoid any ordering bias\n",
        "\n",
        "    program_embeddings = []\n",
        "    true_labels = []\n",
        "\n",
        "    # Measure the total execution time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Measure the training time (embedding generation)\n",
        "    start_training_time = time.time()\n",
        "\n",
        "    for file in sampled_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "            java_code = f.read()\n",
        "\n",
        "            # Get the embedding of the program by taking the mean of line embeddings\n",
        "            program_embedding = get_line_embeddings(java_code)\n",
        "            program_embeddings.append(program_embedding)\n",
        "\n",
        "            # Define true labels (1 for positive, 0 for negative)\n",
        "            true_labels.append(1 if \"builder\" in file.lower() else 0)\n",
        "\n",
        "    # Convert program_embeddings to a NumPy array\n",
        "    program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "    # Measure the end of training time\n",
        "    end_training_time = time.time()\n",
        "    training_time_ms = (end_training_time - start_training_time) * 1000  # Convert to milliseconds\n",
        "    print(f\"Training (Embedding Generation) Time: {training_time_ms:.2f} ms\")\n",
        "\n",
        "    # Measure the prediction time\n",
        "    prediction_start_time = time.time()\n",
        "\n",
        "    # Use Nearest Neighbors to find k-nearest neighbors with Euclidean distance\n",
        "    k = 5  # Adjust this value as needed\n",
        "    neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "    neighbors.fit(program_embeddings)\n",
        "    _, indices = neighbors.kneighbors(program_embeddings)\n",
        "\n",
        "    # Initialize arrays to store actual and predicted labels\n",
        "    actual_labels = np.array(true_labels)\n",
        "    predicted_labels = np.zeros_like(actual_labels)\n",
        "\n",
        "    # Predict labels for each program\n",
        "    for i in range(len(sampled_files)):\n",
        "        # Get the indices of the k-nearest neighbors (excluding the program itself)\n",
        "        neighbor_indices = indices[i, 1:]\n",
        "\n",
        "        # Get the labels of the neighbors\n",
        "        neighbor_labels = [true_labels[idx] for idx in neighbor_indices]\n",
        "\n",
        "        # Assign the majority label to the program\n",
        "        predicted_label = max(set(neighbor_labels), key=neighbor_labels.count)\n",
        "        predicted_labels[i] = predicted_label\n",
        "\n",
        "    # Measure the end of prediction time\n",
        "    prediction_end_time = time.time()\n",
        "    prediction_time_ms = (prediction_end_time - prediction_start_time) * 1000  # Convert to milliseconds\n",
        "    print(f\"Prediction Time: {prediction_time_ms:.2f} ms\")\n",
        "\n",
        "    # Calculate precision, recall, and F1 score for this run\n",
        "    precision = precision_score(actual_labels, predicted_labels, average='weighted')\n",
        "    recall = recall_score(actual_labels, predicted_labels, average='weighted')\n",
        "    f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n",
        "\n",
        "    precision_values.append(precision)\n",
        "    recall_values.append(recall)\n",
        "    f1_values.append(f1)\n",
        "\n",
        "    # Measure total execution time (from the start of the script to the end of prediction)\n",
        "    overall_end_time = time.time()\n",
        "    execution_time_ms = (overall_end_time - start_time) * 1000  # Convert to milliseconds\n",
        "    print(f\"Total Execution Time (Training + Prediction + Misc.): {execution_time_ms:.2f} ms\")\n",
        "\n",
        "# Calculate mean and standard deviation for precision, recall, and F1 score\n",
        "precision_mean = np.mean(precision_values)\n",
        "recall_mean = np.mean(recall_values)\n",
        "f1_mean = np.mean(f1_values)\n",
        "\n",
        "precision_std = calculate_std(precision_values)\n",
        "recall_std = calculate_std(recall_values)\n",
        "f1_std = calculate_std(f1_values)\n",
        "\n",
        "# Print results\n",
        "print(f\"\\nMean Precision: {precision_mean:.2f} ({precision_std:.2f})\")\n",
        "print(f\"Mean Recall: {recall_mean:.2f} ({recall_std:.2f})\")\n",
        "print(f\"Mean F1 Score: {f1_mean:.2f} ({f1_std:.2f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FpEpu76TuQHS",
      "metadata": {
        "id": "FpEpu76TuQHS"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "# Replace 'your_directory_path' with the path to the directory you want to delete\n",
        "shutil.rmtree('/content/builder')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rWMuPVADvRWs",
      "metadata": {
        "id": "rWMuPVADvRWs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "kNWnbirhS8UJ",
      "metadata": {
        "id": "kNWnbirhS8UJ"
      },
      "source": [
        "**Builder, standard deviation, training time, prediction time, calculation. **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GTt9bISqTFeP",
      "metadata": {
        "id": "GTt9bISqTFeP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "NqzT0QqmV5fk",
      "metadata": {
        "id": "NqzT0QqmV5fk"
      },
      "source": [
        "**Builder, standard deviation, training and prediction time.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h3riYf7GghTV",
      "metadata": {
        "id": "h3riYf7GghTV"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "# Replace 'your_directory_path' with the path to the directory you want to delete\n",
        "shutil.rmtree('/content/builder')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rS8Lb_2mghuz",
      "metadata": {
        "id": "rS8Lb_2mghuz"
      },
      "source": [
        "**Singleton, standard deviation, training and prediction time**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf-aclPYp2gl",
      "metadata": {
        "id": "cf-aclPYp2gl"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "# Replace 'your_directory_path' with the path to the directory you want to delete\n",
        "shutil.rmtree('/content/abstractfactory')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7d80RbOpnVt",
      "metadata": {
        "id": "f7d80RbOpnVt"
      },
      "source": [
        "**Prototype, Standard deviation, training, prediction time**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GfuBCNFrHkQx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7336432d80384668826b9279569c0543",
            "10ee323ae58d49428e366c4af4ab9bc0",
            "32bc5c5340704cf68235c7b4a60c4af8",
            "7b5aeacb69504fd5b0b256383ea760d9",
            "51142c1e4645497a90320a305f4b3afa",
            "14ce7c527bd541fc953083c594f018ad",
            "911a56063607445a974c5dd56482a384",
            "ccfdc74ef5804069bb3ee8ae4d09317f",
            "c8e4a72ff0664b63aa8c987e96de8f77",
            "f343fe0262554ab180db6cf31292baab",
            "4b8be88f2a954087966f029db2821a74",
            "4295a6b783d54133a0a8b807be6dde90",
            "c5720d248302470b8e72c1a031b0e998",
            "ed46271c45c04aa5a717c5714e0afbf4",
            "c8f394a0f46c417aa3290e7911c626b9",
            "d39307d1bbfe4fa19e7c6f9ab8042839",
            "92cee2e178734e4bba2a67b88050ceda",
            "629ce8f25ffe4d9cb9af68d2ca3b32c6",
            "5dcd0b80cbc34d248cc2b2c8f1fca86f",
            "0284e8b309cb4e2e84a50403e52c16ea",
            "c4794e622b7245faba495dc5c3310462",
            "efd090c235af4310bfc09e2a5e7eaa60",
            "c3e700adec0a43e29e2226464d254b9d",
            "97c17e16f9884cd0a03d2eded1f17343",
            "4fa03cf6f4374ad3838f4a6c0f9cc35d",
            "2a0b1db7882f41a9825ee8803ae0951e",
            "d0136c3a1c4a459c8cdb5005d5dec5b4",
            "4351a6283b944122bae8c13f5dd07ea8",
            "c781762da4d740a2b3eb166604f90363",
            "1d1d205e469a441a8b6a7d422515fd0b",
            "0fd608a251ed4aa9bd82a4f6bddb2c1a",
            "88d97757387a4b24897f0f044ec917c9",
            "59248e8e53624305831b105fbd3af11b",
            "3f3c928c8d4140109d48c829d8a07f28",
            "30bc0eb0200f4d53b4007995400cab2c",
            "5425e68cd43e40aeb9d0c8a4dddfe540",
            "f8b70bd2a35541e3a5092fdf7c36f26a",
            "dd103126c255416fa1d2684d22444905",
            "dd7370827b5b46e2aa0cc69af63b7f2f",
            "7214cc8402734543a9eb243f52e7d68b",
            "39f8927a5dc7458c8a757e8d69444eb0",
            "c06497a110f54340bd3cc1b6f82714db",
            "eaf10da8ca16499898ef0f215e007442",
            "4af8c3e908904ba6a772c6a155e9be4f",
            "65952686c34c4cfbb4c486eca6afa94f",
            "216e7da312854afda80751902a16677a",
            "7816ea804e694fa59a70cd26bac8a275",
            "f9cb5ce7bb18448a85ae6d787e03b53e",
            "c2ca2ab888f84e818c169df0b96c99d6",
            "0d5d7338abb340909a44ac9d885d6ae7",
            "81365792e7914a768cc03b10176c6715",
            "6990e39445a64aee96b5a4f0749d44e1",
            "5c36c84991444303836dea1b0e1826c1",
            "89fa6068625a48e79585a92d039d2dcf",
            "c721624e54354fa6aa6ab31cf1ce8a21",
            "8608e39b99444ee5b762fc08976a2009",
            "f24a994f5114468b806182c50dc772cd",
            "7379734af4374bc291f024b587fc5ad8",
            "9253ccc9e9e24b06b00e0e0f6bbbf807",
            "d3040754a6e64f87b6d8525c755dfbb0",
            "ee90589f4d7f4fbd8231da6415f9a9a6",
            "ee027706919c48a18046a28b7efa6e4b",
            "fba4e2a5da524d16b13f6ec665e6a884",
            "166e55b110a540e9baca46a65e51fa22",
            "697fc57370414df4906ff6519123f1ae",
            "02a3f0d2a9b94440b0b8d757e66002a0"
          ]
        },
        "id": "GfuBCNFrHkQx",
        "outputId": "fcb40be6-eed9-4fac-9899-762af74bbc80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7336432d80384668826b9279569c0543",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4295a6b783d54133a0a8b807be6dde90",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3e700adec0a43e29e2226464d254b9d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f3c928c8d4140109d48c829d8a07f28",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65952686c34c4cfbb4c486eca6afa94f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8608e39b99444ee5b762fc08976a2009",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run 1 of 10\n",
            "Training Time: 240561430.45 s\n",
            "Prediction Time: 35944344.04 s\n",
            "Run 2 of 10\n",
            "Training Time: 191370008.95 s\n",
            "Prediction Time: 36532283.07 s\n",
            "Run 3 of 10\n",
            "Training Time: 193706413.03 s\n",
            "Prediction Time: 37385383.61 s\n",
            "Run 4 of 10\n",
            "Training Time: 194883079.05 s\n",
            "Prediction Time: 35712990.76 s\n",
            "Run 5 of 10\n",
            "Training Time: 197637397.77 s\n",
            "Prediction Time: 35947496.18 s\n",
            "Run 6 of 10\n",
            "Training Time: 192753757.00 s\n",
            "Prediction Time: 37557792.90 s\n",
            "Run 7 of 10\n",
            "Training Time: 192721746.44 s\n",
            "Prediction Time: 36144608.50 s\n",
            "Run 8 of 10\n",
            "Training Time: 193289364.81 s\n",
            "Prediction Time: 35217309.95 s\n",
            "Run 9 of 10\n",
            "Training Time: 192718112.95 s\n",
            "Prediction Time: 35259389.40 s\n",
            "Run 10 of 10\n",
            "Training Time: 192065253.73 s\n",
            "Prediction Time: 35281665.33 s\n",
            "\n",
            "Mean Precision: 1.00 (0.00)\n",
            "Mean Recall: 1.00 (0.00)\n",
            "Mean F1 Score: 1.00 (0.00)\n",
            "Average Training Time: 198170656.42 s\n",
            "Average Prediction Time: 36098326.37 s\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Function to calculate standard deviation\n",
        "def calculate_std(values):\n",
        "    return np.std(values)\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/prototype\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Running the experiment multiple times to calculate mean and standard deviation\n",
        "n_runs = 10  # Change this value to 10-30 based on reviewer comment\n",
        "precision_values = []\n",
        "recall_values = []\n",
        "f1_values = []\n",
        "training_times = []\n",
        "prediction_times = []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1} of {n_runs}\")\n",
        "\n",
        "    program_embeddings = []\n",
        "    true_labels = []\n",
        "\n",
        "    # Measure training time for each run\n",
        "    start_training_time = time.time()\n",
        "\n",
        "    for file in java_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "            java_code = f.read()\n",
        "\n",
        "            # Get the embedding of the program by taking the mean of line embeddings\n",
        "            program_embedding = get_line_embeddings(java_code)\n",
        "            program_embeddings.append(program_embedding)\n",
        "\n",
        "            # Define true labels based on the file names\n",
        "            true_labels.append(1 if \"prototype\" in file else 0)\n",
        "\n",
        "    # Convert program_embeddings to a NumPy array\n",
        "    program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "    # Measure end of training time\n",
        "    end_training_time = time.time()\n",
        "    training_time_us = (end_training_time - start_training_time) * 1_000_000  # Convert to microseconds\n",
        "    training_times.append(training_time_us)\n",
        "    print(f\"Training Time: {training_time_us:.2f} s\")\n",
        "\n",
        "    # Train the k-NN model\n",
        "    k = 5  # Adjust this value as needed\n",
        "    knn_model = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
        "    knn_model.fit(program_embeddings, true_labels)\n",
        "\n",
        "    # Measure prediction time for unseen examples\n",
        "    unseen_code_dir = \"/content/unseen_examples\"\n",
        "    unseen_files = [file for file in os.listdir(unseen_code_dir) if os.path.isfile(os.path.join(unseen_code_dir, file))]\n",
        "    unseen_embeddings = []\n",
        "    actual_unseen_labels = []\n",
        "\n",
        "    start_prediction_time = time.time()\n",
        "\n",
        "    for file in unseen_files:\n",
        "        with open(os.path.join(unseen_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "            unseen_code = f.read()\n",
        "\n",
        "            # Get the embedding of the unseen program\n",
        "            unseen_embedding = get_line_embeddings(unseen_code)\n",
        "            unseen_embeddings.append(unseen_embedding)\n",
        "\n",
        "            # Determine actual label for unseen file\n",
        "            actual_unseen_labels.append(1 if \"prototype\" in file else 0)\n",
        "\n",
        "    # Convert unseen_embeddings to a NumPy array\n",
        "    unseen_embeddings = np.array(unseen_embeddings)\n",
        "\n",
        "    # Predict using the trained k-NN model\n",
        "    unseen_predictions = knn_model.predict(unseen_embeddings)\n",
        "\n",
        "    # Measure end of prediction time\n",
        "    end_prediction_time = time.time()\n",
        "    prediction_time_us = (end_prediction_time - start_prediction_time) * 1_000_000  # Convert to microseconds\n",
        "    prediction_times.append(prediction_time_us)\n",
        "    print(f\"Prediction Time: {prediction_time_us:.2f} s\")\n",
        "\n",
        "    # Calculate precision, recall, and F1 score for this run\n",
        "    precision = precision_score(actual_unseen_labels, unseen_predictions, average='weighted')\n",
        "    recall = recall_score(actual_unseen_labels, unseen_predictions, average='weighted')\n",
        "    f1 = f1_score(actual_unseen_labels, unseen_predictions, average='weighted')\n",
        "\n",
        "    precision_values.append(precision)\n",
        "    recall_values.append(recall)\n",
        "    f1_values.append(f1)\n",
        "\n",
        "# Calculate mean and standard deviation for precision, recall, and F1 score\n",
        "precision_mean = np.mean(precision_values)\n",
        "recall_mean = np.mean(recall_values)\n",
        "f1_mean = np.mean(f1_values)\n",
        "\n",
        "precision_std = calculate_std(precision_values)\n",
        "recall_std = calculate_std(recall_values)\n",
        "f1_std = calculate_std(f1_values)\n",
        "\n",
        "# Calculate mean training and prediction times\n",
        "mean_training_time = np.mean(training_times)\n",
        "mean_prediction_time = np.mean(prediction_times)\n",
        "\n",
        "# Print results\n",
        "print(f\"\\nMean Precision: {precision_mean:.2f} ({precision_std:.2f})\")\n",
        "print(f\"Mean Recall: {recall_mean:.2f} ({recall_std:.2f})\")\n",
        "print(f\"Mean F1 Score: {f1_mean:.2f} ({f1_std:.2f})\")\n",
        "print(f\"Average Training Time: {mean_training_time:.2f} s\")\n",
        "print(f\"Average Prediction Time: {mean_prediction_time:.2f} s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "O5TQ_xcb5PQH",
      "metadata": {
        "id": "O5TQ_xcb5PQH"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "# Replace 'your_directory_path' with the path to the directory you want to delete\n",
        "shutil.rmtree('/content/prototype')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oJaTBGymCYEJ",
      "metadata": {
        "id": "oJaTBGymCYEJ"
      },
      "source": [
        "**Abstract Factory, standard deviation, training and prediction time**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bZ2cVBvCdGz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bZ2cVBvCdGz",
        "outputId": "1dc668df-e3c1-417f-d20e-74792309e220"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run 1 of 10\n",
            "Training Time: 257003367.19 s\n",
            "Prediction Time: 34014872.79 s\n",
            "Run 2 of 10\n",
            "Training Time: 199426365.14 s\n",
            "Prediction Time: 33852863.55 s\n",
            "Run 3 of 10\n",
            "Training Time: 196936414.00 s\n",
            "Prediction Time: 33206935.41 s\n",
            "Run 4 of 10\n",
            "Training Time: 197287678.24 s\n",
            "Prediction Time: 32533573.87 s\n",
            "Run 5 of 10\n",
            "Training Time: 199120414.97 s\n",
            "Prediction Time: 33882512.33 s\n",
            "Run 6 of 10\n",
            "Training Time: 198061966.90 s\n",
            "Prediction Time: 32871681.69 s\n",
            "Run 7 of 10\n",
            "Training Time: 196410015.11 s\n",
            "Prediction Time: 33240006.69 s\n",
            "Run 8 of 10\n",
            "Training Time: 194554972.41 s\n",
            "Prediction Time: 33758576.87 s\n",
            "Run 9 of 10\n",
            "Training Time: 196183451.89 s\n",
            "Prediction Time: 32735865.83 s\n",
            "Run 10 of 10\n",
            "Training Time: 196415236.95 s\n",
            "Prediction Time: 32641507.63 s\n",
            "\n",
            "Mean Precision: 1.00 (0.00)\n",
            "Mean Recall: 1.00 (0.00)\n",
            "Mean F1 Score: 1.00 (0.00)\n",
            "Average Training Time: 203139988.28 s\n",
            "Average Prediction Time: 33273839.66 s\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Function to calculate standard deviation\n",
        "def calculate_std(values):\n",
        "    return np.std(values)\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/abstractfactory\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Running the experiment multiple times to calculate mean and standard deviation\n",
        "n_runs = 10  # Change this value to 10-30 based on reviewer comment\n",
        "precision_values = []\n",
        "recall_values = []\n",
        "f1_values = []\n",
        "training_times = []\n",
        "prediction_times = []\n",
        "\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1} of {n_runs}\")\n",
        "\n",
        "    program_embeddings = []\n",
        "    true_labels = []\n",
        "\n",
        "    # Measure training time for each run\n",
        "    start_training_time = time.time()\n",
        "\n",
        "    for file in java_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "            java_code = f.read()\n",
        "\n",
        "            # Get the embedding of the program by taking the mean of line embeddings\n",
        "            program_embedding = get_line_embeddings(java_code)\n",
        "            program_embeddings.append(program_embedding)\n",
        "\n",
        "            # Define true labels based on the file names\n",
        "            true_labels.append(1 if \"abstractfactory\" in file else 0)\n",
        "\n",
        "    # Convert program_embeddings to a NumPy array\n",
        "    program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "    # Measure end of training time\n",
        "    end_training_time = time.time()\n",
        "    training_time_us = (end_training_time - start_training_time) * 1_000_000  # Convert to microseconds\n",
        "    training_times.append(training_time_us)\n",
        "    print(f\"Training Time: {training_time_us:.2f} s\")\n",
        "\n",
        "    # Train the k-NN model\n",
        "    k = 5  # Adjust this value as needed\n",
        "    knn_model = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
        "    knn_model.fit(program_embeddings, true_labels)\n",
        "\n",
        "    # Measure prediction time for unseen examples\n",
        "    unseen_code_dir = \"/content/unseen_examples\"\n",
        "    unseen_files = [file for file in os.listdir(unseen_code_dir) if os.path.isfile(os.path.join(unseen_code_dir, file))]\n",
        "    unseen_embeddings = []\n",
        "    actual_unseen_labels = []\n",
        "\n",
        "    start_prediction_time = time.time()\n",
        "\n",
        "    for file in unseen_files:\n",
        "        with open(os.path.join(unseen_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "            unseen_code = f.read()\n",
        "\n",
        "            # Get the embedding of the unseen program\n",
        "            unseen_embedding = get_line_embeddings(unseen_code)\n",
        "            unseen_embeddings.append(unseen_embedding)\n",
        "\n",
        "            # Determine actual label for unseen file\n",
        "            actual_unseen_labels.append(1 if \"abstractfactory\" in file else 0)\n",
        "\n",
        "    # Convert unseen_embeddings to a NumPy array\n",
        "    unseen_embeddings = np.array(unseen_embeddings)\n",
        "\n",
        "    # Predict using the trained k-NN model\n",
        "    unseen_predictions = knn_model.predict(unseen_embeddings)\n",
        "\n",
        "    # Measure end of prediction time\n",
        "    end_prediction_time = time.time()\n",
        "    prediction_time_us = (end_prediction_time - start_prediction_time) * 1_000_000  # Convert to microseconds\n",
        "    prediction_times.append(prediction_time_us)\n",
        "    print(f\"Prediction Time: {prediction_time_us:.2f} s\")\n",
        "\n",
        "    # Calculate precision, recall, and F1 score for this run\n",
        "    precision = precision_score(actual_unseen_labels, unseen_predictions, average='weighted')\n",
        "    recall = recall_score(actual_unseen_labels, unseen_predictions, average='weighted')\n",
        "    f1 = f1_score(actual_unseen_labels, unseen_predictions, average='weighted')\n",
        "\n",
        "    precision_values.append(precision)\n",
        "    recall_values.append(recall)\n",
        "    f1_values.append(f1)\n",
        "\n",
        "# Calculate mean and standard deviation for precision, recall, and F1 score\n",
        "precision_mean = np.mean(precision_values)\n",
        "recall_mean = np.mean(recall_values)\n",
        "f1_mean = np.mean(f1_values)\n",
        "\n",
        "precision_std = calculate_std(precision_values)\n",
        "recall_std = calculate_std(recall_values)\n",
        "f1_std = calculate_std(f1_values)\n",
        "\n",
        "# Calculate mean training and prediction times\n",
        "mean_training_time = np.mean(training_times)\n",
        "mean_prediction_time = np.mean(prediction_times)\n",
        "\n",
        "# Print results\n",
        "print(f\"\\nMean Precision: {precision_mean:.2f} ({precision_std:.2f})\")\n",
        "print(f\"Mean Recall: {recall_mean:.2f} ({recall_std:.2f})\")\n",
        "print(f\"Mean F1 Score: {f1_mean:.2f} ({f1_std:.2f})\")\n",
        "print(f\"Average Training Time: {mean_training_time:.2f} s\")\n",
        "print(f\"Average Prediction Time: {mean_prediction_time:.2f} s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PGYpnzhYDGHL",
      "metadata": {
        "id": "PGYpnzhYDGHL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "QIyxEDjFNLtf",
      "metadata": {
        "id": "QIyxEDjFNLtf"
      },
      "source": [
        "**Prototype, standard deviation, trainig and prediction time**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CJlFWgdJNPhE",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJlFWgdJNPhE",
        "outputId": "0cce3c4b-6f8c-42a8-ed0d-457e7e0a28d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run 1 of 10\n",
            "Training Time: 76869552.37 s\n",
            "Prediction Time: 35232166.29 s\n",
            "Run 2 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Time: 74843153.00 s\n",
            "Prediction Time: 35096647.02 s\n",
            "Run 3 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Time: 74652920.48 s\n",
            "Prediction Time: 34395047.19 s\n",
            "Run 4 of 10\n",
            "Training Time: 68952471.02 s\n",
            "Prediction Time: 35224160.91 s\n",
            "Run 5 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Time: 74231107.23 s\n",
            "Prediction Time: 34848834.28 s\n",
            "Run 6 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Time: 70359312.30 s\n",
            "Prediction Time: 35238266.47 s\n",
            "Run 7 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Time: 70702712.77 s\n",
            "Prediction Time: 35006199.60 s\n",
            "Run 8 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Time: 67310615.30 s\n",
            "Prediction Time: 35104659.80 s\n",
            "Run 9 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Time: 77915308.71 s\n",
            "Prediction Time: 34912229.78 s\n",
            "Run 10 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Time: 74883178.95 s\n",
            "Prediction Time: 35033620.36 s\n",
            "\n",
            "Mean Precision: 0.37 (0.23)\n",
            "Mean Recall: 0.55 (0.10)\n",
            "Mean F1 Score: 0.41 (0.16)\n",
            "Average Training Time: 73072033.21 s\n",
            "Average Prediction Time: 35009183.17 s\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Function to calculate standard deviation\n",
        "def calculate_std(values):\n",
        "    return np.std(values)\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/prototype\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Running the experiment multiple times to calculate mean and standard deviation\n",
        "n_runs = 10  # Change this value to 10-30 based on reviewer comment\n",
        "precision_values = []\n",
        "recall_values = []\n",
        "f1_values = []\n",
        "training_times = []\n",
        "prediction_times = []\n",
        "\n",
        "# Splitting files into positive and negative\n",
        "positive_files = [file for file in java_files if \"prototype\" in file]  # Positive examples\n",
        "negative_files = [file for file in java_files if \"prototype\" not in file]  # Negative examples\n",
        "n_positive = len(positive_files)\n",
        "\n",
        "# Running multiple experiments\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1} of {n_runs}\")\n",
        "\n",
        "    program_embeddings = []\n",
        "    true_labels = []\n",
        "\n",
        "    # Adjusting the ratio of positive to negative examples (40%-60% range)\n",
        "    n_negative_required = int(np.random.uniform(0.4, 0.6) * n_positive)  # Randomly select within the 40%-60% range\n",
        "    negative_subset = np.random.choice(negative_files, n_negative_required, replace=False)\n",
        "\n",
        "    # Combine the positive and randomly selected negative files\n",
        "    selected_files = positive_files + list(negative_subset)\n",
        "\n",
        "    # Measure training time for each run\n",
        "    start_training_time = time.time()\n",
        "\n",
        "    for file in selected_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "            java_code = f.read()\n",
        "\n",
        "            # Get the embedding of the program by taking the mean of line embeddings\n",
        "            program_embedding = get_line_embeddings(java_code)\n",
        "            program_embeddings.append(program_embedding)\n",
        "\n",
        "            # Define true labels based on the file names\n",
        "            true_labels.append(1 if \"prototype\" in file else 0)\n",
        "\n",
        "    # Convert program_embeddings to a NumPy array\n",
        "    program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "    # Measure end of training time\n",
        "    end_training_time = time.time()\n",
        "    training_time_us = (end_training_time - start_training_time) * 1_000_000  # Convert to microseconds\n",
        "    training_times.append(training_time_us)\n",
        "    print(f\"Training Time: {training_time_us:.2f} s\")\n",
        "\n",
        "    # Train the k-NN model\n",
        "    k = 3  # Adjust this value as needed\n",
        "    knn_model = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
        "    knn_model.fit(program_embeddings, true_labels)\n",
        "\n",
        "    # Measure prediction time for unseen examples\n",
        "    unseen_code_dir = \"/content/unseen_examples\"\n",
        "    unseen_files = [file for file in os.listdir(unseen_code_dir) if os.path.isfile(os.path.join(unseen_code_dir, file))]\n",
        "    unseen_embeddings = []\n",
        "    actual_unseen_labels = []\n",
        "\n",
        "    start_prediction_time = time.time()\n",
        "\n",
        "    for file in unseen_files:\n",
        "        with open(os.path.join(unseen_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "            unseen_code = f.read()\n",
        "\n",
        "            # Get the embedding of the unseen program\n",
        "            unseen_embedding = get_line_embeddings(unseen_code)\n",
        "            unseen_embeddings.append(unseen_embedding)\n",
        "\n",
        "            # Determine actual label for unseen file\n",
        "            actual_unseen_labels.append(1 if \"prototype\" in file else 0)\n",
        "\n",
        "    # Convert unseen_embeddings to a NumPy array\n",
        "    unseen_embeddings = np.array(unseen_embeddings)\n",
        "\n",
        "    # Predict using the trained k-NN model\n",
        "    unseen_predictions = knn_model.predict(unseen_embeddings)\n",
        "\n",
        "    # Measure end of prediction time\n",
        "    end_prediction_time = time.time()\n",
        "    prediction_time_us = (end_prediction_time - start_prediction_time) * 1_000_000  # Convert to microseconds\n",
        "    prediction_times.append(prediction_time_us)\n",
        "    print(f\"Prediction Time: {prediction_time_us:.2f} s\")\n",
        "\n",
        "    # Calculate precision, recall, and F1 score for this run\n",
        "    precision = precision_score(actual_unseen_labels, unseen_predictions, average='weighted')\n",
        "    recall = recall_score(actual_unseen_labels, unseen_predictions, average='weighted')\n",
        "    f1 = f1_score(actual_unseen_labels, unseen_predictions, average='weighted')\n",
        "\n",
        "    precision_values.append(precision)\n",
        "    recall_values.append(recall)\n",
        "    f1_values.append(f1)\n",
        "\n",
        "# Calculate mean and standard deviation for precision, recall, and F1 score\n",
        "precision_mean = np.mean(precision_values)\n",
        "recall_mean = np.mean(recall_values)\n",
        "f1_mean = np.mean(f1_values)\n",
        "\n",
        "precision_std = calculate_std(precision_values)\n",
        "recall_std = calculate_std(recall_values)\n",
        "f1_std = calculate_std(f1_values)\n",
        "\n",
        "# Calculate mean training and prediction times\n",
        "mean_training_time = np.mean(training_times)\n",
        "mean_prediction_time = np.mean(prediction_times)\n",
        "\n",
        "# Print results\n",
        "print(f\"\\nMean Precision: {precision_mean:.2f} ({precision_std:.2f})\")\n",
        "print(f\"Mean Recall: {recall_mean:.2f} ({recall_std:.2f})\")\n",
        "print(f\"Mean F1 Score: {f1_mean:.2f} ({f1_std:.2f})\")\n",
        "print(f\"Average Training Time: {mean_training_time:.2f} s\")\n",
        "print(f\"Average Prediction Time: {mean_prediction_time:.2f} s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "CQoYp8hUNluJ",
      "metadata": {
        "id": "CQoYp8hUNluJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "304d0205a97e4835af97afce247b8cba",
            "a3257db4c79e40b086254cee0b0030c4",
            "312d0b961f0e4ead8987ceaa323c8c8f",
            "1d39eaed3b984da485ab7c1e7ef1b706",
            "5ea812ee74cc42d7bf16c2c021f03e04",
            "87a4392d0bb1472dacc0e1012d94d97b",
            "a27c5f6f35b64da3837eaee6255f6a64",
            "e10aaae7d89f47d6a885ee6cd0d31ebd",
            "543dbe34722b421ca22b52526a924278",
            "430074bb131447c2b4cfdecba5a97102",
            "d2cb318c6e364268a684b43c20a238aa",
            "ef18829198b8443c9a5937b9171f91d7",
            "db67fb211aa4448595f5d47c03c44edb",
            "c250b5b0a4b14856854fabf653f1bece",
            "567393e53c4e4e8491ff5936898d6299",
            "6bfc117deeb14040bf3f730850eab1fa",
            "32fe9383d7844504ad7fdd7474c0477b",
            "1b4b030f93c8491197f1a8dd7592e11f",
            "f060b65afa974b27be070d9d0a9a23a2",
            "c06fe36eee7b4c88ae842a367bb594b9",
            "4ecc06638f24481e9a138e9ebfb85fd3",
            "4b7d30dda1574d98ad307186994fa871",
            "0ee13e0fb1b940bd81eeb8331bef5a13",
            "b548e0297d0b4d93bc1ff2627f4ee967",
            "063103c456164bd5b5c86606d159a533",
            "f9f7144b91eb4dbca9e842feea9b92c7",
            "3106210ff05443158eb143b4e3d1f2e4",
            "0bb5a3d252b945c49707e3a4ec318c94",
            "9d1f86017c794e07bae7284346927284",
            "9d042c2ebae94488902b330de25da690",
            "54038cfcd84646b3b9f28c2dd6579c14",
            "3f46538ff4834a8288412077ec53cafa",
            "24354da991024f6fb14e477998265a1e",
            "1269e7f9016f445da176796dc85dda3a",
            "cb5d65d032c7468295395ce5a2467c59",
            "bf2f6004de6d447a96f5291de6656808",
            "7b5875d490f2495abe37adf1c6b6cf76",
            "43c3a1f38dbd47a3a7ad9bff6040464a",
            "02dca7172424490eb58fb56d229881b8",
            "85f989f4aa6c4c2a8b92184ceec02926",
            "8c8f1a5d9d094ac6b40479ea75b04c2c",
            "0d49d3264fff4bcaab9429575c885aa3",
            "cec81927adb246aeaacaed5ec9090b1c",
            "b3a41c064f6249eb833ff1ad771ae630",
            "66d8668b514442efb2c12e49854ff8fb",
            "3a80f92e0e77492c945311479cd65ddc",
            "c724f84aba1a4650941c5e5cee00cdab",
            "a41bff20374b404788ace95f515f1219",
            "eb3c6842afd848e0b3ae75b884b655fd",
            "ad1e90b582274698babac70d20e924a9",
            "947746437b014c43aa70737ff72eae2e",
            "83863989411c4702a62813fa2dbcc301",
            "411a1ea2bc6948119c0879d39cad7655",
            "74a415293b154600bb605da011b8cd1b",
            "f2c9b9377ebb47398eddabdf2aad9645",
            "ac389584aa3d4a669c0f5aa11c465048",
            "e8092290f706423e9467dd1fa2f7671d",
            "2326ac5a4d22410f978034a0de9fac9b",
            "b89f9112be314ea5972778fb7ddc92f3",
            "b6ff54d66ebb438493f35d800435b0e6",
            "84b2b9b4a9ab46f499f84888bdb0eab8",
            "13a3dd1bc47f4d8093b7401817de08fd",
            "982a58aa72e548dc918d98fb345ebaf6",
            "dca1ac8884fb48c38e024ae815c8b09d",
            "290a189e35254ec5b8167a04e8e9260a",
            "f49817ec745042f99df030bb549af1c7"
          ]
        },
        "outputId": "1b269757-ab2f-4fa5-ef7c-53287832efc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "304d0205a97e4835af97afce247b8cba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef18829198b8443c9a5937b9171f91d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ee13e0fb1b940bd81eeb8331bef5a13"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1269e7f9016f445da176796dc85dda3a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66d8668b514442efb2c12e49854ff8fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac389584aa3d4a669c0f5aa11c465048"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1 of 10\n",
            "Training Time: 71377459.76 s\n",
            "Prediction Time: 38948717.59 s\n",
            "Run 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time: 70794164.90 s\n",
            "Prediction Time: 39073465.59 s\n",
            "Run 3 of 10\n",
            "Training Time: 67992859.36 s\n",
            "Prediction Time: 39584215.40 s\n",
            "Run 4 of 10\n",
            "Training Time: 74977650.88 s\n",
            "Prediction Time: 41883585.69 s\n",
            "Run 5 of 10\n",
            "Training Time: 73859887.60 s\n",
            "Prediction Time: 41730218.41 s\n",
            "Run 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time: 72886330.37 s\n",
            "Prediction Time: 42508701.80 s\n",
            "Run 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time: 76345578.19 s\n",
            "Prediction Time: 41499898.43 s\n",
            "Run 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time: 73192703.25 s\n",
            "Prediction Time: 41469253.06 s\n",
            "Run 9 of 10\n",
            "Training Time: 74158991.10 s\n",
            "Prediction Time: 40472797.39 s\n",
            "Run 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Time: 74637725.11 s\n",
            "Prediction Time: 39686716.56 s\n",
            "\n",
            "Mean Precision: 0.22 (0.04)\n",
            "Mean Recall: 0.40 (0.12)\n",
            "Mean F1 Score: 0.28 (0.07)\n",
            "Average Training Time: 73022335.05 s\n",
            "Average Prediction Time: 40685756.99 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Function to calculate standard deviation\n",
        "def calculate_std(values):\n",
        "    return np.std(values)\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/singleton\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    return np.mean(line_embeddings, axis=0)\n",
        "\n",
        "# Running the experiment multiple times to calculate mean and standard deviation\n",
        "n_runs = 10  # Change this value to 10-30 based on reviewer comment\n",
        "precision_values = []\n",
        "recall_values = []\n",
        "f1_values = []\n",
        "training_times = []\n",
        "prediction_times = []\n",
        "\n",
        "# Splitting files into positive and negative\n",
        "positive_files = [file for file in java_files if \"singleton\" in file]  # Positive examples\n",
        "negative_files = [file for file in java_files if \"singleton\" not in file]  # Negative examples\n",
        "n_positive = len(positive_files)\n",
        "\n",
        "# Running multiple experiments\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1} of {n_runs}\")\n",
        "\n",
        "    program_embeddings = []\n",
        "    true_labels = []\n",
        "\n",
        "    # Adjusting the ratio of positive to negative examples (40%-60% range)\n",
        "    n_negative_required = int(np.random.uniform(0.4, 0.6) * n_positive)  # Randomly select within the 40%-60% range\n",
        "    negative_subset = np.random.choice(negative_files, n_negative_required, replace=False)\n",
        "\n",
        "    # Combine the positive and randomly selected negative files\n",
        "    selected_files = positive_files + list(negative_subset)\n",
        "\n",
        "    # Measure training time for each run\n",
        "    start_training_time = time.time()\n",
        "\n",
        "    for file in selected_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "            java_code = f.read()\n",
        "\n",
        "            # Get the embedding of the program by taking the mean of line embeddings\n",
        "            program_embedding = get_line_embeddings(java_code)\n",
        "            program_embeddings.append(program_embedding)\n",
        "\n",
        "            # Define true labels based on the file names\n",
        "            true_labels.append(1 if \"singleton\" in file else 0)\n",
        "\n",
        "    # Convert program_embeddings to a NumPy array\n",
        "    program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "    # Measure end of training time\n",
        "    end_training_time = time.time()\n",
        "    training_time_us = (end_training_time - start_training_time) * 1_000_000  # Convert to microseconds\n",
        "    training_times.append(training_time_us)\n",
        "    print(f\"Training Time: {training_time_us:.2f} s\")\n",
        "\n",
        "    # Train the k-NN model\n",
        "    k = 3 # Adjust this value as needed\n",
        "    knn_model = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
        "    knn_model.fit(program_embeddings, true_labels)\n",
        "\n",
        "    # Measure prediction time for unseen examples\n",
        "    unseen_code_dir = \"/content/unseen_examples\"\n",
        "    unseen_files = [file for file in os.listdir(unseen_code_dir) if os.path.isfile(os.path.join(unseen_code_dir, file))]\n",
        "    unseen_embeddings = []\n",
        "    actual_unseen_labels = []\n",
        "\n",
        "    start_prediction_time = time.time()\n",
        "\n",
        "    for file in unseen_files:\n",
        "        with open(os.path.join(unseen_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "            unseen_code = f.read()\n",
        "\n",
        "            # Get the embedding of the unseen program\n",
        "            unseen_embedding = get_line_embeddings(unseen_code)\n",
        "            unseen_embeddings.append(unseen_embedding)\n",
        "\n",
        "            # Determine actual label for unseen file\n",
        "            actual_unseen_labels.append(1 if \"singleton\" in file else 0)\n",
        "\n",
        "    # Convert unseen_embeddings to a NumPy array\n",
        "    unseen_embeddings = np.array(unseen_embeddings)\n",
        "\n",
        "    # Predict using the trained k-NN model\n",
        "    unseen_predictions = knn_model.predict(unseen_embeddings)\n",
        "\n",
        "    # Measure end of prediction time\n",
        "    end_prediction_time = time.time()\n",
        "    prediction_time_us = (end_prediction_time - start_prediction_time) * 1_000_000  # Convert to microseconds\n",
        "    prediction_times.append(prediction_time_us)\n",
        "    print(f\"Prediction Time: {prediction_time_us:.2f} s\")\n",
        "\n",
        "    # Calculate precision, recall, and F1 score for this run\n",
        "    precision = precision_score(actual_unseen_labels, unseen_predictions, average='weighted')\n",
        "    recall = recall_score(actual_unseen_labels, unseen_predictions, average='weighted')\n",
        "    f1 = f1_score(actual_unseen_labels, unseen_predictions, average='weighted')\n",
        "\n",
        "    precision_values.append(precision)\n",
        "    recall_values.append(recall)\n",
        "    f1_values.append(f1)\n",
        "\n",
        "# Calculate mean and standard deviation for precision, recall, and F1 score\n",
        "precision_mean = np.mean(precision_values)\n",
        "recall_mean = np.mean(recall_values)\n",
        "f1_mean = np.mean(f1_values)\n",
        "\n",
        "precision_std = calculate_std(precision_values)\n",
        "recall_std = calculate_std(recall_values)\n",
        "f1_std = calculate_std(f1_values)\n",
        "\n",
        "# Calculate mean training and prediction times\n",
        "mean_training_time = np.mean(training_times)\n",
        "mean_prediction_time = np.mean(prediction_times)\n",
        "\n",
        "# Print results\n",
        "print(f\"\\nMean Precision: {precision_mean:.2f} ({precision_std:.2f})\")\n",
        "print(f\"Mean Recall: {recall_mean:.2f} ({recall_std:.2f})\")\n",
        "print(f\"Mean F1 Score: {f1_mean:.2f} ({f1_std:.2f})\")\n",
        "print(f\"Average Training Time: {mean_training_time:.2f} s\")\n",
        "print(f\"Average Prediction Time: {mean_prediction_time:.2f} s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Replace 'your_directory_path' with the path to the directory you want to delete\n",
        "shutil.rmtree('/content/singleton')\n"
      ],
      "metadata": {
        "id": "R4sROScCMk3h"
      },
      "id": "R4sROScCMk3h",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Abstract Factory, standard deviation, training and prediction time**"
      ],
      "metadata": {
        "id": "tPrfdEYkMlG4"
      },
      "id": "tPrfdEYkMlG4"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Function to calculate standard deviation\n",
        "def calculate_std(values):\n",
        "    return np.std(values)\n",
        "\n",
        "# Check if GPU is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load your Java programs from a directory\n",
        "java_code_dir = \"/content/abstractfactory\"\n",
        "java_files = [file for file in os.listdir(java_code_dir) if os.path.isfile(os.path.join(java_code_dir, file))]\n",
        "\n",
        "# Load the CodeBERT model and tokenizer\n",
        "model_name = \"microsoft/codebert-base\"\n",
        "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize and encode the Java programs\n",
        "def get_line_embeddings(code):\n",
        "    lines = code.split('\\n')\n",
        "    line_embeddings = []\n",
        "    for line in lines:\n",
        "        if line.strip():  # Check if the line is not empty\n",
        "            inputs = tokenizer(line, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)  # Move inputs to GPU\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # Move result back to CPU\n",
        "            line_embeddings.append(embeddings)\n",
        "    if line_embeddings:\n",
        "        return np.mean(line_embeddings, axis=0)\n",
        "    else:\n",
        "        return None  # Return None if no valid embeddings were found\n",
        "\n",
        "# Running the experiment multiple times to calculate mean and standard deviation\n",
        "n_runs = 10  # Change this value to 10-30 based on reviewer comment\n",
        "precision_values = []\n",
        "recall_values = []\n",
        "f1_values = []\n",
        "training_times = []\n",
        "prediction_times = []\n",
        "\n",
        "# Splitting files into positive and negative\n",
        "positive_files = [file for file in java_files if \"abstractfactory\" in file]  # Positive examples\n",
        "negative_files = [file for file in java_files if \"abstractfactory\" not in file]  # Negative examples\n",
        "n_positive = len(positive_files)\n",
        "\n",
        "# Running multiple experiments\n",
        "for run in range(n_runs):\n",
        "    print(f\"Run {run + 1} of {n_runs}\")\n",
        "\n",
        "    program_embeddings = []\n",
        "    true_labels = []\n",
        "\n",
        "    # Adjusting the ratio of positive to negative examples (40%-60% range)\n",
        "    n_negative_required = int(np.random.uniform(0.4, 0.6) * n_positive)  # Randomly select within the 40%-60% range\n",
        "    negative_subset = np.random.choice(negative_files, n_negative_required, replace=False)\n",
        "\n",
        "    # Combine the positive and randomly selected negative files\n",
        "    selected_files = positive_files + list(negative_subset)\n",
        "\n",
        "    # Measure training time for each run\n",
        "    start_training_time = time.time()\n",
        "\n",
        "    for file in selected_files:\n",
        "        with open(os.path.join(java_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "            java_code = f.read()\n",
        "\n",
        "            # Get the embedding of the program by taking the mean of line embeddings\n",
        "            program_embedding = get_line_embeddings(java_code)\n",
        "\n",
        "            if program_embedding is not None:  # Check if embedding is valid\n",
        "                program_embeddings.append(program_embedding)\n",
        "                true_labels.append(1 if \"abstractfactory\" in file else 0)\n",
        "\n",
        "    # Convert program_embeddings to a NumPy array\n",
        "    if len(program_embeddings) > 0:  # Ensure there are embeddings\n",
        "        program_embeddings = np.array(program_embeddings)\n",
        "\n",
        "        # Check and reshape if necessary\n",
        "        if len(program_embeddings.shape) == 1:\n",
        "            program_embeddings = program_embeddings.reshape(1, -1)\n",
        "\n",
        "    else:\n",
        "        print(\"No embeddings were generated. Skipping run.\")\n",
        "        continue\n",
        "\n",
        "    # Measure end of training time\n",
        "    end_training_time = time.time()\n",
        "    training_time_us = (end_training_time - start_training_time) * 1_000_000  # Convert to microseconds\n",
        "    training_times.append(training_time_us)\n",
        "    print(f\"Training Time: {training_time_us:.2f} s\")\n",
        "\n",
        "    # Train the k-NN model\n",
        "    k = 3  # Adjust this value as needed\n",
        "    knn_model = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
        "    knn_model.fit(program_embeddings, true_labels)\n",
        "\n",
        "    # Measure prediction time for unseen examples\n",
        "    unseen_code_dir = \"/content/unseen_examples\"\n",
        "    unseen_files = [file for file in os.listdir(unseen_code_dir) if os.path.isfile(os.path.join(unseen_code_dir, file))]\n",
        "    unseen_embeddings = []\n",
        "    actual_unseen_labels = []\n",
        "\n",
        "    start_prediction_time = time.time()\n",
        "\n",
        "    for file in unseen_files:\n",
        "        with open(os.path.join(unseen_code_dir, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
        "            unseen_code = f.read()\n",
        "\n",
        "            # Get the embedding of the unseen program\n",
        "            unseen_embedding = get_line_embeddings(unseen_code)\n",
        "            if unseen_embedding is not None:\n",
        "                unseen_embeddings.append(unseen_embedding)\n",
        "                actual_unseen_labels.append(1 if \"abstractfactory\" in file else 0)\n",
        "\n",
        "    # Convert unseen_embeddings to a NumPy array\n",
        "    if len(unseen_embeddings) > 0:\n",
        "        unseen_embeddings = np.array(unseen_embeddings)\n",
        "\n",
        "        # Reshape if needed\n",
        "        if len(unseen_embeddings.shape) == 1:\n",
        "            unseen_embeddings = unseen_embeddings.reshape(1, -1)\n",
        "\n",
        "        # Predict using the trained k-NN model\n",
        "        unseen_predictions = knn_model.predict(unseen_embeddings)\n",
        "\n",
        "        # Measure end of prediction time\n",
        "        end_prediction_time = time.time()\n",
        "        prediction_time_us = (end_prediction_time - start_prediction_time) * 1_000_000  # Convert to microseconds\n",
        "        prediction_times.append(prediction_time_us)\n",
        "        print(f\"Prediction Time: {prediction_time_us:.2f} s\")\n",
        "\n",
        "        # Calculate precision, recall, and F1 score for this run\n",
        "        precision = precision_score(actual_unseen_labels, unseen_predictions, average='weighted')\n",
        "        recall = recall_score(actual_unseen_labels, unseen_predictions, average='weighted')\n",
        "        f1 = f1_score(actual_unseen_labels, unseen_predictions, average='weighted')\n",
        "\n",
        "        precision_values.append(precision)\n",
        "        recall_values.append(recall)\n",
        "        f1_values.append(f1)\n",
        "\n",
        "# Calculate mean and standard deviation for precision, recall, and F1 score\n",
        "precision_mean = np.mean(precision_values)\n",
        "recall_mean = np.mean(recall_values)\n",
        "f1_mean = np.mean(f1_values)\n",
        "\n",
        "precision_std = calculate_std(precision_values)\n",
        "recall_std = calculate_std(recall_values)\n",
        "f1_std = calculate_std(f1_values)\n",
        "\n",
        "# Calculate mean training and prediction times\n",
        "mean_training_time = np.mean(training_times)\n",
        "mean_prediction_time = np.mean(prediction_times)\n",
        "\n",
        "# Print results\n",
        "print(f\"\\nMean Precision: {precision_mean:.2f} ({precision_std:.2f})\")\n",
        "print(f\"Mean Recall: {recall_mean:.2f} ({recall_std:.2f})\")\n",
        "print(f\"Mean F1 Score: {f1_mean:.2f} ({f1_std:.2f})\")\n",
        "print(f\"Average Training Time: {mean_training_time:.2f} s\")\n",
        "print(f\"Average Prediction Time: {mean_prediction_time:.2f} s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-fmmiI9OfEp",
        "outputId": "9c50e750-47f3-4f89-f1ae-1b8cdb71dffa"
      },
      "id": "M-fmmiI9OfEp",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run 1 of 10\n",
            "Training Time: 45999806.88 s\n",
            "Prediction Time: 118551798.82 s\n",
            "Run 2 of 10\n",
            "Training Time: 28268914.94 s\n",
            "Prediction Time: 83693073.03 s\n",
            "Run 3 of 10\n",
            "Training Time: 28051027.77 s\n",
            "Prediction Time: 83834266.42 s\n",
            "Run 4 of 10\n",
            "Training Time: 26480307.34 s\n",
            "Prediction Time: 83779364.82 s\n",
            "Run 5 of 10\n",
            "Training Time: 26349156.62 s\n",
            "Prediction Time: 83220586.30 s\n",
            "Run 6 of 10\n",
            "Training Time: 27898367.17 s\n",
            "Prediction Time: 83218737.60 s\n",
            "Run 7 of 10\n",
            "Training Time: 27535501.96 s\n",
            "Prediction Time: 84245815.04 s\n",
            "Run 8 of 10\n",
            "Training Time: 27811955.69 s\n",
            "Prediction Time: 82373137.71 s\n",
            "Run 9 of 10\n",
            "Training Time: 27378199.34 s\n",
            "Prediction Time: 83262315.27 s\n",
            "Run 10 of 10\n",
            "Training Time: 26670570.37 s\n",
            "Prediction Time: 84888565.78 s\n",
            "\n",
            "Mean Precision: 0.89 (0.01)\n",
            "Mean Recall: 0.86 (0.01)\n",
            "Mean F1 Score: 0.86 (0.01)\n",
            "Average Training Time: 29244380.81 s\n",
            "Average Prediction Time: 87106766.08 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dgtRpn0mgclX"
      },
      "id": "dgtRpn0mgclX",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0284e8b309cb4e2e84a50403e52c16ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02a3f0d2a9b94440b0b8d757e66002a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02b627e68f4a421ba09ba15b9ab08dca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "048224c2fc4d4442ab4ac789c3abe4b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "067dcdd227b74c0b90042e9536cf87ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "069364f5a1be40ae978ba2c9b7a95291": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "069cfab2125844a58cbcc8c5164bb2ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06d0475cb393469781586318d84b4df6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "083fe7730cb740c7b50dfeddede172d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08d7dfaa2b71403a9c8117d46396869b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "093579bea7a64e26a3fc145ffcbff278": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_869934883ee34d3eb7724e99708766cc",
            "placeholder": "",
            "style": "IPY_MODEL_a8a64b6cc4e54bee8192f734e0765727",
            "value": "special_tokens_map.json:100%"
          }
        },
        "0d5d7338abb340909a44ac9d885d6ae7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e706a81e337422fbc7fba5096679a2c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ee01b02d6c64eec998940f865277aa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25102ffcf8b54de2849628f1b25e3ec7",
              "IPY_MODEL_b84c022598c24735a9eeb1e4ad7fab77",
              "IPY_MODEL_dae344eee7424907aa02b0c729b2887f"
            ],
            "layout": "IPY_MODEL_7744fe4224fa4757bdae65ac3704f249"
          }
        },
        "0f5f1c475bc4483e9be3e6d5e00d491b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0fd608a251ed4aa9bd82a4f6bddb2c1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1091411f109f4a168a27a1ce4011d1ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10ee323ae58d49428e366c4af4ab9bc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14ce7c527bd541fc953083c594f018ad",
            "placeholder": "",
            "style": "IPY_MODEL_911a56063607445a974c5dd56482a384",
            "value": "config.json:100%"
          }
        },
        "1252b99ee1b14f6ebec527c36c673044": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94ba75acd1434ed4b791aa83a91bdfeb",
            "max": 498627950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2205c44b144e45cba30f3bde7caa0f3e",
            "value": 498627950
          }
        },
        "1333d801046f4f1d997e2f1088b1580d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb9a0aa90c8e4cfeb5d754964d35333d",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6456c11a56174f23a4a205a16bf0b44a",
            "value": 456318
          }
        },
        "14792133286a4a4d8dc1d3f2bd589ead": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14ce7c527bd541fc953083c594f018ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15bd8236e608410b88cb38d6710d8962": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "166e55b110a540e9baca46a65e51fa22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "176527e43438462b9646c74138242339": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "183973f08d6f41b5bc97cc594ef6d5dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d0a035aa95e4d17893f2fc8123f2e84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e69f775a51134f8db786cfa83ab7d557",
              "IPY_MODEL_ba4bd4494eb34c8999fb6e9c27dde41e",
              "IPY_MODEL_fb4e9bdefed143e0a7cf54b5957bec4f"
            ],
            "layout": "IPY_MODEL_527bcbc98e4d492d87c2edecfeed7979"
          }
        },
        "1d1d205e469a441a8b6a7d422515fd0b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "216e7da312854afda80751902a16677a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d5d7338abb340909a44ac9d885d6ae7",
            "placeholder": "",
            "style": "IPY_MODEL_81365792e7914a768cc03b10176c6715",
            "value": "merges.txt:100%"
          }
        },
        "2205c44b144e45cba30f3bde7caa0f3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "248c8fd066f249829e8ff741b44b9b92": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25102ffcf8b54de2849628f1b25e3ec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a92e02484c8c42dc9c2efa4b38be1163",
            "placeholder": "",
            "style": "IPY_MODEL_c647c9d66a2f46c69d5e0ca332496f68",
            "value": "pytorch_model.bin:100%"
          }
        },
        "25a4d8b8319e4ce8a9faa8541b1946eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf500391e9dc4b8399796cfa9bcb758c",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_adc080130c554507b21c1efe26ee93a7",
            "value": 25
          }
        },
        "26652166ee2e4c289bf4f47c1eb2f57f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5766d5fc03064de69cacabcef689336c",
            "max": 498,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4e67002c7494fe48c3663e075f024ff",
            "value": 498
          }
        },
        "27459b775c0f4c2788325c1b6b7267a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ed29106065e4f909e63daf380c783ab",
            "placeholder": "",
            "style": "IPY_MODEL_a6f508988bfb4871b543c78f25c38b8b",
            "value": "vocab.json:100%"
          }
        },
        "288553384e4541abbdcf55e1003c8cf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29ec4a59b1c843c687fb12ea29c3878e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2f024ad905c4f68a272ba9a89d8ee19",
            "placeholder": "",
            "style": "IPY_MODEL_8868c9d1e2ee4078a0387a8e1c26e8d7",
            "value": "456k/456k[00:00&lt;00:00,22.7MB/s]"
          }
        },
        "2a0b1db7882f41a9825ee8803ae0951e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88d97757387a4b24897f0f044ec917c9",
            "placeholder": "",
            "style": "IPY_MODEL_59248e8e53624305831b105fbd3af11b",
            "value": "25.0/25.0[00:00&lt;00:00,550B/s]"
          }
        },
        "2a6d2ba3a56c43fa83f3957e451bd3a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ed29106065e4f909e63daf380c783ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3039a34550ae4ac690b7019d3d03a80d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30bc0eb0200f4d53b4007995400cab2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd7370827b5b46e2aa0cc69af63b7f2f",
            "placeholder": "",
            "style": "IPY_MODEL_7214cc8402734543a9eb243f52e7d68b",
            "value": "vocab.json:100%"
          }
        },
        "3138a201a11a4c9c8e00cacdfd0cd4f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32bc5c5340704cf68235c7b4a60c4af8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccfdc74ef5804069bb3ee8ae4d09317f",
            "max": 498,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8e4a72ff0664b63aa8c987e96de8f77",
            "value": 498
          }
        },
        "34dc93f2356b4b0d80c9621dea9f24f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3512aab0fc6f4e3db3e9847684ea6639": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "352d2ce09dce4eb68f7c8af13db4791b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35689df6cbaa415e8339a85527800bf1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37f1382bde094b37bfd597ac8be0c4f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38b9e17c1eb64cc6954d9286a9d8b916": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3039a34550ae4ac690b7019d3d03a80d",
            "placeholder": "",
            "style": "IPY_MODEL_352d2ce09dce4eb68f7c8af13db4791b",
            "value": "498/498[00:00&lt;00:00,24.5kB/s]"
          }
        },
        "390e89587a10429fb923114e9246fce6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39f8927a5dc7458c8a757e8d69444eb0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b5aea119777494f995f99ca3e44e3ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d01efc07acb4f1da8b0eadc4781638c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d123770cc92497d851afdfe0b46a80e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d2c725bbb9c40f9a256303467eefd87": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d4ca38f1a6a4473a589188fa038dd10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2ad85ad1a0e4cc5ab055f123c4339f9",
            "placeholder": "",
            "style": "IPY_MODEL_06d0475cb393469781586318d84b4df6",
            "value": "25.0/25.0[00:00&lt;00:00,529B/s]"
          }
        },
        "3e0d4b26ccd7424cb3abaf96cf80bdf2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e0dfff6c8c44447b9182344c7cac666": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f3c928c8d4140109d48c829d8a07f28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30bc0eb0200f4d53b4007995400cab2c",
              "IPY_MODEL_5425e68cd43e40aeb9d0c8a4dddfe540",
              "IPY_MODEL_f8b70bd2a35541e3a5092fdf7c36f26a"
            ],
            "layout": "IPY_MODEL_dd103126c255416fa1d2684d22444905"
          }
        },
        "4043a7a7182b451b987566dca1af8e67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "407aeeb0f0034feaacdae64f186c8045": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db0b368c1a2942fca050b477b18e6feb",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_faa3279aaf4b46e7b7de865b12730f1d",
            "value": 898822
          }
        },
        "4295a6b783d54133a0a8b807be6dde90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5720d248302470b8e72c1a031b0e998",
              "IPY_MODEL_ed46271c45c04aa5a717c5714e0afbf4",
              "IPY_MODEL_c8f394a0f46c417aa3290e7911c626b9"
            ],
            "layout": "IPY_MODEL_d39307d1bbfe4fa19e7c6f9ab8042839"
          }
        },
        "4351a6283b944122bae8c13f5dd07ea8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43a9d3c5cde042af84ecb5c5dbf94065": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45d1fabc784c4ac0a0dd507af3f58fe2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4609b2d80963451db2bfb61687830391": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51074d03825c4a608109357d88c33e7e",
              "IPY_MODEL_c350a42f47b64f74a18fbe971c1f5ad8",
              "IPY_MODEL_d264453bb3864d26a8615fb05cf718f6"
            ],
            "layout": "IPY_MODEL_e804483d6fa04040a4d04f518c422ecc"
          }
        },
        "47b7ee25a40647139540842772a670aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49fd5d28bad14dafb77a25ce5badc759": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a19bc50728340f9a4c7b23f8ff18294": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_deddf28b7f834d09aedcd06a964ce5c1",
            "placeholder": "",
            "style": "IPY_MODEL_176527e43438462b9646c74138242339",
            "value": "150/150[00:00&lt;00:00,3.37kB/s]"
          }
        },
        "4ac8dc3f637144088040304f53d17604": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4af8c3e908904ba6a772c6a155e9be4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b8be88f2a954087966f029db2821a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4dfad4af40354dfcb41567e32f527fb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e27634be5cf4e59b42b086b14160f79",
            "placeholder": "",
            "style": "IPY_MODEL_c304ffe74f92430394d29e61b59bed7d",
            "value": "merges.txt:100%"
          }
        },
        "4dfe97c2b40a449ebcbb0b35cd84f7af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4dff183204c541d3989f22e7e0b03dd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_812f69994d4f4b09beef13af48108d68",
            "placeholder": "",
            "style": "IPY_MODEL_d0ec6e98a08b483f88fc3a13a666af91",
            "value": "899k/899k[00:00&lt;00:00,17.3MB/s]"
          }
        },
        "4f0a5d8a186744b8914ae9978726e2e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f78fc52fb2a418c87770ba3fb041990": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fa03cf6f4374ad3838f4a6c0f9cc35d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d1d205e469a441a8b6a7d422515fd0b",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0fd608a251ed4aa9bd82a4f6bddb2c1a",
            "value": 25
          }
        },
        "51074d03825c4a608109357d88c33e7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3138a201a11a4c9c8e00cacdfd0cd4f0",
            "placeholder": "",
            "style": "IPY_MODEL_47b7ee25a40647139540842772a670aa",
            "value": "special_tokens_map.json:100%"
          }
        },
        "51142c1e4645497a90320a305f4b3afa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "514a89e105f64ce7ad4e3d63e8768259": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "527bcbc98e4d492d87c2edecfeed7979": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53314f68b919408eb7bd21d31241a7b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5425e68cd43e40aeb9d0c8a4dddfe540": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39f8927a5dc7458c8a757e8d69444eb0",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c06497a110f54340bd3cc1b6f82714db",
            "value": 898822
          }
        },
        "542d184132e546d8a005d7a11a1045d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55b553fecf3943d48474d1c5dbc608fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55cf4187a01344dbbf4af4d16a148a82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5766d5fc03064de69cacabcef689336c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5907ebb8962d41269e8b790132be3200": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4a0917627e146cb920637a654862c89",
              "IPY_MODEL_5df0656f326d4adeaca6dbf477f6c5f0",
              "IPY_MODEL_b70ea907b945487699a1136c23f18150"
            ],
            "layout": "IPY_MODEL_a532e7986bbd42328ec25474fab7654b"
          }
        },
        "59248e8e53624305831b105fbd3af11b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c36c84991444303836dea1b0e1826c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5dcd0b80cbc34d248cc2b2c8f1fca86f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dcfcd189dda4f69922c16c20c68c69a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5df0656f326d4adeaca6dbf477f6c5f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35689df6cbaa415e8339a85527800bf1",
            "max": 498,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a6d2ba3a56c43fa83f3957e451bd3a9",
            "value": 498
          }
        },
        "5e27634be5cf4e59b42b086b14160f79": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "629ce8f25ffe4d9cb9af68d2ca3b32c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62a4ac8655de4477839e5e121b225b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34dc93f2356b4b0d80c9621dea9f24f0",
            "placeholder": "",
            "style": "IPY_MODEL_f306098093cf4f54bb99a66e43699a69",
            "value": "special_tokens_map.json:100%"
          }
        },
        "6456c11a56174f23a4a205a16bf0b44a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64e57361b5944b2a91112225696c0490": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65952686c34c4cfbb4c486eca6afa94f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_216e7da312854afda80751902a16677a",
              "IPY_MODEL_7816ea804e694fa59a70cd26bac8a275",
              "IPY_MODEL_f9cb5ce7bb18448a85ae6d787e03b53e"
            ],
            "layout": "IPY_MODEL_c2ca2ab888f84e818c169df0b96c99d6"
          }
        },
        "66eb1acdc50040d6b5a098ae00035610": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "697fc57370414df4906ff6519123f1ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6990e39445a64aee96b5a4f0749d44e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69fb4505d7464d4092c8d543ee596c61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a13f5d9e3034c60b8db1d512d507971": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27459b775c0f4c2788325c1b6b7267a2",
              "IPY_MODEL_407aeeb0f0034feaacdae64f186c8045",
              "IPY_MODEL_e4d70e9bdeef43edb4bffae6c7b06cf4"
            ],
            "layout": "IPY_MODEL_3b5aea119777494f995f99ca3e44e3ac"
          }
        },
        "6b82c85c2b3b4ba3b2c82540f1dac4db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6cc85f34154a43d3965e3f2b0166a936": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_effd9f74cf9141e38aceac60efdc3742",
              "IPY_MODEL_7a8b6bfe90ed4c14adce23d5e0631711",
              "IPY_MODEL_29ec4a59b1c843c687fb12ea29c3878e"
            ],
            "layout": "IPY_MODEL_15bd8236e608410b88cb38d6710d8962"
          }
        },
        "7060a98ce8e24e988e78dd87906bade5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7214cc8402734543a9eb243f52e7d68b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72291a608b8443c8acf6abf06c8753e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "727b8510d4ab460fa6061119ae7636f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8102aa727066499e90e4afa59ed88f99",
              "IPY_MODEL_26652166ee2e4c289bf4f47c1eb2f57f",
              "IPY_MODEL_38b9e17c1eb64cc6954d9286a9d8b916"
            ],
            "layout": "IPY_MODEL_88d598437ce74979aa7383ccbcfd4d86"
          }
        },
        "72cd107feb67478e90d92162add6c261": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7328e328f2eb4fd68619159748eb3540": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d500e7de70e34c67af5a3aac614b2622",
            "placeholder": "",
            "style": "IPY_MODEL_dbb19fbfaa8e40cfa1523f3210144828",
            "value": "150/150[00:00&lt;00:00,3.16kB/s]"
          }
        },
        "7336432d80384668826b9279569c0543": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10ee323ae58d49428e366c4af4ab9bc0",
              "IPY_MODEL_32bc5c5340704cf68235c7b4a60c4af8",
              "IPY_MODEL_7b5aeacb69504fd5b0b256383ea760d9"
            ],
            "layout": "IPY_MODEL_51142c1e4645497a90320a305f4b3afa"
          }
        },
        "7379734af4374bc291f024b587fc5ad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fba4e2a5da524d16b13f6ec665e6a884",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_166e55b110a540e9baca46a65e51fa22",
            "value": 150
          }
        },
        "74d65ad56aba4db28066ed3c5a8fb048": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4dfad4af40354dfcb41567e32f527fb2",
              "IPY_MODEL_1333d801046f4f1d997e2f1088b1580d",
              "IPY_MODEL_80946a3b82f648c3827bfba6702fff02"
            ],
            "layout": "IPY_MODEL_e6626ebeab394b35ab4c715961959eef"
          }
        },
        "750225f407e640808ccabe29221e4b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "752b1d31e3324aa0a8c00e1856aa78e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75a52a6867754aa790c4fa0011a4d86b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43a9d3c5cde042af84ecb5c5dbf94065",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbd1eae035b44e758f3033ffeef65847",
            "value": 898822
          }
        },
        "770ce23b84fe4e419b2fbb19d2ed2d13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c7b1e1fc23b4643b0346651b247438d",
            "max": 498,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc4f1a5759e54b1ca200d354d37b99c7",
            "value": 498
          }
        },
        "7744fe4224fa4757bdae65ac3704f249": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7816ea804e694fa59a70cd26bac8a275": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6990e39445a64aee96b5a4f0749d44e1",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c36c84991444303836dea1b0e1826c1",
            "value": 456318
          }
        },
        "784bdcecc2304b3ea0d049ab9b4636da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a8b6bfe90ed4c14adce23d5e0631711": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55cf4187a01344dbbf4af4d16a148a82",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7c7f79570d84667b72913f79d0def6f",
            "value": 456318
          }
        },
        "7b5aeacb69504fd5b0b256383ea760d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f343fe0262554ab180db6cf31292baab",
            "placeholder": "",
            "style": "IPY_MODEL_4b8be88f2a954087966f029db2821a74",
            "value": "498/498[00:00&lt;00:00,15.5kB/s]"
          }
        },
        "7c7b1e1fc23b4643b0346651b247438d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ff94a11c31a47a09228f2f9b662318a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80946a3b82f648c3827bfba6702fff02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc2a5116e0fd43ae8cf6d0fce3d5c651",
            "placeholder": "",
            "style": "IPY_MODEL_4043a7a7182b451b987566dca1af8e67",
            "value": "456k/456k[00:00&lt;00:00,16.2MB/s]"
          }
        },
        "8102aa727066499e90e4afa59ed88f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d2c725bbb9c40f9a256303467eefd87",
            "placeholder": "",
            "style": "IPY_MODEL_4ac8dc3f637144088040304f53d17604",
            "value": "config.json:100%"
          }
        },
        "812f69994d4f4b09beef13af48108d68": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81356b11043c4ef081fb196bc00db57b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c187cb5e29224545bacbb57f89078dfb",
              "IPY_MODEL_a41e6faf3bf94cfdb875dd2575d61720",
              "IPY_MODEL_a51ecdec6d384172bbb9627a4c8f85fa"
            ],
            "layout": "IPY_MODEL_cdc7ca4fa7e44c42acd49042505133ca"
          }
        },
        "81365792e7914a768cc03b10176c6715": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8327eb9accd443b5aa9dbff743e0065d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e0dfff6c8c44447b9182344c7cac666",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_083fe7730cb740c7b50dfeddede172d6",
            "value": 150
          }
        },
        "8596e8a719f6402199e14d5c78127405": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_069cfab2125844a58cbcc8c5164bb2ca",
            "placeholder": "",
            "style": "IPY_MODEL_97e9c9d72f184fc39d0b8dd121f7e351",
            "value": "899k/899k[00:00&lt;00:00,2.72MB/s]"
          }
        },
        "8608e39b99444ee5b762fc08976a2009": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f24a994f5114468b806182c50dc772cd",
              "IPY_MODEL_7379734af4374bc291f024b587fc5ad8",
              "IPY_MODEL_9253ccc9e9e24b06b00e0e0f6bbbf807"
            ],
            "layout": "IPY_MODEL_d3040754a6e64f87b6d8525c755dfbb0"
          }
        },
        "869934883ee34d3eb7724e99708766cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86ffef4a494d4a2ba427ce3622399b5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8868c9d1e2ee4078a0387a8e1c26e8d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88d598437ce74979aa7383ccbcfd4d86": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88d97757387a4b24897f0f044ec917c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89fa6068625a48e79585a92d039d2dcf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a11a4f5e04443ca94769314d5ca58bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b628394476340688c29a9a5f42e825f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c83c857ea7c49289ab85ed3736d2558": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d17f81b4b884012bdcc8c53e6cc7d74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba13e71bca71463b9bc1548aaf49e352",
              "IPY_MODEL_f8a346924c644c8f9631b9f86daaf73e",
              "IPY_MODEL_d728658f24914208a3e107b8d6d0973f"
            ],
            "layout": "IPY_MODEL_af8e45438afd4672967c9817435a0ed4"
          }
        },
        "8dca732697b543f4853b4a3371aa3c26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_093579bea7a64e26a3fc145ffcbff278",
              "IPY_MODEL_c5a037ffd0424927936caa0711379c1b",
              "IPY_MODEL_4a19bc50728340f9a4c7b23f8ff18294"
            ],
            "layout": "IPY_MODEL_af8fc74b36ef4db38466f59575ba2988"
          }
        },
        "911a56063607445a974c5dd56482a384": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9123abd540ca44509adc6e189a6fe14f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9253ccc9e9e24b06b00e0e0f6bbbf807": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_697fc57370414df4906ff6519123f1ae",
            "placeholder": "",
            "style": "IPY_MODEL_02a3f0d2a9b94440b0b8d757e66002a0",
            "value": "150/150[00:00&lt;00:00,2.82kB/s]"
          }
        },
        "92cee2e178734e4bba2a67b88050ceda": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9497be65739b4919abea118d344bd4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c83c857ea7c49289ab85ed3736d2558",
            "placeholder": "",
            "style": "IPY_MODEL_0f5f1c475bc4483e9be3e6d5e00d491b",
            "value": "498/498[00:00&lt;00:00,7.54kB/s]"
          }
        },
        "94ba75acd1434ed4b791aa83a91bdfeb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "951655ab30284914acbb21393ed98655": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97c17e16f9884cd0a03d2eded1f17343": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4351a6283b944122bae8c13f5dd07ea8",
            "placeholder": "",
            "style": "IPY_MODEL_c781762da4d740a2b3eb166604f90363",
            "value": "tokenizer_config.json:100%"
          }
        },
        "97e9c9d72f184fc39d0b8dd121f7e351": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "990c38df28e443dd94ab0b9f8ac7d36e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e706a81e337422fbc7fba5096679a2c",
            "placeholder": "",
            "style": "IPY_MODEL_4dfe97c2b40a449ebcbb0b35cd84f7af",
            "value": "merges.txt:100%"
          }
        },
        "9c5732a354ec40ae919d917b98314f2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c87e1e31a2b84a9dac6a54eba85413d7",
              "IPY_MODEL_25a4d8b8319e4ce8a9faa8541b1946eb",
              "IPY_MODEL_3d4ca38f1a6a4473a589188fa038dd10"
            ],
            "layout": "IPY_MODEL_3e0d4b26ccd7424cb3abaf96cf80bdf2"
          }
        },
        "9ed22cb538594777a328111f6a14b84b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a422160c58ff47c0bd3a599511599076",
              "IPY_MODEL_1252b99ee1b14f6ebec527c36c673044",
              "IPY_MODEL_ddd84975ba3743b4b1d68dc88e9bbca5"
            ],
            "layout": "IPY_MODEL_3d123770cc92497d851afdfe0b46a80e"
          }
        },
        "a2ad85ad1a0e4cc5ab055f123c4339f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3f6c7e8f4fa41a2b209b80a85456158": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a41e6faf3bf94cfdb875dd2575d61720": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02b627e68f4a421ba09ba15b9ab08dca",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53314f68b919408eb7bd21d31241a7b6",
            "value": 25
          }
        },
        "a422160c58ff47c0bd3a599511599076": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_752b1d31e3324aa0a8c00e1856aa78e2",
            "placeholder": "",
            "style": "IPY_MODEL_e577e207cda54e939d20a8ca7e86d721",
            "value": "pytorch_model.bin:100%"
          }
        },
        "a4fca2b9be304de984d5460b8fc72367": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a51ecdec6d384172bbb9627a4c8f85fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3dfd3d0b5444676b863f4d174018255",
            "placeholder": "",
            "style": "IPY_MODEL_8b628394476340688c29a9a5f42e825f",
            "value": "25.0/25.0[00:00&lt;00:00,372B/s]"
          }
        },
        "a532e7986bbd42328ec25474fab7654b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6f508988bfb4871b543c78f25c38b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8a64b6cc4e54bee8192f734e0765727": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8dfac5df8ef4315a37e4bcefc25902e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a92e02484c8c42dc9c2efa4b38be1163": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adc080130c554507b21c1efe26ee93a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af8e45438afd4672967c9817435a0ed4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af8fc74b36ef4db38466f59575ba2988": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2b134a3cdfd4176afb896313ec427a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2f024ad905c4f68a272ba9a89d8ee19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3fc0f4e42504654b315ca9d5ed75258": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4a0917627e146cb920637a654862c89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_390e89587a10429fb923114e9246fce6",
            "placeholder": "",
            "style": "IPY_MODEL_067dcdd227b74c0b90042e9536cf87ac",
            "value": "config.json:100%"
          }
        },
        "b4e67002c7494fe48c3663e075f024ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b70ea907b945487699a1136c23f18150": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a11a4f5e04443ca94769314d5ca58bb",
            "placeholder": "",
            "style": "IPY_MODEL_3d01efc07acb4f1da8b0eadc4781638c",
            "value": "498/498[00:00&lt;00:00,10.3kB/s]"
          }
        },
        "b84c022598c24735a9eeb1e4ad7fab77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_248c8fd066f249829e8ff741b44b9b92",
            "max": 498627950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4fca2b9be304de984d5460b8fc72367",
            "value": 498627950
          }
        },
        "ba13e71bca71463b9bc1548aaf49e352": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3b552e728ce41f7a555e650269d736b",
            "placeholder": "",
            "style": "IPY_MODEL_542d184132e546d8a005d7a11a1045d5",
            "value": "pytorch_model.bin:100%"
          }
        },
        "ba4bd4494eb34c8999fb6e9c27dde41e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb90e164238c495d80f85df3d3486407",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55b553fecf3943d48474d1c5dbc608fa",
            "value": 25
          }
        },
        "bc2a5116e0fd43ae8cf6d0fce3d5c651": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd5d543825ce4d318d4e586ef1b9266e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd9466475a2046d79f8b010c6acef4b2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf500391e9dc4b8399796cfa9bcb758c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c06497a110f54340bd3cc1b6f82714db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c187cb5e29224545bacbb57f89078dfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_784bdcecc2304b3ea0d049ab9b4636da",
            "placeholder": "",
            "style": "IPY_MODEL_66eb1acdc50040d6b5a098ae00035610",
            "value": "tokenizer_config.json:100%"
          }
        },
        "c2ca2ab888f84e818c169df0b96c99d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2f9b055f60c4596bfb958998443d5ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c304ffe74f92430394d29e61b59bed7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c350a42f47b64f74a18fbe971c1f5ad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd9466475a2046d79f8b010c6acef4b2",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3fc0f4e42504654b315ca9d5ed75258",
            "value": 150
          }
        },
        "c3dfd3d0b5444676b863f4d174018255": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3e700adec0a43e29e2226464d254b9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97c17e16f9884cd0a03d2eded1f17343",
              "IPY_MODEL_4fa03cf6f4374ad3838f4a6c0f9cc35d",
              "IPY_MODEL_2a0b1db7882f41a9825ee8803ae0951e"
            ],
            "layout": "IPY_MODEL_d0136c3a1c4a459c8cdb5005d5dec5b4"
          }
        },
        "c4794e622b7245faba495dc5c3310462": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5720d248302470b8e72c1a031b0e998": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92cee2e178734e4bba2a67b88050ceda",
            "placeholder": "",
            "style": "IPY_MODEL_629ce8f25ffe4d9cb9af68d2ca3b32c6",
            "value": "pytorch_model.bin:100%"
          }
        },
        "c5a037ffd0424927936caa0711379c1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45d1fabc784c4ac0a0dd507af3f58fe2",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5dcfcd189dda4f69922c16c20c68c69a",
            "value": 150
          }
        },
        "c6070bea59504e2ea266d52ac85f0f20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c647c9d66a2f46c69d5e0ca332496f68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c721624e54354fa6aa6ab31cf1ce8a21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c781762da4d740a2b3eb166604f90363": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7c7f79570d84667b72913f79d0def6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c87e1e31a2b84a9dac6a54eba85413d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72cd107feb67478e90d92162add6c261",
            "placeholder": "",
            "style": "IPY_MODEL_7060a98ce8e24e988e78dd87906bade5",
            "value": "tokenizer_config.json:100%"
          }
        },
        "c8e4a72ff0664b63aa8c987e96de8f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8f394a0f46c417aa3290e7911c626b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4794e622b7245faba495dc5c3310462",
            "placeholder": "",
            "style": "IPY_MODEL_efd090c235af4310bfc09e2a5e7eaa60",
            "value": "499M/499M[00:03&lt;00:00,179MB/s]"
          }
        },
        "cb3ac662a20740bc890b7a15dd35ae3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08d7dfaa2b71403a9c8117d46396869b",
            "placeholder": "",
            "style": "IPY_MODEL_86ffef4a494d4a2ba427ce3622399b5a",
            "value": "vocab.json:100%"
          }
        },
        "cb471ac99b1d4f288fba0e997493e82c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc4f1a5759e54b1ca200d354d37b99c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ccfdc74ef5804069bb3ee8ae4d09317f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cda51966c77f45e396647ce7e587712e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdc7ca4fa7e44c42acd49042505133ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0136c3a1c4a459c8cdb5005d5dec5b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0c2dd25680d4139b5581c6da5f06049": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_183973f08d6f41b5bc97cc594ef6d5dc",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b82c85c2b3b4ba3b2c82540f1dac4db",
            "value": 456318
          }
        },
        "d0ec6e98a08b483f88fc3a13a666af91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d264453bb3864d26a8615fb05cf718f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cda51966c77f45e396647ce7e587712e",
            "placeholder": "",
            "style": "IPY_MODEL_048224c2fc4d4442ab4ac789c3abe4b6",
            "value": "150/150[00:00&lt;00:00,9.41kB/s]"
          }
        },
        "d3040754a6e64f87b6d8525c755dfbb0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d39307d1bbfe4fa19e7c6f9ab8042839": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d500e7de70e34c67af5a3aac614b2622": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d728658f24914208a3e107b8d6d0973f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64e57361b5944b2a91112225696c0490",
            "placeholder": "",
            "style": "IPY_MODEL_069364f5a1be40ae978ba2c9b7a95291",
            "value": "499M/499M[00:05&lt;00:00,107MB/s]"
          }
        },
        "d7eebb5c6cd74a9d9901d9eab71a6a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9123abd540ca44509adc6e189a6fe14f",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f0a5d8a186744b8914ae9978726e2e2",
            "value": 898822
          }
        },
        "dae344eee7424907aa02b0c729b2887f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ff94a11c31a47a09228f2f9b662318a",
            "placeholder": "",
            "style": "IPY_MODEL_49fd5d28bad14dafb77a25ce5badc759",
            "value": "499M/499M[00:05&lt;00:00,69.3MB/s]"
          }
        },
        "db0b368c1a2942fca050b477b18e6feb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db6e83e495d748f3832fe4f6842abeb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3f6c7e8f4fa41a2b209b80a85456158",
            "placeholder": "",
            "style": "IPY_MODEL_288553384e4541abbdcf55e1003c8cf5",
            "value": "config.json:100%"
          }
        },
        "dbb19fbfaa8e40cfa1523f3210144828": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbd1eae035b44e758f3033ffeef65847": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd103126c255416fa1d2684d22444905": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd7370827b5b46e2aa0cc69af63b7f2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddd84975ba3743b4b1d68dc88e9bbca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8dfac5df8ef4315a37e4bcefc25902e",
            "placeholder": "",
            "style": "IPY_MODEL_750225f407e640808ccabe29221e4b2d",
            "value": "499M/499M[00:16&lt;00:00,34.3MB/s]"
          }
        },
        "deddf28b7f834d09aedcd06a964ce5c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df56c6c33fe4465d9e7ceec2f78eb045": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0e038ec9ab94480bdf722160c35ddad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4d70e9bdeef43edb4bffae6c7b06cf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14792133286a4a4d8dc1d3f2bd589ead",
            "placeholder": "",
            "style": "IPY_MODEL_72291a608b8443c8acf6abf06c8753e8",
            "value": "899k/899k[00:00&lt;00:00,12.3MB/s]"
          }
        },
        "e577e207cda54e939d20a8ca7e86d721": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6626ebeab394b35ab4c715961959eef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e667eb72729f4cfbbfac941cd3ecb21f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e69f775a51134f8db786cfa83ab7d557": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_514a89e105f64ce7ad4e3d63e8768259",
            "placeholder": "",
            "style": "IPY_MODEL_e0e038ec9ab94480bdf722160c35ddad",
            "value": "tokenizer_config.json:100%"
          }
        },
        "e71aacc132b44a2b9537042d2acee67d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa833aef462f49ac9f5de3d43d60432d",
              "IPY_MODEL_75a52a6867754aa790c4fa0011a4d86b",
              "IPY_MODEL_8596e8a719f6402199e14d5c78127405"
            ],
            "layout": "IPY_MODEL_37f1382bde094b37bfd597ac8be0c4f7"
          }
        },
        "e804483d6fa04040a4d04f518c422ecc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaf10da8ca16499898ef0f215e007442": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed46271c45c04aa5a717c5714e0afbf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dcd0b80cbc34d248cc2b2c8f1fca86f",
            "max": 498627950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0284e8b309cb4e2e84a50403e52c16ea",
            "value": 498627950
          }
        },
        "ee027706919c48a18046a28b7efa6e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee90589f4d7f4fbd8231da6415f9a9a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eed0003fa6ca4a5085def1f17daa547f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df56c6c33fe4465d9e7ceec2f78eb045",
            "placeholder": "",
            "style": "IPY_MODEL_1091411f109f4a168a27a1ce4011d1ff",
            "value": "456k/456k[00:00&lt;00:00,1.85MB/s]"
          }
        },
        "efd090c235af4310bfc09e2a5e7eaa60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efdbde77bb3e4dee8c997bcf39ffae98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb3ac662a20740bc890b7a15dd35ae3b",
              "IPY_MODEL_d7eebb5c6cd74a9d9901d9eab71a6a39",
              "IPY_MODEL_4dff183204c541d3989f22e7e0b03dd8"
            ],
            "layout": "IPY_MODEL_c6070bea59504e2ea266d52ac85f0f20"
          }
        },
        "effd9f74cf9141e38aceac60efdc3742": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2f9b055f60c4596bfb958998443d5ce",
            "placeholder": "",
            "style": "IPY_MODEL_bd5d543825ce4d318d4e586ef1b9266e",
            "value": "merges.txt:100%"
          }
        },
        "f0a7f19611d54ebfa4ffacccd79c91ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f24a994f5114468b806182c50dc772cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee90589f4d7f4fbd8231da6415f9a9a6",
            "placeholder": "",
            "style": "IPY_MODEL_ee027706919c48a18046a28b7efa6e4b",
            "value": "special_tokens_map.json:100%"
          }
        },
        "f306098093cf4f54bb99a66e43699a69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f343fe0262554ab180db6cf31292baab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3b552e728ce41f7a555e650269d736b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f66166883b294dddbf0125787eec3866": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62a4ac8655de4477839e5e121b225b1a",
              "IPY_MODEL_8327eb9accd443b5aa9dbff743e0065d",
              "IPY_MODEL_7328e328f2eb4fd68619159748eb3540"
            ],
            "layout": "IPY_MODEL_ffaabcb4e78043a19a630270d709447a"
          }
        },
        "f66d5e14400a4b22862fdfe1d821305d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_990c38df28e443dd94ab0b9f8ac7d36e",
              "IPY_MODEL_d0c2dd25680d4139b5581c6da5f06049",
              "IPY_MODEL_eed0003fa6ca4a5085def1f17daa547f"
            ],
            "layout": "IPY_MODEL_f0a7f19611d54ebfa4ffacccd79c91ec"
          }
        },
        "f8a346924c644c8f9631b9f86daaf73e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3512aab0fc6f4e3db3e9847684ea6639",
            "max": 498627950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69fb4505d7464d4092c8d543ee596c61",
            "value": 498627950
          }
        },
        "f8b70bd2a35541e3a5092fdf7c36f26a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaf10da8ca16499898ef0f215e007442",
            "placeholder": "",
            "style": "IPY_MODEL_4af8c3e908904ba6a772c6a155e9be4f",
            "value": "899k/899k[00:00&lt;00:00,5.30MB/s]"
          }
        },
        "f9cb5ce7bb18448a85ae6d787e03b53e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89fa6068625a48e79585a92d039d2dcf",
            "placeholder": "",
            "style": "IPY_MODEL_c721624e54354fa6aa6ab31cf1ce8a21",
            "value": "456k/456k[00:00&lt;00:00,7.20MB/s]"
          }
        },
        "fa833aef462f49ac9f5de3d43d60432d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f78fc52fb2a418c87770ba3fb041990",
            "placeholder": "",
            "style": "IPY_MODEL_b2b134a3cdfd4176afb896313ec427a8",
            "value": "vocab.json:100%"
          }
        },
        "faa3279aaf4b46e7b7de865b12730f1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb4e9bdefed143e0a7cf54b5957bec4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb471ac99b1d4f288fba0e997493e82c",
            "placeholder": "",
            "style": "IPY_MODEL_951655ab30284914acbb21393ed98655",
            "value": "25.0/25.0[00:00&lt;00:00,968B/s]"
          }
        },
        "fb90e164238c495d80f85df3d3486407": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb9a0aa90c8e4cfeb5d754964d35333d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fba4e2a5da524d16b13f6ec665e6a884": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbb3a7d54d3f4b979da8a0fb599a5de7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db6e83e495d748f3832fe4f6842abeb4",
              "IPY_MODEL_770ce23b84fe4e419b2fbb19d2ed2d13",
              "IPY_MODEL_9497be65739b4919abea118d344bd4f6"
            ],
            "layout": "IPY_MODEL_e667eb72729f4cfbbfac941cd3ecb21f"
          }
        },
        "ffaabcb4e78043a19a630270d709447a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "304d0205a97e4835af97afce247b8cba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a3257db4c79e40b086254cee0b0030c4",
              "IPY_MODEL_312d0b961f0e4ead8987ceaa323c8c8f",
              "IPY_MODEL_1d39eaed3b984da485ab7c1e7ef1b706"
            ],
            "layout": "IPY_MODEL_5ea812ee74cc42d7bf16c2c021f03e04"
          }
        },
        "a3257db4c79e40b086254cee0b0030c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87a4392d0bb1472dacc0e1012d94d97b",
            "placeholder": "",
            "style": "IPY_MODEL_a27c5f6f35b64da3837eaee6255f6a64",
            "value": "config.json:100%"
          }
        },
        "312d0b961f0e4ead8987ceaa323c8c8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e10aaae7d89f47d6a885ee6cd0d31ebd",
            "max": 498,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_543dbe34722b421ca22b52526a924278",
            "value": 498
          }
        },
        "1d39eaed3b984da485ab7c1e7ef1b706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_430074bb131447c2b4cfdecba5a97102",
            "placeholder": "",
            "style": "IPY_MODEL_d2cb318c6e364268a684b43c20a238aa",
            "value": "498/498[00:00&lt;00:00,36.3kB/s]"
          }
        },
        "5ea812ee74cc42d7bf16c2c021f03e04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87a4392d0bb1472dacc0e1012d94d97b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a27c5f6f35b64da3837eaee6255f6a64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e10aaae7d89f47d6a885ee6cd0d31ebd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "543dbe34722b421ca22b52526a924278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "430074bb131447c2b4cfdecba5a97102": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2cb318c6e364268a684b43c20a238aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef18829198b8443c9a5937b9171f91d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db67fb211aa4448595f5d47c03c44edb",
              "IPY_MODEL_c250b5b0a4b14856854fabf653f1bece",
              "IPY_MODEL_567393e53c4e4e8491ff5936898d6299"
            ],
            "layout": "IPY_MODEL_6bfc117deeb14040bf3f730850eab1fa"
          }
        },
        "db67fb211aa4448595f5d47c03c44edb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32fe9383d7844504ad7fdd7474c0477b",
            "placeholder": "",
            "style": "IPY_MODEL_1b4b030f93c8491197f1a8dd7592e11f",
            "value": "pytorch_model.bin:100%"
          }
        },
        "c250b5b0a4b14856854fabf653f1bece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f060b65afa974b27be070d9d0a9a23a2",
            "max": 498627950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c06fe36eee7b4c88ae842a367bb594b9",
            "value": 498627950
          }
        },
        "567393e53c4e4e8491ff5936898d6299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ecc06638f24481e9a138e9ebfb85fd3",
            "placeholder": "",
            "style": "IPY_MODEL_4b7d30dda1574d98ad307186994fa871",
            "value": "499M/499M[00:04&lt;00:00,65.5MB/s]"
          }
        },
        "6bfc117deeb14040bf3f730850eab1fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32fe9383d7844504ad7fdd7474c0477b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b4b030f93c8491197f1a8dd7592e11f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f060b65afa974b27be070d9d0a9a23a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c06fe36eee7b4c88ae842a367bb594b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ecc06638f24481e9a138e9ebfb85fd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b7d30dda1574d98ad307186994fa871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ee13e0fb1b940bd81eeb8331bef5a13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b548e0297d0b4d93bc1ff2627f4ee967",
              "IPY_MODEL_063103c456164bd5b5c86606d159a533",
              "IPY_MODEL_f9f7144b91eb4dbca9e842feea9b92c7"
            ],
            "layout": "IPY_MODEL_3106210ff05443158eb143b4e3d1f2e4"
          }
        },
        "b548e0297d0b4d93bc1ff2627f4ee967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bb5a3d252b945c49707e3a4ec318c94",
            "placeholder": "",
            "style": "IPY_MODEL_9d1f86017c794e07bae7284346927284",
            "value": "tokenizer_config.json:100%"
          }
        },
        "063103c456164bd5b5c86606d159a533": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d042c2ebae94488902b330de25da690",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54038cfcd84646b3b9f28c2dd6579c14",
            "value": 25
          }
        },
        "f9f7144b91eb4dbca9e842feea9b92c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f46538ff4834a8288412077ec53cafa",
            "placeholder": "",
            "style": "IPY_MODEL_24354da991024f6fb14e477998265a1e",
            "value": "25.0/25.0[00:00&lt;00:00,1.46kB/s]"
          }
        },
        "3106210ff05443158eb143b4e3d1f2e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bb5a3d252b945c49707e3a4ec318c94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d1f86017c794e07bae7284346927284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d042c2ebae94488902b330de25da690": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54038cfcd84646b3b9f28c2dd6579c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f46538ff4834a8288412077ec53cafa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24354da991024f6fb14e477998265a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1269e7f9016f445da176796dc85dda3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb5d65d032c7468295395ce5a2467c59",
              "IPY_MODEL_bf2f6004de6d447a96f5291de6656808",
              "IPY_MODEL_7b5875d490f2495abe37adf1c6b6cf76"
            ],
            "layout": "IPY_MODEL_43c3a1f38dbd47a3a7ad9bff6040464a"
          }
        },
        "cb5d65d032c7468295395ce5a2467c59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02dca7172424490eb58fb56d229881b8",
            "placeholder": "",
            "style": "IPY_MODEL_85f989f4aa6c4c2a8b92184ceec02926",
            "value": "vocab.json:100%"
          }
        },
        "bf2f6004de6d447a96f5291de6656808": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c8f1a5d9d094ac6b40479ea75b04c2c",
            "max": 898822,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d49d3264fff4bcaab9429575c885aa3",
            "value": 898822
          }
        },
        "7b5875d490f2495abe37adf1c6b6cf76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cec81927adb246aeaacaed5ec9090b1c",
            "placeholder": "",
            "style": "IPY_MODEL_b3a41c064f6249eb833ff1ad771ae630",
            "value": "899k/899k[00:00&lt;00:00,3.52MB/s]"
          }
        },
        "43c3a1f38dbd47a3a7ad9bff6040464a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02dca7172424490eb58fb56d229881b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85f989f4aa6c4c2a8b92184ceec02926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c8f1a5d9d094ac6b40479ea75b04c2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d49d3264fff4bcaab9429575c885aa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cec81927adb246aeaacaed5ec9090b1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3a41c064f6249eb833ff1ad771ae630": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66d8668b514442efb2c12e49854ff8fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a80f92e0e77492c945311479cd65ddc",
              "IPY_MODEL_c724f84aba1a4650941c5e5cee00cdab",
              "IPY_MODEL_a41bff20374b404788ace95f515f1219"
            ],
            "layout": "IPY_MODEL_eb3c6842afd848e0b3ae75b884b655fd"
          }
        },
        "3a80f92e0e77492c945311479cd65ddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad1e90b582274698babac70d20e924a9",
            "placeholder": "",
            "style": "IPY_MODEL_947746437b014c43aa70737ff72eae2e",
            "value": "merges.txt:100%"
          }
        },
        "c724f84aba1a4650941c5e5cee00cdab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83863989411c4702a62813fa2dbcc301",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_411a1ea2bc6948119c0879d39cad7655",
            "value": 456318
          }
        },
        "a41bff20374b404788ace95f515f1219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74a415293b154600bb605da011b8cd1b",
            "placeholder": "",
            "style": "IPY_MODEL_f2c9b9377ebb47398eddabdf2aad9645",
            "value": "456k/456k[00:00&lt;00:00,2.62MB/s]"
          }
        },
        "eb3c6842afd848e0b3ae75b884b655fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad1e90b582274698babac70d20e924a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "947746437b014c43aa70737ff72eae2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83863989411c4702a62813fa2dbcc301": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "411a1ea2bc6948119c0879d39cad7655": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74a415293b154600bb605da011b8cd1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2c9b9377ebb47398eddabdf2aad9645": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac389584aa3d4a669c0f5aa11c465048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8092290f706423e9467dd1fa2f7671d",
              "IPY_MODEL_2326ac5a4d22410f978034a0de9fac9b",
              "IPY_MODEL_b89f9112be314ea5972778fb7ddc92f3"
            ],
            "layout": "IPY_MODEL_b6ff54d66ebb438493f35d800435b0e6"
          }
        },
        "e8092290f706423e9467dd1fa2f7671d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84b2b9b4a9ab46f499f84888bdb0eab8",
            "placeholder": "",
            "style": "IPY_MODEL_13a3dd1bc47f4d8093b7401817de08fd",
            "value": "special_tokens_map.json:100%"
          }
        },
        "2326ac5a4d22410f978034a0de9fac9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_982a58aa72e548dc918d98fb345ebaf6",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dca1ac8884fb48c38e024ae815c8b09d",
            "value": 150
          }
        },
        "b89f9112be314ea5972778fb7ddc92f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_290a189e35254ec5b8167a04e8e9260a",
            "placeholder": "",
            "style": "IPY_MODEL_f49817ec745042f99df030bb549af1c7",
            "value": "150/150[00:00&lt;00:00,11.2kB/s]"
          }
        },
        "b6ff54d66ebb438493f35d800435b0e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84b2b9b4a9ab46f499f84888bdb0eab8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13a3dd1bc47f4d8093b7401817de08fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "982a58aa72e548dc918d98fb345ebaf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dca1ac8884fb48c38e024ae815c8b09d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "290a189e35254ec5b8167a04e8e9260a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f49817ec745042f99df030bb549af1c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}